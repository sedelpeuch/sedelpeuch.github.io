"use strict";(self.webpackChunksedelpeuch_net=self.webpackChunksedelpeuch_net||[]).push([[8130],{77735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/2024/08/26/09-scripting/fastapi","metadata":{"permalink":"/blog/2024/08/26/09-scripting/fastapi","source":"@site/blog/09-scripting/2024-08-26-fastapi.md","title":"FastAPI","description":"FastAPI est un framework web moderne et rapide (hautes performances) pour la cr\xe9ation d\'API avec Python, bas\xe9 sur les annotations de types standard de Python.","date":"2024-08-26T00:00:00.000Z","tags":[{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"},{"inline":true,"label":"Python","permalink":"/blog/tags/python"}],"readingTime":3.58,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"FastAPI","description":"FastAPI est un framework web moderne et rapide (hautes performances) pour la cr\xe9ation d\'API avec Python, bas\xe9 sur les annotations de types standard de Python.","tags":["Devops","Python"]},"unlisted":false,"nextItem":{"title":"Docker pratiques de production","permalink":"/blog/2024/03/17/03-containerization/docker-best-practices"}},"content":"FastAPI est un framework web moderne et rapide (hautes performances) pour la cr\xe9ation d\'API avec Python, bas\xe9 sur les annotations de types standard de Python.\\n\\n\x3c!--truncate--\x3e\\n\\n## Aper\xe7u\\n\\nFastAPI est un framework web moderne et rapide (hautes performances) pour la cr\xe9ation d\'API avec Python, bas\xe9 sur les annotations de types standard de Python. Il offre des performances \xe9lev\xe9es, comparables \xe0 celles de NodeJS et Go, gr\xe2ce \xe0 Starlette et Pydantic, ce qui en fait l\'un des frameworks Python les plus rapides disponibles. FastAPI permet d\'augmenter la vitesse de d\xe9veloppement des fonctionnalit\xe9s de 200% \xe0 300%, de r\xe9duire d\'environ 40% les erreurs humaines des d\xe9veloppeurs, et propose un excellent support des \xe9diteurs avec des compl\xe9tions.\\n\\n|                         |                                 |\\n| ----------------------- | ------------------------------- |\\n| Site Web                | [https://fastapi.tiangolo.com/](https://fastapi.tiangolo.com/) |\\n| GitHub Stars            | > 75k \u2b50                         |\\n| Nombre de contributeurs | 700                             |\\n| Licence                 | MIT                             |\\n\\n- Finalit\xe9 : Cr\xe9ation des API web avec Python\\n- Int\xe9r\xeat : FastAPI est facile \xe0 utiliser et \xe0 apprendre, r\xe9duit la duplication de code, et produit du code pr\xeat pour la production avec une documentation interactive bas\xe9e sur les standards OpenAPI et JSON Schema.\\n- Gouvernance : Assur\xe9e par une \xe9quipe de mainteneurs dont [tiangolo](https://github.com/tiangolo) est le cr\xe9ateur et mainteneurs principal. A cela s\'ajoute des contributeurs individuels, le projet est soutenu par la communaut\xe9.\\n\\n### FastAPI vs Flask\\n\\n**FastAPI** est reconnu pour sa rapidit\xe9 et ses performances \xe9lev\xe9es, gr\xe2ce \xe0 Starlette et Pydantic. Il utilise les annotations de types standard de Python, ce qui am\xe9liore la validation et la s\xe9rialisation des donn\xe9es. FastAPI g\xe9n\xe8re automatiquement une documentation interactive et est bas\xe9 sur les standards OpenAPI et JSON Schema. Il est id\xe9al pour les projets n\xe9cessitant des performances \xe9lev\xe9es et une validation stricte des donn\xe9es.\\n\\n**Flask**, en revanche, est un micro-framework l\xe9ger et flexible, facile \xe0 apprendre et \xe0 utiliser. Il offre une grande libert\xe9 aux d\xe9veloppeurs pour structurer leurs applications comme ils le souhaitent. Flask est extensible via de nombreuses extensions tierces, ce qui le rend adapt\xe9 aux projets de toutes tailles. Cependant, il ne fournit pas de validation de donn\xe9es int\xe9gr\xe9e ni de documentation automatique comme FastAPI.\\n\\nEn r\xe9sum\xe9, FastAPI est plus adapt\xe9 pour les projets n\xe9cessitant des performances \xe9lev\xe9es et une validation stricte des donn\xe9es, tandis que Flask est con\xe7u pour les projets n\xe9cessitant flexibilit\xe9 et simplicit\xe9.\\n\\n## Utilisation\\n\\nPour installer FastAPI, vous pouvez utiliser pip :\\n\\n```bash\\npip install \\"fastapi[standard]\\"\\n```\\n\\nL\'exemple ci dessous est une API simpliste de gestion des To-Do List permettant aux utilisateurs de cr\xe9\xe9r, lire, mettre \xe0 jour et supprimer des t\xe2ches. Les sp\xe9cifications sont les suivantes :\\n\\n1. Cr\xe9er une t\xe2che : Permettre aux utilisateurs de cr\xe9er une nouvelle t\xe2che avec un titre et une description.\\n2. Lire les t\xe2ches : R\xe9cup\xe9rer la liste de toutes les t\xe2ches ou une t\xe2che sp\xe9cifique par son identifiant.\\n3. Mettre \xe0 jour une t\xe2che : Modifier les d\xe9tails d\'une t\xe2che existante.\\n4. Supprimer une t\xe2che : Supprimer une t\xe2che par son identifiant.\\n\\nL\'exemple ci dessous m\xe9lange plusieurs fonctionnalit\xe9s de FastAPI.\\n\\n```python\\nfrom datetime import date\\nfrom typing import Optional\\nfrom fastapi import FastAPI, Query\\nfrom pydantic import BaseModel\\nimport uvicorn\\n\\napp = FastAPI()\\n\\n\\nclass Task(BaseModel):\\n    id: int\\n    title: str\\n    description: str\\n    date: date\\n\\n\\ntasks: list[Task] = []\\n\\n\\n@app.post(\\"/tasks/\\", response_model=Task)\\ndef create_task(task: Task):\\n    tasks.append(task)\\n    return task\\n\\n\\n@app.get(\\"/tasks/\\", response_model=list[Task])\\ndef read_tasks(skip: int = 0, limit: int = 10):\\n    return tasks[skip : skip + limit]\\n\\n\\n@app.get(\\"/tasks/{task_id}\\", response_model=Task)\\ndef read_task(task_id: int):\\n    for task in tasks:\\n        if task.id == task_id:\\n            return task\\n    return {\\"error\\": \\"Task not found\\"}\\n\\n\\n@app.put(\\"/tasks/{task_id}\\", response_model=Task)\\ndef update_task(task_id: int, updated_task: Task):\\n    for task in tasks:\\n        if task.id == task_id:\\n            task.title = updated_task.title\\n            task.description = updated_task.description\\n            task.date = updated_task.date\\n            return task\\n    return {\\"error\\": \\"Task not found\\"}\\n\\n\\n@app.delete(\\"/tasks/{task_id}\\")\\ndef delete_task(task_id: int):\\n    global tasks\\n    tasks = [task for task in tasks if task.id != task_id]\\n    return {\\"message\\": \\"Task deleted\\"}\\n\\n\\n@app.get(\\"/search_tasks\\", response_model=list[Task])\\ndef search_tasks(\\n    title: Optional[str] = Query(None), date: Optional[date] = Query(None)\\n):\\n    results = tasks\\n    if title:\\n        results = [task for task in results if title.lower() in task.title.lower()]\\n    if date:\\n        results = [task for task in results if task.date == date]\\n    return results\\n```\\n\\nPour lancer l\'application :\\n\\n```bash\\nfastapi run /path/to/file.py # production mode\\nfastapi dev /path/to/file.py # development mode\\n```\\n\\nEn plus de l\'API, FastAPI g\xe9n\xe8re automatiquement une documentation interactive accessible \xe0 l\'adresse `http://127.0.0.1:8000/docs`\\n\\n![documentation](/img/fast-api-documentation.png)"},{"id":"/2024/03/17/03-containerization/docker-best-practices","metadata":{"permalink":"/blog/2024/03/17/03-containerization/docker-best-practices","source":"@site/blog/03-containerization/2024-03-17-docker-best-practices.md","title":"Docker pratiques de production","description":"L\'adoption de Docker augmente constamment et beaucoup le connaissent, mais tout le monde n\'utilise pas Docker selon les meilleures pratiques.","date":"2024-03-17T00:00:00.000Z","tags":[{"inline":true,"label":"Conteneur","permalink":"/blog/tags/conteneur"},{"inline":true,"label":"Docker","permalink":"/blog/tags/docker"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":4.505,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Docker pratiques de production","description":"L\'adoption de Docker augmente constamment et beaucoup le connaissent, mais tout le monde n\'utilise pas Docker selon les meilleures pratiques.","tags":["Conteneur","Docker","Devops"]},"unlisted":false,"prevItem":{"title":"FastAPI","permalink":"/blog/2024/08/26/09-scripting/fastapi"},"nextItem":{"title":"Dokku","permalink":"/blog/2024/03/10/06-orchestration/orchestration-dokku"}},"content":"\x3c!--truncate--\x3e\\n\\n## Utilisez une image Docker officielle et v\xe9rifi\xe9e comme image de base, chaque fois disponible\\n\\nDisons que vous d\xe9veloppez une application Node.js et que vous souhaitez la cr\xe9er et l\'ex\xe9cuter en tant qu\'image Docker.\\n\\nAu lieu de prendre une image du syst\xe8me d\'exploitation de base et d\'installer Node.js, NPM et tous les autres outils dont vous avez besoin pour votre application, utilisez l\'image de node officiel pour votre application.\\n\\n## Utilisez des versions d\'image docker sp\xe9cifiques\\n\\nD\'accord, nous avons donc s\xe9lectionn\xe9 l\'image de base, mais maintenant lorsque nous construisons notre image d\'applications \xe0 partir de ce Dockerfile, il utilisera toujours la derni\xe8re balise de l\'image de n\u0153ud.\\n\\nAinsi, au lieu d\'une \xe9tiquette d\'image al\xe9atoire, vous souhaitez fixer la version, et tout comme vous d\xe9ployez votre propre application avec une version sp\xe9cifique, vous souhaitez utiliser l\'image officielle avec une version sp\xe9cifique.\\n\\n## Utiliser des images officielles de petite taille\\n\\nLors du choix d\'une image Node.js, vous verrez qu\'il y a en fait plusieurs images officielles. Non seulement avec diff\xe9rents num\xe9ros de version mais aussi avec diff\xe9rentes distributions de syst\xe8mes d\'exploitation:\\n\\n1) Taille de l\'image : si l\'image est bas\xe9e sur une distribution de syst\xe8me d\'exploitation \xe0 part enti\xe8re comme Ubuntu ou Centos, vous aurez un tas d\'outils d\xe9j\xe0 emball\xe9s dans l\'image. Ainsi, la taille de l\'image sera plus grande, mais vous n\'avez pas besoin de la plupart de ces outils dans vos images d\'application.\\n\\n2) Probl\xe8me de s\xe9curit\xe9 : avec de nombreux outils install\xe9s \xe0 l\'int\xe9rieur, vous devez consid\xe9rer l\'aspect de s\xe9curit\xe9. Parce que ces images de base contiennent g\xe9n\xe9ralement [des centaines de vuln\xe9rabilit\xe9s connues](https://snyk.io/blog/openSourcesEcurity-2020Survey/) et cr\xe9ent essentiellement une plus grande surface d\'attaque \xe0 votre image d\'application.\\n\\nAinsi, la meilleure pratique ici serait de s\xe9lectionner une image avec une version sp\xe9cifique bas\xe9e sur une distribution plus maigre comme Alpine.\\n\\n## Optimiser la mise en cache pour les couches d\'image lors de la construction d\'une image\\n\\n1) Que sont les layer d\'image? Une image Docker est construite sur la base d\'un dockerfile.\\n\\nEt dans un dockerfile, chaque commande ou instruction cr\xe9e un layer d\'image.\\n\\nAinsi, lorsque nous utilisons une image de base d\'alpine, il a d\xe9j\xe0 des layers, car il a d\xe9j\xe0 \xe9t\xe9 construit en utilisant son propre dockerfile. Dans notre dockerfile, nous avons quelques autres commandes qui ajouteront chacune un nouveau layer \xe0 cette image.\\n\\nAinsi, lorsque vous reconstruisez votre image, si votre Dockerfile n\'a pas chang\xe9, Docker n\'utilisera que les layers en cache pour construire l\'image.\\n\\nAvantages des layers d\'image en cache:\\n\\n- Contruction d\'image plus rapide\\n- Push et pull plus rapides de nouvelles versions d\'image: Si je pull une nouvelle version d\'image de la m\xeame application et, disons, 2 nouveaux layers ont \xe9t\xe9 ajout\xe9es dans la nouvelle version: seule la nouvelle version des layers ajout\xe9es seront t\xe9l\xe9charg\xe9es Les autres sont d\xe9j\xe0 mis en cache localement par Docker.\\n\\nOptimiser la mise en cache : une fois qu\'un layer change, tous les layers suivants doivent \xe9galement \xeatre recr\xe9\xe9es. En d\'autres termes: lorsque vous modifiez le contenu d\'une ligne dans le dockerfile, les caches de toutes les lignes ou layers suivantes seront invalid\xe9s.\\n\\nAinsi, la r\xe8gle ici et la meilleure pratique est: placez vos commandes dans le Dockerfile du moins au plus fr\xe9quemment modif\xe9.\\n\\n## \xe0 l\'aide d\'un fichier .dockerignore\\n\\nC\'est assez simple. Nous cr\xe9ons simplement ce fichier .dockerignore et r\xe9pertorions tous les fichiers et dossiers que nous voulons \xeatre ignor\xe9s, et lors de la cr\xe9ation de l\'image, Docker examinera le contenu et ignorera tout ce qui est sp\xe9cifi\xe9 \xe0 l\'int\xe9rieur.\\n\\n## Utilisez des versions multi-\xe9tages\\n\\nMaintenant, disons qu\'il existe un outil dans votre projet dont vous avez besoin pour construire l\'image mais vous n\'en avez pas besoin dans l\'image finale pour ex\xe9cuter leapplication.\\n\\nSupposons que vous conserviez ces artefacts dans votre image finale, m\xeame s\'ils sont absolument inutiles pour ex\xe9cuter l\'application. Dans ce cas, cela entra\xeenera \xe0 nouveau une augmentation de la taille de l\'image et une augmentation de la surface d\'attaque.\\n\\nPour cela, vous pouvez utiliser ce qu\'on appelle les constructions \xe0 plusieurs \xe9tages\\n\\nLa fonction de construction en plusieurs \xe9tapes vous permet d\'utiliser plusieurs images temporaires pendant le processus de construction, mais ne conserve que la derni\xe8re image comme artefact final.\\n\\n## Utilisez l\'utilisateur le moins privil\xe9gi\xe9\\n\\nMaintenant, lorsque nous cr\xe9ons cette image et que nous l\'ex\xe9cutons finalement en tant que conteneur, quel utilisateur du syst\xe8me d\'exploitation sera utilis\xe9 pour d\xe9marrer l\'application \xe0 l\'int\xe9rieur? Par d\xe9faut, lorsqu\'un DockerFile ne sp\xe9cifie pas un utilisateur, il utilise un utilisateur root. Mais en r\xe9alit\xe9, il n\'y a surtout aucune raison d\'ex\xe9cuter des conteneurs avec des privil\xe8ges root.\\n\\nCela introduit essentiellement un probl\xe8me de s\xe9curit\xe9 car lorsque le conteneur commence sur l\'h\xf4te, il aura potentiellement un acc\xe8s root sur l\'h\xf4te Docker.\\n\\nPour \xe9viter cela, la meilleure pratique consiste \xe0 cr\xe9er simplement un utilisateur d\xe9di\xe9 et un groupe d\xe9di\xe9 dans l\'image Docker pour ex\xe9cuter l\'application et \xe9galement ex\xe9cuter l\'application \xe0 l\'int\xe9rieur du conteneur avec cet utilisateur.\\n\\n## Scannez vos images pour les vuln\xe9rabilit\xe9s de s\xe9curit\xe9\\n\\nEnfin, comment s\'assurer et valider que l\'image que vous construisez a peu ou pas de vuln\xe9rabilit\xe9s de s\xe9curit\xe9 ?\\n\\nLa meilleure pratique est, une fois que vous avez construit l\'image, la scannez pour des vuln\xe9rabilit\xe9s de s\xe9curit\xe9 \xe0 l\'aide de la commande docker scan.\\n\\nEn arri\xe8re-plan, Docker utilise en fait un service appel\xe9 SNYK pour faire la num\xe9risation de la vuln\xe9rabilit\xe9 des images. Le scan utilise une base de donn\xe9es de vuln\xe9rabilit\xe9s, qui est constamment mise \xe0 jour."},{"id":"/2024/03/10/06-orchestration/orchestration-dokku","metadata":{"permalink":"/blog/2024/03/10/06-orchestration/orchestration-dokku","source":"@site/blog/06-orchestration/2024-03-10-orchestration-dokku.md","title":"Dokku","description":"Dokku est une plateforme open-source permettant le d\xe9ploiement, la gestion et la mise \xe0 l\'\xe9chelle des applications sur un serveur.","date":"2024-03-10T00:00:00.000Z","tags":[{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"},{"inline":true,"label":"Orchestration","permalink":"/blog/tags/orchestration"},{"inline":true,"label":"Alternatives","permalink":"/blog/tags/alternatives"}],"readingTime":3.9,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Dokku","description":"Dokku est une plateforme open-source permettant le d\xe9ploiement, la gestion et la mise \xe0 l\'\xe9chelle des applications sur un serveur.","tags":["Devops","Orchestration","Alternatives"]},"unlisted":false,"prevItem":{"title":"Docker pratiques de production","permalink":"/blog/2024/03/17/03-containerization/docker-best-practices"},"nextItem":{"title":"Architecture compl\xe8te","permalink":"/blog/2024/03/03/04-ci-cd/exemple"}},"content":"Une alternative PAAS open source \xe0 Heroku [https://dokku.com/](https://dokku.com/)\\nDokku est une plateforme open-source permettant le d\xe9ploiement, la gestion et la mise \xe0 l\'\xe9chelle des applications sur un serveur. Inspir\xe9 par Heroku, il utilise une approche similaire pour le d\xe9ploiement d\'applications : le code se d\xe9ploie en effectuant un \\"push\\" vers un d\xe9p\xf4t Git sur le serveur. \xc0 la diff\xe9rence de Heroku, Dokku offre un contr\xf4le total sur l\'environnement de d\xe9ploiement. Ainsi, l\'infrastructure, le syst\xe8me d\'exploitation et les services (tels que les bases de donn\xe9es ou les files d\'attente de t\xe2ches) peuvent \xeatre personnalis\xe9s selon les besoins. Dokku s\'appuie sur Docker pour g\xe9rer les applications dans des conteneurs isol\xe9s, ce qui simplifie la gestion des applications et de leurs d\xe9pendances. Chaque \\"push\\" d\'une application \xe0 Dokku cr\xe9e un nouveau conteneur Docker.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Installation\\n\\n```shell\\n# download the installation script\\nwget -NP . <https://dokku.com/bootstrap.sh>\\n# run the installer\\nsudo DOKKU_TAG=v0.32.3 bash bootstrap.sh\\n# and your ssh key to the dokku user\\nPUBLIC_KEY=\\"your-public-key-contents-here\\"\\necho \\"$PUBLIC_KEY\\" | dokku ssh-keys:add admin\\n```\\n\\n## Premi\xe8re application\\n\\n```shell\\n# define global domains\\ndokku domains:set-global <your-domain>\\n# <your-domain> can be a rd party domain or a local domain like sonu-dev-gzsim.local\\n```\\n\\nSur la machine o\xf9 `dokku` est install\xe9\\n\\n```shell\\ndokku apps:create <app-name>\\nsudo dokku plugin:install <https://github.com/dokku/dokku-postgres.git>\\ndokku postgres:create railsdatabase\\ndokku postgres:link railsdatabase <app-name>\\n```\\n\\nSur la machine locale\\n\\n```shell\\ncd <app-name>\\ngit remote add dokku dokku@<your-domain>:<app-name>\\ngit push dokku main\\n```\\n\\n## Construire sa propre application\\n\\nDokku supporte plusieurs m\xe9thodes de build pour cr\xe9er des applications, chacun avec ses propres avantages sp\xe9cifiques :\\n\\n1. [**builder-dockerfile**](https://dokku.com/docs/deployment/builders/dockerfiles/): Cette m\xe9thode utilise un Dockerfile pour construire des applications via la commande `docker build`. Il donne un contr\xf4le maximal sur l\'environnement d\'ex\xe9cution de l\'application et sur la mani\xe8re dont l\'application est assembl\xe9e.\\n2. [**builder-herokuish**](https://dokku.com/docs/deployment/builders/herokuish-buildpacks/): Avec cette m\xe9thode, Dokku cr\xe9e des applications en utilisant la sp\xe9cification v2a Buildpack de Heroku via `gliderlabs/herokuish`. Il vous permet de profiter du m\xeame pipeline de build que Heroku, qui inclut le support pour de nombreux langages de programmation par d\xe9faut.\\n3. builder-lambda: Ce g\xe9n\xe9rateur construit des fonctions AWS Lambda dans un environnement simulant les temps d\'ex\xe9cution d\'AWS Lambda.\\n4. **builder-null**: Cette m\xe9thode ne fait rien pendant la phase de construction. C\'est utile pour les sc\xe9narios o\xf9 aucune construction n\'est n\xe9cessaire, comme le d\xe9ploiement d\'applications d\xe9j\xe0 compil\xe9es ou de conteneurs Docker.\\n5. **builder-pack**: Cette m\xe9thode utilise les Cloud Native Buildpacks pour construire des applications via l\'outil pack-cli. Les Cloud Native Buildpacks sont une norme ouverte qui \xe9tend les capacit\xe9s des Buildpacks classiques.\\n\\n## Automatiser le d\xe9ploiement via Github Actions\\n\\n```yaml\\nname: Deploy to Dokku (sonu-dev-gzsim)\\non:\\n    schedule:\\n    - cron: \'0 0 * * *\'\\n    workflow_dispatch:\\n    workflow_run:\\n    workflows: [ \\"Test build\\" ]\\n    types:\\n        - completed\\njobs:\\n    deploy:\\n    runs-on:\\n        group: default\\n    steps:\\n        - name: Cloning repo\\n        uses: actions/checkout@v4\\n        with:\\n            fetch-depth: 0\\n\\n        - name: Tailscale\\n        uses: tailscale/github-action@v2\\n        with:\\n            oauth-client-id: ${{ secrets.TS_OAUTH_CLIENT_ID }}\\n            oauth-secret: ${{ secrets.TS_OAUTH_SECRET }}\\n            tags: tag:server\\n\\n        - name: Push to dokku\\n        uses: dokku/github-action@master\\n        with:\\n            git_remote_url: \'ssh://dokku@100.65.237.90:22/rd25-robotics\'\\n            ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}\\n            branch: main\\n            git_push_flags: \'--force\'\\n\\n    if: ${{ github.event.workflow_run.conclusion == \'success\' }}\\n```\\n\\n## Astuces\\n\\n \u26a0\ufe0f Les astuces ci dessous correspondent **tr\xe8s certainement** \xe0 une incompr\xe9hension des m\xe9canismes de domain, proxy et reverse proxy\\n\\nPar d\xe9faut `dokku` d\xe9ploie l\u2019application sur une url construite comme suit : `http://<app-name>.<your-domain>` visiblement si le domaine est local (comme `sonu-dev-gzsim.local`) le reverse proxy ne fonctionne pas (la configuration `nginx` est \xe0 creuser) il est donc n\xe9cessaire de `disable` les domains avec la commande\\n\\n```shell\\ndokku domains:disable <app-name>\\n```\\n\\nCela aura pour effet de d\xe9sactiver le domaine pour l\u2019application en question. Elle tournera donc directement sur le port d\xe9fini al\xe9atoirement par `dokku`.\\n\xc0 chaque d\xe9ploiement, `dokku` construit un `dokker` pour g\xe9rer les applications de mani\xe8re isol\xe9e. Par d\xe9faut, les applications de type web doivent fournir leurs services sur le port `5000`. Par la suite, `dokku` s\u2019occupe de faire la redirection de port entre la machine et le container. Pour \xe9viter d\u2019avoir un port al\xe9atoire, il est possible de faire\\n\\n```shell\\ndokku ports:set <app-name> http:<machine-port>:<docker-port>\\n```\\n\\nAinsi, \xe0 chaque d\xe9ploiement, `dokku` redirigera le port de la machine vers le port du docker.\\nFinalement si vous souhaitez mettre en place une redirection comme `http://<your-domain>/<app-name>` vers l\u2019application il suffit de faire les modifications suivantes dans `nginx`\\nModifiez le fichier de configuration de Nginx pour votre site :\\n\\n```shell\\nsudo nano /etc/nginx/sites-available/your-config-file\\n```\\n\\nAjoutez la directive location dans votre configuration :\\n\\n```txt\\nserver { listen 80; server_name <your-domain>; location = <app-name> { return 301 http://$host:<machine-port>; } }\\n```\\n\\nCr\xe9ez un lien symbolique vers le fichier de configuration :\\n\\n```shell\\nsudo ln -s /etc/nginx/sites-available/your-config-file /etc/nginx/sites-enabled/\\n```\\n\\nV\xe9rifiez la configuration de Nginx :\\n\\n```shell\\nsudo nginx -t\\n```\\n\\nRed\xe9marrez Nginx pour appliquer les modifications :\\n\\n```shell\\nsudo systemctl restart nginx\\n```"},{"id":"/2024/03/03/04-ci-cd/exemple","metadata":{"permalink":"/blog/2024/03/03/04-ci-cd/exemple","source":"@site/blog/04-ci-cd/2024-03-03-exemple.md","title":"Architecture compl\xe8te","description":"Exemple complet d\'architecture CI/CD r\xe9utilisable","date":"2024-03-03T00:00:00.000Z","tags":[{"inline":true,"label":"CI/CD","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":2.71,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Architecture compl\xe8te","description":"Exemple complet d\'architecture CI/CD r\xe9utilisable","tags":["CI/CD","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Dokku","permalink":"/blog/2024/03/10/06-orchestration/orchestration-dokku"},"nextItem":{"title":"Action Runner Controller GitHub","permalink":"/blog/2024/02/25/04-ci-cd/github-arc"}},"content":"L\'objectif est de cr\xe9er une architecture CI/CD compl\xe8te pour un projet de d\xe9veloppement adressant une technologie (par exemple ROS). Cette architecture doit \xeatre :\\n\\n- facilement r\xe9utilisable dans d\'autres projets\\n- \xe9viter la duplication de code\\n- maintenable et \xe9volutive ais\xe9ment\\n- applicable \xe0 d\'autres projets\\n\\n\x3c!--truncate--\x3e\\n\\nNous avons \xe0 notre dispositions les outils suivants :\\n\\n- [La cr\xe9ation de workflows](/blog/04-ci-cd/2024-02-04-workflow.md)\\n- [La cr\xe9ation d\'actions](/blog/04-ci-cd/2024-02-04-action.md)\\n- [La r\xe9utilisation d\'actions et de workflows](/blog/04-ci-cd/2024-02-04-workflow.md)\\n\\n## Cr\xe9ation d\'une architecture CI/CD\\n\\nL\'id\xe9e de l\'architecture est de cr\xe9er un d\xe9p\xf4t contenant tous les workflows et les actions propres \xe0 une technologie / projet (par exemple ROS). Ce d\xe9p\xf4t sera ensuite utilis\xe9 comme cible pour les workflows des projets utilisant cette technologie.\\n\\n```mermaid\\ngraph LR\\n    subgraph Repositories ROS1\\n        repo1[ros_package_1/.github/workflows/ci.yml]\\n        repo2[ros_package_2/.github/workflows/ci.yml]\\n        repo3[ros_package_n/.github/workflows/ci.yml]\\n    end\\n    subgraph ros_workflows\\n        ros.yml[.github/workflows/ros1.yml]\\n        ros2.yml[.github/workflows/ros2.yml]\\n        ros_build.yml[ros_build/action.yml]\\n        ros.yml --\x3e ros_build.yml\\n        ros2.yml --\x3e ros_build.yml\\n    end\\n    subgraph generic_workflows\\n        pre-commit.yml[.github/workflows/pre-commit.yml]\\n\\n    end\\n\\n    ros.yml --\x3e pre-commit.yml\\n\\n    repo1 --\x3e ros.yml\\n    repo2 --\x3e ros.yml\\n    repo3 --\x3e ros.yml\\n```\\n\\nDans cet exemple, nous avons un d\xe9p\xf4t `ros_workflows` contenant les workflows et les actions propres \xe0 la technologie ROS. Ce d\xe9p\xf4t est ensuite utilis\xe9 par les d\xe9p\xf4ts `ros_package_1`, `ros_package_2`, `ros_package_n` pour ex\xe9cuter les workflows. Les diff\xe9rents workflows pr\xe9sents dans `ros_workflows` sont les **uniques** points d\'entr\xe9e pour les workflows des d\xe9p\xf4ts `ros_package_1`, `ros_package_2`, `ros_package_n`. Ainsi s\'il est n\xe9cessaire de modifier un workflow, il suffit de le faire dans le d\xe9p\xf4t `ros_workflows` et tous les d\xe9p\xf4ts utilisant ce workflow seront mis \xe0 jour.\\n\\nDe plus le d\xe9p\xf4t `ros_workflows` peut d\xe9finir des `actions-composites` pour \xe9viter la duplication de code entre leurs propres workflows. Ces actions sont utilis\xe9es par les workflows du d\xe9p\xf4t `ros_workflows` et par cons\xe9quent des d\xe9p\xf4ts `ros_package_1`, `ros_package_2`, `ros_package_n`. Elles peuvent aussi \xeatre appel\xe9es directement au besoin.\\n\\nFinalemet, le d\xe9p\xf4t `ros_workflows` peut aussi utiliser des workflows g\xe9n\xe9riques (par exemple `pre-commit.yml`) pour automatiser des t\xe2ches communes \xe0 toutes les technologies.\\n\\n### Exemple de workflow `ros1.yml`\\n\\n```yaml\\nname: Build & Test ROS Packages\\n\\non:\\n  workflow_call:\\n    inputs:\\n      package-name:\\n        description: \'The name of the ROS package to build and test.\'\\n        required: true\\n        type: string\\n    secrets:\\n      PAT:\\n        required: false\\n        description: \'A GitHub Personal Access Token (PAT) used to import the private repository into the container.\'\\n\\n\\njobs:\\n  pre-commit:\\n    uses: catie-aq/generic_workflows/.github/workflows/pre-commit.yaml@main\\n  build_and_test_ros_package:\\n    runs-on: self-hosted # Use self-hosted runner\\n    strategy: # Define a matrix of ROS distributions and Docker images\\n      matrix:\\n        include:\\n          - docker_image: osrf/ros:noetic-desktop-full\\n            ros_distribution: noetic\\n    container: # Use the Docker image defined in the matrix\\n      image: ${{ matrix.docker_image }}\\n    steps:\\n      - name: Setup ROS environment\\n        uses: ros-tooling/setup-ros@v0.7\\n        with:\\n          required-ros-distributions: ${{ matrix.ros_distribution }}\\n\\n      - name: Build and test ROS\\n        uses: ros-tooling/action-ros-ci@v0.2\\n        with:\\n          package-name: ${{ inputs.package-name }}\\n          target-ros1-distro: ${{ matrix.ros_distribution }}\\n          import-token: ${{ secrets.PAT }}\\n```\\n\\n### Exemple de workflow `ci.yml`\\n\\n```yaml\\nname: \\"ROS CI/CD\\"\\n\\non:\\n  push:\\n\\njobs:\\n  ros:\\n    uses: {user}/ros_workflows/.github/workflows/ros.yml@main\\n```\\n\\n### Exemple d\'action composite `ros_build/action.yml`\\n\\n```yaml\\nname: \'Build and Test ROS\'\\ndescription: \'Build and test a ROS package\'\\n\\ninputs:\\n  package-name:\\n    description: \'The name of the ROS package to build and test.\'\\n    required: true\\n    type: string\\n  ros-distribution:\\n    description: \'The ROS distribution to use for building and testing.\'\\n    required: true\\n    type: string\\n  import-token:\\n    description: \'A GitHub Personal Access Token (PAT) used to import the private repository into the container.\'\\n    required: false\\n    type: string\\n\\nruns:\\n    using: \\"composite\\"\\n    steps:\\n        - run: echo \\"Building and testing ROS package ${{ inputs.package-name }} for ROS ${{ inputs.ros-distribution }}.\\"\\n        shell: bash\\n```"},{"id":"/2024/02/25/04-ci-cd/github-arc","metadata":{"permalink":"/blog/2024/02/25/04-ci-cd/github-arc","source":"@site/blog/04-ci-cd/2024-02-25-github-arc.md","title":"Action Runner Controller GitHub","description":"Explication de l\'installation et de l\'utilisation de l\'Action Runner Controller GitHub","date":"2024-02-25T00:00:00.000Z","tags":[{"inline":true,"label":"CI/CD","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":2.41,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Action Runner Controller GitHub","description":"Explication de l\'installation et de l\'utilisation de l\'Action Runner Controller GitHub","tags":["CI/CD","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Architecture compl\xe8te","permalink":"/blog/2024/03/03/04-ci-cd/exemple"},"nextItem":{"title":"Le concept de conteneur Docker","permalink":"/blog/2024/02/18/03-containerization/docker"}},"content":"Actions Runner Controller (ARC) est un op\xe9rateur de Kubernetes qui orchestre et g\xe8re les runners auto-h\xe9berg\xe9s pour les actions GitHub.\\n\\n\x3c!--truncate--\x3e\\n\\nAvec ARC, il est possible de cr\xe9er des ensembles de runners qui \xe9voluent automatiquement en fonction du nombre de workflows ex\xe9cut\xe9s dans votre d\xe9p\xf4t, organisation ou entreprise.\\n\\nLe diagramme suivant illustre l\'architecture du mode Scaleset Runner Autoscaling d\'Arc.\\n\\n[Documentation compl\xe8te](https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/quickstart-for-actions-runner-controller)\\n\\n![alt text](/img/arc.png)\\n\\n:::danger\\nSur GitHub les ARC sont identifi\xe9s par leur nom d\'installation. Il est important de choisir un nom unique pour chaque installation. De plus pour simplifier l\'\xe9criture des workflows il est consill\xe9 de g\xe9rer les runners par des groupes de runners. La cl\xe9 `runs-on` des jobs des workflows doit \xeatre \xe9gale \xe0 un groupe de runners.\\n:::\\n\\n## Pr\xe9requis\\n\\nPour utiliser l\'ARC, il est n\xe9cessaire de disposer des \xe9l\xe9ments suivants :\\n\\n- Un cluster Kubernetes\\n- Helm 3.0 ou version ult\xe9rieure\\n\\n## Installation rapide\\n\\n:::warning\\nLa suite du guide permet de rapidement installer ARC. Les diff\xe9rents concepts et la configuration avanc\xe9e ne sont pas abord\xe9s. Pour une installation plus compl\xe8te, regarder la [documentation officielle](https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/quickstart-for-actions-runner-controller).\\n:::\\n\\n- Le pod de contr\xf4le est en charge de la gestion des pods de runner. Il s\'occupe de la cr\xe9ation, de la mise \xe0 l\'\xe9chelle et de la suppression des pods de runner.\\n- Le pod de runner est d\xe9di\xe9 \xe0 l\'ex\xe9cution des workflows GitHub Actions. Il se compose de deux conteneurs : un conteneur DinD et un conteneur runner. Le conteneur DinD fournit un environnement d\'ex\xe9cution Docker pour le conteneur runner. Le conteneur runner est utilis\xe9 pour ex\xe9cuter les workflows GitHub Actions.\\n\\n## Usage\\n\\nPour lancer le pod de contr\xf4le :\\n\\n```shell\\nNAMESPACE=\\"arc-systems\\"\\nhelm install arc \\\\\\n    --namespace \\"${NAMESPACE}\\" \\\\\\n    --create-namespace \\\\\\n    oci://ghcr.io/actions/actions-runner-controller-charts/gha-runner-scale-set-controller\\n```\\n\\nPour lancer le pod de runner :\\n\\n```shell\\nINSTALLATION_NAME=\\"elegantencoder\\"\\nNAMESPACE=\\"arc-runners\\"\\nhelm install \\"${INSTALLATION_NAME}\\" \\\\\\n    --namespace \\"${NAMESPACE}\\" \\\\\\n    --create-namespace \\\\\\n    -f value.yaml \\\\\\n    oci://ghcr.io/actions/actions-runner-controller-charts/gha-runner-scale-set;\\n```\\n\\n## Authentification\\n\\nPour que le pod de contr\xf4le puisse cr\xe9er des pods de runner, il faut lui donner les droits n\xe9cessaires. Pour cela, il faut cr\xe9er un secret contenant un token d\'authentification. Les diff\xe9rents \xe9l\xe9ments proviennent de l\'enregistrement d\'une application GitHub au niveau de l\'organisation concern\xe9e.\\n\\n```shell\\nkubectl create secret generic pre-defined-secret \\\\\\n   --namespace=arc-runners \\\\\\n   --from-literal=github_app_id=xxx \\\\\\n   --from-literal=github_app_installation_id=xxx \\\\\\n   --from-literal=github_app_private_key=\'xxx\'\\n```\\n\\n## Monitoring\\n\\nDashboard Helm\\n\\n```shell\\nhelm dashboard --bind 0.0.0.0\\n```\\n\\nPortainer\\n\\n## Docker cache\\n\\nNous avons rencontr\xe9 un probl\xe8me de lenteur lors de la construction des images Docker. Pour y rem\xe9dier, nous avons mis en place la mutualisation des couches des images Docker entre les diff\xe9rents pods et l\'h\xf4te. Cela implique la cr\xe9ation d\'un volume partag\xe9 entre les diff\xe9rents pods et l\'h\xf4te. Ces volumes sont mont\xe9s dans le conteneur DinD du pod qui les utilise pour fournir les images Docker au conteneur du runner. Chaque pod de runner contient un conteneur DinD qui est utilis\xe9 pour construire les images Docker.\\n\\n```yaml\\n- name: overlay2\\n    hostPath:\\n    path: /var/lib/docker/overlay2\\n- name: image-overlay2\\n    hostPath:\\n    path: /var/lib/docker/image/overlay2\\n```"},{"id":"/2024/02/18/03-containerization/docker","metadata":{"permalink":"/blog/2024/02/18/03-containerization/docker","source":"@site/blog/03-containerization/2024-02-18-docker.md","title":"Le concept de conteneur Docker","description":"Docker est un outil open source qui permet aux d\xe9veloppeurs de cr\xe9er, d\xe9ployer, ex\xe9cuter, mettre \xe0 jour et g\xe9rer les conteneurs.","date":"2024-02-18T00:00:00.000Z","tags":[{"inline":true,"label":"Conteneur","permalink":"/blog/tags/conteneur"},{"inline":true,"label":"Docker","permalink":"/blog/tags/docker"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":3.095,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Le concept de conteneur Docker","description":"Docker est un outil open source qui permet aux d\xe9veloppeurs de cr\xe9er, d\xe9ployer, ex\xe9cuter, mettre \xe0 jour et g\xe9rer les conteneurs.","tags":["Conteneur","Docker","Devops"]},"unlisted":false,"prevItem":{"title":"Action Runner Controller GitHub","permalink":"/blog/2024/02/25/04-ci-cd/github-arc"},"nextItem":{"title":"GitHub GHCR","permalink":"/blog/2024/02/18/04-ci-cd/ghrc"}},"content":"\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce qu\'un conteneur et quels probl\xe8mes r\xe9sout-il?\\n\\nUn conteneur est un **moyen de packager des applications** avec tout ce dont ils ont besoin \xe0 l\'int\xe9rieur de ce package, y compris toutes ses d\xe9pendances et toutes les configurations n\xe9cessaires.\\n\\nLe package est portable comme tout autre artefact, et ce package peut \xeatre facilement partag\xe9 et d\xe9plac\xe9 entre une \xe9quipe de d\xe9veloppement ou une \xe9quipe de d\xe9veloppement et d\'op\xe9rations.\\n\\nLa portabilit\xe9 des conteneurs, ainsi que tout ce qui est packag\xe9 dans un **environnement isol\xe9**, lui donne des avantages qui rendent le processus de d\xe9veloppement et de d\xe9ploiement plus efficace.\\n\\n## D\xe9veloppement d\'applications avant / apr\xe8s conteneur\\n\\nVoyons maintenant comment les conteneurs am\xe9liorent le processus de d\xe9veloppement par des exemples sp\xe9cifiques.\\n\\nComment avons-nous d\xe9velopp\xe9 des applications avant les conteneurs?\\n\\nHabituellement, lorsque vous avez une \xe9quipe de d\xe9veloppeurs travaillant sur une application, vous devez installer directement la plupart des services sur votre syst\xe8me d\'exploitation.\\n\\nChaque d\xe9veloppeur de l\'\xe9quipe devrait alors aller installer les binaires de ces services, les configurer et les ex\xe9cuter sur son environnement de d\xe9veloppement local. Le processus d\'installation sera diff\xe9rent en fonction du syst\xe8me d\'exploitation qu\'ils utilisent.\\n\\nVous avez donc quelques commandes \xe0 ex\xe9cuter, et les **chances qu\'une erreur se produise sont \xe9lev\xe9es**, en raison du nombre d\'\xe9tapes n\xe9cessaires pour installer chaque service.\\n\\nMaintenant, voyons comment les conteneurs r\xe9solvent certains de ces probl\xe8mes.\\n\\nVous n\'avez pas \xe0 installer des services directement sur votre syst\xe8me d\'exploitation, car le conteneur poss\xe8de **sa propre couche de syst\xe8me d\'exploitation isol\xe9e** avec une image de base Linux.\\n\\nVous avez tout packag\xe9 dans un environnement isol\xe9, en tant que d\xe9veloppeur, vous n\'avez pas chercher les binaires \xe0 t\xe9l\xe9charger sur votre machine. Au lieu de cela, vous allez consulter le registre de conteneurs pour trouver le conteneur sp\xe9cifique \xe0 votre application et le t\xe9l\xe9charger sur votre machine locale.\\n\\n## D\xe9ploiement d\'application avant / apr\xe8s conteneur\\n\\n### Avant les conteneurs\\n\\nUn processus de d\xe9ploiement traditionnel ressemblera \xe0 ceci:\\n\\nL\'\xe9quipe de d\xe9veloppeur cr\xe9era des artefacts, qui sont essentiellement des fichiers, ainsi que des instructions sur l\'installation et les configurer sur le serveur. Tous ces artefacts et instructions seront fournis par l\'\xe9quipe de d\xe9veloppement:\\n\\n![alt text](/img/image.png)\\n\\nL\'\xe9quipe de d\xe9veloppement donnerait donc ces artefacts \xe0 l\'\xe9quipe des op\xe9rations, et l\'\xe9quipe d\'op\xe9ration mettrait en place les environnements pour d\xe9ployer ces applications:\\n\\n![Texte alt](/img/image-1.png)\\n\\n- **D\xe9pendances externes sur le syst\xe8me d\'exploitation du serveur**: Le probl\xe8me avec cette approche est que vous devez d\'abord configurer tout et tout installer directement sur le syst\xe8me d\'exploitation du serveur. Cela pourrait entra\xeener des conflits avec les versions de d\xe9pendance.\\n- **Mauvaise communication**: un autre probl\xe8me qui pourrait r\xe9sulter de ce processus est un malentendu entre l\'\xe9quipe de d\xe9veloppement et les op\xe9rations. Parce que tout est dans un guide textuel, il pourrait y avoir des cas, o\xf9 les d\xe9veloppeurs manquent de mentionner certains points critiques sur la configuration et en cas d\'\xe9chec, l\'\xe9quipe d\'op\xe9rations doit retourner aux d\xe9veloppeurs et demander plus de d\xe9tails.\\n\\n### Avec les Conteneurs\\n\\nAvec les conteneurs, ce processus est simplifi\xe9, car maintenant les d\xe9veloppeurs et les op\xe9rations fonctionnent dans une \xe9quipe pour former toutes les d\xe9pendances de configuration dans l\'application.\\n\\n![Texte alt](/img/image-2.png)\\n\\nCela signifie que si vous utilisez un conteneur Docker, vous n\'avez pas besoin de configurer quoi que ce soit directement sur le serveur, car tout est d\xe9j\xe0 encapsul\xe9 dans le conteneur. Au lieu de cela, il vous suffit d\'ex\xe9cuter une commande docker qui r\xe9cup\xe8re le conteneur que vous avez stock\xe9 dans le registre, puis l\'ex\xe9cute.\\n\\nC\'est donc beaucoup plus simple et aucune configuration environnementale n\'est n\xe9cessaire sur le serveur. La seule chose bien s\xfbr est que vous devez installer et configurer le runtime docker sur le serveur avant de pouvoir y ex\xe9cuter des conteneurs. Mais ce n\'est qu\'un effort unique."},{"id":"/2024/02/18/04-ci-cd/ghrc","metadata":{"permalink":"/blog/2024/02/18/04-ci-cd/ghrc","source":"@site/blog/04-ci-cd/2024-02-18-ghrc.md","title":"GitHub GHCR","description":"GitHub Container Registry (GHCR) est un service d\'h\xe9bergement de packages logiciels propos\xe9 par GitHub, permettant aux utilisateurs de stocker des packages priv\xe9s ou publics et de les utiliser comme d\xe9pendances dans leurs projets. Compatible avec plusieurs langages de programmation, GitHub Packages propose des registres pour des gestionnaires de packages tels que npm, RubyGems, Maven, Gradle, Docker, et NuGet. L\'authentification sur GitHub Packages se fait exclusivement via un \\"personal access token (classic)\\". Les utilisateurs doivent disposer de ce token pour effectuer des op\xe9rations telles que la publication, l\'installation et la suppression de packages, qu\'ils soient publics, priv\xe9s ou internes. Pour les packages priv\xe9s, GitHub Packages applique des limites de stockage et de transfert de donn\xe9es en fonction du plan du compte. La gestion des packages peut \xeatre r\xe9alis\xe9e \xe0 travers l\'interface utilisateur GitHub ou via l\'API REST. Des webhooks peuvent \xe9galement \xeatre configur\xe9s pour suivre des \xe9v\xe9nements li\xe9s aux packages, comme la publication ou la mise \xe0 jour.","date":"2024-02-18T00:00:00.000Z","tags":[{"inline":true,"label":"CI/CD","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":2.845,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"GitHub GHCR","tags":["CI/CD","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Le concept de conteneur Docker","permalink":"/blog/2024/02/18/03-containerization/docker"},"nextItem":{"title":"Runner GitHub Self-Hosted","permalink":"/blog/2024/02/11/04-ci-cd/self-host-runner"}},"content":"GitHub Container Registry (GHCR) est un service d\'h\xe9bergement de packages logiciels propos\xe9 par GitHub, permettant aux utilisateurs de stocker des packages priv\xe9s ou publics et de les utiliser comme d\xe9pendances dans leurs projets. Compatible avec plusieurs langages de programmation, GitHub Packages propose des registres pour des gestionnaires de packages tels que npm, RubyGems, Maven, Gradle, Docker, et NuGet. L\'authentification sur GitHub Packages se fait exclusivement via un \\"personal access token (classic)\\". Les utilisateurs doivent disposer de ce token pour effectuer des op\xe9rations telles que la publication, l\'installation et la suppression de packages, qu\'ils soient publics, priv\xe9s ou internes. Pour les packages priv\xe9s, GitHub Packages applique des limites de stockage et de transfert de donn\xe9es en fonction du plan du compte. La gestion des packages peut \xeatre r\xe9alis\xe9e \xe0 travers l\'interface utilisateur GitHub ou via l\'API REST. Des webhooks peuvent \xe9galement \xeatre configur\xe9s pour suivre des \xe9v\xe9nements li\xe9s aux packages, comme la publication ou la mise \xe0 jour.\\n\\n\x3c!--truncate--\x3e\\n\\nLe workflow suppose que vous avez un `Dockerfile` \xe0 la racine du d\xe9p\xf4t. Ce `Dockerfile` doit r\xe9ussir la commande de `build` avec succ\xe8s\\n\\n## Cr\xe9ez un fichier YAML pour le Workflow\\n\\nCr\xe9ez un fichier YAML (par exemple, `docker-publish.yml`) dans le r\xe9pertoire `.github/workflows/` de votre d\xe9p\xf4t avec le contenu suivant :\\n\\n```yaml\\nname: Create and publish a Docker image\\n\\non:\\n    push:\\n    branches: [\'release\']\\n\\nenv:\\n    REGISTRY: ghcr.io\\n    IMAGE_NAME: ${{ github.repository }}\\n\\njobs:\\n    build-and-push-image:\\n    runs-on: ubuntu-latest\\n\\n    permissions:\\n        contents: read\\n        packages: write\\n\\n    steps:\\n        - name: Checkout repository\\n        uses: actions/checkout@v4\\n\\n        - name: Log in to the Container registry\\n        uses: docker/login-action@65b78e6e13532edd9afa3aa52ac7964289d1a9c1\\n        with:\\n            registry: ${{ env.REGISTRY }}\\n            username: ${{ github.actor }}\\n            password: ${{ secrets.GITHUB_TOKEN }}\\n\\n        - name: Extract metadata (tags, labels) for Docker\\n        id: meta\\n        uses: docker/metadata-action@9ec57ed1fcdbf14dcef7dfbe97b2010124a938b7\\n        with:\\n            images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\\n\\n        - name: Build and push Docker image\\n        uses: docker/build-push-action@f2a1d5e99d037542a71f64918e516c093c6f3fc4\\n        with:\\n            context: .\\n            push: true\\n            tags: ${{ steps.meta.outputs.tags }}\\n            labels: ${{ steps.meta.outputs.labels }}\\n```\\n\\n### Configurez les Options du Workflow\\n\\nDans le fichier YAML, vous pouvez personnaliser les options suivantes selon vos besoins :\\n\\n- `branches`: Modifiez la branche d\xe9clenchant le workflow.\\n- `REGISTRY` et `IMAGE_NAME`: Modifiez-les si vous souhaitez utiliser un autre registre ou nom d\'image.\\n- `permissions`: Ajustez les autorisations en fonction de vos besoins.\\n\\n**Enregistrez et Poussez vos Modifications**\\nEnregistrez les modifications dans le fichier YAML et poussez-les vers la branche \\"release\\" de votre d\xe9p\xf4t GitHub.\\n\\n```shell\\ngit add .github/workflows/docker-publish.yml\\ngit commit -m \\"Ajout du workflow de publication Docker\\"\\ngit push origin release\\n```\\n\\n## Utilisation d\u2019un package GHCR\\n\\nUne fois d\xe9ploy\xe9, le package s\u2019utilise comme n\u2019importe quel docker\\n\\n```shell\\ndocker pull ghcr.io/{USER}/{REPO-NAME}:master\\n```\\n\\n\ud83d\udca1 L\u2019utilisation des Github GHCR entraine des consommations d\u2019espace. Le CATIE a le droit \xe0 2Gb de stockage sur GHCR et 10Gb de transit par mois. Au del\xe0 de ces limites, nous sommes factur\xe9s.\\nL\u2019utilisation (sous n\u2019importe quelle forme) de GHCR sur des d\xe9p\xf4ts **publics** est totalement gratuite Sur des d\xe9p\xf4ts priv\xe9s : le pull via des actions est gratuit. Pour les actions `self-hosted` le pull est gratuit si l\u2019action est authentifi\xe9e par le `GITHUB_TOKEN` et non un PAT.\\n\\nVoici un exemple d\u2019utilisation sans co\xfbt associ\xe9\\n\\n```yaml\\nname: Run in container from GHCR\\n\\non: [ push ]\\n\\njobs:\\n    myJob:\\n    runs-on: ubuntu-latest\\n    container:\\n        image: ghcr.io/sedelpeuch/github-ghcr-test:master\\n    steps:\\n\\n        - name: Checkout code\\n        uses: actions/checkout@v2\\n\\n        - name: Run a command\\n        run: echo \\"Running inside the container\\"\\n```\\n\\nL\u2019image [ghcr.io/sedelpeuch/github-ghcr-test:master](<http://ghcr.io/sedelpeuch/github-ghcr-test:master>) est priv\xe9e, l\u2019acc\xe8s est possible sans donner de PAT gr\xe2ce \xe0 l\u2019authentification par jeton automatique qui poss\xe8de la lecture des packages priv\xe9s [https://docs.github.com/fr/actions/security-guides/automatic-token-authentication#permissions-for-the-github_token](https://docs.github.com/fr/actions/security-guides/automatic-token-authentication#permissions-for-the-github_token)"},{"id":"/2024/02/11/04-ci-cd/self-host-runner","metadata":{"permalink":"/blog/2024/02/11/04-ci-cd/self-host-runner","source":"@site/blog/04-ci-cd/2024-02-11-self-host-runner.md","title":"Runner GitHub Self-Hosted","description":"Explication de la cr\xe9ation et de l\'installation d\'un nouveau runner au niveau de l\'organisation","date":"2024-02-11T00:00:00.000Z","tags":[{"inline":true,"label":"CI/CD","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":2.35,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Runner GitHub Self-Hosted","description":"Explication de la cr\xe9ation et de l\'installation d\'un nouveau runner au niveau de l\'organisation","tags":["CI/CD","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"GitHub GHCR","permalink":"/blog/2024/02/18/04-ci-cd/ghrc"},"nextItem":{"title":"Actions Composites","permalink":"/blog/2024/02/04/04-ci-cd/action"}},"content":"Un `runner` est une machine virtuelle ou physique qui ex\xe9cute des `jobs` dans un `workflow`. Les `runners` peuvent \xeatre h\xe9berg\xe9s par GitHub ou auto-h\xe9berg\xe9s. Les `runners` h\xe9berg\xe9s par GitHub sont ex\xe9cut\xe9s dans un environnement de cloud partag\xe9 et sont g\xe9r\xe9s par GitHub et peuvent entrainer des surcouts. Les `runners` auto-h\xe9berg\xe9s sont ex\xe9cut\xe9s sur une machine que vous poss\xe9dez et g\xe9rez.\\n\\n\x3c!--truncate--\x3e\\n\\nPour t\xe9l\xe9charger un nouveau `runner`, ex\xe9cutez les lignes suivantes\\n\\n```shell\\n# Create a folder\\nmkdir actions-runner && cd actions-runner\\n# Download the latest runner package\\ncurl -o actions-runner-linux-x64-2.312.0.tar.gz -L <https://github.com/actions/runner/releases/download/v2.312.0/actions-runner-linux-x64-2.312.0.tar.gz> # ! update this documentation with the latest release\\n# Optional: Validate the hash\\necho \\"85c1bbd104d539f666a89edef70a18db2596df374a1b51670f2af1578ecbe031  actions-runner-linux-x64-2.312.0.tar.gz\\" | shasum -a 256 -c\\n# Extract the installer\\ntar xzf ./actions-runner-linux-x64-2.312.0.tar.gz\\n```\\n\\nIl est ensuite n\xe9cessaire de configurer votre `runner`\\n\\n```shell\\n# Create the runner and start the configuration experience\\n./config.sh --url <https://github.com/><org>/<repo> --token <token># Last step, run it!\\n./run.sh\\n```\\n\\n:::info\\nLe token est \xe0 obtenir au pr\xe8s d\u2019un `owner` de l\u2019organisation accessible sur le lien suivant [https://github.com/organizations/](https://github.com/organizations/org/settings/actions/runners/new?arch=x64&os=linux)\\n:::\\n\\n\u27a1\ufe0f Lors de la configuration, il est possible d\'ajouter des **labels** pour identifier la machine (par exemple `GPU`).\\n\\n## Cr\xe9er une action `self-hosted`\\n\\nIl n\u2019est pas possible de cr\xe9er une action visant une machine `self-hosted` particuli\xe8re (\xe0 confirmer). Chaque `repository` d\u2019une organisation peut acc\xe9der \xe0 :\\n\\n- Toutes les machines dans le groupe `D\xe9faut` qui sont automatiquement partag\xe9es \xe0 tous les d\xe9p\xf4ts.\\n- Toutes les machines dans un groupe `Name` qui sont manuellement partag\xe9es au d\xe9p\xf4t concern\xe9 (l\u2019affectation manuelle des d\xe9p\xf4ts \xe0 des groupes de machines nous encourage \xe0 ne pas utiliser ceci sauf cas particulier)\\n\\nParmi les machines disponibles le `repository` peut demander d\u2019utiliser une machine en fonction de son `label` par exemple l\u2019action ci-dessous, permettant de v\xe9rifier que le d\xe9p\xf4t est compilable sous ROS, r\xe9quisitionne une machine ayant le label `Robotics`. Ceci est modifiable \xe0 la ligne `runs-on: Robotics`.\\n\\n```yaml\\nname: CI\\n\\non: [pull_request]\\n\\njobs:\\n  industrial_ci:\\n    strategy:\\n      matrix:\\n        env:\\n          - {ROS_DISTRO: melodic, ROS_REPO: main}\\n    runs-on: Robotics\\n    steps:\\n      - uses: actions/checkout@v3\\n      - uses: \'ros-industrial/industrial_ci@master\'\\n        env: ${{matrix.env}}\\n```\\n\\nLors de la premi\xe8re utilisation, si vous rencontrez un erreur `docker` sp\xe9cifiant un manque de permission, il est n\xe9cessaire de taper la commande suivante sur la machine distance `sudo setfacl --modify user:<user>:rw /var/run/docker.sock`\\nLorsqu\u2019une action est cr\xe9\xe9 en `self-hosted` il est fortement conseill\xe9 de mettre les actions dans un `container`. Lorsque c\u2019est impossible (comme `tailscale`) il est n\xe9cessaire d\u2019ajouer un clean de l\u2019environnement \xe0 la fin de l\u2019action en ajoutant cette `step`\\n\\n```yaml\\n- name: Clean runner\\n  if: always()\\n  run: rm -rf ${{ github.workspace }}/*\\n```\\n\\n## Mettre en place le runner sous forme de service\\n\\nDans le dossier de votre `runnner` sur la machine, transformer le `./run.sh` en service, tapez simplement les lignes ci-dessous pour que le `runner` s\u2019active au d\xe9marrage de la machine.\\n\\n```shell\\nsudo ./svc.sh install\\nsudo ./svc.sh start\\n```"},{"id":"/2024/02/04/04-ci-cd/action","metadata":{"permalink":"/blog/2024/02/04/04-ci-cd/action","source":"@site/blog/04-ci-cd/2024-02-04-action.md","title":"Actions Composites","description":"Cr\xe9\xe9er une action r\xe9utilisable","date":"2024-02-04T00:00:00.000Z","tags":[{"inline":true,"label":"CI/CD","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":2.81,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Actions Composites","description":"Cr\xe9\xe9er une action r\xe9utilisable","tags":["CI/CD","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Runner GitHub Self-Hosted","permalink":"/blog/2024/02/11/04-ci-cd/self-host-runner"},"nextItem":{"title":"Workflows","permalink":"/blog/2024/02/04/04-ci-cd/workflow"}},"content":"Les actions GitHub permettent d\'automatiser, personnaliser et ex\xe9cuter un flux de travail directement depuis votre d\xe9p\xf4t. Avec les actions GitHub, il est possible de cr\xe9er des t\xe2ches personnalis\xe9es pour automatiser un flux de travail, partager et d\xe9couvrir des actions pour effectuer des t\xe2ches sp\xe9cifiques.\\n\\n\x3c!--truncate--\x3e\\n\\n## Comment cr\xe9er ses propres actions\\n\\nDocumentation compl\xe8te : [https://docs.github.com/fr/actions/creating-actions](https://docs.github.com/fr/actions/creating-actions)\\n\\nPr\xe9requis : [Workflow](/blog/04-ci-cd/2024-02-04-workflow.md)\\n\\nLa cr\xe9ation d\'actions personnalis\xe9es offre la possibilit\xe9 de concevoir du code sp\xe9cifique qui interagit avec le d\xe9p\xf4t selon les besoins. Ces actions peuvent s\'int\xe9grer aux API de GitHub ou \xe0 toute API tierce accessible publiquement. Par exemple, une action pourrait \xeatre configur\xe9e pour publier des modules npm, envoyer des alertes par SMS en cas de cr\xe9ation de probl\xe8mes urgents, ou encore d\xe9ployer du code pr\xeat pour la production.\\nCe guide expose les \xe9l\xe9ments fondamentaux requis pour la cr\xe9ation et l\'utilisation d\'une action composite empaquet\xe9e.\\n\\n:::warning\\nLors de la cr\xe9ation de flux de travail et d\'actions, il est imp\xe9ratif d\'\xe9valuer constamment la possibilit\xe9 d\'ex\xe9cution d\'une entr\xe9e non fiable provenant de sources potentiellement malveillantes. Certains contextes doivent \xeatre trait\xe9s comme des entr\xe9es non fiables, car un attaquant pourrait ins\xe9rer son propre contenu malveillant. Pour de plus amples informations, veuillez consulter la section \xab [Durcissement de la s\xe9curit\xe9 pour GitHub Actions](https://docs.github.com/fr/actions/security-guides/security-hardening-for-github-actions#understanding-the-risk-of-script-injections) \xbb.\\n:::\\n\\n## Cr\xe9ation d\u2019une action\\n\\nUn d\xe9p\xf4t doit \xeatre cr\xe9\xe9 sur [GitHub.com](http://GitHub.com).\\n\\n- Cr\xe9ez un nouveau d\xe9p\xf4t sur [GitHub](http://GitHub.com), en choisissant n\'importe quel nom de d\xe9p\xf4t ou en utilisant l\'exemple suivant : `hello-world-composite-action`. Les fichiers peuvent \xeatre ajout\xe9s une fois que le projet est pouss\xe9 sur GitHub. Pour plus d\'informations, veuillez vous r\xe9f\xe9rer \xe0 la section [Cr\xe9ation d\'un d\xe9p\xf4t](https://docs.github.com/fr/repositories/creating-and-managing-repositories/creating-a-new-repository).\\n- Dans le d\xe9p\xf4t `hello-world-composite-action`, cr\xe9ez un fichier nomm\xe9 `goodbye.sh` et ajoutez le code `echo \\"Goodbye`\\n- Rendez `goodbye.sh` ex\xe9cutable depuis votre terminal.\\n- Dans le d\xe9p\xf4t `hello-world-composite-action`, cr\xe9ez un fichier nomm\xe9 `action.yml` et ajoutez le code suivant en exemple. Pour plus d\'informations sur cette syntaxe, consultez la section [Syntaxe des m\xe9tadonn\xe9es pour les actions GitHub](https://docs.github.com/fr/actions/creating-actions/metadata-syntax-for-github-actions#runs-for-composite-actions) .\\n\\n```yaml\\n    name: \'Hello World\'\\n    description: \'Greet someone\'\\n    inputs:\\n      who-to-greet:  # id of input\\n        description: \'Who to greet\'\\n        required: true\\n        default: \'World\'\\n    outputs:\\n      random-number:\\n        description: \\"Random number\\"\\n        value: ${{ steps.random-number-generator.outputs.random-number }}\\n    runs:\\n      using: \\"composite\\"\\n      steps:\\n        - run: echo Hello ${{ inputs.who-to-greet }}.\\n          shell: bash\\n        - id: random-number-generator\\n          run: echo \\"random-number=$(echo $RANDOM)\\" >> $GITHUB_OUTPUT\\n          shell: bash\\n        - run: echo \\"${{ github.action_path }}\\" >> $GITHUB_PATH\\n          shell: bash\\n        - run: goodbye.sh\\n          shell: bash\\n```\\n\\n- Ce fichier d\xe9finit l\'entr\xe9e `who-to-greet`, mappe le nombre g\xe9n\xe9r\xe9 al\xe9atoirement \xe0 la variable de sortie `random-number`, ajoute le chemin d\'acc\xe8s de l\'action au chemin d\'acc\xe8s du syst\xe8me de l\'ex\xe9cuteur (pour localiser le script `goodbye.sh` lors de l\'ex\xe9cution) et ex\xe9cute le script .\\n- Effectuez le commit de votre fichier `action.yml` depuis votre terminal.\\n\\n```shell\\n    git add action.yml\\n    git commit -m \\"Add action\\"\\n    git push\\n```\\n\\n- Ajoutez une \xe9tiquette depuis votre terminal. Cet exemple utilise une \xe9tiquette nomm\xe9e `v1`.\\n\\n```shell\\n    git tag -a -m \\"Description of this release\\" v1\\n    git push --follow-tags\\n```\\n\\n## Tester l\u2019action dans un workflow\\n\\nCopiez le code de workflow dans un fichier `.github/workflows/main.yml` d\'un autre d\xe9p\xf4t\\n\\n```yaml\\n    on: [push]\\n\\n    jobs:\\n      hello_world_job:\\n        runs-on: ubuntu-latest\\n        name: A job to say hello\\n        steps:\\n          - uses: actions/checkout@v4\\n          - id: foo\\n            uses: actions/hello-world-composite-action@v1\\n            with:\\n              who-to-greet: \'Mona the Octocat\'\\n          - run: echo random-number ${{ steps.foo.outputs.random-number }}\\n            shell: bash\\n```\\n\\n## Action dans un workflow priv\xe9\\n\\nDans les param\xe8tres des actions, il est n\xe9cessaire de la partager \xe0 l\u2019organisation\\n\\n![AllowAction](/img/allow_action.png)"},{"id":"/2024/02/04/04-ci-cd/workflow","metadata":{"permalink":"/blog/2024/02/04/04-ci-cd/workflow","source":"@site/blog/04-ci-cd/2024-02-04-workflow.md","title":"Workflows","description":"Cr\xe9\xe9er un workflow avec GitHub Actions","date":"2024-02-04T00:00:00.000Z","tags":[{"inline":true,"label":"CI/CD","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":4.765,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Workflows","description":"Cr\xe9\xe9er un workflow avec GitHub Actions","tags":["CI/CD","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Actions Composites","permalink":"/blog/2024/02/04/04-ci-cd/action"},"nextItem":{"title":"DevOps Roadmap","permalink":"/blog/2024/02/02/devops-roadmap"}},"content":"Un workflow est l\'\xe9l\xe9ment central de GitHub Actions. Il s\'agit d\'un processus automatis\xe9 compos\xe9 de `jobs` et de `steps` qui s\'ex\xe9cutent sur des `runners`. Les workflows sont d\xe9clench\xe9s par des \xe9v\xe9nements, tels que des pushs, des pull requests, des forks, etc.\\n\\n\x3c!--truncate--\x3e\\n\\nPour cr\xe9er un fichier de workflow, il faut cr\xe9er un fichier `.yml` dans le dossier `.github/workflows` du d\xe9p\xf4t. Un workflow est compos\xe9 de `jobs` et de `steps`. Un `job` est une suite d\'\xe9tapes qui s\'ex\xe9cutent sur le m\xeame runner, tandis qu\'un `step` est une t\xe2che individuelle qui peut s\'ex\xe9cuter dans un `job`. Chaque `job` est ex\xe9cut\xe9 dans un environnement d\xe9di\xe9 d\xe9fini par [`runs-on`](#type-de-machine).\\n\\n```yml\\nname: CI\\n\\non: [push]\\n\\njobs:\\n  build:\\n    runs-on: ubuntu-latest\\n    steps:\\n      - uses: actions/checkout@v2\\n      - name: Run a one-line script\\n        run: echo Hello, world!\\n      - name: Run a multi-line script\\n        run: |\\n          echo Add other actions to build,\\n          echo test, and deploy your project.\\n```\\n\\nDocumentation Compl\xe8te  : [https://docs.github.com/en/actions/learn-github-actions/introduction-to-github-actions](https://docs.github.com/en/actions/learn-github-actions/introduction-to-github-actions)\\n\\n## D\xe9clenchement des actions\\n\\nLes d\xe9clencheurs de workflow sont des \xe9v\xe9nements qui entra\xeenent l\u2019ex\xe9cution d\u2019un workflow. La syntaxe d\xe9pend du niveau de pr\xe9cision\\n\\n- Pour tout ce qui concerne un \xe9v\xe9nement :\\n\\n```yaml\\n    on: [push] # pull_request, fork etc\\n```\\n\\n- Pour plus de finesse sur l\u2019\xe9v\xe9nement :\\n\\n```yaml\\n    on: # trigger\\n      label: # type d\'event (push, fork, pull_request)\\n        types:\\n          - created # trigger \xe0 chaque fois qu\'un label est cr\xe9\xe9\\n      push:\\n        branches:\\n          - main # tous les push sur la branche main\\n```\\n\\n- D\xe9clenchement manuel de l\u2019op\xe9ration (avec prise d\u2019argument)\\n\\n```yaml\\n    on:\\n      workflow_dispatch:\\n        inputs:\\n          test_mode:\\n            description: \'True or False\'\\n            required: true\\n```\\n\\nLa liste compl\xe8te des d\xe9clencheurs est disponible dans la [Documentation Github](https://docs.github.com/fr/actions/using-workflows/events-that-trigger-workflows)\\n\\nUne ex\xe9cution de workflow est compos\xe9e d\u2019un ou de plusieurs `jobs`, qui s\u2019ex\xe9cutent en parall\xe8le par d\xe9faut. Chaque job est constitu\xe9 d\u2019un `name` et d\u2019au moins un `step` pour \xeatre ex\xe9cutable et peut \xeatre configur\xe9.\\nLa documentation pr\xe9cise des job est disponible dans la [Documentation Github](https://docs.github.com/fr/actions/using-workflows/workflow-syntax-for-github-actions#jobs)\\n\\n## Marketplace\\n\\nChaque `job` permet d\u2019ex\xe9cuter un script. Le script le plus basique est un simple `run` avec des commandes `bash` derri\xe8re. Cependant, il est possible de r\xe9utiliser des actions d\xe9finies dans le marketplace. Par exemple le `steps` ci-dessous permet d\u2019ex\xe9cuter l\u2019action [https://github.com/ros-tooling/action-ros-ci](https://github.com/ros-tooling/action-ros-ci). Le mot cl\xe9 `with` permet de passer des param\xe8tres \xe0 l\u2019action.\\n\\n:::danger\\nLe marketplace permet de r\xe9utiliser des actions d\xe9j\xe0 d\xe9finies par la communaut\xe9. Il est important de v\xe9rifier la source de l\u2019action avant de l\u2019utiliser.\\n:::\\n\\n```yaml\\nsteps:\\n    - name: build and test ROS 2\\n    uses: ros-tooling/action-ros-ci@v0.2\\n    with:\\n        package-name: github-action-test\\n        target-ros2-distro: ${{ matrix.ros_distribution }}\\n        import-token: ${{ secrets.GITHUB_TOKEN }} # token autogenerated par github\\n```\\n\\n## R\xe9utiliser les Workflows et Actions\\n\\nIl est possible de r\xe9utiliser des `workflows` et des `actions` dans un workflow. Pour cela, il est possible de cr\xe9er des `workflows` et des `actions` dans des fichiers s\xe9par\xe9s et de les appeler dans le workflow principal.\\n\\n```yaml\\njobs:\\n    workflow: # r\xe9utilisation du workflow\\n      uses: path/to/your-workflow.yml@v1\\n    action: # r\xe9utilisation d\'une action\\n      runs-on: ubuntu-latest\\n      container: ubuntu:latest\\n      steps:\\n        - uses: path/to/your-action@v1\\n```\\n\\n[Documentation des wokflows r\xe9utilisables](https://docs.github.com/en/actions/learn-github-actions/reusing-workflows)\\n\\n[Documentation des actions r\xe9utilisables](https://docs.github.com/en/actions/creating-actions/creating-a-composite-action)\\n\\n:::info\\n\\nLorsqu\'un workflow est r\xe9utilis\xe9 il d\xe9fini son propre environnement (runner, container, etc). De plus il n\'est pas utilisable dans une `step`.\\n\\n\xc0 l\'inverse, une action est utilisable dans une `step` et fonctionne dans l\'environnement du `job` qui l\'appelle.\\n:::\\n\\n## Type de machine\\n\\nUtilisez `jobs.<job_id>.runs-on` pour d\xe9finir le type de machine sur laquelle le travail doit \xeatre ex\xe9cut\xe9. La configuration prend en argument un `tag` d\xe9fini pour les runners\\n\\n```yaml\\njobs:\\n    name-job:\\n    runs-on: ubuntu-latest # runner distant sur les serveur de Github\\n    runs-on: self-hosted # runner local\\n    steps:\\n        - run: echo \\"Hello World !\\"\\n```\\n\\nLes `runners` distants fourni par Github consomment du temps pour l\u2019organisation dans les limites de 2 000 minutes gratuites par mois. Il est pr\xe9f\xe9rable d\u2019utiliser des `runners self hosted` (voir [https://docs.github.com/fr/actions/hosting-your-own-runners/managing-self-hosted-runners/about-self-hosted-runners](https://docs.github.com/fr/actions/hosting-your-own-runners/managing-self-hosted-runners/about-self-hosted-runners))\\n\\nLe choix du `runner` se fait via les tags. Toutes les machines auto-h\xe9berg\xe9es partagent le tag `self-hosted` , le tag de leur syst\xe8me d\u2019exploitation (`Linux`, `Windows`), leur architecture (`x64`) et des tags personnalis\xe9s par machine.\\n\\n## Container\\n\\nL\u2019utilisation d\u2019un `container` permet de cr\xe9er un nouveau conteneur permettant d\u2019ex\xe9cuter les \xe9tapes d\u2019un travail dans un conteneur sp\xe9cifif\xe9. Si vous ne d\xe9finissez pas de `container`, toutes les \xe9tapes s\u2019ex\xe9cutent directement sur l\u2019h\xf4te sp\xe9cifi\xe9 par `runs-on` dans le cas d\u2019une machine auto-h\xe9berg\xe9es, il n\u2019y a donc acc\xe8s qu\u2019aux packages install\xe9s sur la machine. Un `container` est rattach\xe9 \xe0 un `job`.\\n\\n```yaml\\njobs:\\n    name-job:\\n    runs-on: self-hosted\\n    container:\\n    image: ubuntu:jammy # run job with ubuntu:jammy docker\\n        steps:\\n            - run: echo \\"Hello World !\\"\\n```\\n\\n## Strategy\\n\\nL\u2019utilisation de `strategy` permet cr\xe9er automatiquement plusieurs ex\xe9cutions de travaux bas\xe9es sur des combinaisons de variables. Une strat\xe9gie de matrice est utile pour tester du code dans diff\xe9rentes versions d\'un langage ou sur diff\xe9rents syst\xe8mes d\'exploitation.\\nPar exemple\\n\\n```yaml\\njobs:\\n    example_matrix:\\n    strategy:\\n        matrix:\\n        version: [10, 12, 14]\\n        os: [ubuntu-latest, windows-latest]\\n        steps:\\n            - run : echo \\"${{ matrix.version }} ${{ matrix.os }}\\"\\n```\\n\\nUn travail s\u2019ex\xe9cute pour chaque combinaison possible des variables. Dans cet exemple, le workflow ex\xe9cute six travaux, un pour chaque combinaison des variables `os` et `version`.\\n\\n## Art\xe9fact\\n\\nLes artefacts permettent de conserver des donn\xe9es une fois un travail termin\xe9 et de les partager avec une autre action. Un artefact est un fichier ou une collection de fichiers g\xe9n\xe9r\xe9s pendant l\u2019ex\xe9cution d\u2019un workflow. Cet exemple permet de stocker un fichier comme artefact.\\n\\n```yaml\\n- name: Archive code coverage results\\n    uses: actions/upload-artifact@v3\\n    with:\\n        name: code-coverage-report\\n        path: output/test/code-coverage.html\\n```\\n\\nPour r\xe9cup\xe9rer un artefact\\n\\n```yaml\\n- name: Download math result for job 2\\n    uses: actions/download-artifact@v3\\n    with:\\n        name: homework\\n```\\n\\n## Vrac\\n\\n- `needs` le job actuel ne commencera que quand le job mentionn\xe9 sera termin\xe9\\n- `if` condition de lancement du job\\n- `permission` permet d\u2019augmenter les droits du `GITHUB_TOKEN` (voir [https://docs.github.com/fr/actions/security-guides/automatic-token-authentication#permissions-for-the-github_token](https://docs.github.com/fr/actions/security-guides/automatic-token-authentication#permissions-for-the-github_token))\\n- `environnement` permet de d\xe9finir des variables d\u2019environnement"},{"id":"/2024/02/02/devops-roadmap","metadata":{"permalink":"/blog/2024/02/02/devops-roadmap","source":"@site/blog/2024-02-02-devops-roadmap.md","title":"DevOps Roadmap","description":"Pr\xe9sentation de ma roadmap DevOps personnelle 2024","date":"2024-02-02T00:00:00.000Z","tags":[{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"},{"inline":true,"label":"Roadmap","permalink":"/blog/tags/roadmap"}],"readingTime":6.335,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"DevOps Roadmap","description":"Pr\xe9sentation de ma roadmap DevOps personnelle 2024","tags":["Devops","Roadmap"]},"unlisted":false,"prevItem":{"title":"Workflows","permalink":"/blog/2024/02/04/04-ci-cd/workflow"}},"content":"Ing\xe9nieur en informatique au [CATIE](http://catie.fr/) sp\xe9cialis\xe9 en Robotique je suis amen\xe9 \xe0 travailler sur des projets de d\xe9veloppement logiciel et d\'int\xe9gration sur diff\xe9rentes plateformes. Intrigu\xe9 et passion\xe9 par l\'int\xe9gration et l\'automatisation des t\xe2ches, j\'ai d\xe9cid\xe9 d\'approfondir mes connaissances en DevOps.\\n\\n\x3c!--truncate--\x3e\\n\\nVoici un r\xe9sum\xe9 de ma roadmap DevOps personnelle pour 2024. Cette roadmap est bas\xe9e sur mes exp\xe9riences et mes objectifs personnels. Elle est sujette \xe0 des changements et des mises \xe0 jour r\xe9guli\xe8res. N\'h\xe9sitez pas \xe0 me contacter si vous avez des suggestions ou des commentaires.\\n\\n# DevOps Roadmap\\n\\nimport IconTitle from \'@site/src/components/IconTitle\';\\n\\n![DevOps](/img/devops.png)\\n\\nL\xe9gende :\\n\\n- [ ] \xc0 apprendre\\n- [x] En cours d\'apprentissage\\n- [x] ~~Ma\xeetris\xe9~~\\n\\n## <IconTitle logo=\\"mdi:code-braces\\" name=\\"Concepts du d\xe9veloppement logiciel\\"/>\\n\\nEn tant qu\'ing\xe9nieur DevOps, vous ne programmerez pas l\'application, mais comme vous travaillez en \xe9troite collaboration avec l\'\xe9quipe de d\xe9veloppement pour am\xe9liorer et automatiser les t\xe2ches pour eux, vous devez comprendre les concepts de :\\n\\n- [x] Collaboration des d\xe9veloppeurs (Agile, Jira)\\n- [x] ~~Utilisation de Git~~\\n- [x] Configuration des applications (Outils de build)\\n- [x] ~~Compr\xe9hension du cycle de vie du d\xe9veloppement logiciel~~\\n- [x] Tests automatis\xe9s\\n\\n## <IconTitle logo=\\"skill-icons:linux-light\\" name=\\"OS & Linux\\"/>\\n\\nEn tant qu\'ing\xe9nieur DevOps, vous \xeates responsable de la pr\xe9paration et de la maintenance de l\'infrastructure (serveurs) sur laquelle l\'application est d\xe9ploy\xe9e. Vous devez donc conna\xeetre les bases de l\'administration d\'un serveur et de l\'installation de diff\xe9rents outils sur celui-ci. Voici les concepts de base des syst\xe8mes d\'exploitation que vous devez comprendre :\\n\\n- [x] ~~Commandes Shell~~\\n- [x] ~~Syst\xe8me de fichiers Linux & Permissions~~\\n- [x] ~~Gestion des cl\xe9s SSH~~\\n- [x] Notions de base de la mise en r\xe9seau et de la s\xe9curit\xe9\\n- [x] Configuration des pare-feu pour s\xe9curiser l\'acc\xe8s\\n- [x] ~~Comprendre comment fonctionnent les adresses IP, les ports et le DNS~~\\n- [ ] \xc9quilibreurs de charge\\n- [x] Proxies\\n- [x] ~~HTTP/HTTPS~~\\n- [x] Virtualisation\\n\\n## <IconTitle logo=\\"skill-icons:docker\\" name=\\"Conten\xe9risation - Docker\\"/>\\n\\nLes conteneurs sont devenus le nouveau standard de l\'emballage logiciel, vous ex\xe9cuterez probablement votre application en tant que conteneur. Cela signifie que vous devez g\xe9n\xe9ralement comprendre :\\n\\n- [ ] Concepts de virtualisation\\n- [x] ~~Concepts de conteneurisation~~\\n- [x] Comment g\xe9rer les applications conteneuris\xe9es sur un serveur.\\n\\nDocker est de loin la technologie de conteneur la plus populaire ! Voici quelques points que vous devriez conna\xeetre :\\n\\n- [x] ~~Ex\xe9cuter des conteneurs~~\\n- [x] ~~Inspecter les conteneurs actifs~~\\n- [x] ~~R\xe9seau Docker~~\\n- [x] ~~Persister les donn\xe9es avec les volumes Docker~~\\n- [x] ~~Dockeriser les applications en utilisant Dockerfiles~~\\n- [x] ~~Ex\xe9cuter plusieurs conteneurs en utilisant Docker-Compose~~\\n- [x] ~~Travailler avec le d\xe9p\xf4t Docker~~\\n\\nLes conteneurs et les machines virtuelles ont des avantages similaires en termes d\'isolation et d\'allocation des ressources, mais fonctionnent diff\xe9remment. Les VMs virtualisent tout le syst\xe8me d\'exploitation. Les conteneurs virtualisent uniquement le niveau d\'application du syst\xe8me d\'exploitation. Par cons\xe9quent, les conteneurs sont plus l\xe9gers et plus rapides.\\n\\n## <IconTitle logo=\\"skill-icons:githubactions-light\\" name=\\"CI/CD Pipeline\\"/>\\n\\nCI/CD Pipelines\\n\\nCI/CD est en quelque sorte le c\u0153ur de DevOps. En DevOps, toutes les modifications de code, comme les nouvelles fonctionnalit\xe9s ou les corrections de bugs, doivent \xeatre int\xe9gr\xe9es dans l\'application existante et d\xe9ploy\xe9es pour l\'utilisateur final de mani\xe8re continue et automatis\xe9e. D\'o\xf9 le terme :\\nInt\xe9gration Continue et D\xe9ploiement Continu (CI/CD)\\n\\nComp\xe9tences que vous devez apprendre ici :\\n\\n- [x] ~~Configuration du serveur CI/CD~~\\n- [x] ~~Int\xe9gration du d\xe9p\xf4t de code pour d\xe9clencher le pipeline automatiquement~~\\n- [x] Outils de construction et de gestion de packages pour ex\xe9cuter les tests et emballer l\'application\\n- [x] Configuration des d\xe9p\xf4ts d\'artefacts (comme Nexus) et int\xe9gration avec le pipeline\\n\\n## <IconTitle logo=\\"skill-icons:aws-light\\" name=\\"Apprendre un fournisseur de Cloud\\"/>\\n\\nDe nos jours, de nombreuses entreprises utilisent une infrastructure virtuelle sur le cloud, au lieu de g\xe9rer leur propre infrastructure. Ce sont des plateformes Infrastructure as a Service (IaaS), qui offrent une gamme de services suppl\xe9mentaires, comme la sauvegarde, la s\xe9curit\xe9, l\'\xe9quilibrage de charge, etc.\\n\\nAWS est la plateforme IaaS la plus puissante et la plus largement utilis\xe9e, mais aussi une des plus difficiles. D\'autres populaires : Microsoft Azure, Google Cloud.\\n\\nCes services sont sp\xe9cifiques \xe0 la plateforme. Vous devez donc apprendre les services de cette plateforme sp\xe9cifique et apprendre \xe0 g\xe9rer toute l\'infrastructure de d\xe9ploiement sur celle-ci. Par exemple, pour AWS, vous devez conna\xeetre les bases de :\\n\\n- [ ] Service IAM - gestion des utilisateurs et des permissions\\n- [ ] Service VPC - votre r\xe9seau priv\xe9\\n- [ ] Service EC2 - serveurs virtuels\\n\\n## <IconTitle logo=\\"skill-icons:kubernetes\\" name=\\"Orchestration de conteneurs - Kubernetes & Docker Swarm\\"/>\\n\\nComme les conteneurs sont populaires et faciles \xe0 utiliser, de nombreuses entreprises ex\xe9cutent des centaines ou des milliers de conteneurs sur plusieurs serveurs. Cela signifie que ces conteneurs doivent \xeatre g\xe9r\xe9s d\'une mani\xe8re ou d\'une autre.\\n\\n\xc0 cette fin, il existe des outils d\'orchestration de conteneurs. Kubernetes (\xe9galement connu sous le nom de K8s) est l\'outil d\'orchestration de conteneurs le plus populaire.\\n\\nVous devez donc apprendre :\\n\\n- [x] ~~Apprendre les composants de base comme, Deployment, Service, ConfigMap, Secret, StatefulSet,~~ Ingress\\n- [x] CLI Kubernetes (Kubectl)\\n- [x] Persistance des donn\xe9es avec les volumes K8s\\n- [x] Namespaces\\n- [ ] Docker Swarm\\n\\n## <IconTitle logo=\\"skill-icons:prometheus\\" name=\\"Monitoring & Observabilit\xe9\\"/>\\n\\nUne fois que le logiciel est en production, il est important de le surveiller pour suivre les performances, d\xe9couvrir les probl\xe8mes dans votre infrastructure et l\'application. Donc, l\'une de vos responsabilit\xe9s en tant qu\'ing\xe9nieur DevOps est de :\\n\\n- [ ] Prometheus : Un outil de surveillance et d\'alerte populaire\\n- [x] Grafana : Outil d\'analyse et de visualisation interactive\\n- [ ] ELK Stack : Une pile de gestion de logs populaire\\n\\n## <IconTitle logo=\\"skill-icons:terraform-light\\" name=\\"Infrastructure as Code\\"/>\\n\\nCr\xe9er et maintenir manuellement une infrastructure est chronophage et sujet \xe0 erreurs. Surtout lorsque vous devez r\xe9pliquer l\'infrastructure, par exemple pour un environnement de d\xe9veloppement, de test et de production.\\n\\nEn DevOps, nous voulons automatiser autant que possible et c\'est l\xe0 qu\'intervient l\'Infrastructure as Code.\\n\\n- [ ] Terraform est l\'outil de provisionnement d\'infrastructure le plus populaire\\n- [ ] Ansible est l\'outil de gestion de configuration le plus populaire\\n\\n## <IconTitle logo=\\"skill-icons:python-light\\" name=\\"Langages de script - Python\\"/>\\n\\nEn travaillant \xe9troitement avec les d\xe9veloppeurs et les administrateurs syst\xe8me pour automatiser les t\xe2ches de d\xe9veloppement et d\'op\xe9rations, vous aurez besoin d\'\xe9crire des scripts et de petites applications. Pour cela, vous aurez besoin de comp\xe9tences en scripting ou en programmation de base. Python est un langage largement utilis\xe9, facile \xe0 apprendre et utilis\xe9 pour de nombreux cas d\'utilisation diff\xe9rents, en particulier en DevOps.\\n\\n- [x] ~~Apprendre les bases de Python~~\\n- [x] ~~\xc9crire des scripts utilitaires, par exemple pour vider le cache, d\xe9marrer les builds et les d\xe9ploiements~~\\n- [x] ~~Comprendre les concepts de programmation de base~~\\n\\n<IconTitle logo=\\"skill-icons:git\\" name=\\"Contr\xf4le de version - Git\\"/>\\n\\nToute la logique d\'automatisation est \xe9crite sous forme de code. Tout comme le code d\'application, le code d\'automatisation doit \xe9galement \xeatre g\xe9r\xe9 et h\xe9berg\xe9 sur un outil de contr\xf4le de version, comme Git. Git est l\'outil de contr\xf4le de version le plus populaire et le plus largement utilis\xe9. Vos fichiers sont stock\xe9s de mani\xe8re centralis\xe9e dans un d\xe9p\xf4t Git distant sur le web. Les d\xe9p\xf4ts Git les plus populaires sont GitHub et GitLab. Git est un outil CLI, que vous installez localement. Il permet de suivre les modifications du code source et facilite la collaboration sur le code.\\n\\n- [x] ~~Apprendre \xe0 utiliser un d\xe9p\xf4t Git~~\\n- [x] ~~Ma\xeetriser les commandes de base de Git, comme git clone, git branch, git pull/push, git merge, etc.~~\\n- [x] ~~Apprendre \xe0 collaborer sur un projet, comme cr\xe9er des pull requests, faire des revues de code, g\xe9rer les branches~~"}]}}')}}]);