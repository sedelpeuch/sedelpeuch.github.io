"use strict";(self.webpackChunksedelpeuch_net=self.webpackChunksedelpeuch_net||[]).push([[8130],{77735(e){e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/2026/02/21/05-cloud/aws-cli","metadata":{"permalink":"/blog/2026/02/21/05-cloud/aws-cli","source":"@site/blog/05-cloud/2026-02-21-aws-cli.md","title":"AWS : CLI","description":"Installation, configuration et commandes courantes pour d\xe9marrer avec l\'AWS CLI v2.","date":"2026-02-21T00:00:00.000Z","tags":[{"inline":false,"label":"Cloud","permalink":"/blog/tags/cloud"},{"inline":true,"label":"aws","permalink":"/blog/tags/aws"},{"inline":true,"label":"cli","permalink":"/blog/tags/cli"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":2.93,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"AWS : CLI","description":"Installation, configuration et commandes courantes pour d\xe9marrer avec l\'AWS CLI v2.","tags":["cloud","aws","cli","devops"]},"unlisted":false,"nextItem":{"title":"AWS : Lambda","permalink":"/blog/2026/02/21/05-cloud/lambda"}},"content":"import Tabs from \'@theme/Tabs\';\\nimport TabItem from \'@theme/TabItem\';\\n\\nL\'AWS CLI (Command Line Interface) fournit un acc\xe8s en ligne de commande aux services AWS.\\n\\n\x3c!--truncate--\x3e\\n\\n## Installation\\n\\nLes distributions officielles de l\'AWS CLI v2 sont disponibles pour Linux, macOS et Windows. Choisir l\'onglet correspondant au syst\xe8me d\'exploitation pour l\'instruction d\'installation.\\n\\n<Tabs>\\n<TabItem value=\\"linux\\" label=\\"Linux\\">\\n\\nSur Linux (exemple Debian/Ubuntu) :\\n\\n```bash\\ncurl \\"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\\" -o \\"awscliv2.zip\\"\\nunzip awscliv2.zip\\nsudo ./aws/install\\naws --version\\n```\\n\\nPour d\'autres distributions, suivre le guide officiel adapt\xe9 au package manager (yum, apt, pacman).\\n\\n</TabItem>\\n<TabItem value=\\"macos\\" label=\\"macOS\\">\\n\\nSur macOS, utiliser Homebrew ou le package officiel :\\n\\n```bash\\n# Homebrew\\nbrew install awscli\\n\\n# V\xe9rifier\\naws --version\\n```\\n\\nOu t\xe9l\xe9charger le package macOS depuis la page officielle et installer via l\'installateur.\\n\\n</TabItem>\\n<TabItem value=\\"windows\\" label=\\"Windows\\">\\n\\nSur Windows, t\xe9l\xe9charger l\'installateur MSI depuis la page officielle et ex\xe9cuter l\'assistant d\'installation. Apr\xe8s installation, ouvrir PowerShell ou CMD et v\xe9rifier :\\n\\n```powershell\\naws --version\\n```\\n\\nPour Windows Subsystem for Linux (WSL), suivre les instructions Linux depuis l\'environnement WSL.\\n\\n</TabItem>\\n</Tabs>\\n\\n## Configuration initiale\\n\\nLa commande `aws configure` permet d\'initialiser un profil par d\xe9faut : cl\xe9 d\'acc\xe8s, cl\xe9 secr\xe8te, r\xe9gion et format de sortie.\\n\\n```bash\\naws configure\\n```\\n\\nPour g\xe9rer plusieurs comptes ou r\xf4les, utiliser des profils nomm\xe9s :\\n\\n```bash\\naws configure --profile dev\\naws --profile dev s3 ls\\n```\\n\\nLes fichiers principaux sont `~/.aws/credentials` et `~/.aws/config`.\\n\\n## M\xe9thodes d\'authentification\\n\\n- **Cl\xe9s d\'acc\xe8s (access key/secret)** : pratiques pour scripts, mais sensibles \u2014 les stocker dans `~/.aws/credentials` ou un gestionnaire s\xe9curis\xe9.\\n- **AWS SSO / Cognito** : pour comptes d\'entreprise, utiliser `aws sso login` (CLI v2) et profils SSO.\\n- **Assume role (STS)** : pour ex\xe9cuter des actions avec un r\xf4le diff\xe9rent : `aws sts assume-role` ou configurer `source_profile` + `role_arn` dans `~/.aws/config`.\\n- **Outils tiers** : `aws-vault`, `saml2aws` facilitent la gestion des sessions et la s\xe9curit\xe9 des credentials.\\n\\n## Commandes courantes (exemples)\\n\\n- S3 : transf\xe9rer un fichier\\n\\n```bash\\naws s3 cp ./index.html s3://mon-bucket/index.html --acl private --profile dev\\n```\\n\\n- EC2 : lister les instances\\n\\n```bash\\naws ec2 describe-instances --query \'Reservations[].Instances[].{ID:InstanceId,State:State.Name,IP:PublicIpAddress}\' --output table\\n```\\n\\n- Lambda : invoquer une fonction\\n\\n```bash\\naws lambda invoke --function-name my-func --payload \'{}\' response.json\\ncat response.json\\n```\\n\\n- STS : assumer un r\xf4le\\n\\n```bash\\naws sts assume-role --role-arn arn:aws:iam::123456789012:role/RoleName --role-session-name session1\\n```\\n\\n## Requ\xeates complexes et JMESPath\\n\\nLa CLI prend en charge JMESPath pour filtrer et transformer la sortie JSON via `--query`.\\n\\n```bash\\naws ec2 describe-instances --query \'Reservations[].Instances[?State.Name==`running`].InstanceId\' --output text\\n```\\n\\n## Bonnes pratiques\\n\\n- Pr\xe9f\xe9rer les profils nomm\xe9s plut\xf4t que d\'exporter `AWS_ACCESS_KEY_ID` en clair.\\n- Minimiser les permissions (IAM least privilege) pour les r\xf4les et utilisateurs utilis\xe9s par la CLI.\\n- Pour les workflows locaux, pr\xe9f\xe9rer `aws-vault` ou sessions SSO plut\xf4t que laisser des cl\xe9s longues dans des fichiers.\\n- Utiliser `--region` et `--profile` explicitement dans les scripts pour rendre les commandes reproductibles.\\n- Activer les logs et m\xe9triques CloudWatch c\xf4t\xe9 services pour tracer l\'impact des automatisations.\\n\\n## Astuces utiles\\n\\n- Pagination : la CLI g\xe8re la pagination automatiquement, ou utiliser `--page-size`/`--max-items` pour contr\xf4ler.\\n- Format de sortie : `--output json|yaml|table|text` ; pour les pipelines, `json` et `jq` sont pratiques.\\n- Session interactive : `aws configure list` et `aws sts get-caller-identity` pour v\xe9rifier l\'identit\xe9 active.\\n\\n## R\xe9f\xe9rences rapides\\n\\n- Documentation AWS CLI v2 : https://docs.aws.amazon.com/cli/latest/\\n- Tutoriels SSO et `aws-vault` pour gestion s\xe9curis\xe9e des credentials.\\n\\n---\\n\\nCe billet peut \xeatre compl\xe9t\xe9 par des exemples SAM/CloudFormation de d\xe9ploiement automatis\xe9 et des recettes de scripts pour CI/CD. Souhaites\u2011tu que j\'ajoute un guide pas\u2011\xe0\u2011pas d\'installation (commands) adapt\xe9 \xe0 Linux ou un `template.yaml` SAM d\'exemple ?"},{"id":"/2026/02/21/05-cloud/lambda","metadata":{"permalink":"/blog/2026/02/21/05-cloud/lambda","source":"@site/blog/05-cloud/2026-02-21-lambda.md","title":"AWS : Lambda","description":"D\xe9couverte d\'AWS Lambda et d\'une URL de fonction.","date":"2026-02-21T00:00:00.000Z","tags":[{"inline":false,"label":"Cloud","permalink":"/blog/tags/cloud"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":5.16,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"AWS : Lambda","description":"D\xe9couverte d\'AWS Lambda et d\'une URL de fonction.","tags":["cloud","devops"]},"unlisted":false,"prevItem":{"title":"AWS : CLI","permalink":"/blog/2026/02/21/05-cloud/aws-cli"},"nextItem":{"title":"AWS : Free Tier, EC2 et IAM","permalink":"/blog/2026/02/19/05-cloud/ec2"}},"content":"AWS Lambda permet d\'ex\xe9cuter du code sans g\xe9rer de serveurs. Ce document d\xe9crit le d\xe9ploiement d\'une fonction qui restitue une page HTML via une Function URL, les m\xe9thodes de test applicables et les op\xe9rations de nettoyage des ressources associ\xe9es.\\n\\n\x3c!--truncate--\x3e\\n\\nAWS Lambda est un service d\'ex\xe9cution serverless orient\xe9 \xe9v\xe9nements. Une fonction Lambda ex\xe9cute du code en r\xe9ponse \xe0 des d\xe9clencheurs (HTTP via Function URL ou API Gateway, \xe9v\xe9nements S3, messages SNS/SQS, EventBridge, etc.). Le mod\xe8le de facturation repose sur le temps d\'ex\xe9cution et la m\xe9moire allou\xe9e : il n\'y a pas de co\xfbt pour des serveurs continus, seules les invocations et la dur\xe9e d\'ex\xe9cution sont factur\xe9es.\\n\\nL\'ex\xe9cution se fait dans des environnements \xe9ph\xe9m\xe8res isol\xe9s ; le d\xe9marrage initial peut entra\xeener un \\"cold start\\" pour certains runtimes. Les fonctions disposent de limites configurables (m\xe9moire, timeout, taille du bundle) et peuvent utiliser des layers pour partager des d\xe9pendances. Les logs et m\xe9triques sont \xe9mis vers CloudWatch, et l\'ex\xe9cution requiert un r\xf4le IAM avec permissions minimales (principle du least privilege) pour les actions n\xe9cessaires.\\n\\nCas d\'usage courants : backends HTTP l\xe9gers, transformations d\'objets S3, t\xe2ches asynchrones, webhooks et prototypes rapides. Pour des charges statiques ou des assets lourds, l\'utilisation de S3 + CloudFront reste pr\xe9f\xe9rable.\\n\\n## Cr\xe9er la fonction\\n\\nLa cr\xe9ation de la fonction peut s\'effectuer depuis la console AWS Lambda.\\n\\nLa fonction peut \xeatre configur\xe9e avec des valeurs simples, par exemple `runtime` `nodejs22.x`, `architecture` `x86_64` et un nommage tel que `http-function-url-tutorial`. Le r\xf4le d\'ex\xe9cution peut \xeatre cr\xe9\xe9 automatiquement et doit autoriser l\'envoi de logs vers CloudWatch.\\n\\nLe plan \\"Getting started with Lambda HTTP\\" fournit un `index.html` et un handler simple lisant ce fichier et renvoyant son contenu comme body HTML. La fonction traite une requ\xeate HTTP et retourne un document HTML.\\n\\n## Exemple de handler\\n\\nLe handler renvoie simplement `index.html`. Exemple (ESM) :\\n\\n```javascript\\n// index.mjs\\nimport fs from \'node:fs\';\\n\\nconst html = fs.readFileSync(\'index.html\', \'utf8\');\\n\\nexport async function handler(event, context) {\\n    // `event` contient les donn\xe9es de la requ\xeate HTTP ou l\'\xe9v\xe9nement d\xe9clencheur.\\n    // `context` fournit des m\xe9tadonn\xe9es d\'ex\xe9cution (requestId, timeout restant, etc.).\\n    return {\\n        statusCode: 200,\\n        headers: { \'Content-Type\': \'text/html\' },\\n        body: html,\\n    };\\n}\\n```\\n\\nLe handler re\xe7oit deux param\xe8tres principaux : `event` et `context`. Pour une invocation HTTP, `event` inclut la m\xe9thode, les en-t\xeates et le corps de la requ\xeate. Le param\xe8tre `context` fournit des informations sur l\'ex\xe9cution en cours (identifiant de la requ\xeate, temps restant avant timeout). Les messages envoy\xe9s via `console.log` apparaissent automatiquement dans CloudWatch Logs.\\n\\nLe d\xe9marrage initial d\'un environnement d\'ex\xe9cution peut entra\xeener un \\"cold start\\" qui augmente la latence pour la premi\xe8re invocation. Les cold starts sont plus perceptibles pour certains runtimes et lorsque la fonction a des d\xe9pendances lourdes. Les strat\xe9gies pour r\xe9duire l\'impact comprennent le provisioned concurrency, le choix d\'un runtime optimis\xe9 et la r\xe9duction de la taille du bundle.\\n\\nLes variables d\'environnement permettent de param\xe9trer le comportement sans modifier le code. Les layers servent \xe0 partager des d\xe9pendances entre fonctions et \xe0 r\xe9duire la taille des packages d\xe9ploy\xe9s. Pour des fichiers statiques ou des assets volumineux, h\xe9berger les ressources sur S3 et servir via CloudFront est g\xe9n\xe9ralement plus performant que de les embarquer dans le package Lambda.\\n\\n## Invoquer la Function URL\\n\\nPour v\xe9rifier le d\xe9ploiement, l\'onglet Code affiche le handler et le fichier `index.html`. L\'ouverture de l\'URL de Function (Configuration \u2192 Function URL) dans un navigateur d\xe9clenche l\'invocation et retourne la page HTML.\\n\\n\\nLe test en ligne de commande s\'effectue avec la commande suivante (remplacer `<FUNCTION_URL>` par l\'URL fournie par la console) :\\n\\n```bash\\ncurl -i \\"https://<FUNCTION_URL>\\"\\n```\\n\\n### V\xe9rifier les logs\\n\\n\\nLes logs CloudWatch fournissent les informations de diagnostic et les traces d\'ex\xe9cution. Les entr\xe9es `START/END/REPORT` et les erreurs JavaScript y sont visibles. Pour suivre les logs en temps r\xe9el, utiliser :\\n\\n```bash\\naws logs tail /aws/lambda/http-function-url-tutorial --follow --since 1h\\n```\\n\\nLa CLI AWS permet \xe9galement d\'invoquer la fonction directement sans passer par la Function URL :\\n\\n```bash\\naws lambda invoke --function-name http-function-url-tutorial out.txt\\n```\\n\\nLa diff\xe9rence principale est l\'endpoint : `aws lambda invoke` appelle l\'API Lambda en mode administr\xe9 et ne refl\xe8te pas le comportement exact d\'une invocation HTTP via Function URL (en-t\xeates, codes de statut). Pour une Function URL configur\xe9e en `AWS_IAM`, les requ\xeates HTTP doivent \xeatre sign\xe9es (SigV4) ; les SDK AWS g\xe8rent cette signature automatiquement.\\n\\n## Alternatives et bonnes pratiques\\n\\nPour un usage public statique, il est pr\xe9f\xe9rable d\'h\xe9berger `index.html` sur S3 et d\'utiliser CloudFront. Pour s\xe9curiser l\'acc\xe8s \xe0 une fonction, il est recommand\xe9 d\'utiliser `AWS_IAM` ou de placer un API Gateway avec des m\xe9canismes d\'authentification. Pour la performance, pr\xe9compiler et bundler les assets et \xe9viter les lectures synchrones \xe0 chaque invocation.\\n\\n## Exemple cha\xeenage simple entre deux Lambdas\\n\\nUn cha\xeenage simple entre deux fonctions Lambda permet d\'illustrer les concepts d\'invocation et de permissions sans introduire d\'infrastructure suppl\xe9mentaire. Dans cet exemple, la fonction *producer* invoque de mani\xe8re asynchrone la fonction *consumer* via l\'API Lambda (`Invoke` avec `InvocationType=\'Event\'`).\\n\\nExtrait du producer (Python) :\\n\\n```python\\nimport os, json, boto3\\n\\nlambda_client = boto3.client(\'lambda\')\\nCONSUMER = os.environ.get(\'CONSUMER_FUNCTION_NAME\', \'lambda-consumer\')\\n\\ndef handler(event, context):\\n    payload = { \'message\': \'Hello from producer\', \'input\': event }\\n    lambda_client.invoke(\\n        FunctionName=CONSUMER,\\n        InvocationType=\'Event\',\\n        Payload=json.dumps(payload).encode()\\n    )\\n    return { \'statusCode\': 202, \'body\': json.dumps({\'sent\': True}) }\\n```\\n\\nComportement attendu du consumer : consigner le payload re\xe7u dans les logs CloudWatch et ex\xe9cuter le traitement asynchrone. Pour une invocation asynchrone, la r\xe9ponse renvoy\xe9e par le consumer n\'est pas retourn\xe9e au caller.\\n\\nPermissions minimales : le r\xf4le d\'ex\xe9cution de la fonction producer doit inclure l\'action `lambda:InvokeFunction` ciblant l\'ARN de la fonction consumer (ex. `arn:aws:lambda:REGION:ACCOUNT_ID:function:lambda-consumer`).\\n\\nTest rapide (CLI) :\\n\\n```bash\\naws lambda invoke --function-name lambda-producer --payload \'{}\' /tmp/out.json\\ncat /tmp/out.json\\n# Consulter les logs du consumer dans CloudWatch pour v\xe9rifier la r\xe9ception\\n```\\n\\nRemarques pratiques :\\n- V\xe9rifier la taille du payload ; pour des objets volumineux, stocker sur S3 et transmettre un lien.\\n- Inclure des m\xe9tadonn\xe9es (horodatage, requestId) facilite le tra\xe7age entre producer et consumer.\\n- Pr\xe9voir l\'idempotence c\xf4t\xe9 consumer si des duplications peuvent survenir.\\n\\nLes fichiers d\'exemple correspondants se trouvent dans `examples/lambda-two/` du d\xe9p\xf4t.\\n\\n## Nettoyage\\n\\nLa suppression des ressources commence par la suppression de la Function URL si elle n\'est pas n\xe9cessaire, puis par la suppression de la fonction :\\n\\n```bash\\naws lambda delete-function --function-name http-function-url-tutorial\\n```\\n\\nApr\xe8s suppression de la fonction, supprimer le r\xf4le IAM si celui-ci n\'est plus utilis\xe9."},{"id":"/2026/02/19/05-cloud/ec2","metadata":{"permalink":"/blog/2026/02/19/05-cloud/ec2","source":"@site/blog/05-cloud/2026-02-19-ec2.md","title":"AWS : Free Tier, EC2 et IAM","description":"Ma\xeetrise des fondamentaux AWS : cr\xe9ation de compte, mod\xe8le IAM, lancement et gestion d\'instances EC2.","date":"2026-02-19T00:00:00.000Z","tags":[{"inline":false,"label":"Cloud","permalink":"/blog/tags/cloud"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":12.65,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"AWS : Free Tier, EC2 et IAM","description":"Ma\xeetrise des fondamentaux AWS : cr\xe9ation de compte, mod\xe8le IAM, lancement et gestion d\'instances EC2.","tags":["cloud","devops"]},"unlisted":false,"prevItem":{"title":"AWS : Lambda","permalink":"/blog/2026/02/21/05-cloud/lambda"},"nextItem":{"title":"Docker Swarm","permalink":"/blog/2026/02/15/06-orchestration/docker-swarm"}},"content":"import Tabs from \'@theme/Tabs\';\\nimport TabItem from \'@theme/TabItem\';\\n\\nAmazon Web Services (AWS) est l\'une des premi\xe8res plateformes cloud au monde. Ses services fondamentaux comme EC2 et IAM permettent de d\xe9ployer et g\xe9rer une infrastructure compl\xe8te sans mat\xe9riel physique.\\n\\n\x3c!--truncate--\x3e\\n\\n## Cr\xe9er un compte AWS Free Tier\\n\\nAWS reste le leader incontest\xe9 du march\xe9 du cloud avec une part de march\xe9 significative. Pour un ing\xe9nieur ou un d\xe9veloppeur souhaitant ma\xeetriser les technologies cloud, l\'acc\xe8s \xe0 une plateforme de qualit\xe9 production est essentiel. L\'offre Free Tier permet d\'explorer AWS \xe0 co\xfbt z\xe9ro pendant une p\xe9riode initiale, ce qui en fait un point de d\xe9part id\xe9al.\\n\\n### Structure et avantages du Free Tier\\n\\nAWS propose plusieurs niveaux d\'offres gratuits adapt\xe9s \xe0 diff\xe9rents usages. Le forfait principal offre un cr\xe9dit de 200 USD valable pendant 12 mois pour explorer les services. Ce cr\xe9dit couvre une majorit\xe9 des cas d\'usage basiques :\\n\\n- EC2 : 750 heures de t2.micro par mois (suffisant pour une instance 24/7)\\n- S3 : 5 GB de stockage\\n- RDS : 750 heures de db.t2.micro par mois\\n- CloudWatch : Monitoring gratuit\\n- Transferts de donn\xe9es : Jusqu\'\xe0 1 GB d\'entr\xe9e/sortie gratuit par mois\\n\\nCertains services restent gratuits ind\xe9finiment, m\xeame apr\xe8s les 12 mois, \xe0 condition de rester dans les limites d\'utilisation. Par exemple, AWS Lambda propose 1 million de requ\xeates gratuites par mois, DynamoDB offre 25 Go de stockage.\\n\\nLes avantages principaux sont : aucun risque financier (aucune charge si les limites gratuites ne sont pas d\xe9pass\xe9es), acc\xe8s complet \xe0 plus de 150 services AWS, dur\xe9e suffisante pour apprendre (12 mois), et services identiques \xe0 ceux utilis\xe9s en production.\\n\\n### Inscription et acc\xe8s\\n\\nL\'inscription se fait via https://aws.amazon.com/fr/free/. Les \xe9tapes cl\xe9s incluent : entr\xe9e des informations personnelles (email, nom, mot de passe), v\xe9rification de l\'identit\xe9 (AWS demande une carte bancaire pour v\xe9rification uniquement, pas de charge), validation par SMS, et s\xe9lection du plan de support gratuit (Basic Support).\\n\\nUne fois inscrit, l\'acc\xe8s \xe0 la console se fait sur https://console.aws.amazon.com.\\n\\nIl est crucial de mettre en place des garde-fous pour \xe9viter les d\xe9passements. AWS Budgets permet de d\xe9finir des alertes automatiques qui vous notifient avant toute charge inattendue. Le template \\"Zero spend budget\\" est recommand\xe9 pour d\xe9buter : il cr\xe9e une alerte d\xe8s que l\'utilisation risque de d\xe9passer le Free Tier. Ces pratiques de surveillance des co\xfbts forment de bonnes habitudes pour la gestion en production.\\n\\n---\\n\\n## Comprendre le mod\xe8le IAM\\n\\nIdentity and Access Management (IAM) est le service AWS responsable de la gestion des acc\xe8s et des permissions. C\'est un composant critique de la s\xe9curit\xe9 infrastrukturelle qui doit \xeatre compris d\xe8s le d\xe9part, tant il influence toute l\'architecture en production.\\n\\nAcc\xe8s \xe0 la console IAM : https://console.aws.amazon.com/iam/\\n\\n### Mod\xe8le de s\xe9curit\xe9 bas\xe9 sur les permissions\\n\\nAWS fonctionne selon un principe de permission explicite : par d\xe9faut, tout acc\xe8s est refus\xe9. Seules les actions explicitement autoris\xe9es sont possibles. Cette approche s\xe9curitaire signifie que chaque utilisateur, chaque service, chaque ressource doit disposer des permissions minimales n\xe9cessaires \xe0 son fonctionnement.\\n\\nLes quatre concepts cl\xe9s d\'IAM sont :\\n\\n**Users** : Entit\xe9s repr\xe9sentant des personnes ou des applications. Chaque utilisateur poss\xe8de des identifiants uniques et des credentials de connexion. Un root user est cr\xe9\xe9 automatiquement lors de la cr\xe9ation du compte, mais il est recommand\xe9 de ne pas l\'utiliser en production.\\n\\n**Groups** : Ensemble logique d\'utilisateurs partageant les m\xeames permissions. Plut\xf4t que d\'assigner des permissions \xe0 chaque utilisateur individuellement, les groupes permettent une gestion centralis\xe9e et scalable.\\n\\n**Roles** : Identit\xe9s destin\xe9es \xe0 \xeatre assum\xe9es temporairement, g\xe9n\xe9ralement par des services ou des utilisateurs externes. Contrairement aux users, les roles n\'ont pas de credentials permanentes mais g\xe9n\xe8rent des tokens temporaires.\\n\\n**Policies** : Documents JSON d\xe9finissant pr\xe9cis\xe9ment les actions autoris\xe9es (Allow) ou refus\xe9es (Deny) sur les ressources AWS. Une policy peut \xeatre attach\xe9e \xe0 des users, groups, ou roles pour d\xe9finir leurs permissions.\\n\\n### Bonnes pratiques d\xe8s le d\xe9part\\n\\nAppliquer les bonnes pratiques d\xe8s le d\xe9but forme de solides habitudes. Ne jamais utiliser le root user apr\xe8s la cr\xe9ation initiale du compte, cr\xe9er un utilisateur IAM administrateur avec authentification multifacteur (MFA), utiliser des groupes pour simplifier la gestion des permissions, et r\xe9guli\xe8rement auditer les acc\xe8s sont les r\xe8gles de base.\\n\\nPour un projet personnel, cr\xe9er au minimum un utilisateur IAM avec permissions compl\xe8tes et l\'utiliser comme administrateur du compte lib\xe8re le root user, qui ne devrait \xeatre utilis\xe9 que pour les changements critiques (r\xe9cup\xe9ration de compte, modifications de facturation).\\n\\n---\\n\\n## Lancer une instance EC2\\n\\nLe lancement d\'une instance EC2 est un processus guid\xe9 compos\xe9 de plusieurs \xe9tapes. L\'objectif est de configurer tous les param\xe8tres n\xe9cessaires pour que la machine virtuelle d\xe9marre correctement et soit accessible.\\n\\n### Nommage et identification\\n\\nChaque instance doit recevoir un nom permettant de l\'identifier facilement dans la console. Ce nom est en r\xe9alit\xe9 une \xe9tiquette (tag) avec la cl\xe9 \\"Name\\". Pour un projet de test, un simple \\"Test Instance\\" suffit. Ce nommage devient critique en production o\xf9 vous aurez potentiellement des dizaines ou centaines d\'instances : une politique de nommage coh\xe9rente (par exemple `projet-env-role-numero`) facilite la gestion et l\'automatisation.\\n\\n### S\xe9lection de l\'Amazon Machine Image (AMI)\\n\\nUne AMI est un mod\xe8le pr\xeat \xe0 l\'emploi contenant un syst\xe8me d\'exploitation complet et un ensemble de logiciels pr\xe9configur\xe9s. AWS propose plusieurs AMI de d\xe9marrage rapide gratuites : Amazon Linux, Ubuntu, Debian, CentOS. Le choix d\xe9pend de votre pr\xe9f\xe9rence et de votre exp\xe9rience. Amazon Linux est optimis\xe9 pour AWS, Ubuntu offre une large communaut\xe9 de d\xe9veloppeurs, Debian est minimaliste.\\n\\nPour d\xe9buter, choisissez simplement Amazon Linux 2 ou Ubuntu. Ces AMI sont disponibles dans le Free Tier.\\n\\n### Configuration du type d\'instance\\n\\nLe type d\'instance d\xe9termine les ressources mat\xe9rielles : processeur, m\xe9moire, r\xe9seau. AWS propose plusieurs familles (`t2`, `t3`, `m5`, etc.). Le type `t3.micro` est inclus dans le Free Tier (750 heures par mois) et convient parfaitement pour apprendre, tester une application, ou servir une charge tr\xe8s l\xe9g\xe8re.\\n\\nNe modifiez pas le type par d\xe9faut propos\xe9 pour une premi\xe8re instance. Vous pouvez toujours le changer plus tard.\\n\\n### Paire de cl\xe9s SSH\\n\\nAvant de lancer l\'instance, vous devez cr\xe9er ou s\xe9lectionner une paire de cl\xe9s SSH. La paire de cl\xe9s se compose d\'une cl\xe9 publique (stock\xe9e sur l\'instance) et d\'une cl\xe9 priv\xe9e (conserv\xe9e sur votre ordinateur local). La cl\xe9 priv\xe9e est votre secret : ne la partagez jamais.\\n\\nAWS vous permet de t\xe9l\xe9charger la cl\xe9 priv\xe9e une seule fois lors de la cr\xe9ation. Si vous la perdez, vous ne pourrez plus acc\xe9der \xe0 l\'instance. Stockez-la dans un endroit s\xfbr, comme `~/.ssh/` sur Linux/Mac ou `C:\\\\Users\\\\VotreNom\\\\.ssh\\\\` sur Windows.\\n\\nNommez votre paire de cl\xe9s de mani\xe8re explicite (ex: `aws-key-2026`) pour \xe9viter confusion avec d\'autres cl\xe9s.\\n\\n### Configuration r\xe9seau (VPC et sous-r\xe9seau)\\n\\nAWS cr\xe9e automatiquement un VPC (Virtual Private Cloud) par d\xe9faut pour votre compte. Les instances doivent \xeatre lanc\xe9es dans ce VPC, id\xe9alement dans un sous-r\xe9seau public pour un acc\xe8s Internet. Le sous-r\xe9seau par d\xe9faut est public et attribue une adresse IP publique \xe0 votre instance, ce qui la rend accessible depuis Internet.\\n\\nPour un test, gardez les param\xe8tres par d\xe9faut. En production, une segmentation r\xe9seau appropri\xe9e devient critique pour la s\xe9curit\xe9.\\n\\n### Pare-feu (Security Group)\\n\\nUn Security Group fonctionne comme un pare-feu applicatif. Il d\xe9finit les r\xe8gles de trafic entrant et sortant pour votre instance. Pour vous connecter en SSH, vous avez besoin d\'une r\xe8gle permettant le trafic sur le port 22 (SSH).\\n\\nPour d\xe9buter, autorisez SSH de n\'importe o\xf9 (`0.0.0.0/0`). En production, limitez toujours SSH aux adresses IP connues.\\n\\n### Stockage (EBS)\\n\\nUn volume EBS (Elastic Block Store) est le disque de votre instance. Le volume racine contient le syst\xe8me d\'exploitation. Pour une instance de test, un volume de 8-20 GB suffit, sans chiffrement suppl\xe9mentaire n\xe9cessaire.\\n\\n### V\xe9rification et lancement\\n\\nPassez en revue le r\xe9sum\xe9 de tous les param\xe8tres. V\xe9rifiez que vous avez s\xe9lectionn\xe9 la paire de cl\xe9s correcte et que le Security Group autorise SSH. Une fois satisfait, cliquez sur \\"Lancer l\'instance\\".\\n\\nL\'instance d\xe9marre en quelques secondes. Vous pouvez suivre son \xe9tat dans la console : elle passe de \\"Pending\\" \xe0 \\"Running\\". Notez son adresse IP publique (affich\xe9e dans les d\xe9tails de l\'instance) : vous en aurez besoin pour la connexion SSH.\\n\\n---\\n\\n## Se connecter en SSH\\n\\nUne fois l\'instance en \xe9tat \\"Running\\" avec une adresse IP publique, vous pouvez \xe9tablir une connexion SSH s\xe9curis\xe9e depuis votre terminal local.\\n\\n### Pr\xe9paration de la cl\xe9 priv\xe9e\\n\\nLa cl\xe9 priv\xe9e t\xe9l\xe9charg\xe9e lors du lancement doit \xeatre prot\xe9g\xe9e avec les permissions appropri\xe9es. Sur Linux/Mac, ex\xe9cutez :\\n\\n```bash\\nchmod 400 ~/.ssh/votre-cle.pem\\n```\\n\\nCette commande restreint l\'acc\xe8s \xe0 la cl\xe9 : seul le propri\xe9taire peut la lire. SSH refusera de fonctionner si la cl\xe9 a des permissions trop larges.\\n\\n### Commande SSH\\n\\nLa syntaxe SSH d\xe9pend du syst\xe8me d\'exploitation de l\'AMI utilis\xe9e :\\n\\n<Tabs>\\n<TabItem value=\\"amazon-linux\\" label=\\"Amazon Linux\\">\\n\\n```bash\\nssh -i ~/.ssh/votre-cle.pem ec2-user@adresse-ip-publique\\n```\\n\\n</TabItem>\\n<TabItem value=\\"ubuntu\\" label=\\"Ubuntu\\">\\n\\n```bash\\nssh -i ~/.ssh/votre-cle.pem ubuntu@adresse-ip-publique\\n```\\n\\n</TabItem>\\n<TabItem value=\\"debian\\" label=\\"Debian\\">\\n\\n```bash\\nssh -i ~/.ssh/votre-cle.pem admin@adresse-ip-publique\\n```\\n\\n</TabItem>\\n</Tabs>\\n\\nRemplacez `votre-cle.pem` par le chemin r\xe9el de votre cl\xe9 et `adresse-ip-publique` par l\'IP publique de votre instance.\\n\\n### Connexion et v\xe9rification\\n\\nLa premi\xe8re connexion SSH vous affiche g\xe9n\xe9ralement une empreinte digitale de la cl\xe9 h\xf4te (host key fingerprint) pour v\xe9rifier que vous vous connectez au bon serveur. Acceptez-la en tapant \\"yes\\".\\n\\nUne fois connect\xe9, vous \xeates en tant qu\'utilisateur `ec2-user`, `ubuntu`, ou `admin` (selon l\'AMI). Vous avez un acc\xe8s utilisateur \xe0 l\'instance. Pour les op\xe9rations d\'administration (installation de logiciels, modifications syst\xe8me), utilisez `sudo`.\\n\\n### Acc\xe8s root et administration\\n\\nL\'utilisateur par d\xe9faut (`ec2-user`, `ubuntu`, `admin`) dispose de sudo sans mot de passe. Vous pouvez donc ex\xe9cuter des commandes en root simplement en pr\xe9fixant avec `sudo` :\\n\\n<Tabs>\\n<TabItem value=\\"amazon-linux-sudo\\" label=\\"Amazon Linux\\">\\n\\n```bash\\nsudo yum update\\n```\\n\\n</TabItem>\\n<TabItem value=\\"ubuntu-debian-sudo\\" label=\\"Ubuntu / Debian\\">\\n\\n```bash\\nsudo apt update\\n```\\n\\n</TabItem>\\n</Tabs>\\n\\n### Fermeture de la connexion\\n\\nTapez `exit` ou appuyez sur Ctrl+D pour fermer la connexion SSH. Votre instance reste active \xe0 moins que vous ne l\'arr\xeatiez explicitement.\\n\\n---\\n\\n## Installer Nginx\\n\\nNginx est un serveur web l\xe9ger et performant, id\xe9al pour d\xe9buter avec une application web simple. L\'installation est directe via le gestionnaire de paquets de votre syst\xe8me d\'exploitation.\\n\\n### Installation\\n\\nUne fois connect\xe9 en SSH \xe0 votre instance, commencez par mettre \xe0 jour les paquets syst\xe8me :\\n\\n<Tabs>\\n<TabItem value=\\"amazon-linux\\" label=\\"Amazon Linux\\">\\n\\n```bash\\nsudo yum update -y\\n```\\n\\n</TabItem>\\n<TabItem value=\\"ubuntu-debian\\" label=\\"Ubuntu / Debian\\">\\n\\n```bash\\nsudo apt update && sudo apt upgrade -y\\n```\\n\\n</TabItem>\\n</Tabs>\\n\\nInstallez ensuite Nginx :\\n\\n<Tabs>\\n<TabItem value=\\"amazon-linux-install\\" label=\\"Amazon Linux\\">\\n\\n```bash\\nsudo yum install nginx -y\\n```\\n\\n</TabItem>\\n<TabItem value=\\"ubuntu-debian-install\\" label=\\"Ubuntu / Debian\\">\\n\\n```bash\\nsudo apt install nginx -y\\n```\\n\\n</TabItem>\\n</Tabs>\\n\\n### D\xe9marrage du service\\n\\nApr\xe8s installation, d\xe9marrez le service Nginx :\\n\\n```bash\\nsudo systemctl start nginx\\n```\\n\\nV\xe9rifiez que le service est bien actif :\\n\\n```bash\\nsudo systemctl status nginx\\n```\\n\\nVous devez voir un statut \\"active (running)\\".\\n\\nPour que Nginx d\xe9marre automatiquement au red\xe9marrage de l\'instance :\\n\\n```bash\\nsudo systemctl enable nginx\\n```\\n\\n### Configuration du Security Group\\n\\nPour que Nginx soit accessible depuis Internet, vous devez autoriser le trafic HTTP (port 80) dans le Security Group de votre instance. C\'est une \xe9tape critique souvent oubli\xe9e, qui explique pourquoi l\'adresse IP publique ne charge pas initialement.\\n\\nDans la console AWS, allez \xe0 **EC2 \u2192 Security Groups**, s\xe9lectionnez le Security Group de votre instance, puis cliquez sur **Edit inbound rules**. Ajoutez une nouvelle r\xe8gle :\\n\\n- Type : HTTP\\n- Port : 80\\n- Protocol : TCP\\n- Source : 0.0.0.0/0\\n\\nSauvegardez les modifications.\\n\\n### Acc\xe8s au serveur web\\n\\nR\xe9cup\xe9rez l\'adresse IP publique de votre instance (visible dans les d\xe9tails EC2), puis acc\xe9dez-y via HTTP dans votre navigateur :\\n\\n```text\\nhttp://votre-ip-publique\\n```\\n\\nVous devez voir la page de bienvenue Nginx, confirmant que le serveur est op\xe9rationnel. Cette page est servie depuis `/usr/share/nginx/html/index.html`.\\n\\n### V\xe9rification locale\\n\\nDepuis la session SSH, vous pouvez aussi v\xe9rifier que Nginx \xe9coute correctement :\\n\\n```bash\\nsudo netstat -tlnp | grep nginx\\n```\\n\\nou\\n\\n```bash\\ncurl http://localhost\\n```\\n\\nCes commandes confirment que Nginx est bien configur\xe9 et accessible localement. L\'absence de r\xe8gle HTTP dans le Security Group \xe9tait le blocage : m\xeame si Nginx tourne, le pare-feu AWS bloque l\'acc\xe8s externe sans cette r\xe8gle explicite.\\n\\n---\\n\\n## G\xe9rer l\'instance\\n\\nLe cycle de vie d\'une instance EC2 comprend plusieurs \xe9tats critiques pour la gestion des co\xfbts et des ressources. Comprendre la diff\xe9rence entre \\"Stop\\" et \\"Terminate\\" est essentiel pour \xe9viter des frais inattendus.\\n\\n### \xc9tats d\'une instance\\n\\nUne instance EC2 peut se trouver dans plusieurs \xe9tats :\\n\\n- **Running** : L\'instance est en cours d\'ex\xe9cution et vous facturation pour le calcul (CPU, m\xe9moire)\\n- **Stopped** : L\'instance est arr\xeat\xe9e mais conserve ses donn\xe9es et peux \xeatre red\xe9marr\xe9e. Vous \xeates factur\xe9 pour le stockage EBS uniquement\\n- **Terminated** : L\'instance est supprim\xe9e d\xe9finitivement. Les donn\xe9es sont perdues (sauf si \xe0 sauvegard\xe9 les volumes EBS). Pas de frais (ou frais minimaux pour EBS selon la configuration)\\n\\n### Stop vs Terminate\\n\\n**Stop (Arr\xeat)** : Comme \xe9teindre un ordinateur \xe0 la maison. L\'instance s\'arr\xeate mais subsiste. Vous pouvez la red\xe9marrer plus tard. Les donn\xe9es sur le volume racine (EBS) sont conserv\xe9es. Vous \xeates factur\xe9 pour le stockage EBS (quelques centimes par mois) mais pas pour le calcul.\\n\\n```bash\\n# Depuis la console AWS : clic-droit sur l\'instance \u2192 Instance State \u2192 Stop\\n```\\n\\n**Terminate (Suppression)** : Suppression d\xe9finitive de l\'instance. Les donn\xe9es du volume racine sont perdues par d\xe9faut (sauf si vous avez configur\xe9 \\"Delete on Termination = No\\"). Vous cessez imm\xe9diatement d\'\xeatre factur\xe9 pour le calcul et le stockage racine.\\n\\n```bash\\n# Depuis la console AWS : clic-droit sur l\'instance \u2192 Instance State \u2192 Terminate\\n```\\n\\n### Facturation dans le Free Tier\\n\\nDans le Free Tier (750 heures par mois de t3.micro gratuit) :\\n\\n- **Running** : Consomme vos 750 heures gratuites\\n- **Stopped** : Ne consomme pas les heures gratuites, mais factur\xe9 pour EBS (~$0.10 par Go/mois)\\n- **Terminated** : Pas de frais\\n\\nPour une instance de test \xe0 court terme (une journ\xe9e d\'apprentissage), il est judicieux de **Terminate** pour \xe9viter les frais EBS. Pour une instance que vous revisiterez plus tard, **Stop** pour la conserver \xe0 bas co\xfbt.\\n\\n### Commandes via la console\\n\\n**Arr\xeater (Stop) l\'instance :**\\n\\n1. Allez \xe0 EC2 \u2192 Instances\\n2. S\xe9lectionnez votre instance\\n3. Clic-droit \u2192 Instance State \u2192 Stop\\n4. Confirmez l\'arr\xeat\\n5. L\'\xe9tat change \xe0 \\"Stopped\\" en quelques secondes\\n\\n**Red\xe9marrer (Start) l\'instance :**\\n\\n1. Allez \xe0 EC2 \u2192 Instances\\n2. S\xe9lectionnez votre instance (\xe9tat \\"Stopped\\")\\n3. Clic-droit \u2192 Instance State \u2192 Start\\n4. L\'instance red\xe9marre, les donn\xe9es persistent\\n\\n**Supprimer (Terminate) l\'instance :**\\n\\n1. Allez \xe0 EC2 \u2192 Instances\\n2. S\xe9lectionnez votre instance\\n3. Clic-droit \u2192 Instance State \u2192 Terminate\\n4. Confirmez la suppression (attention : irr\xe9versible)\\n5. L\'instance dispara\xeet apr\xe8s quelques secondes\\n\\n### Impact sur les donn\xe9es\\n\\nLe comportement des donn\xe9es d\xe9pend du type de stockage :\\n\\n- **Volume EBS racine** : Par d\xe9faut configur\xe9 \xe0 \xeatre supprim\xe9 avec l\'instance. On peut le modifier lors du lancement pour le conserver.\\n- **Volumes EBS suppl\xe9mentaires** : Conserv\xe9s ind\xe9pendamment de l\'instance, facturable s\xe9par\xe9ment.\\n- **Stockage local de l\'instance (ephemeral)** : Perdu lors de l\'arr\xeat ou la suppression.\\n\\nPour conserver des donn\xe9es importantes sans l\'instance, transf\xe9rez-les vers S3 (stockage objet) ou sur un volume EBS s\xe9par\xe9.\\n\\n### Bonnes pratiques\\n\\nPour d\xe9buter avec le Free Tier :\\n\\n- **Terminate** les instances de test apr\xe8s usage pour \xe9viter les frais EBS\\n- **Stop** les instances que vous r\xe9utiliserez r\xe9guli\xe8rement\\n- **Configurez des alarmes de co\xfbts** pour d\xe9tecter les d\xe9passements accidentels\\n- **Taguez clairement** les instances (\\"Test\\", \\"Production\\", etc.) pour savoir lesquelles arr\xeater\\n\\nUne fois familiaris\xe9 avec les bases, arr\xeater votre instance actuelle vous \xe9vitera des frais inattendus sur votre Free Tier.\\n\\n---"},{"id":"/2026/02/15/06-orchestration/docker-swarm","metadata":{"permalink":"/blog/2026/02/15/06-orchestration/docker-swarm","source":"@site/blog/06-orchestration/2026-02-15-docker-swarm.md","title":"Docker Swarm","description":"Introduction \xe0 Docker Swarm, l\'orchestrateur natif de Docker. D\xe9couvrez comment d\xe9ployer et g\xe9rer des clusters de conteneurs.","date":"2026-02-15T00:00:00.000Z","tags":[{"inline":false,"label":"Orchestration","permalink":"/blog/tags/orchestration"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":2.98,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Docker Swarm","description":"Introduction \xe0 Docker Swarm, l\'orchestrateur natif de Docker. D\xe9couvrez comment d\xe9ployer et g\xe9rer des clusters de conteneurs.","tags":["orchestration","devops"]},"unlisted":false,"prevItem":{"title":"AWS : Free Tier, EC2 et IAM","permalink":"/blog/2026/02/19/05-cloud/ec2"},"nextItem":{"title":"Python : Packaging","permalink":"/blog/2026/02/15/09-scripting/packaging-python"}},"content":"Docker Swarm est le syst\xe8me d\'orchestration natif de Docker qui permet de g\xe9rer un cluster de conteneurs de mani\xe8re simple et int\xe9gr\xe9e. Contrairement \xe0 Kubernetes, Swarm est plus l\xe9ger et plus facile \xe0 configurer, le rendant id\xe9al pour les petits \xe0 moyens d\xe9ploiements.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que Docker Swarm ?\\n\\nDocker Swarm est un mode de clustering int\xe9gr\xe9 directement dans Docker qui transforme plusieurs machines Docker en un seul cluster logique. Il offre :\\n\\n- **Gestion distribu\xe9e** : Coordination automatique des conteneurs sur plusieurs n\u0153uds\\n- **Haute disponibilit\xe9** : R\xe9plication des services et basculement automatique\\n- **Load balancing** : Distribution automatique du trafic\\n- **S\xe9curit\xe9 native** : Chiffrement TLS automatique et gestion des secrets\\n\\n## Architecture de Docker Swarm\\n\\n### Composants principaux\\n\\n**Manager Nodes** (N\u0153uds gestionnaires)\\n\\n- G\xe8rent l\'\xe9tat du cluster\\n- Maintiennent la base de donn\xe9es distribu\xe9e (raft)\\n- Orchestre les services\\n- \xc9lection leader automatique\\n\\n**Worker Nodes** (N\u0153uds de travail)\\n\\n- Ex\xe9cutent les conteneurs\\n- Re\xe7oivent les t\xe2ches du manager\\n- Rapportent leur \xe9tat au manager\\n\\n## Initialiser un Swarm\\n\\n### Cr\xe9er un premier n\u0153ud manager\\n\\n```bash\\ndocker swarm init\\n```\\n\\nCela initie le swarm et retourne un token pour ajouter d\'autres n\u0153uds :\\n\\n```\\nSwarm initialized: current node (id) is now a manager.\\n\\nTo add a worker to this swarm, run the following command:\\n\\n    docker swarm join --token SWMTKN-1-xxx <MANAGER_IP>:2377\\n```\\n\\n### Ajouter des n\u0153uds workers\\n\\nSur une autre machine :\\n\\n```bash\\ndocker swarm join --token SWMTKN-1-xxx <MANAGER_IP>:2377\\n```\\n\\n### V\xe9rifier le cluster\\n\\n```bash\\ndocker node ls\\n```\\n\\n## D\xe9ployer des Services\\n\\nLes services Swarm remplacent les conteneurs simples dans un cluster. Ils garantissent que le nombre de r\xe9pliques souhait\xe9 est toujours en ex\xe9cution.\\n\\n### Cr\xe9er un service simple\\n\\n```bash\\ndocker service create \\\\\\n  --name web-app \\\\\\n  --replicas 3 \\\\\\n  -p 80:8080 \\\\\\n  nginx:latest\\n```\\n\\n### Lister les services\\n\\n```bash\\ndocker service ls\\n```\\n\\n### Voir les t\xe2ches d\'un service\\n\\n```bash\\ndocker service ps web-app\\n```\\n\\n## Gestion des Services\\n\\n### Mettre \xe0 jour un service\\n\\n```bash\\ndocker service update \\\\\\n  --image nginx:alpine \\\\\\n  web-app\\n```\\n\\n### Redimensionner un service\\n\\n```bash\\ndocker service scale web-app=5\\n```\\n\\n### Supprimer un service\\n\\n```bash\\ndocker service rm web-app\\n```\\n\\n## Configuration avec Docker Compose\\n\\nDocker Swarm supporte \xe9galement le d\xe9ploiement via Docker Compose avec la command `docker stack deploy`.\\n\\n**docker-compose.yml**\\n\\n```yaml\\nversion: \'3.8\'\\n\\nservices:\\n  web:\\n    image: nginx:alpine\\n    ports:\\n      - \\"80:80\\"\\n    deploy:\\n      replicas: 3\\n      update_config:\\n        parallelism: 1\\n        delay: 10s\\n    networks:\\n      - webnet\\n\\n  db:\\n    image: postgres:13\\n    environment:\\n      POSTGRES_PASSWORD: secret\\n    volumes:\\n      - db_data:/var/lib/postgresql/data\\n    deploy:\\n      replicas: 1\\n    networks:\\n      - webnet\\n\\nvolumes:\\n  db_data:\\n\\nnetworks:\\n  webnet:\\n    driver: overlay\\n```\\n\\n### D\xe9ployer la stack\\n\\n```bash\\ndocker stack deploy -c docker-compose.yml myapp\\n```\\n\\n### Consulter les stacks\\n\\n```bash\\ndocker stack ls\\ndocker stack ps myapp\\n```\\n\\n## Gestion des Secrets\\n\\nDocker Swarm offre une gestion native des secrets chiffr\xe9s.\\n\\n### Cr\xe9er un secret\\n\\n```bash\\necho \\"my_secret_password\\" | docker secret create db_password -\\n```\\n\\n### Utiliser un secret dans un service\\n\\n```bash\\ndocker service create \\\\\\n  --name myservice \\\\\\n  --secret db_password \\\\\\n  -e DB_PASSWORD_FILE=/run/secrets/db_password \\\\\\n  myimage\\n```\\n\\n## R\xe9seaux Overlay\\n\\nLes r\xe9seaux overlay permettent la communication entre conteneurs sur diff\xe9rents n\u0153uds.\\n\\n### Cr\xe9er un r\xe9seau overlay\\n\\n```bash\\ndocker network create -d overlay --attachable mynetwork\\n```\\n\\n### Connecter un service \xe0 un r\xe9seau\\n\\n```bash\\ndocker service create \\\\\\n  --name web \\\\\\n  --network mynetwork \\\\\\n  nginx\\n```\\n\\n## Avantages et Limitations\\n\\n### \u2705 Avantages\\n\\n- Int\xe9gration native avec Docker\\n- Configuration simple et rapide\\n- Parfait pour petits/moyens clusters\\n- Faible overhead de ressources\\n\\n### \u274c Limitations\\n\\n- Moins de fonctionnalit\xe9s que Kubernetes\\n- Pas d\'autoscaling sophistiqu\xe9\\n- Scheduling moins flexible\\n- \xc9cosyst\xe8me moins riche\\n\\n## Quand utiliser Docker Swarm ?\\n\\n- **Clusters petits \xe0 moyens** (< 50 n\u0153uds)\\n- **D\xe9ploiements simples** sans besoins complexes\\n- **\xc9quipes** pr\xe9f\xe9rant la simplicit\xe9 \xe0 la puissance\\n- **Prototypage rapide** et POC\\n\\n## Conclusion\\n\\nDocker Swarm reste une excellente option pour l\'orchestration de conteneurs quand on privil\xe9gie la simplicit\xe9. Pour des d\xe9ploiements plus complexes et \xe0 grande \xe9chelle, Kubernetes reste le choix de r\xe9f\xe9rence. Le choix entre les deux d\xe9pend vraiment des besoins sp\xe9cifiques du projet."},{"id":"/2026/02/15/09-scripting/packaging-python","metadata":{"permalink":"/blog/2026/02/15/09-scripting/packaging-python","source":"@site/blog/09-scripting/2026-02-15-packaging-python.md","title":"Python : Packaging","description":"Comprendre le packaging Python : qu\'est-ce qu\'un package, PyPI, wheel, distributions, setuptools, m\xe9tadonn\xe9es et versioning.","date":"2026-02-15T00:00:00.000Z","tags":[{"inline":false,"label":"Scripting","permalink":"/blog/tags/scripting"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":7.55,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Python : Packaging","description":"Comprendre le packaging Python : qu\'est-ce qu\'un package, PyPI, wheel, distributions, setuptools, m\xe9tadonn\xe9es et versioning.","tags":["scripting","devops"]},"unlisted":false,"prevItem":{"title":"Docker Swarm","permalink":"/blog/2026/02/15/06-orchestration/docker-swarm"},"nextItem":{"title":"Python : Pytest","permalink":"/blog/2026/02/15/09-scripting/pytest-testing"}},"content":"Publier son code Python sur PyPI c\'est le rendre accessible \xe0 des milliers de d\xe9veloppeurs. Exploration des concepts fondamentaux du packaging Python.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce qu\'un Package Python ?\\n\\n### Diff\xe9rence : Module vs Package\\n\\n**Module** : Un fichier Python unique\\n```\\ncalculator.py  # C\'est un module\\n```\\n\\n**Package** : Un dossier contenant des modules\\n```\\ncalculator/\\n\u251c\u2500\u2500 __init__.py        # Marque le dossier comme package\\n\u251c\u2500\u2500 operations.py\\n\u251c\u2500\u2500 utils.py\\n\u2514\u2500\u2500 constants.py\\n```\\n\\nLe fichier `__init__.py` est crucial : c\'est ce qui dit \xe0 Python \\"je suis un package\\".\\n\\n### Structure simple\\n\\n```\\nmy_package/\\n\u251c\u2500\u2500 my_package/           # Code source\\n\u2502   \u251c\u2500\u2500 __init__.py\\n\u2502   \u251c\u2500\u2500 core.py\\n\u2502   \u2514\u2500\u2500 utils.py\\n\u251c\u2500\u2500 tests/                # Tests\\n\u251c\u2500\u2500 README.md\\n\u251c\u2500\u2500 LICENSE\\n\u2514\u2500\u2500 pyproject.toml        # Configuration de packaging\\n```\\n\\n### D\xe9pendances du package\\n\\nUn package peut d\xe9pendre d\'autres packages (import\xe9s via `pip install`).\\n\\n```python\\n# Dans my_package/core.py\\nimport requests  # D\xe9pendance externe\\nfrom .utils import helper  # D\xe9pendance interne\\n```\\n\\nCes d\xe9pendances externes doivent \xeatre d\xe9clar\xe9es lors du packaging.\\n\\n## Distributions : Wheel vs Source\\n\\nQuand on publie un package, on cr\xe9e deux types de distribution :\\n\\n### Source Distribution (sdist)\\n\\n**Format** : `my_package-1.0.0.tar.gz` (ou `.zip`)\\n\\n```\\nmy_package-1.0.0/\\n\u251c\u2500\u2500 my_package/\\n\u2502   \u251c\u2500\u2500 __init__.py\\n\u2502   \u251c\u2500\u2500 core.py\\n\u2502   \u2514\u2500\u2500 utils.py\\n\u251c\u2500\u2500 setup.py\\n\u251c\u2500\u2500 README.md\\n\u2514\u2500\u2500 pyproject.toml\\n```\\n\\n**Avantages** \u2705\\n- Contient le code source complet\\n- Portable sur tous les OS/architectures\\n- Permet inspection du code\\n\\n**Inconv\xe9nients** \u274c\\n- Installation lente (compilation n\xe9cessaire)\\n- Requiert les build tools (compilateur C, etc.)\\n- Plus volumineux\\n\\n### Wheel Distribution (bdist_wheel)\\n\\n**Format** : `my_package-1.0.0-py3-none-any.whl` (archive ZIP)\\n\\n```\\nmy_package-1.0.0.dist-info/\\n\u251c\u2500\u2500 METADATA\\n\u251c\u2500\u2500 RECORD\\n\u251c\u2500\u2500 entry_points.txt\\n\u2514\u2500\u2500 top_level.txt\\n\\nmy_package/\\n\u251c\u2500\u2500 __init__.py\\n\u251c\u2500\u2500 core.py\\n\u2514\u2500\u2500 utils.py\\n```\\n\\n**Avantages** \u2705\\n- Installation ultra-rapide (pas de compilation)\\n- Ne requiert que pip\\n- Coh\xe9rent sur tous les environnements\\n\\n**Inconv\xe9nients** \u274c\\n- Sp\xe9cifique \xe0 une version Python/plateforme\\n- Code pr\xe9-compil\xe9 (moins d\'inspection)\\n\\n**Verdict** : Toujours publier les deux. Wheel en priorit\xe9, source en fallback.\\n\\n## M\xe9tadonn\xe9es : D\xe9clarer un Package\\n\\nLes m\xe9tadonn\xe9es c\'est tout ce qu\'on doit savoir sur un package : nom, version, d\xe9pendances, auteur, licence, etc.\\n\\n### Configuration avec pyproject.toml (Modern)\\n\\nDepuis PEP 517/518 (2015+), c\'est l\'approche moderne :\\n\\n```toml\\n[build-system]\\nrequires = [\\"setuptools>=61.0\\", \\"wheel\\"]\\nbuild-backend = \\"setuptools.build_meta\\"\\n\\n[project]\\nname = \\"my-awesome-lib\\"\\nversion = \\"1.0.0\\"\\ndescription = \\"Une libraire incroyable\\"\\nreadme = \\"README.md\\"\\nrequires-python = \\">=3.8\\"\\nlicense = {text = \\"MIT\\"}\\nauthors = [\\n    {name = \\"John Doe\\", email = \\"john@example.com\\"}\\n]\\nkeywords = [\\"awesome\\", \\"library\\", \\"python\\"]\\n\\n# URLs\\n[project.urls]\\nHomepage = \\"https://github.com/user/my-awesome-lib\\"\\nDocumentation = \\"https://my-awesome-lib.readthedocs.io\\"\\nRepository = \\"https://github.com/user/my-awesome-lib\\"\\n\\n# D\xe9pendances\\n[project.dependencies]\\nrequests = \\">=2.28.0\\"\\npydantic = \\">=1.10\\"\\n\\n# D\xe9pendances optionnelles\\n[project.optional-dependencies]\\ndatabase = [\\"sqlalchemy>=1.4\\", \\"psycopg2>=2.9\\"]\\nemail = [\\"aiosmtplib>=2.0\\"]\\n\\n# Scripts CLI\\n[project.scripts]\\nmy-cli = \\"my_lib.cli:main\\"\\n\\n# Classifiers\\n[project.classifiers]\\n\\"Development Status :: 4 - Beta\\"\\n\\"Intended Audience :: Developers\\"\\n\\"License :: OSI Approved :: MIT License\\"\\n\\"Programming Language :: Python :: 3\\"\\n\\"Programming Language :: Python :: 3.8\\"\\n\\"Programming Language :: Python :: 3.9\\"\\n\\"Programming Language :: Python :: 3.10\\"\\n```\\n\\n### Configuration avec setup.py (Legacy)\\n\\nEncore utilis\xe9, particuli\xe8rement pour les extensions C :\\n\\n```python\\nfrom setuptools import setup, find_packages\\n\\nsetup(\\n    name=\\"my-awesome-lib\\",\\n    version=\\"1.0.0\\",\\n    description=\\"Une libraire incroyable\\",\\n    author=\\"John Doe\\",\\n    author_email=\\"john@example.com\\",\\n    url=\\"https://github.com/user/my-awesome-lib\\",\\n    long_description=open(\\"README.md\\").read(),\\n    long_description_content_type=\\"text/markdown\\",\\n    license=\\"MIT\\",\\n    packages=find_packages(),\\n    python_requires=\\">=3.8\\",\\n    install_requires=[\\n        \\"requests>=2.28.0\\",\\n        \\"pydantic>=1.10\\",\\n    ],\\n    extras_require={\\n        \\"database\\": [\\"sqlalchemy>=1.4\\", \\"psycopg2>=2.9\\"],\\n        \\"email\\": [\\"aiosmtplib>=2.0\\"],\\n    },\\n    entry_points={\\n        \\"console_scripts\\": [\\n            \\"my-cli=my_lib.cli:main\\",\\n        ],\\n    },\\n    classifiers=[\\n        \\"Development Status :: 4 - Beta\\",\\n        \\"Intended Audience :: Developers\\",\\n        \\"License :: OSI Approved :: MIT License\\",\\n        \\"Programming Language :: Python :: 3.8\\",\\n    ],\\n)\\n```\\n\\n### Configuration avec setup.cfg (Alternative)\\n\\nFormat INI, utile pour projects complexes :\\n\\n```ini\\n[metadata]\\nname = my-awesome-lib\\nversion = 1.0.0\\ndescription = Une libraire incroyable\\nauthor = John Doe\\nauthor_email = john@example.com\\nurl = https://github.com/user/my-awesome-lib\\nlong_description = file: README.md\\nlong_description_content_type = text/markdown\\nlicense = MIT\\n\\n[options]\\npackages = find:\\npython_requires = >=3.8\\ninstall_requires =\\n    requests>=2.28.0\\n    pydantic>=1.10\\n\\n[options.extras_require]\\ndatabase =\\n    sqlalchemy>=1.4\\n    psycopg2>=2.9\\nemail =\\n    aiosmtplib>=2.0\\n\\n[options.entry_points]\\nconsole_scripts =\\n    my-cli = my_lib.cli:main\\n```\\n\\n## Building : Cr\xe9er les Distributions\\n\\n### Installer les outils\\n\\n```bash\\npip install setuptools wheel build\\n```\\n\\n`build` est l\'outil moderne et recommand\xe9 pour cr\xe9er distributions.\\n\\n### Cr\xe9er wheel + sdist\\n\\n```bash\\npython -m build\\n```\\n\\nG\xe9n\xe8re dans le dossier `dist/` :\\n- `my_package-1.0.0-py3-none-any.whl`\\n- `my_package-1.0.0.tar.gz`\\n\\n### V\xe9rifier la distribution\\n\\n```bash\\n# Lister le contenu du wheel\\nunzip -l dist/my_package-1.0.0-py3-none-any.whl\\n\\n# Lister le contenu du sdist\\ntar -tzf dist/my_package-1.0.0.tar.gz\\n```\\n\\n## PyPI : La Registry Centrale\\n\\n### Qu\'est-ce que PyPI ?\\n\\n**Python Package Index** : Registry centrale o\xf9 vivent tous les packages Python publics.\\n\\n- **URL** : https://pypi.org\\n- **Packages** : Environ 500k packages\\n- **T\xe9l\xe9chargements/jour** : Millions\\n\\nC\'est l\xe0 qu\'on publie avec `pip install le-package`.\\n\\n### Cr\xe9er un compte\\n\\n1. Aller sur https://pypi.org/account/register/\\n2. V\xe9rifier l\'email\\n3. Activer 2FA (recommand\xe9)\\n4. G\xe9n\xe9rer un token API : https://pypi.org/account/tokens/\\n\\n### TestPyPI : Sandbox\\n\\nPour tester avant vraie publication.\\n\\n- **URL** : https://test.pypi.org\\n- **Compt\xe9 s\xe9par\xe9** : Faut aussi s\'y enregistrer\\n- **Token s\xe9par\xe9** : \xc0 g\xe9n\xe9rer sur https://test.pypi.org/account/tokens/\\n\\nUtile pour tester le processus de publication sans polluer PyPI.\\n\\n## Publication sur PyPI\\n\\n### Installation du CLI\\n\\n```bash\\npip install twine\\n```\\n\\n`twine` est l\'outil de publication, plus robust que `python setup.py upload` (d\xe9pr\xe9ci\xe9e).\\n\\n### Configuration des Credentials\\n\\nOption 1 : Token API (recommand\xe9)\\n\\n```bash\\n# Dans ~/.pypirc\\n[distutils]\\nindex-servers =\\n    pypi\\n\\n[pypi]\\nrepository = https://upload.pypi.org/legacy/\\nusername = __token__\\npassword = pypi-AgEIcHlwaS5vcmc...  # Votre token\\n```\\n\\nOption 2 : Username/password (moins s\xfbr, legacy)\\n\\n```bash\\n[pypi]\\nusername = john\\npassword = mon_mot_de_passe_clair  # Mauvaise id\xe9e !\\n```\\n\\n### Publier sur TestPyPI\\n\\nD\'abord, ajouter TestPyPI \xe0 `~/.pypirc` :\\n\\n```\\n[distutils]\\nindex-servers =\\n    pypi\\n    test-pypi\\n\\n[test-pypi]\\nrepository = https://test.pypi.org/legacy/\\nusername = __token__\\npassword = pypi-AgEIcHlwaS5vcm9qZWN0...\\n```\\n\\nPuis publier :\\n\\n```bash\\npython -m twine upload --repository test-pypi dist/*\\n```\\n\\n### Tester l\'installation\\n\\n```bash\\n# Depuis TestPyPI\\npip install --index-url https://test.pypi.org/simple/ my-awesome-lib\\n\\n# Depuis PyPI\\npip install my-awesome-lib\\n```\\n\\n### Publier sur PyPI Official\\n\\n```bash\\npython -m twine upload dist/*\\n```\\n\\nOu avec version sp\xe9cifique :\\n\\n```bash\\npython -m twine upload dist/my_package-1.0.0*\\n```\\n\\n## Semantic Versioning\\n\\nFormat : `MAJOR.MINOR.PATCH[-pre-release][+build]`\\n\\n```\\n1.0.0          # Release stable\\n1.0.1          # Bugfix (PATCH)\\n1.1.0          # Feature (MINOR)\\n2.0.0          # Breaking change (MAJOR)\\n1.0.0-beta.1   # Pre-release (beta/alpha/rc)\\n1.0.0+build.1  # Build metadata\\n```\\n\\n**R\xe8gles** :\\n- `MAJOR` : Breaking change, code client doit changer\\n- `MINOR` : Feature r\xe9tro-compatible\\n- `PATCH` : Bugfix r\xe9tro-compatible\\n\\n## Metadata compl\xe8tes\\n\\n### __init__.py\\n\\n```python\\n# my_lib/__init__.py\\n__version__ = \\"1.0.0\\"\\n__author__ = \\"John Doe\\"\\n__email__ = \\"john@example.com\\"\\n__license__ = \\"MIT\\"\\n\\n# Exposer l\'API publique\\nfrom .core import main_function\\nfrom .utils import helper\\n\\n__all__ = [\\"main_function\\", \\"helper\\"]\\n```\\n\\n### Classifiers importants\\n\\n```toml\\n[project.classifiers]\\n# Status\\n\\"Development Status :: 3 - Alpha\\"\\n\\"Development Status :: 4 - Beta\\"\\n\\"Development Status :: 5 - Production/Stable\\"\\n\\n# Licence\\n\\"License :: OSI Approved :: MIT License\\"\\n\\"License :: OSI Approved :: Apache Software License\\"\\n\\n# Public\\n\\"Intended Audience :: Developers\\"\\n\\"Intended Audience :: System Administrators\\"\\n\\n# Topics\\n\\"Topic :: Software Development\\"\\n\\"Topic :: System :: Monitoring\\"\\n\\n# Python versions\\n\\"Programming Language :: Python :: 3\\"\\n\\"Programming Language :: Python :: 3.8\\"\\n\\"Programming Language :: Python :: 3.9\\"\\n\\"Programming Language :: Python :: 3.10\\"\\n\\"Programming Language :: Python :: 3.11\\"\\n```\\n\\n## Checklist Avant Publication\\n\\n- \u2705 Tests passent : `pytest`\\n- \u2705 Code format\xe9 et lint\xe9\\n- \u2705 Version mise \xe0 jour (semantic versioning)\\n- \u2705 CHANGELOG.md compl\xe9t\xe9\\n- \u2705 README.md avec instructions d\'installation/usage\\n- \u2705 LICENSE.md pr\xe9sent\\n- \u2705 M\xe9tadonn\xe9es compl\xe8tes dans pyproject.toml/setup.py\\n- \u2705 Test\xe9 sur TestPyPI d\'abord\\n- \u2705 Tag Git : `git tag v1.0.0`\\n- \u2705 Commit des changements\\n- \u2705 Build g\xe9n\xe9r\xe9 : `python -m build`\\n\\n## Workflow Complet avec setuptools\\n\\n```bash\\n# 1. Initialiser la structure\\nmkdir my-awesome-lib && cd my-awesome-lib\\ngit init\\n\\n# 2. Cr\xe9er pyproject.toml et source\\ncat > pyproject.toml << \'EOF\'\\n[build-system]\\nrequires = [\\"setuptools>=61.0\\", \\"wheel\\"]\\nbuild-backend = \\"setuptools.build_meta\\"\\n\\n[project]\\nname = \\"my-awesome-lib\\"\\nversion = \\"1.0.0\\"\\ndescription = \\"Une libraire incroyable\\"\\nrequires-python = \\">=3.8\\"\\ndependencies = [\\"requests>=2.28.0\\"]\\nEOF\\n\\nmkdir my_lib\\ntouch my_lib/__init__.py\\n\\n# 3. Tester le build\\npip install build\\npython -m build\\n\\n# 4. V\xe9rifier\\npip install --dry-run dist/my_awesome_lib-1.0.0-py3-none-any.whl\\n\\n# 5. Publier sur TestPyPI\\ntwine upload --repository test-pypi dist/*\\n\\n# 6. Tester installation\\npip install --index-url https://test.pypi.org/simple/ my-awesome-lib\\n\\n# 7. Publier sur PyPI official\\ntwine upload dist/*\\n```\\n\\n## Bonnes Pratiques\\n\\n### D\xe9pendances\\n\\n```toml\\n# BON : Version mineure fix\xe9e\\nrequests = \\">=2.28.0,<3.0\\"\\npydantic = \\">=1.10,<2.0\\"\\n\\n# MAUVAIS : Pas de limite sup\\nrequests = \\">=2.28.0\\"\\n\\n# BON : Version exacte pour stabilit\xe9\\nsome-critical-lib = \\"1.2.3\\"\\n```\\n\\n### Namespace packages\\n\\nUtile si on maintient plusieurs packages li\xe9s :\\n\\n```\\nsrc/\\n\u251c\u2500\u2500 mycompany/\\n\u2502   \u251c\u2500\u2500 __init__.py          (empty!)\\n\u2502   \u251c\u2500\u2500 lib1/\\n\u2502   \u2502   \u2514\u2500\u2500 __init__.py\\n\u2502   \u2514\u2500\u2500 lib2/\\n\u2502       \u2514\u2500\u2500 __init__.py\\n```\\n\\n```toml\\n[tool.setuptools.packages]\\nfind = {where = [\\"src\\"]}\\n```\\n\\nAlors `from mycompany.lib1 import ...` \xe7a marche.\\n\\n### Entry points / Scripts CLI\\n\\n```toml\\n[project.scripts]\\nmy-cli = \\"my_lib.cli:main\\"\\nmagic-tool = \\"my_lib.tools:run_magic\\"\\n```\\n\\nL\'installation du package rend ces commandes disponibles partout :\\n\\n```bash\\npip install my-awesome-lib\\nmy-cli --help        # Fonctionne!\\nmagic-tool config    # Fonctionne!\\n```\\n\\n### Extras / Optional dependencies\\n\\n```toml\\n[project.optional-dependencies]\\ndatabase = [\\"sqlalchemy>=1.4\\"]\\nemail = [\\"aiosmtplib>=2.0\\"]\\ndev = [\\"pytest\\", \\"black\\", \\"mypy\\"]\\n```\\n\\nInstallation s\xe9lective :\\n\\n```bash\\npip install my-awesome-lib                    # Bare minimum\\npip install my-awesome-lib[database]          # + database\\npip install my-awesome-lib[database,email]    # + database et email\\npip install my-awesome-lib[dev]               # + all dev tools\\n```\\n\\n## Alternatives Modernes (Optionnel)\\n\\n### Poetry\\n\\nSi vous pr\xe9f\xe9rez une approche all-in-one avec lock file :\\n\\n```bash\\npoetry new my-lib\\npoetry add requests pydantic\\npoetry build && poetry publish\\n```\\n\\nPoetry g\xe8re pyproject.toml, dependencies, et publication automatiquement. Id\xe9al si vous aimez la coh\xe9sion.\\n\\n### uv\\n\\nPackage manager ultra-rapide (\xe9crit en Rust) :\\n\\n```bash\\nuv pip install requests\\nuv venv\\n```\\n\\nRemplace pip pour des workflows rapides. Toujours utilise pyproject.toml/setup.py pour packages, juste acc\xe9l\xe8re les installations.\\n\\n**Les deux restent compatibles avec le syst\xe8me d\'emballage standard** (wheel, sdist, PyPI, setuptools). Juste des wrapper/helpers autour.\\n\\n## R\xe9sources\\n\\n- [Official Packaging Guide](https://packaging.python.org/tutorials/packaging-projects/)\\n- [setuptools Documentation](https://setuptools.pypa.io/)\\n- [PEP 427 - Wheel Format](https://peps.python.org/pep-0427/)\\n- [PEP 440 - Versioning](https://peps.python.org/pep-0440/)\\n- [PyPI Classifiers](https://pypi.org/classifiers/)\\n- [Twine Documentation](https://twine.readthedocs.io/)\\n\\n## Conclusion\\n\\nLe packaging Python s\'appuie sur des concepts simples : modules, packages, distributions (wheel/sdist), m\xe9tadonn\xe9es, et PyPI. Une fois qu\'on comprend \xe7a, publier son code devient facile. setuptools + twine suffisent pour la plupart des cas. Les alternatives modernes comme Poetry offrent plus de confort mais reposent toujours sur les m\xeames fondations.\\n\\n\xc0 vos pipelines! \ud83d\ude80"},{"id":"/2026/02/15/09-scripting/pytest-testing","metadata":{"permalink":"/blog/2026/02/15/09-scripting/pytest-testing","source":"@site/blog/09-scripting/2026-02-15-pytest-testing.md","title":"Python : Pytest","description":"Ma\xeetrisez Pytest, le framework de testing le plus populaire en Python. Fixtures, parametrization, mocking et bonnes pratiques.","date":"2026-02-15T00:00:00.000Z","tags":[{"inline":false,"label":"Scripting","permalink":"/blog/tags/scripting"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":5.08,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Python : Pytest","description":"Ma\xeetrisez Pytest, le framework de testing le plus populaire en Python. Fixtures, parametrization, mocking et bonnes pratiques.","tags":["scripting","devops"]},"unlisted":false,"prevItem":{"title":"Python : Packaging","permalink":"/blog/2026/02/15/09-scripting/packaging-python"},"nextItem":{"title":"DevOps Roadmap 2026","permalink":"/blog/2026/01/01/devops-roadmap-2026"}},"content":"Pytest est le framework de testing le plus populaire en Python. Il offre une syntaxe simple, des fonctionnalit\xe9s puissantes et une grande flexibilit\xe9 pour \xe9crire des tests de qualit\xe9.\\n\\n\x3c!--truncate--\x3e\\n\\n## Installation et Configuration\\n\\n### Installer pytest\\n\\n```bash\\npip install pytest\\n```\\n\\nOu avec uv :\\n\\n```bash\\nuv pip install pytest\\n```\\n\\n### Structure basique\\n\\n```\\nproject/\\n\u251c\u2500\u2500 src/\\n\u2502   \u2514\u2500\u2500 mymodule.py\\n\u251c\u2500\u2500 tests/\\n\u2502   \u251c\u2500\u2500 __init__.py\\n\u2502   \u251c\u2500\u2500 test_mymodule.py\\n\u2502   \u2514\u2500\u2500 conftest.py\\n\u2514\u2500\u2500 pytest.ini\\n```\\n\\n## Tests Simples\\n\\n### Premi\xe8re fonction\\n\\n```python\\n# src/calculator.py\\ndef add(a, b):\\n    return a + b\\n\\ndef multiply(a, b):\\n    return a * b\\n```\\n\\n### \xc9crire des tests\\n\\n```python\\n# tests/test_calculator.py\\nfrom src.calculator import add, multiply\\n\\ndef test_add():\\n    assert add(2, 3) == 5\\n\\ndef test_add_negative():\\n    assert add(-1, 1) == 0\\n\\ndef test_multiply():\\n    assert multiply(3, 4) == 12\\n```\\n\\n### Lancer les tests\\n\\n```bash\\n# Tous les tests\\npytest\\n\\n# Fichier sp\xe9cifique\\npytest tests/test_calculator.py\\n\\n# Test sp\xe9cifique\\npytest tests/test_calculator.py::test_add\\n\\n# Verbose\\npytest -v\\n\\n# Avec couverture\\npytest --cov=src\\n```\\n\\n## Assertions\\n\\n### Assertions de base\\n\\n```python\\ndef test_assertions():\\n    # \xc9galit\xe9\\n    assert 1 == 1\\n\\n    # In\xe9galit\xe9\\n    assert 1 != 2\\n\\n    # Comparaisons\\n    assert 5 > 3\\n    assert 3 <= 3\\n\\n    # V\xe9rit\xe9\\n    assert True\\n    assert not False\\n\\n    # Contenance\\n    assert \\"hello\\" in \\"hello world\\"\\n    assert 1 in [1, 2, 3]\\n```\\n\\n### Messages personnalis\xe9s\\n\\n```python\\ndef test_with_message():\\n    result = add(2, 3)\\n    assert result == 5, f\\"Expected 5, got {result}\\"\\n```\\n\\n### Assertions sur les exceptions\\n\\n```python\\nimport pytest\\n\\ndef divide(a, b):\\n    if b == 0:\\n        raise ValueError(\\"Division by zero\\")\\n    return a / b\\n\\ndef test_division_by_zero():\\n    with pytest.raises(ValueError):\\n        divide(10, 0)\\n\\n    # V\xe9rifier le message\\n    with pytest.raises(ValueError, match=\\"Division by zero\\"):\\n        divide(10, 0)\\n```\\n\\n## Fixtures\\n\\nLes fixtures fournissent des donn\xe9es/ressources r\xe9utilisables pour les tests.\\n\\n### Fixture simple\\n\\n```python\\nimport pytest\\n\\n@pytest.fixture\\ndef sample_data():\\n    return {\\"name\\": \\"John\\", \\"age\\": 30}\\n\\ndef test_with_fixture(sample_data):\\n    assert sample_data[\\"name\\"] == \\"John\\"\\n    assert sample_data[\\"age\\"] == 30\\n```\\n\\n### Fixture avec setup/teardown\\n\\n```python\\n@pytest.fixture\\ndef database():\\n    # Setup\\n    db = create_connection()\\n    yield db  # Le test s\'ex\xe9cute ici\\n    # Teardown\\n    db.close()\\n\\ndef test_database_query(database):\\n    result = database.query(\\"SELECT * FROM users\\")\\n    assert len(result) > 0\\n```\\n\\n### Fixtures conftest.py (partage)\\n\\nLes fixtures dans `conftest.py` sont disponibles pour tous les tests du projet.\\n\\n```python\\n# tests/conftest.py\\nimport pytest\\n\\n@pytest.fixture(scope=\\"session\\")\\ndef app():\\n    \\"\\"\\"Partag\xe9e pour toute la session de test\\"\\"\\"\\n    return create_app()\\n\\n@pytest.fixture(scope=\\"module\\")\\ndef client(app):\\n    \\"\\"\\"Partag\xe9e pour tout le module\\"\\"\\"\\n    return app.test_client()\\n\\n@pytest.fixture(scope=\\"function\\")\\ndef temp_file():\\n    \\"\\"\\"Nouvelle instance pour chaque test (par d\xe9faut)\\"\\"\\"\\n    file = open(\\"temp.txt\\", \\"w\\")\\n    yield file\\n    file.close()\\n```\\n\\n## Parametrization\\n\\nTester une fonction avec plusieurs jeux de donn\xe9es.\\n\\n### @pytest.mark.parametrize\\n\\n```python\\n@pytest.mark.parametrize(\\"input,expected\\", [\\n    (2, 4),\\n    (3, 9),\\n    (5, 25),\\n    (-2, 4),\\n])\\ndef test_square(input, expected):\\n    assert input ** 2 == expected\\n```\\n\\n### Parametrization multiple\\n\\n```python\\n@pytest.mark.parametrize(\\"a,b,expected\\", [\\n    (2, 3, 5),\\n    (0, 0, 0),\\n    (-1, 1, 0),\\n    (10, -5, 5),\\n])\\ndef test_add_multiple(a, b, expected):\\n    assert add(a, b) == expected\\n```\\n\\n### Combinaison avec fixtures\\n\\n```python\\n@pytest.mark.parametrize(\\"username\\", [\\"alice\\", \\"bob\\", \\"charlie\\"])\\ndef test_user_creation(client, username):\\n    response = client.post(\\"/users\\", json={\\"name\\": username})\\n    assert response.status_code == 201\\n```\\n\\n## Mocking avec unittest.mock\\n\\nRemplacer des d\xe9pendances pour isoler le code test\xe9.\\n\\n### Mock simple\\n\\n```python\\nfrom unittest.mock import patch, MagicMock\\nimport requests\\n\\ndef fetch_data(url):\\n    response = requests.get(url)\\n    return response.json()\\n\\n@patch(\'requests.get\')\\ndef test_fetch_data(mock_get):\\n    mock_get.return_value.json.return_value = {\\"name\\": \\"John\\"}\\n    result = fetch_data(\\"http://example.com/api/user\\")\\n    assert result[\\"name\\"] == \\"John\\"\\n```\\n\\n### Mock avec side_effect\\n\\n```python\\n@patch(\'requests.get\')\\ndef test_fetch_data_error(mock_get):\\n    mock_get.side_effect = requests.ConnectionError(\\"Connection failed\\")\\n\\n    with pytest.raises(requests.ConnectionError):\\n        fetch_data(\\"http://example.com/api/user\\")\\n```\\n\\n### V\xe9rifier les appels\\n\\n```python\\n@patch(\'requests.get\')\\ndef test_api_called_correctly(mock_get):\\n    mock_get.return_value.json.return_value = {}\\n    fetch_data(\\"http://example.com/user/1\\")\\n\\n    # V\xe9rifier l\'appel\\n    mock_get.assert_called_once_with(\\"http://example.com/user/1\\")\\n    assert mock_get.call_count == 1\\n```\\n\\n## pytest-mock (recommand\xe9)\\n\\nPlugin qui simplifie le mocking.\\n\\n```bash\\npip install pytest-mock\\n```\\n\\n```python\\ndef test_with_mocker(mocker):\\n    mock_get = mocker.patch(\'requests.get\')\\n    mock_get.return_value.json.return_value = {\\"status\\": \\"ok\\"}\\n\\n    result = fetch_data(\\"http://example.com\\")\\n    assert result[\\"status\\"] == \\"ok\\"\\n```\\n\\n## Marqueurs (Markers)\\n\\nOrganiser et filtrer les tests.\\n\\n### Marqueurs int\xe9gr\xe9s\\n\\n```python\\n@pytest.mark.skip(reason=\\"Non impl\xe9ment\xe9\\")\\ndef test_feature_new():\\n    pass\\n\\n@pytest.mark.skipif(sys.version_info < (3, 9), reason=\\"Python 3.9+\\")\\ndef test_new_feature():\\n    pass\\n\\n@pytest.mark.xfail(reason=\\"Bug connu\\")\\ndef test_buggy_feature():\\n    assert False  # Attendu d\'\xe9chouer\\n```\\n\\n### Marqueurs personnalis\xe9s\\n\\n```python\\n# pytest.ini\\n[pytest]\\nmarkers =\\n    slow: tests lents\\n    integration: tests d\'int\xe9gration\\n    db: tests utilisant la base de donn\xe9es\\n\\n# Tests\\n@pytest.mark.slow\\ndef test_heavy_computation():\\n    pass\\n\\n@pytest.mark.integration\\ndef test_api_integration():\\n    pass\\n\\n# Ex\xe9cution\\n# pytest -m slow\\n# pytest -m \\"not slow\\"\\n# pytest -m \\"integration or db\\"\\n```\\n\\n## Plugins Utiles\\n\\n### pytest-cov (Couverture)\\n\\n```bash\\npip install pytest-cov\\n```\\n\\n```bash\\npytest --cov=src --cov-report=html\\n```\\n\\n### pytest-asyncio (Tests async)\\n\\n```bash\\npip install pytest-asyncio\\n```\\n\\n```python\\n@pytest.mark.asyncio\\nasync def test_async_function():\\n    result = await async_add(2, 3)\\n    assert result == 5\\n```\\n\\n### pytest-timeout (Timeout)\\n\\n```bash\\npip install pytest-timeout\\n```\\n\\n```bash\\npytest --timeout=10  # 10 secondes\\n```\\n\\n```python\\n@pytest.mark.timeout(5)\\ndef test_performance():\\n    pass\\n```\\n\\n## Structure d\'un Bon Test\\n\\n### AAA Pattern (Arrange, Act, Assert)\\n\\n```python\\ndef test_user_registration():\\n    # Arrange - Pr\xe9parer les donn\xe9es\\n    user_data = {\\n        \\"username\\": \\"alice\\",\\n        \\"email\\": \\"alice@example.com\\",\\n        \\"password\\": \\"secure123\\"\\n    }\\n\\n    # Act - Ex\xe9cuter l\'action\\n    user = register_user(user_data)\\n\\n    # Assert - V\xe9rifier le r\xe9sultat\\n    assert user.username == \\"alice\\"\\n    assert user.email == \\"alice@example.com\\"\\n    assert user.is_active is True\\n```\\n\\n## Configuration avanc\xe9e\\n\\n### pytest.ini\\n\\n```ini\\n[pytest]\\nminversion = 7.0\\naddopts = -v --strict-markers --tb=short\\ntestpaths = tests\\npython_files = test_*.py\\npython_classes = Test*\\npython_functions = test_*\\n```\\n\\n### pyproject.toml\\n\\n```toml\\n[tool.pytest.ini_options]\\nminversion = \\"7.0\\"\\naddopts = \\"-v --strict-markers --tb=short\\"\\ntestpaths = [\\"tests\\"]\\npythonpath = [\\".\\"]\\n```\\n\\n## Bonnes Pratiques\\n\\n\u2705 **\xc0 faire**\\n- Nommer les tests clairement : `test_<fonction>_<condition>`\\n- Un test = une responsabilit\xe9\\n- Utiliser des fixtures plut\xf4t que du setup/teardown\\n- Tester les cas normaux et les edge cases\\n- Viser 80%+ de couverture de code\\n- Garder les tests rapides\\n\\n\u274c **\xc0 \xe9viter**\\n- Tests d\xe9pendants l\'un de l\'autre\\n- Tests flaky (non-d\xe9terministes)\\n- Assertions multiples et sans rapport\\n- Tests trop complexes\\n- Ignorer les erreurs\\n\\n## Exemple Complet\\n\\n```python\\n# src/user_service.py\\nclass UserService:\\n    def __init__(self, db):\\n        self.db = db\\n\\n    def create_user(self, username, email):\\n        if not username or not email:\\n            raise ValueError(\\"Username and email required\\")\\n\\n        user = {\\"username\\": username, \\"email\\": email}\\n        self.db.insert(user)\\n        return user\\n\\n# tests/test_user_service.py\\nimport pytest\\nfrom unittest.mock import MagicMock\\nfrom src.user_service import UserService\\n\\n@pytest.fixture\\ndef mock_db():\\n    return MagicMock()\\n\\n@pytest.fixture\\ndef service(mock_db):\\n    return UserService(mock_db)\\n\\n@pytest.mark.parametrize(\\"username,email\\", [\\n    (\\"alice\\", \\"alice@example.com\\"),\\n    (\\"bob\\", \\"bob@example.com\\"),\\n])\\ndef test_create_user(service, mock_db, username, email):\\n    user = service.create_user(username, email)\\n    assert user[\\"username\\"] == username\\n    assert user[\\"email\\"] == email\\n    mock_db.insert.assert_called_once()\\n\\ndef test_create_user_missing_username(service):\\n    with pytest.raises(ValueError, match=\\"Username and email required\\"):\\n        service.create_user(\\"\\", \\"test@example.com\\")\\n\\ndef test_create_user_missing_email(service):\\n    with pytest.raises(ValueError, match=\\"Username and email required\\"):\\n        service.create_user(\\"alice\\", \\"\\")\\n```\\n\\n## Conclusion\\n\\nPytest est un outil puissant pour \xe9crire des tests maintenables et fiables. Avec les fixtures, parametrization et mocking, vous pouvez couvrir n\'importe quel sc\xe9nario. Investir dans une bonne suite de tests paie rapidement en termes de confiance et de refactoring s\xe9curis\xe9 !"},{"id":"/2026/01/01/devops-roadmap-2026","metadata":{"permalink":"/blog/2026/01/01/devops-roadmap-2026","source":"@site/blog/2026-01-01-devops-roadmap-2026.md","title":"DevOps Roadmap 2026","description":"Pr\xe9sentation de ma roadmap DevOps personnelle 2026","date":"2026-01-01T00:00:00.000Z","tags":[{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":1.46,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"DevOps Roadmap 2026","description":"Pr\xe9sentation de ma roadmap DevOps personnelle 2026","tags":["devops"]},"unlisted":false,"prevItem":{"title":"Python : Pytest","permalink":"/blog/2026/02/15/09-scripting/pytest-testing"},"nextItem":{"title":"Python : uv","permalink":"/blog/2025/12/19/09-scripting/uv-python"}},"content":"Voici un r\xe9sum\xe9 de ma roadmap DevOps personnelle pour 2026. Cette roadmap s\u2019appuie sur les r\xe9alisations de l\u2019ann\xe9e pr\xe9c\xe9dente et vise \xe0 approfondir le cloud et l\u2019Infrastructure as Code. Elle \xe9volue au fil des projets, des exp\xe9rimentations et des apprentissages partag\xe9s sur le blog.\\n\\n\x3c!--truncate--\x3e\\n\\n# DevOps Roadmap 2026\\n\\nimport IconTitle from \'@site/src/components/IconTitle\';\\n\\n![DevOps](/img/devops.png)\\n\\n## Roadmap 2026\\n\\n### <IconTitle logo=\\"skill-icons:aws-light\\" name=\\"05 Apprendre un fournisseur de Cloud\\"/>\\n\\n[Cloud](/blog/tags/cloud) Ma\xeetrise des plateformes cloud (AWS, Azure, Google Cloud), gestion des utilisateurs et des permissions (IAM), administration des r\xe9seaux priv\xe9s (VPC) et des serveurs virtuels (EC2). Objectif\u202f: automatiser le d\xe9ploiement, renforcer la s\xe9curit\xe9 et optimiser la scalabilit\xe9 des infrastructures.\\n\\n### <IconTitle logo=\\"skill-icons:terraform-light\\" name=\\"08 Infrastructure as Code - Terraform\\"/>\\n\\n[Infrastructure as Code](/blog/tags/iac) Automatisation avanc\xe9e du provisionnement d\u2019infrastructure avec Terraform, gestion multi-environnements (dev, test, prod), documentation des workflows et partage des bonnes pratiques.\\n\\n## Bilan 2025\\n\\n### <IconTitle logo=\\"skill-icons:kubernetes\\" name=\\"06 Orchestration de conteneurs - Kubernetes & Docker Swarm\\"/>\\n\\n[Orchestration](/blog/tags/orchestration) Ma\xeetrise des composants de base, utilisation avanc\xe9e de la CLI Kubernetes, persistance des donn\xe9es, externalisation des configurations, gestion des acc\xe8s via Ingress. Voir [GitHub ARC Kubeadm](/docs/projects/professionnel/github-arc-kubeadm).\\n\\n### <IconTitle logo=\\"skill-icons:prometheus\\" name=\\"07 Monitoring & Observabilit\xe9\\"/>\\n\\n[Observabilit\xe9](/blog/tags/monitoring) Int\xe9gration de Grafana, Prometheus et Loki pour la supervision, la visualisation et la gestion des logs. Mise en place de dashboards, alertes et supervision multi-environnements. Voir [FervantFactory](/docs/projects/personnel/fervantfactory).\\n\\n### <IconTitle logo=\\"skill-icons:terraform-light\\" name=\\"08 Infrastructure as Code\\"/>\\n\\n[Infrastructure as Code](/blog/tags/iac) Automatisation de la configuration et du d\xe9ploiement avec Ansible, exploration de Terraform, documentation des workflows et partage des bonnes pratiques. Voir [CI/CD GitHub Actions](/docs/projects/professionnel/cicd)."},{"id":"/2025/12/19/09-scripting/uv-python","metadata":{"permalink":"/blog/2025/12/19/09-scripting/uv-python","source":"@site/blog/09-scripting/2025-12-19-uv-python.md","title":"Python : uv","description":"Pr\xe9sentation de uv, un gestionnaire de paquets Python ultra-rapide, compatible pip, pip-tools et pipenv.","date":"2025-12-19T00:00:00.000Z","tags":[{"inline":false,"label":"Scripting","permalink":"/blog/tags/scripting"}],"readingTime":1.56,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Python : uv","description":"Pr\xe9sentation de uv, un gestionnaire de paquets Python ultra-rapide, compatible pip, pip-tools et pipenv.","tags":["scripting"]},"unlisted":false,"prevItem":{"title":"DevOps Roadmap 2026","permalink":"/blog/2026/01/01/devops-roadmap-2026"},"nextItem":{"title":"Python : Ruff","permalink":"/blog/2025/12/09/09-scripting/ruff-linting-formatting"}},"content":"uv est un gestionnaire de paquets Python nouvelle g\xe9n\xe9ration, con\xe7u pour \xeatre extr\xeamement rapide et compatible avec les outils existants comme pip, pip-tools et pipenv. Il vise \xe0 acc\xe9l\xe9rer l\'installation, la r\xe9solution et la gestion des d\xe9pendances dans les projets Python, tout en restant simple \xe0 utiliser.\\n\\n\x3c!--truncate--\x3e\\n\\n## Pourquoi utiliser uv ?\\n\\n- **Ultra-rapide** : uv est \xe9crit en Rust et surpasse pip en vitesse d\'installation et de r\xe9solution.\\n- **Compatible** : uv fonctionne avec les fichiers requirements.txt, pip-tools, pipenv, et la plupart des workflows Python existants.\\n- **Gestion de l\'environnement** : uv peut cr\xe9er et g\xe9rer des environnements virtuels, simplifiant la configuration des projets.\\n- **S\xe9curit\xe9** : v\xe9rification des hashs, isolation des environnements, et gestion fine des d\xe9pendances.\\n\\n## Commandes principales\\n\\n- `uv pip install <package>` : Installe un paquet comme pip, mais bien plus vite !\\n- `uv venv` : Cr\xe9e un environnement virtuel.\\n- `uv pip sync` : Synchronise l\'environnement avec un fichier requirements.txt.\\n- `uv pip compile` : G\xe9n\xe8re un fichier requirements.txt \xe0 partir d\'un fichier de contraintes.\\n\\n## Exemple d\'utilisation\\n\\n```bash\\n# Cr\xe9er un environnement virtuel\\nuv venv\\n\\n# Installer les d\xe9pendances\\nuv pip install requests fastapi\\n\\n# G\xe9rer les d\xe9pendances avec pip-tools\\nuv pip compile requirements.in\\nuv pip sync requirements.txt\\n```\\n\\n## Avantages par rapport \xe0 pip\\n\\n- Installation et r\xe9solution des d\xe9pendances beaucoup plus rapides\\n- Gestion native des environnements virtuels\\n- Compatible avec les outils de l\'\xe9cosyst\xe8me Python\\n- Exp\xe9rience utilisateur moderne (progress bar, logs clairs)\\n\\n## Pour aller plus loin\\n\\n- [Documentation officielle uv](https://docs.astral.sh/uv/)\\n- [Projet GitHub](https://github.com/astral-sh/uv)\\n\\n\\n## uv vs Poetry\\n\\n|                | uv                                   | Poetry                                 |\\n|----------------|--------------------------------------|----------------------------------------|\\n| **Vitesse**    | Ultra-rapide (Rust)                  | Plus lent (Python)                     |\\n| **Compatibilit\xe9** | pip, pip-tools, pipenv, requirements.txt | pyproject.toml uniquement              |\\n| **Gestion env**| Oui (uv venv)                        | Oui (poetry shell/install)             |\\n| **R\xe9solution** | Rapide, compatible pip-tools         | Avanc\xe9e, mais plus lente               |\\n| **Philosophie**| Minimaliste, compatible \xe9cosyst\xe8me   | Tout-en-un, gestion centralis\xe9e        |\\n\\nuv est id\xe9al pour ceux qui veulent booster la vitesse et rester compatibles avec l\'\xe9cosyst\xe8me pip, tandis que Poetry propose une gestion centralis\xe9e et moderne des projets Python."},{"id":"/2025/12/09/09-scripting/ruff-linting-formatting","metadata":{"permalink":"/blog/2025/12/09/09-scripting/ruff-linting-formatting","source":"@site/blog/09-scripting/2025-12-09-ruff-linting-formatting.md","title":"Python : Ruff","description":"D\xe9couvrir Ruff, l\'outil Python ultra-rapide \xe9crit en Rust pour remplacer flake8, black et isort.","date":"2025-12-09T00:00:00.000Z","tags":[{"inline":false,"label":"Scripting","permalink":"/blog/tags/scripting"}],"readingTime":2.84,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Python : Ruff","description":"D\xe9couvrir Ruff, l\'outil Python ultra-rapide \xe9crit en Rust pour remplacer flake8, black et isort.","tags":["scripting"]},"unlisted":false,"prevItem":{"title":"Python : uv","permalink":"/blog/2025/12/19/09-scripting/uv-python"},"nextItem":{"title":"Ansible : Vault","permalink":"/blog/2025/11/28/08-iac/ansible-vault"}},"content":"Ruff est un **linter et formatter Python ultra-rapide** \xe9crit en Rust. Il remplace plusieurs outils comme flake8, black, isort et pylint en \xe9tant 10 \xe0 100 fois plus rapide. Cet outil simplifie consid\xe9rablement la cha\xeene de qualit\xe9 du code Python.\\n\\n\x3c!--truncate--\x3e\\n\\n# Ruff : Linting et Formatting Python\\n\\n## Qu\'est-ce que Ruff ?\\n\\nRuff est un outil tout-en-un pour la qualit\xe9 du code Python :\\n\\n- **flake8** (linting)\\n- **black** (formatting)\\n- **isort** (import sorting)\\n- **pylint** (linting avanc\xe9)\\n\\nLe principal avantage : une performance exceptionnelle gr\xe2ce \xe0 son impl\xe9mentation en Rust.\\n\\n## Installation\\n\\n```bash\\n# Avec pip\\npip install ruff\\n\\n# Avec poetry\\npoetry add --group dev ruff\\n```\\n\\n## Configuration (`pyproject.toml`)\\n\\n```toml\\n[tool.ruff]\\nline-length = 88\\ntarget-version = \\"py310\\"\\n\\n[tool.ruff.lint]\\n# R\xe8gles activ\xe9es\\nselect = [\\n    \\"E\\",    # pycodestyle errors\\n    \\"W\\",    # pycodestyle warnings\\n    \\"F\\",    # Pyflakes\\n    \\"I\\",    # isort (import sorting)\\n    \\"N\\",    # pep8-naming\\n    \\"C4\\",   # flake8-comprehensions\\n    \\"UP\\",   # pyupgrade\\n]\\n\\n# R\xe8gles ignor\xe9es\\nignore = [\\n    \\"E501\\",  # line-too-long (g\xe9r\xe9 par formatter)\\n    \\"W503\\",  # line-break-before-binary-operator\\n]\\n\\n[tool.ruff.format]\\n# Identique \xe0 black\\nquote-style = \\"double\\"\\nindent-style = \\"space\\"\\n```\\n\\n## Utilisation en ligne de commande\\n\\n```bash\\n# V\xe9rifier les erreurs sans corriger\\nruff check .\\n# Analyse le r\xe9pertoire courant et affiche toutes les violations.\\n\\n# Auto-corriger les erreurs d\xe9tectables\\nruff check --fix .\\n# Corrige automatiquement les probl\xe8mes qui peuvent l\'\xeatre (imports, formatting, etc.).\\n\\n# Formater le code\\nruff format .\\n# Applique les conventions de formatting \xe0 tous les fichiers Python.\\n\\n# Combiner v\xe9rification et formatting\\nruff check --fix . && ruff format .\\n# Workflow complet : correction des erreurs puis formatting.\\n\\n# V\xe9rifier le formatting sans modifier\\nruff format --check .\\n# Utile en CI/CD pour v\xe9rifier que le code est bien format\xe9.\\n```\\n\\n## Int\xe9gration VSCode\\n\\n### Installation de l\'extension\\n\\n1. Ouvrir VSCode\\n2. Extensions (Ctrl+Shift+X)\\n3. Chercher **\\"Ruff\\"** (par Astral)\\n4. Installer l\'extension\\n\\n### Configuration VSCode (`settings.json`)\\n\\n```json\\n{\\n  \\"[python]\\": {\\n    \\"editor.defaultFormatter\\": \\"charliermarsh.ruff\\",\\n    \\"editor.formatOnSave\\": true,\\n    \\"editor.codeActionsOnSave\\": {\\n      \\"source.fixAll.ruff\\": \\"explicit\\",\\n      \\"source.organizeImports.ruff\\": \\"explicit\\"\\n    }\\n  },\\n  \\"ruff.importStrategy\\": \\"fromEnvironment\\",\\n  \\"ruff.showNotifications\\": \\"onWarning\\"\\n}\\n```\\n\\n### Fonctionnalit\xe9s\\n\\n- **Diagnostic en temps r\xe9el** : Erreurs soulign\xe9es imm\xe9diatement dans l\'\xe9diteur\\n- **Auto-fix** : Appui sur Ctrl+S pour formater et corriger le fichier\\n- **Hover info** : Survoler une erreur pour acc\xe9der \xe0 la documentation\\n- **Command Palette** : `Ruff: Fix all auto-fixable problems`\\n\\n## Pre-commit Hook\\n\\nAjouter Ruff comme v\xe9rification automatique avant chaque commit :\\n\\n```yaml\\n# .pre-commit-config.yaml\\nrepos:\\n  - repo: https://github.com/astral-sh/ruff-pre-commit\\n    rev: v0.5.0\\n    hooks:\\n      - id: ruff\\n        args: [--fix]\\n      - id: ruff-format\\n```\\n\\nInstallation du hook :\\n\\n```bash\\npre-commit install\\n```\\n\\n## R\xe8gles courantes\\n\\n| Code | Description |\\n|------|-------------|\\n| E    | PEP 8 errors |\\n| W    | PEP 8 warnings |\\n| F    | Pyflakes (undefined names, unused imports) |\\n| I    | Import sorting |\\n| N    | Naming conventions |\\n| C4   | Comprehensions optimizations |\\n| UP   | Modernize Python syntax |\\n| B    | Bugbear (bugs courants) |\\n| D    | Docstring conventions |\\n\\n## Workflow recommand\xe9\\n\\n### \xc0 chaque sauvegarde (VSCode)\\n\\nFormat automatique et fix automatique gr\xe2ce \xe0 la configuration VSCode.\\n\\n### Avant commit (pre-commit hook)\\n\\n```bash\\nruff check --fix .\\nruff format .\\n```\\n\\n### En CI/CD\\n\\n```bash\\nruff check .           # V\xe9rifier sans corriger\\nruff format --check .  # V\xe9rifier le formatting\\n```\\n\\n## Exemple d\'utilisation\\n\\nSoit le fichier `main.py` avec plusieurs probl\xe8mes :\\n\\n```python\\nimport os\\nimport sys\\nimport json\\n\\ndef calculate(x,y):\\n    result=x+y\\n    return result\\n\\nunused_var = 42\\n```\\n\\nApr\xe8s `ruff check --fix . && ruff format .` :\\n\\n```python\\nimport json\\nimport os\\nimport sys\\n\\ndef calculate(x, y):\\n    result = x + y\\n    return result\\n```\\n\\nRuff a automatiquement :\\n\\n- Tri\xe9 les imports (isort)\\n- Ajout\xe9 les espaces autour des op\xe9rateurs (black)\\n- Supprim\xe9 la variable non utilis\xe9e (avec `--fix`)\\n\\n## Ressources\\n\\n- [Documentation officielle Ruff](https://docs.astral.sh/ruff/)\\n- [Extension VSCode](https://marketplace.visualstudio.com/items?itemName=charliermarsh.ruff)\\n- [Liste compl\xe8te des r\xe8gles](https://docs.astral.sh/ruff/rules/)\\n\\nRuff repr\xe9sente une \xe9volution majeure dans l\'\xe9cosyst\xe8me Python, combinant performance et simplicit\xe9. Son adoption am\xe9liore significativement la productivit\xe9 des d\xe9veloppeurs et la qualit\xe9 du code."},{"id":"/2025/11/28/08-iac/ansible-vault","metadata":{"permalink":"/blog/2025/11/28/08-iac/ansible-vault","source":"@site/blog/08-iac/2025-11-28-ansible-vault.md","title":"Ansible : Vault","description":"Introduction \xe0 Ansible Vault pour la gestion s\xe9curis\xe9e des secrets dans les playbooks Ansible.","date":"2025-11-28T00:00:00.000Z","tags":[{"inline":false,"label":"Infrastructure as Code","permalink":"/blog/tags/iac"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":2.07,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Ansible : Vault","description":"Introduction \xe0 Ansible Vault pour la gestion s\xe9curis\xe9e des secrets dans les playbooks Ansible.","tags":["iac","devops"]},"unlisted":false,"prevItem":{"title":"Python : Ruff","permalink":"/blog/2025/12/09/09-scripting/ruff-linting-formatting"},"nextItem":{"title":"Kubernetes : kubectl","permalink":"/blog/2025/11/21/06-orchestration/kubectl-commandes-essentielles"}},"content":"Ansible Vault est un outil int\xe9gr\xe9 \xe0 Ansible permettant de chiffrer et de g\xe9rer les secrets (mots de passe, cl\xe9s, variables sensibles) dans les fichiers de configuration et les playbooks. Cette fonctionnalit\xe9 est essentielle pour garantir la s\xe9curit\xe9 des donn\xe9es confidentielles lors de l\'automatisation de l\'infrastructure.\\n\\n\x3c!--truncate--\x3e\\n\\n# Ansible Vault : S\xe9curisation des secrets\\n\\n## Pourquoi utiliser Ansible Vault ?\\n\\n- Prot\xe9ger les mots de passe, cl\xe9s API et autres secrets dans les fichiers de configuration\\n- \xc9viter de stocker des informations sensibles en clair dans le d\xe9p\xf4t Git\\n- Faciliter la collaboration tout en maintenant la s\xe9curit\xe9\\n\\n## Fonctionnalit\xe9s principales\\n\\n- Chiffrement et d\xe9chiffrement de fichiers YAML ou variables\\n- Modification s\xe9curis\xe9e des fichiers chiffr\xe9s\\n- Int\xe9gration transparente dans les playbooks et r\xf4les Ansible\\n\\n## Commandes de base\\n\\nVoici les principales commandes \xe0 conna\xeetre, avec leurs options utiles :\\n\\n```bash\\n# Cr\xe9er un nouveau fichier chiffr\xe9\\nansible-vault create secrets.yml\\n# Ouvre un \xe9diteur pour saisir le contenu, qui sera chiffr\xe9 \xe0 la sauvegarde.\\n\\n# Chiffrer un fichier existant\\nansible-vault encrypt group_vars/prod.yml\\n# Chiffre le fichier en place. Utilisez --vault-id pour g\xe9rer plusieurs mots de passe.\\n\\n# D\xe9chiffrer un fichier\\nansible-vault decrypt secrets.yml\\n# Remplace le fichier chiffr\xe9 par sa version en clair.\\n\\n# Modifier un fichier chiffr\xe9\\nansible-vault edit secrets.yml\\n# Ouvre le fichier dans l\'\xe9diteur, le contenu reste chiffr\xe9 \xe0 la sauvegarde.\\n\\n# Afficher le contenu d\'un fichier chiffr\xe9 sans le d\xe9chiffrer sur disque\\nansible-vault view secrets.yml\\n\\n# Changer le mot de passe d\'un fichier Vault\\nansible-vault rekey secrets.yml\\n# Permet de modifier le mot de passe utilis\xe9 pour le chiffrement.\\n\\n# Ex\xe9cuter un playbook en utilisant Vault\\nansible-playbook playbook.yml --ask-vault-pass\\n# Demande le mot de passe Vault \xe0 l\'ex\xe9cution. Utilisez --vault-id pour des cas avanc\xe9s.\\n\\n# Utiliser plusieurs Vault ID (pour plusieurs mots de passe)\\nansible-playbook playbook.yml --vault-id prod@prompt --vault-id dev@prompt\\n```\\n\\n## Exemple d\'utilisation dans un playbook\\n\\n```yaml\\n---\\n- hosts: all\\n  vars_files:\\n    - secrets.yml\\n  tasks:\\n    - name: Afficher une variable secr\xe8te\\n      debug:\\n        msg: \\"Le mot de passe est : {{ vault_password }}\\"\\n```\\n\\n## Bonnes pratiques\\n\\n- Utiliser des fichiers Vault pour toutes les variables sensibles\\n- Ne jamais stocker le mot de passe Vault dans le d\xe9p\xf4t\\n- Changer r\xe9guli\xe8rement le mot de passe Vault\\n- Limiter l\'acc\xe8s aux fichiers Vault aux personnes autoris\xe9es\\n\\n## Pour aller plus loin\\n\\n- Rotation des secrets\\n- Utilisation de Vault ID pour g\xe9rer plusieurs mots de passe\\n- Int\xe9gration avec des outils externes de gestion de secrets\\n\\nAnsible Vault est un outil simple mais puissant pour renforcer la s\xe9curit\xe9 des automatisations. Il s\'int\xe8gre naturellement dans les workflows DevOps et permet de respecter les bonnes pratiques de gestion des secrets."},{"id":"/2025/11/21/06-orchestration/kubectl-commandes-essentielles","metadata":{"permalink":"/blog/2025/11/21/06-orchestration/kubectl-commandes-essentielles","source":"@site/blog/06-orchestration/2025-11-21-kubectl-commandes-essentielles.md","title":"Kubernetes : kubectl","description":"Les commandes kubectl indispensables pour g\xe9rer efficacement des clusters Kubernetes au quotidien.","date":"2025-11-21T00:00:00.000Z","tags":[{"inline":false,"label":"Orchestration","permalink":"/blog/tags/orchestration"}],"readingTime":4.9,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Kubernetes : kubectl","description":"Les commandes kubectl indispensables pour g\xe9rer efficacement des clusters Kubernetes au quotidien.","tags":["orchestration"]},"unlisted":false,"prevItem":{"title":"Ansible : Vault","permalink":"/blog/2025/11/28/08-iac/ansible-vault"},"nextItem":{"title":"Loki","permalink":"/blog/2025/11/21/07-monitoring/loki-logs-management"}},"content":"Kubectl est l\'outil en ligne de commande officiel pour interagir avec les clusters Kubernetes. La ma\xeetrise de kubectl est essentielle pour tout DevOps ou d\xe9veloppeur travaillant avec Kubernetes. Cet article explore les commandes de base et avanc\xe9es, ainsi que des astuces pour am\xe9liorer la productivit\xe9. \ud83d\ude80\\n\\n\x3c!--truncate--\x3e\\n\\n## Configuration et contextes \ud83d\udd27\\n\\n### Gestion des contextes\\n\\nKubectl utilise des contextes pour basculer entre diff\xe9rents clusters :\\n\\n```bash\\n# Afficher la configuration actuelle\\nkubectl config view\\n\\n# Lister tous les contextes disponibles\\nkubectl config get-contexts\\n\\n# Afficher le contexte actuel\\nkubectl config current-context\\n\\n# Changer de contexte\\nkubectl config use-context mon-cluster-prod\\n\\n# Cr\xe9er un nouveau contexte\\nkubectl config set-context mon-contexte \\\\\\n  --cluster=mon-cluster \\\\\\n  --user=mon-utilisateur \\\\\\n  --namespace=mon-namespace\\n\\n# D\xe9finir le namespace par d\xe9faut pour le contexte actuel\\nkubectl config set-context --current --namespace=production\\n```\\n\\n## Commandes de base \ud83d\udcdd\\n\\n### Gestion des ressources\\n\\n```bash\\n# Cr\xe9er une ressource depuis un fichier YAML\\nkubectl apply -f deployment.yaml\\n\\n# Cr\xe9er plusieurs ressources depuis un r\xe9pertoire\\nkubectl apply -f ./manifests/\\n\\n# Cr\xe9er une ressource depuis une URL\\nkubectl apply -f https://example.com/deployment.yaml\\n\\n# Supprimer une ressource\\nkubectl delete -f deployment.yaml\\nkubectl delete deployment mon-deployment\\n\\n# Supprimer toutes les ressources d\'un type\\nkubectl delete deployments --all\\n```\\n\\n### Consultation des ressources\\n\\n```bash\\n# Lister toutes les ressources d\'un type\\nkubectl get pods\\nkubectl get deployments\\nkubectl get services\\n\\n# Afficher plus de d\xe9tails\\nkubectl get pods -o wide\\n\\n# Afficher au format YAML ou JSON\\nkubectl get pod mon-pod -o yaml\\nkubectl get pod mon-pod -o json\\n\\n# Lister toutes les ressources dans tous les namespaces\\nkubectl get pods --all-namespaces\\nkubectl get pods -A  # Raccourci\\n\\n# Filtrer par labels\\nkubectl get pods -l app=nginx\\nkubectl get pods -l environment=production,tier=frontend\\n\\n# Trier les r\xe9sultats\\nkubectl get pods --sort-by=.metadata.creationTimestamp\\nkubectl get pods --sort-by=.status.startTime\\n```\\n\\n### Informations d\xe9taill\xe9es\\n\\n```bash\\n# D\xe9crire une ressource (informations d\xe9taill\xe9es + \xe9v\xe9nements)\\nkubectl describe pod mon-pod\\nkubectl describe deployment mon-deployment\\nkubectl describe node mon-node\\n\\n# Afficher les logs d\'un pod\\nkubectl logs mon-pod\\n\\n# Afficher les logs en temps r\xe9el\\nkubectl logs -f mon-pod\\n\\n# Afficher les logs d\'un conteneur sp\xe9cifique dans un pod\\nkubectl logs mon-pod -c mon-conteneur\\n\\n# Afficher les logs des 100 derni\xe8res lignes\\nkubectl logs mon-pod --tail=100\\n\\n# Afficher les logs depuis les 5 derni\xe8res minutes\\nkubectl logs mon-pod --since=5m\\n\\n# Afficher les logs du conteneur pr\xe9c\xe9dent (en cas de crash)\\nkubectl logs mon-pod --previous\\n```\\n\\n## Commandes avanc\xe9es \ud83c\udfaf\\n\\n### Ex\xe9cution de commandes dans les pods\\n\\n```bash\\n# Ex\xe9cuter une commande dans un pod\\nkubectl exec mon-pod -- ls /app\\n\\n# Ouvrir un shell interactif\\nkubectl exec -it mon-pod -- /bin/bash\\nkubectl exec -it mon-pod -- /bin/sh\\n\\n# Ex\xe9cuter dans un conteneur sp\xe9cifique\\nkubectl exec -it mon-pod -c mon-conteneur -- /bin/bash\\n\\n# Copier des fichiers depuis/vers un pod\\nkubectl cp mon-pod:/app/config.json ./config.json\\nkubectl cp ./config.json mon-pod:/app/config.json\\n```\\n\\n### Port-forwarding et proxy\\n\\n```bash\\n# Rediriger un port local vers un pod\\nkubectl port-forward pod/mon-pod 8080:80\\n\\n# Rediriger vers un service\\nkubectl port-forward service/mon-service 8080:80\\n\\n# Rediriger vers un deployment\\nkubectl port-forward deployment/mon-deployment 8080:80\\n\\n# Permettre l\'acc\xe8s depuis toutes les interfaces\\nkubectl port-forward --address 0.0.0.0 pod/mon-pod 8080:80\\n\\n# Cr\xe9er un proxy vers l\'API Kubernetes\\nkubectl proxy --port=8001\\n```\\n\\n### D\xe9bogage et d\xe9pannage\\n\\n```bash\\n# Obtenir les \xe9v\xe9nements du cluster\\nkubectl get events\\nkubectl get events --sort-by=.metadata.creationTimestamp\\nkubectl get events --field-selector type=Warning\\n\\n# V\xe9rifier l\'\xe9tat des n\u0153uds\\nkubectl top nodes\\n\\n# V\xe9rifier l\'utilisation des ressources des pods\\nkubectl top pods\\nkubectl top pods --containers\\n\\n# Afficher les pods en erreur\\nkubectl get pods --field-selector=status.phase=Failed\\n\\n# Afficher les pods non pr\xeats\\nkubectl get pods --field-selector=status.phase!=Running\\n\\n# Obtenir le YAML complet d\'une ressource en cours d\'ex\xe9cution\\nkubectl get pod mon-pod -o yaml > pod-backup.yaml\\n```\\n\\n### \xc9dition en place\\n\\n```bash\\n# \xc9diter une ressource avec l\'\xe9diteur par d\xe9faut\\nkubectl edit deployment mon-deployment\\n\\n# D\xe9finir l\'\xe9diteur (exemple avec vim)\\nKUBE_EDITOR=\\"vim\\" kubectl edit deployment mon-deployment\\n\\n# Mettre \xe0 jour l\'image d\'un deployment\\nkubectl set image deployment/mon-deployment nginx=nginx:1.21\\n\\n# Mettre \xe0 l\'\xe9chelle un deployment\\nkubectl scale deployment mon-deployment --replicas=5\\n\\n# Mettre en pause / reprendre un rollout\\nkubectl rollout pause deployment/mon-deployment\\nkubectl rollout resume deployment/mon-deployment\\n\\n# V\xe9rifier le statut d\'un rollout\\nkubectl rollout status deployment/mon-deployment\\n\\n# Voir l\'historique des r\xe9visions\\nkubectl rollout history deployment/mon-deployment\\n\\n# Revenir \xe0 la r\xe9vision pr\xe9c\xe9dente\\nkubectl rollout undo deployment/mon-deployment\\n\\n# Revenir \xe0 une r\xe9vision sp\xe9cifique\\nkubectl rollout undo deployment/mon-deployment --to-revision=2\\n```\\n\\n## Techniques de filtrage avanc\xe9es \ud83d\udd0d\\n\\n### JSONPath\\n\\nJSONPath permet d\'extraire des informations sp\xe9cifiques des objets Kubernetes :\\n\\n```bash\\n# Obtenir uniquement les noms des pods\\nkubectl get pods -o jsonpath=\'{.items[*].metadata.name}\'\\n\\n# Obtenir les IPs des pods\\nkubectl get pods -o jsonpath=\'{.items[*].status.podIP}\'\\n\\n# Obtenir les noms et IPs (avec formatage)\\nkubectl get pods -o jsonpath=\'{range .items[*]}{.metadata.name}{\\"\\\\t\\"}{.status.podIP}{\\"\\\\n\\"}{end}\'\\n\\n# Obtenir les images des conteneurs\\nkubectl get pods -o jsonpath=\'{.items[*].spec.containers[*].image}\'\\n\\n# Obtenir les nodes et leur capacit\xe9 CPU\\nkubectl get nodes -o jsonpath=\'{range .items[*]}{.metadata.name}{\\"\\\\t\\"}{.status.capacity.cpu}{\\"\\\\n\\"}{end}\'\\n```\\n\\n### Custom Columns\\n\\nCr\xe9er un affichage personnalis\xe9 des ressources :\\n\\n```bash\\n# Affichage personnalis\xe9 avec custom-columns\\nkubectl get pods -o custom-columns=NAME:.metadata.name,STATUS:.status.phase,IP:.status.podIP\\n\\n# Afficher les nodes avec leur version\\nkubectl get nodes -o custom-columns=NAME:.metadata.name,VERSION:.status.nodeInfo.kubeletVersion\\n\\n# Afficher les deployments avec leurs replicas\\nkubectl get deployments -o custom-columns=NAME:.metadata.name,DESIRED:.spec.replicas,CURRENT:.status.replicas\\n```\\n\\n## Ressources utiles \ud83d\udcda\\n\\n- [Documentation officielle kubectl](https://kubernetes.io/docs/reference/kubectl/)\\n- [Kubectl Cheat Sheet](https://kubernetes.io/docs/reference/kubectl/cheatsheet/)\\n- [JSONPath dans Kubernetes](https://kubernetes.io/docs/reference/kubectl/jsonpath/)\\n\\n## Conclusion \ud83c\udfaf\\n\\nKubectl est un outil puissant et flexible pour g\xe9rer des clusters Kubernetes. La ma\xeetrise de ces commandes et astuces permet de gagner en productivit\xe9 et en efficacit\xe9 au quotidien. La pratique r\xe9guli\xe8re est la cl\xe9 pour devenir expert avec kubectl.\\n\\nL\'exploration des fonctionnalit\xe9s avanc\xe9es et la cr\xe9ation d\'alias et scripts personnalis\xe9s peuvent automatiser les t\xe2ches r\xe9currentes. \ud83d\ude80"},{"id":"/2025/11/21/07-monitoring/loki-logs-management","metadata":{"permalink":"/blog/2025/11/21/07-monitoring/loki-logs-management","source":"@site/blog/07-monitoring/2025-11-21-loki-logs-management.md","title":"Loki","description":"Loki, le syst\xe8me de gestion de logs inspir\xe9 de Prometheus, con\xe7u pour \xeatre simple, efficace et \xe9conomique.","date":"2025-11-21T00:00:00.000Z","tags":[{"inline":false,"label":"Observabilit\xe9","permalink":"/blog/tags/monitoring"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":8.22,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Loki","description":"Loki, le syst\xe8me de gestion de logs inspir\xe9 de Prometheus, con\xe7u pour \xeatre simple, efficace et \xe9conomique.","tags":["monitoring","devops"]},"unlisted":false,"prevItem":{"title":"Kubernetes : kubectl","permalink":"/blog/2025/11/21/06-orchestration/kubectl-commandes-essentielles"},"nextItem":{"title":"Prometheus","permalink":"/blog/2025/11/21/07-monitoring/prometheus-introduction"}},"content":"Loki est un syst\xe8me d\'agr\xe9gation de logs horizontalement scalable, hautement disponible et multi-tenant, inspir\xe9 par Prometheus. Cr\xe9\xe9 par Grafana Labs, Loki se distingue par son approche minimaliste : plut\xf4t que d\'indexer le contenu des logs, il n\'indexe que les m\xe9tadonn\xe9es (labels), ce qui le rend extr\xeamement efficace et \xe9conomique. \ud83d\udcdd\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que Loki ? \ud83e\udd14\\n\\nLoki est souvent d\xe9crit comme \\"Prometheus, mais pour les logs\\". Il partage plusieurs concepts avec Prometheus :\\n\\n- **Mod\xe8le de donn\xe9es bas\xe9 sur les labels** : identification des flux de logs par des labels\\n- **Langage de requ\xeate puissant** : LogQL, inspir\xe9 de PromQL\\n- **Int\xe9gration native avec Grafana** : visualisation unifi\xe9e des m\xe9triques et logs\\n- **Architecture cloud-native** : con\xe7u pour Kubernetes et les microservices\\n\\n### Pourquoi Loki ? \ud83c\udfaf\\n\\nLes syst\xe8mes de logs traditionnels (ELK, Splunk) indexent tout le contenu des logs, ce qui :\\n\\n- **Co\xfbte cher** en stockage et en ressources de calcul\\n- **Est lent** \xe0 l\'ingestion pour de gros volumes\\n- **N\xe9cessite** une infrastructure complexe\\n\\nLoki adopte une approche diff\xe9rente :\\n\\n- **N\'indexe que les m\xe9tadonn\xe9es** (labels), pas le contenu\\n- **Stocke les logs compress\xe9s** de mani\xe8re s\xe9quentielle\\n- **Utilise le stockage objet** (S3, GCS, etc.) pour r\xe9duire les co\xfbts\\n- **Requ\xeates rapides** gr\xe2ce aux labels index\xe9s\\n\\n## Architecture de Loki \ud83c\udfd7\ufe0f\\n\\nL\'architecture de Loki se compose de plusieurs composants :\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                         Applications                         \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                     \u2502\\n                     \u25bc\\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n              \u2502  Promtail   \u2502  (Agent de collecte)\\n              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                     \u2502\\n                     \u25bc\\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n         \u2502   Loki Distributor    \u2502  (Point d\'entr\xe9e)\\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                    \u2502\\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n         \u2502                     \u2502\\n         \u25bc                     \u25bc\\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n    \u2502 Ingester\u2502          \u2502 Ingester\u2502  (Buffer + \xc9criture)\\n    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\\n         \u2502                    \u2502\\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                    \u2502\\n                    \u25bc\\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n            \u2502   Storage    \u2502  (S3, GCS, Filesystem)\\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                   \u2502\\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n        \u2502                     \u2502\\n        \u25bc                     \u25bc\\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n   \u2502 Querier \u2502          \u2502 Querier \u2502  (Lecture)\\n   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\\n        \u2502                    \u2502\\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                   \u2502\\n                   \u25bc\\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n            \u2502  Grafana   \u2502  (Visualisation)\\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\n### Composants principaux\\n\\n1. **Promtail** : Agent qui collecte les logs et les envoie \xe0 Loki\\n2. **Distributor** : Re\xe7oit les logs et les distribue aux ingesters\\n3. **Ingester** : Tampon en m\xe9moire qui \xe9crit les logs par batch dans le stockage\\n4. **Querier** : Traite les requ\xeates LogQL\\n5. **Storage** : Stockage backend (filesystem, S3, GCS, etc.)\\n\\n## Installation de Loki \ud83d\ude80\\n\\n### Installation avec Docker Compose\\n\\nLa m\xe9thode la plus simple pour tester localement :\\n\\n```yaml\\n# docker-compose.yml\\nversion: \\"3\\"\\n\\nservices:\\n  loki:\\n    image: grafana/loki:2.9.0\\n    ports:\\n      - \\"3100:3100\\"\\n    command: -config.file=/etc/loki/local-config.yaml\\n    volumes:\\n      - ./loki-data:/loki\\n\\n  promtail:\\n    image: grafana/promtail:2.9.0\\n    volumes:\\n      - /var/log:/var/log\\n      - ./promtail-config.yml:/etc/promtail/config.yml\\n    command: -config.file=/etc/promtail/config.yml\\n\\n  grafana:\\n    image: grafana/grafana:latest\\n    ports:\\n      - \\"3000:3000\\"\\n    environment:\\n      - GF_SECURITY_ADMIN_PASSWORD=admin\\n    volumes:\\n      - grafana-storage:/var/lib/grafana\\n\\nvolumes:\\n  grafana-storage:\\n```\\n\\n```bash\\n# D\xe9marrer la stack\\ndocker-compose up -d\\n```\\n\\n### Installation sur Kubernetes avec Helm\\n\\n```bash\\n# Ajouter le repo Helm de Grafana\\nhelm repo add grafana https://grafana.github.io/helm-charts\\nhelm repo update\\n\\n# Installer Loki (mode simple)\\nhelm install loki grafana/loki-stack \\\\\\n  --namespace monitoring \\\\\\n  --create-namespace \\\\\\n  --set grafana.enabled=true \\\\\\n  --set prometheus.enabled=true \\\\\\n  --set promtail.enabled=true\\n\\n# V\xe9rifier le d\xe9ploiement\\nkubectl get pods -n monitoring\\n```\\n\\n### Installation distribu\xe9e sur Kubernetes\\n\\nPour la production, utilisez le mode distribu\xe9 :\\n\\n```bash\\n# Installer Loki en mode distribu\xe9\\nhelm install loki grafana/loki-distributed \\\\\\n  --namespace monitoring \\\\\\n  --create-namespace \\\\\\n  --set loki.schemaConfig.configs[0].from=\\"2024-01-01\\" \\\\\\n  --set loki.schemaConfig.configs[0].store=boltdb-shipper \\\\\\n  --set loki.schemaConfig.configs[0].object_store=s3 \\\\\\n  --set loki.storageConfig.boltdb_shipper.shared_store=s3 \\\\\\n  --set loki.storageConfig.aws.s3=s3://region/bucket\\n```\\n\\n## Configuration de Promtail \ud83d\udccb\\n\\nPromtail est l\'agent qui collecte les logs et les envoie \xe0 Loki.\\n\\n### Configuration de base\\n\\nCr\xe9ez un fichier `promtail-config.yml` :\\n\\n```yaml\\nserver:\\n  http_listen_port: 9080\\n  grpc_listen_port: 0\\n\\npositions:\\n  filename: /tmp/positions.yaml\\n\\nclients:\\n  - url: http://loki:3100/loki/api/v1/push\\n\\nscrape_configs:\\n  # Collecter les logs syst\xe8me\\n  - job_name: system\\n    static_configs:\\n      - targets:\\n          - localhost\\n        labels:\\n          job: varlogs\\n          host: my-server\\n          __path__: /var/log/*.log\\n\\n  # Collecter les logs d\'une application\\n  - job_name: myapp\\n    static_configs:\\n      - targets:\\n          - localhost\\n        labels:\\n          job: myapp\\n          environment: production\\n          __path__: /app/logs/*.log\\n```\\n\\n### Configuration avanc\xe9e avec pipeline\\n\\nPromtail peut parser et enrichir les logs avant de les envoyer :\\n\\n```yaml\\nscrape_configs:\\n  - job_name: nginx\\n    static_configs:\\n      - targets:\\n          - localhost\\n        labels:\\n          job: nginx\\n          __path__: /var/log/nginx/access.log\\n\\n    pipeline_stages:\\n      # Parser le format de log nginx\\n      - regex:\\n          expression: \'^(?P<ip>\\\\S+) \\\\S+ \\\\S+ \\\\[(?P<time>[^\\\\]]+)\\\\] \\"(?P<method>\\\\S+) (?P<path>\\\\S+) \\\\S+\\" (?P<status>\\\\d+) (?P<size>\\\\d+)\'\\n\\n      # Extraire des labels depuis les champs pars\xe9s\\n      - labels:\\n          method:\\n          status:\\n          path:\\n\\n      # Ajouter un timestamp\\n      - timestamp:\\n          source: time\\n          format: \'02/Jan/2006:15:04:05 -0700\'\\n\\n      # Filtrer certains logs (optionnel)\\n      - match:\\n          selector: \'{status=\\"200\\"}\'\\n          action: drop\\n```\\n\\n### Configuration pour Kubernetes\\n\\nPromtail peut automatiquement d\xe9couvrir les pods Kubernetes :\\n\\n```yaml\\nscrape_configs:\\n  - job_name: kubernetes-pods\\n    kubernetes_sd_configs:\\n      - role: pod\\n\\n    relabel_configs:\\n      # Extraire les m\xe9tadonn\xe9es Kubernetes\\n      - source_labels:\\n          - __meta_kubernetes_pod_node_name\\n        target_label: __host__\\n\\n      - action: labelmap\\n        regex: __meta_kubernetes_pod_label_(.+)\\n\\n      - source_labels:\\n          - __meta_kubernetes_namespace\\n        target_label: namespace\\n\\n      - source_labels:\\n          - __meta_kubernetes_pod_name\\n        target_label: pod\\n\\n      - source_labels:\\n          - __meta_kubernetes_pod_container_name\\n        target_label: container\\n\\n      - replacement: /var/log/pods/*$1/*.log\\n        separator: /\\n        source_labels:\\n          - __meta_kubernetes_pod_uid\\n          - __meta_kubernetes_pod_container_name\\n        target_label: __path__\\n```\\n\\n## Introduction \xe0 LogQL \ud83d\udd0d\\n\\nLogQL est le langage de requ\xeate de Loki, inspir\xe9 de PromQL.\\n\\n### S\xe9lecteurs de flux de logs\\n\\n```logql\\n# S\xe9lectionner par label exact\\n{job=\\"nginx\\"}\\n\\n# Combiner plusieurs labels\\n{job=\\"nginx\\", environment=\\"production\\"}\\n\\n# Op\xe9rateurs de correspondance\\n{job=~\\"nginx|apache\\"}  # Regex: nginx OU apache\\n{status!=\\"200\\"}        # status diff\xe9rent de 200\\n{path=~\\"/api/.*\\"}      # path commence par /api/\\n```\\n\\n### Filtres de lignes\\n\\n```logql\\n# Rechercher une cha\xeene de caract\xe8res\\n{job=\\"nginx\\"} |= \\"error\\"\\n\\n# Exclure une cha\xeene\\n{job=\\"nginx\\"} != \\"debug\\"\\n\\n# Utiliser des regex\\n{job=\\"nginx\\"} |~ \\"error|ERROR|Error\\"\\n\\n# Combiner plusieurs filtres\\n{job=\\"nginx\\"} |= \\"error\\" != \\"timeout\\"\\n```\\n\\n### Parsers\\n\\n```logql\\n# Parser JSON\\n{job=\\"myapp\\"} | json\\n\\n# Parser JSON et extraire des champs\\n{job=\\"myapp\\"} | json | level=\\"error\\"\\n\\n# Parser avec regex\\n{job=\\"nginx\\"} | regexp \\"(?P<method>\\\\\\\\w+) (?P<path>\\\\\\\\S+)\\"\\n\\n# Parser logfmt\\n{job=\\"myapp\\"} | logfmt\\n```\\n\\n### Filtres de labels extraits\\n\\n```logql\\n# Apr\xe8s parsing, filtrer sur les labels extraits\\n{job=\\"myapp\\"} | json | level=\\"error\\"\\n\\n# Utiliser les op\xe9rateurs de comparaison\\n{job=\\"nginx\\"} | json | status >= 400\\n\\n# Combiner avec des filtres de lignes\\n{job=\\"myapp\\"} | json | level=\\"error\\" |= \\"database\\"\\n```\\n\\n### Agr\xe9gations et fonctions\\n\\n```logql\\n# Compter le nombre de lignes\\ncount_over_time({job=\\"nginx\\"}[5m])\\n\\n# Taux de logs par seconde\\nrate({job=\\"nginx\\"}[5m])\\n\\n# Somme des octets\\nsum(rate({job=\\"nginx\\"} | json | unwrap bytes[5m]))\\n\\n# Compter par label\\nsum by (status) (count_over_time({job=\\"nginx\\"} | json [5m]))\\n\\n# Moyenne d\'une valeur num\xe9rique\\navg(rate({job=\\"myapp\\"} | json | unwrap response_time [5m]))\\n\\n# Quantiles (p95, p99)\\nquantile_over_time(0.95, {job=\\"myapp\\"} | json | unwrap duration [5m])\\n```\\n\\n### Exemples pratiques\\n\\n```logql\\n# Tous les logs d\'erreur des 5 derni\xe8res minutes\\n{job=\\"myapp\\"} |= \\"error\\" [5m]\\n\\n# Taux d\'erreurs HTTP 5xx\\nsum(rate({job=\\"nginx\\"} | json | status >= 500 [5m]))\\n\\n# Top 5 des chemins les plus appel\xe9s\\ntopk(5, sum by (path) (rate({job=\\"nginx\\"} | json [5m])))\\n\\n# Logs d\'erreur dans un namespace Kubernetes sp\xe9cifique\\n{namespace=\\"production\\"} |= \\"error\\" | json | level=\\"error\\"\\n\\n# Dur\xe9e moyenne des requ\xeates API\\navg(rate({job=\\"api\\"} | json | unwrap duration [5m]))\\n\\n# Logs avec un certain pattern dans les derni\xe8res heures\\n{job=\\"myapp\\"} |~ \\"database.*timeout\\" [1h]\\n\\n# Grouper par niveau de log et compter\\nsum by (level) (count_over_time({job=\\"myapp\\"} | json [5m]))\\n\\n# D\xe9tecter les pics de logs (anomalies)\\ncount_over_time({job=\\"myapp\\"}[5m]) > 1000\\n```\\n\\n## Visualisation avec Grafana \ud83d\udcca\\n\\n### Ajouter Loki comme source de donn\xe9es\\n\\n1. Ouvrir Grafana : `http://localhost:3000`\\n2. Aller dans **Configuration > Data Sources**\\n3. Cliquer sur **Add data source**\\n4. S\xe9lectionner **Loki**\\n5. Configurer l\'URL : `http://loki:3100`\\n6. Cliquer sur **Save & Test**\\n\\n### Cr\xe9er un dashboard\\n\\n```jsonnet\\n// Exemple de panel Grafana avec LogQL\\n{\\n  \\"datasource\\": \\"Loki\\",\\n  \\"targets\\": [\\n    {\\n      \\"expr\\": \\"sum by (level) (count_over_time({job=\\\\\\"myapp\\\\\\"} | json [5m]))\\",\\n      \\"refId\\": \\"A\\"\\n    }\\n  ],\\n  \\"title\\": \\"Logs par niveau\\",\\n  \\"type\\": \\"timeseries\\"\\n}\\n```\\n\\n### Explorer les logs\\n\\nL\'onglet **Explore** de Grafana permet d\'explorer les logs interactivement :\\n\\n1. S\xe9lectionner **Loki** comme source de donn\xe9es\\n2. Utiliser le builder de requ\xeate ou \xe9crire du LogQL\\n3. Visualiser les r\xe9sultats en temps r\xe9el\\n4. Filtrer, parser et agr\xe9ger les logs\\n\\n## Int\xe9gration avec Kubernetes \ud83d\udea2\\n\\n### Collecter les logs de pods\\n\\nAvec Promtail d\xe9ploy\xe9 en DaemonSet, les logs de tous les pods sont automatiquement collect\xe9s.\\n\\n### Annoter les pods pour enrichir les logs\\n\\n```yaml\\napiVersion: v1\\nkind: Pod\\nmetadata:\\n  name: myapp\\n  labels:\\n    app: myapp\\n    version: v1.2.3\\n  annotations:\\n    loki.io/scrape: \\"true\\"\\n    loki.io/parser: \\"json\\"\\nspec:\\n  containers:\\n    - name: myapp\\n      image: myapp:1.2.3\\n```\\n\\n### Requ\xeates LogQL pour Kubernetes\\n\\n```logql\\n# Logs d\'un pod sp\xe9cifique\\n{pod=\\"myapp-5d8f7c8b9-abc12\\"}\\n\\n# Logs d\'un namespace\\n{namespace=\\"production\\"}\\n\\n# Logs d\'une application (via label)\\n{app=\\"myapp\\"}\\n\\n# Logs d\'erreur dans tous les pods d\'une app\\n{app=\\"myapp\\"} |= \\"error\\"\\n\\n# Combiner plusieurs filtres Kubernetes\\n{namespace=\\"production\\", app=\\"api\\"} | json | level=\\"error\\"\\n```\\n\\n## Bonnes pratiques \ud83d\udc4d\\n\\n### 1. Utiliser des labels efficacement\\n\\n```yaml\\n# \u2705 BON : Labels avec cardinalit\xe9 faible\\nlabels:\\n  environment: production\\n  app: myapp\\n  level: error\\n\\n# \u274c MAUVAIS : Labels avec cardinalit\xe9 \xe9lev\xe9e\\nlabels:\\n  user_id: \\"123456\\"      # \xc9viter\\n  request_id: \\"abc-def\\"  # \xc9viter\\n  timestamp: \\"...\\"       # \xc9viter\\n```\\n\\n### 2. Structurer les logs en JSON\\n\\n```python\\n# Python avec structlog\\nimport structlog\\n\\nlog = structlog.get_logger()\\nlog.info(\\n    \\"user_login\\",\\n    user_id=\\"12345\\",\\n    ip=\\"192.168.1.1\\",\\n    status=\\"success\\"\\n)\\n```\\n\\nSortie :\\n```json\\n{\\"event\\": \\"user_login\\", \\"user_id\\": \\"12345\\", \\"ip\\": \\"192.168.1.1\\", \\"status\\": \\"success\\", \\"timestamp\\": \\"2025-11-15T10:00:00Z\\"}\\n```\\n\\n### 3. Optimiser les requ\xeates LogQL\\n\\n```logql\\n# \u2705 BON : Filtrer d\'abord avec des labels\\n{job=\\"nginx\\", status=\\"500\\"}\\n\\n# \u274c MOINS BON : Filtrer seulement avec le contenu\\n{job=\\"nginx\\"} |= \\"500\\"\\n\\n# \u2705 BON : Utiliser des plages temporelles courtes\\n{job=\\"nginx\\"}[5m]\\n\\n# \u274c MAUVAIS : Plages temporelles tr\xe8s longues\\n{job=\\"nginx\\"}[24h]\\n```\\n\\n### 4. Configurer la r\xe9tention des logs\\n\\n```yaml\\n# loki-config.yaml\\nlimits_config:\\n  retention_period: 744h  # 31 jours\\n\\ntable_manager:\\n  retention_deletes_enabled: true\\n  retention_period: 744h\\n```\\n\\n### 5. Utiliser le multi-tenancy\\n\\n```yaml\\n# Configuration Loki pour multi-tenancy\\nauth_enabled: true\\n\\n# Promtail avec tenant_id\\nclients:\\n  - url: http://loki:3100/loki/api/v1/push\\n    tenant_id: team-a\\n```\\n\\n## Cas d\'usage avanc\xe9s \ud83d\ude80\\n\\n### Alerting avec Loki et Prometheus\\n\\nLa cr\xe9ation d\'alertes bas\xe9es sur les logs est possible via le ruler Loki ou en exposant des m\xe9triques \xe0 Prometheus :\\n\\n```yaml\\n# Recording rules dans Loki\\ngroups:\\n  - name: logs\\n    interval: 1m\\n    rules:\\n      - record: log_error_rate\\n        expr: |\\n          sum by (app) (rate({job=\\"myapp\\"} |= \\"error\\" [5m]))\\n```\\n\\n### Tracer les requ\xeates entre services\\n\\nUtiliser le trace ID dans les logs pour corr\xe9ler les logs entre microservices :\\n\\n```logql\\n# Rechercher tous les logs d\'une trace\\n{job=\\"myapp\\"} | json | trace_id=\\"abc123\\"\\n```\\n\\n### D\xe9tecter les anomalies\\n\\n```logql\\n# Comparer le taux actuel au taux habituel\\n(\\n  sum(rate({job=\\"myapp\\"}[5m]))\\n  /\\n  avg_over_time(sum(rate({job=\\"myapp\\"}[5m]))[1h:5m])\\n) > 2\\n```\\n\\n## Conclusion \ud83c\udfaf\\n\\nLoki r\xe9volutionne la gestion des logs en adoptant une approche minimaliste et efficace. Son int\xe9gration native avec Grafana et sa compatibilit\xe9 avec l\'\xe9cosyst\xe8me Prometheus en font un choix excellent pour les infrastructures cloud-native.\\n\\nLes points cl\xe9s \xe0 retenir :\\n\\n- **\xc9conomique** : pas d\'indexation du contenu, stockage objet\\n- **Performant** : indexation des labels seulement\\n- **Simple** : architecture inspir\xe9e de Prometheus\\n- **Puissant** : LogQL pour requ\xeater et agr\xe9ger les logs\\n- **Cloud-native** : parfait pour Kubernetes\\n\\nLes prochains articles aborderont la combinaison de Loki avec Prometheus et Grafana pour une stack d\'observabilit\xe9 compl\xe8te.\\n\\n## Ressources utiles \ud83d\udcda\\n\\n- [Documentation officielle Loki](https://grafana.com/docs/loki/)\\n- [LogQL Cheat Sheet](https://grafana.com/docs/loki/latest/logql/)\\n- [Best practices Loki](https://grafana.com/docs/loki/latest/best-practices/)\\n- [Promtail configuration](https://grafana.com/docs/loki/latest/clients/promtail/)"},{"id":"/2025/11/21/07-monitoring/prometheus-introduction","metadata":{"permalink":"/blog/2025/11/21/07-monitoring/prometheus-introduction","source":"@site/blog/07-monitoring/2025-11-21-prometheus-introduction.md","title":"Prometheus","description":"Prometheus, l\'outil de monitoring et d\'alerting open-source devenu incontournable dans l\'\xe9cosyst\xe8me Cloud Native.","date":"2025-11-21T00:00:00.000Z","tags":[{"inline":false,"label":"Observabilit\xe9","permalink":"/blog/tags/monitoring"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":7.3,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Prometheus","description":"Prometheus, l\'outil de monitoring et d\'alerting open-source devenu incontournable dans l\'\xe9cosyst\xe8me Cloud Native.","tags":["monitoring","devops"]},"unlisted":false,"prevItem":{"title":"Loki","permalink":"/blog/2025/11/21/07-monitoring/loki-logs-management"},"nextItem":{"title":"Ansible : avanc\xe9","permalink":"/blog/2025/11/21/08-iac/ansible-playbooks-avances"}},"content":"Prometheus est un syst\xe8me de monitoring et d\'alerting open-source qui s\'est impos\xe9 comme la r\xe9f\xe9rence dans l\'\xe9cosyst\xe8me Cloud Native. Con\xe7u initialement chez SoundCloud en 2012, Prometheus est aujourd\'hui un projet gradu\xe9 de la Cloud Native Computing Foundation (CNCF). Cet article explore l\'installation, le fonctionnement et les bases du langage de requ\xeate PromQL. \ud83d\udcca\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que Prometheus ? \ud83e\udd14\\n\\nPrometheus est un syst\xe8me de monitoring qui collecte et stocke des m\xe9triques sous forme de s\xe9ries temporelles (time-series). Il se distingue par :\\n\\n- **Architecture pull** : Prometheus r\xe9cup\xe8re activement les m\xe9triques depuis les cibles\\n- **Mod\xe8le de donn\xe9es multi-dimensionnel** : m\xe9triques identifi\xe9es par un nom et des labels (cl\xe9-valeur)\\n- **Langage de requ\xeate puissant** : PromQL pour interroger et agr\xe9ger les donn\xe9es\\n- **Syst\xe8me d\'alerting int\xe9gr\xe9** : d\xe9finition de r\xe8gles d\'alerte directement dans Prometheus\\n- **D\xe9couverte de services** : int\xe9gration native avec Kubernetes, Consul, etc.\\n- **Stockage local** : pas de d\xe9pendance \xe0 un syst\xe8me de stockage distribu\xe9\\n\\n## Architecture de Prometheus \ud83c\udfd7\ufe0f\\n\\nL\'architecture de Prometheus se compose de plusieurs \xe9l\xe9ments :\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                    Prometheus Server                     \u2502\\n\u2502                                                           \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\\n\u2502  \u2502   Retrieval   \u2502  \u2502   Storage    \u2502  \u2502  HTTP Server \u2502 \u2502\\n\u2502  \u2502   (Scraping)  \u2502\u2500\u25b6\u2502  (TSDB)      \u2502\u25c0\u2500\u2502  (PromQL)    \u2502 \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\\n\u2502         \u2502                                      \u25b2         \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n          \u2502                                      \u2502\\n          \u25bc                                      \u2502\\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n  \u2502   Exporters   \u2502                    \u2502   Grafana /     \u2502\\n  \u2502   (Metrics)   \u2502                    \u2502   API Clients   \u2502\\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n          \u2502\\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n  \u2502  Pushgateway   \u2502  (pour jobs courts)\\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n          \u2502\\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n  \u2502  Alertmanager   \u2502  (gestion des alertes)\\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\n**Composants principaux :**\\n\\n- **Prometheus Server** : collecte, stocke et permet d\'interroger les m\xe9triques\\n- **Exporters** : exposent les m\xe9triques des syst\xe8mes tiers au format Prometheus\\n- **Pushgateway** : permet aux jobs courts de pousser leurs m\xe9triques\\n- **Alertmanager** : g\xe8re les alertes (d\xe9duplication, groupage, routage, notifications)\\n\\n## Installation de Prometheus \ud83d\ude80\\n\\n### Installation avec Docker\\n\\nLa m\xe9thode la plus simple pour tester Prometheus :\\n\\n```bash\\n# T\xe9l\xe9charger et lancer Prometheus\\ndocker run -d \\\\\\n  --name prometheus \\\\\\n  -p 9090:9090 \\\\\\n  -v $(pwd)/prometheus.yml:/etc/prometheus/prometheus.yml \\\\\\n  prom/prometheus\\n```\\n\\n### Installation binaire\\n\\nPour une installation plus traditionnelle :\\n\\n```bash\\n# T\xe9l\xe9charger la derni\xe8re version\\nwget https://github.com/prometheus/prometheus/releases/download/v2.45.0/prometheus-2.45.0.linux-amd64.tar.gz\\n\\n# Extraire\\ntar xvfz prometheus-2.45.0.linux-amd64.tar.gz\\ncd prometheus-2.45.0.linux-amd64\\n\\n# Lancer Prometheus\\n./prometheus --config.file=prometheus.yml\\n```\\n\\n### Installation sur Kubernetes avec Helm\\n\\nPour d\xe9ployer Prometheus dans un cluster Kubernetes :\\n\\n```bash\\n# Ajouter le repo Helm de Prometheus\\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\\nhelm repo update\\n\\n# Installer Prometheus\\nhelm install prometheus prometheus-community/prometheus \\\\\\n  --namespace monitoring \\\\\\n  --create-namespace\\n\\n# V\xe9rifier le d\xe9ploiement\\nkubectl get pods -n monitoring\\n```\\n\\n### Configuration de base\\n\\nCr\xe9ez un fichier `prometheus.yml` avec la configuration minimale :\\n\\n```yaml\\nglobal:\\n  scrape_interval: 15s      # Intervalle de collecte par d\xe9faut\\n  evaluation_interval: 15s  # Intervalle d\'\xe9valuation des r\xe8gles\\n  external_labels:\\n    cluster: \'dev\'\\n    environment: \'development\'\\n\\n# R\xe8gles d\'alerting (optionnel)\\nrule_files:\\n  - \\"rules/*.yml\\"\\n\\n# Configuration des cibles \xe0 scraper\\nscrape_configs:\\n  # Prometheus se monitore lui-m\xeame\\n  - job_name: \'prometheus\'\\n    static_configs:\\n      - targets: [\'localhost:9090\']\\n        labels:\\n          instance: \'prometheus-server\'\\n\\n  # Exemple : monitorer Node Exporter\\n  - job_name: \'node-exporter\'\\n    static_configs:\\n      - targets: [\'localhost:9100\']\\n        labels:\\n          instance: \'server-01\'\\n```\\n\\n## Concepts de base : M\xe9triques et Scraping \ud83d\udcc8\\n\\n### Les types de m\xe9triques\\n\\nPrometheus supporte quatre types de m\xe9triques :\\n\\n1. **Counter** : compteur qui ne peut qu\'augmenter (ou se r\xe9initialiser \xe0 0)\\n\\n   ```\\n   http_requests_total{method=\\"GET\\", status=\\"200\\"} 1234\\n   ```\\n\\n   Exemples : nombre de requ\xeates, erreurs, t\xe2ches compl\xe9t\xe9es\\n\\n2. **Gauge** : valeur qui peut augmenter ou diminuer\\n\\n   ```\\n   memory_usage_bytes{instance=\\"server-01\\"} 8589934592\\n   ```\\n\\n   Exemples : temp\xe9rature, m\xe9moire utilis\xe9e, nombre de connexions actives\\n\\n3. **Histogram** : \xe9chantillonne des observations et les compte dans des buckets\\n\\n   ```\\n   http_request_duration_seconds_bucket{le=\\"0.1\\"} 100\\n   http_request_duration_seconds_bucket{le=\\"0.5\\"} 250\\n   http_request_duration_seconds_bucket{le=\\"1.0\\"} 300\\n   ```\\n\\n   Exemples : dur\xe9e de requ\xeates, taille de r\xe9ponses\\n\\n4. **Summary** : similaire \xe0 histogram, mais calcule des quantiles c\xf4t\xe9 client\\n\\n   ```\\n   http_request_duration_seconds{quantile=\\"0.5\\"} 0.23\\n   http_request_duration_seconds{quantile=\\"0.9\\"} 0.87\\n   http_request_duration_seconds{quantile=\\"0.99\\"} 1.2\\n   ```\\n\\n### Le mod\xe8le de donn\xe9es\\n\\nChaque m\xe9trique dans Prometheus est identifi\xe9e par :\\n\\n- **Nom de la m\xe9trique** : d\xe9crit ce qui est mesur\xe9\\n- **Labels** : paires cl\xe9-valeur pour distinguer les dimensions\\n\\nExemple :\\n\\n```\\napi_http_requests_total{method=\\"POST\\", handler=\\"/users\\", status=\\"200\\"} 1234\\n```\\n\\n- Nom : `api_http_requests_total`\\n- Labels : `method=\\"POST\\"`, `handler=\\"/users\\"`, `status=\\"200\\"`\\n- Valeur : `1234`\\n\\n### Le processus de scraping\\n\\nLe scraping est le processus par lequel Prometheus collecte les m\xe9triques :\\n\\n1. **Prometheus initie la connexion** vers la cible (pull model)\\n2. **Requ\xeate HTTP GET** sur l\'endpoint `/metrics`\\n3. **R\xe9ception des m\xe9triques** au format texte Prometheus\\n4. **Stockage** dans la base de donn\xe9es time-series\\n\\nExemple de r\xe9ponse d\'un endpoint `/metrics` :\\n\\n```\\n# HELP http_requests_total Total number of HTTP requests\\n# TYPE http_requests_total counter\\nhttp_requests_total{method=\\"GET\\",status=\\"200\\"} 1234\\nhttp_requests_total{method=\\"GET\\",status=\\"404\\"} 42\\nhttp_requests_total{method=\\"POST\\",status=\\"200\\"} 567\\n\\n# HELP memory_usage_bytes Current memory usage in bytes\\n# TYPE memory_usage_bytes gauge\\nmemory_usage_bytes 8589934592\\n\\n# HELP http_request_duration_seconds HTTP request duration\\n# TYPE http_request_duration_seconds histogram\\nhttp_request_duration_seconds_bucket{le=\\"0.1\\"} 100\\nhttp_request_duration_seconds_bucket{le=\\"0.5\\"} 250\\nhttp_request_duration_seconds_bucket{le=\\"1.0\\"} 300\\nhttp_request_duration_seconds_sum 187.5\\nhttp_request_duration_seconds_count 300\\n```\\n\\n## Exporters : collecter des m\xe9triques \ud83d\udce1\\n\\nLes exporters sont des programmes qui exposent des m\xe9triques de syst\xe8mes tiers au format Prometheus.\\n\\n### Node Exporter (m\xe9triques syst\xe8me)\\n\\n```bash\\n# Installation avec Docker\\ndocker run -d \\\\\\n  --name node-exporter \\\\\\n  --net=\\"host\\" \\\\\\n  --pid=\\"host\\" \\\\\\n  -v \\"/:/host:ro,rslave\\" \\\\\\n  prom/node-exporter \\\\\\n  --path.rootfs=/host\\n\\n# Configuration dans prometheus.yml\\nscrape_configs:\\n  - job_name: \'node\'\\n    static_configs:\\n      - targets: [\'localhost:9100\']\\n```\\n\\n### Exporters populaires\\n\\n- **node_exporter** : m\xe9triques syst\xe8me (CPU, m\xe9moire, disque, r\xe9seau)\\n- **blackbox_exporter** : probes HTTP, TCP, ICMP, DNS\\n- **mysqld_exporter** : m\xe9triques MySQL/MariaDB\\n- **postgres_exporter** : m\xe9triques PostgreSQL\\n- **redis_exporter** : m\xe9triques Redis\\n- **nginx_exporter** : m\xe9triques Nginx\\n- **kube-state-metrics** : m\xe9triques d\'\xe9tat Kubernetes\\n\\n## Introduction \xe0 PromQL \ud83d\udcca\\n\\nPromQL (Prometheus Query Language) est le langage de requ\xeate pour interroger les m\xe9triques.\\n\\n### Requ\xeates de base\\n\\n```promql\\n# S\xe9lectionner toutes les s\xe9ries d\'une m\xe9trique\\nhttp_requests_total\\n\\n# Filtrer par label\\nhttp_requests_total{method=\\"GET\\"}\\n\\n# Filtrer avec plusieurs labels\\nhttp_requests_total{method=\\"GET\\", status=\\"200\\"}\\n\\n# Op\xe9rateurs de correspondance\\nhttp_requests_total{status=~\\"2..\\"} # Regex: status commence par 2\\nhttp_requests_total{status!=\\"200\\"} # status diff\xe9rent de 200\\nhttp_requests_total{method=~\\"GET|POST\\"} # method est GET ou POST\\n```\\n\\n### S\xe9lecteurs temporels\\n\\n```promql\\n# Valeur actuelle\\nhttp_requests_total\\n\\n# Plage de temps (range vector)\\nhttp_requests_total[5m] # Les 5 derni\xe8res minutes\\n\\n# D\xe9calage temporel (offset)\\nhttp_requests_total offset 5m # Valeur d\'il y a 5 minutes\\nhttp_requests_total[1h] offset 1d # Les valeurs d\'hier sur 1h\\n```\\n\\n### Fonctions courantes\\n\\n```promql\\n# Rate : taux de changement par seconde (pour les counters)\\nrate(http_requests_total[5m])\\n\\n# Increase : augmentation totale sur une p\xe9riode\\nincrease(http_requests_total[1h])\\n\\n# Sum : somme des valeurs\\nsum(http_requests_total)\\n\\n# Sum by : grouper par label\\nsum by (method) (http_requests_total)\\n\\n# Avg : moyenne\\navg(cpu_usage_percent)\\n\\n# Max / Min\\nmax(memory_usage_bytes)\\nmin(disk_free_bytes)\\n\\n# Count : nombre de s\xe9ries\\ncount(up == 1) # Nombre de cibles up\\n```\\n\\n### Op\xe9rations math\xe9matiques\\n\\n```promql\\n# Op\xe9rations arithm\xe9tiques\\nnode_memory_MemTotal_bytes - node_memory_MemFree_bytes\\n\\n# Pourcentage\\n(node_memory_MemTotal_bytes - node_memory_MemFree_bytes) / node_memory_MemTotal_bytes * 100\\n\\n# Comparaisons\\nup == 1 # Toutes les cibles actives\\nhttp_requests_total > 1000 # Requ\xeates sup\xe9rieures \xe0 1000\\n```\\n\\n### Agr\xe9gations avanc\xe9es\\n\\n```promql\\n# Grouper par plusieurs labels\\nsum by (method, status) (rate(http_requests_total[5m]))\\n\\n# Exclure des labels du groupage\\nsum without (instance) (rate(http_requests_total[5m]))\\n\\n# Top K\\ntopk(5, http_requests_total) # Top 5 des s\xe9ries\\n\\n# Bottom K\\nbottomk(3, rate(cpu_usage[5m])) # Bottom 3 des taux CPU\\n```\\n\\n### Exemples pratiques\\n\\n```promql\\n# Taux de requ\xeates HTTP par seconde\\nrate(http_requests_total[5m])\\n\\n# Taux d\'erreur HTTP (5xx)\\nsum(rate(http_requests_total{status=~\\"5..\\"}[5m]))\\n/\\nsum(rate(http_requests_total[5m]))\\n\\n# Utilisation m\xe9moire en pourcentage\\n100 * (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes))\\n\\n# Utilisation disque en pourcentage\\n100 * (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes\\n\\n# Latence p95 (histogram)\\nhistogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))\\n\\n# Pr\xe9diction : disque plein dans combien de temps ?\\npredict_linear(node_filesystem_free_bytes[1h], 4*3600) < 0\\n```\\n\\n## Interface Web de Prometheus \ud83d\udda5\ufe0f\\n\\nPrometheus embarque une interface web accessible sur `http://localhost:9090` :\\n\\n### Onglet Graph\\n\\nPermet d\'ex\xe9cuter des requ\xeates PromQL et de visualiser les r\xe9sultats sous forme de graphique ou de tableau.\\n\\n### Onglet Alerts\\n\\nAffiche l\'\xe9tat des r\xe8gles d\'alerting et les alertes actives.\\n\\n### Onglet Status\\n\\n- **Targets** : \xe9tat des cibles scrap\xe9es (up/down)\\n- **Configuration** : configuration actuelle de Prometheus\\n- **Rules** : r\xe8gles d\'alerting et d\'enregistrement charg\xe9es\\n- **Service Discovery** : cibles d\xe9couvertes dynamiquement\\n\\n## D\xe9couverte de services \ud83d\udd0d\\n\\nPrometheus peut d\xe9couvrir automatiquement les cibles \xe0 monitorer.\\n\\n### D\xe9couverte Kubernetes\\n\\n```yaml\\nscrape_configs:\\n  - job_name: \'kubernetes-pods\'\\n    kubernetes_sd_configs:\\n      - role: pod\\n    relabel_configs:\\n      # Ne scraper que les pods avec l\'annotation prometheus.io/scrape\\n      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\\n        action: keep\\n        regex: true\\n      # Utiliser le port d\xe9fini dans l\'annotation\\n      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]\\n        action: replace\\n        target_label: __address__\\n        regex: ([^:]+)(?::\\\\d+)?;(\\\\d+)\\n        replacement: $1:$2\\n      # Ajouter des labels depuis les annotations\\n      - action: labelmap\\n        regex: __meta_kubernetes_pod_label_(.+)\\n```\\n\\n### D\xe9couverte avec fichiers\\n\\n```yaml\\nscrape_configs:\\n  - job_name: \'file_sd\'\\n    file_sd_configs:\\n      - files:\\n          - \'targets/*.json\'\\n          - \'targets/*.yml\'\\n        refresh_interval: 5m\\n```\\n\\nFichier `targets/web-servers.json` :\\n\\n```json\\n[\\n  {\\n    \\"targets\\": [\\"web-01:9100\\", \\"web-02:9100\\"],\\n    \\"labels\\": {\\n      \\"job\\": \\"web-servers\\",\\n      \\"environment\\": \\"production\\"\\n    }\\n  }\\n]\\n```\\n\\n## Bonnes pratiques \ud83d\udc4d\\n\\n1. **Nommer les m\xe9triques correctement** :\\n   - Format : `namespace_subsystem_unit_suffix`\\n   - Exemple : `http_requests_total`, `node_cpu_seconds_total`\\n\\n2. **Utiliser des labels judicieusement** :\\n   - Labels pour les dimensions importantes (method, status, instance)\\n   - \xc9viter les labels avec une cardinalit\xe9 \xe9lev\xe9e (user_id, request_id)\\n\\n3. **Choisir le bon intervalle de scraping** :\\n   - 15-60s pour la plupart des cas\\n   - Plus court pour des syst\xe8mes critiques\\n   - Plus long pour des m\xe9triques qui changent lentement\\n\\n4. **Utiliser rate() pour les counters** :\\n   - Ne jamais afficher un counter brut (il ne fait qu\'augmenter)\\n   - Toujours utiliser `rate()` ou `increase()`\\n\\n5. **D\xe9finir des alertes pertinentes** :\\n   - Alerter sur les sympt\xf4mes, pas sur les causes\\n   - \xc9viter les alertes redondantes\\n   - Pr\xe9voir des p\xe9riodes de silence (for: 5m)\\n\\n## Conclusion \ud83c\udfaf\\n\\nPrometheus est devenu l\'outil de monitoring de r\xe9f\xe9rence dans l\'\xe9cosyst\xe8me Cloud Native. Sa simplicit\xe9 d\'installation, son mod\xe8le de donn\xe9es flexible et son langage de requ\xeate puissant en font un choix excellent pour monitorer les infrastructures modernes.\\n\\nLes prochains articles aborderont :\\n\\n- La cr\xe9ation de dashboards avec Grafana\\n- La configuration d\'alertes avec Alertmanager\\n- Le monitoring d\'applications Kubernetes\\n- L\'optimisation des performances et du stockage\\n\\n## Ressources utiles \ud83d\udcda\\n\\n- [Documentation officielle Prometheus](https://prometheus.io/docs/)\\n- [PromQL Cheat Sheet](https://promlabs.com/promql-cheat-sheet/)\\n- [Awesome Prometheus](https://github.com/roaldnefs/awesome-prometheus)\\n- [Prometheus Exporters](https://prometheus.io/docs/instrumenting/exporters/)"},{"id":"/2025/11/21/08-iac/ansible-playbooks-avances","metadata":{"permalink":"/blog/2025/11/21/08-iac/ansible-playbooks-avances","source":"@site/blog/08-iac/2025-11-21-ansible-playbooks-avances.md","title":"Ansible : avanc\xe9","description":"Fonctionnalit\xe9s avanc\xe9es d\'Ansible pour cr\xe9er des playbooks modulaires, s\xe9curiser les secrets et automatiser les d\xe9ploiements.","date":"2025-11-21T00:00:00.000Z","tags":[{"inline":false,"label":"Infrastructure as Code","permalink":"/blog/tags/iac"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":6.51,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Ansible : avanc\xe9","description":"Fonctionnalit\xe9s avanc\xe9es d\'Ansible pour cr\xe9er des playbooks modulaires, s\xe9curiser les secrets et automatiser les d\xe9ploiements.","tags":["iac","devops"]},"unlisted":false,"prevItem":{"title":"Prometheus","permalink":"/blog/2025/11/21/07-monitoring/prometheus-introduction"},"nextItem":{"title":"Python : async/await","permalink":"/blog/2025/11/21/09-scripting/python-async-await"}},"content":"L\'[article pr\xe9c\xe9dent sur Ansible](/blog/2025/06/09/08-iac/ansible-introduction) couvrait les bases de cet outil d\'automatisation puissant. Cet article explore des concepts avanc\xe9s qui permettent de cr\xe9er des infrastructures complexes de mani\xe8re modulaire, s\xe9curis\xe9e et automatis\xe9e. \ud83d\ude80\\n\\n\x3c!--truncate--\x3e\\n\\n## Les r\xf4les Ansible : modularit\xe9 et r\xe9utilisabilit\xe9 \ud83d\udce6\\n\\nLes r\xf4les sont la pierre angulaire de la modularit\xe9 dans Ansible. Ils permettent d\'organiser les playbooks en composants r\xe9utilisables et maintenables.\\n\\n### Structure d\'un r\xf4le\\n\\nUn r\xf4le suit une structure de r\xe9pertoires standardis\xe9e :\\n\\n```\\nroles/\\n\u2514\u2500\u2500 webserver/\\n    \u251c\u2500\u2500 defaults/           # Variables par d\xe9faut (priorit\xe9 la plus basse)\\n    \u2502   \u2514\u2500\u2500 main.yml\\n    \u251c\u2500\u2500 vars/              # Variables du r\xf4le (priorit\xe9 haute)\\n    \u2502   \u2514\u2500\u2500 main.yml\\n    \u251c\u2500\u2500 tasks/             # T\xe2ches principales du r\xf4le\\n    \u2502   \u2514\u2500\u2500 main.yml\\n    \u251c\u2500\u2500 handlers/          # Gestionnaires d\'\xe9v\xe9nements\\n    \u2502   \u2514\u2500\u2500 main.yml\\n    \u251c\u2500\u2500 templates/         # Templates Jinja2\\n    \u2502   \u2514\u2500\u2500 nginx.conf.j2\\n    \u251c\u2500\u2500 files/             # Fichiers statiques\\n    \u2502   \u2514\u2500\u2500 index.html\\n    \u251c\u2500\u2500 meta/              # M\xe9tadonn\xe9es et d\xe9pendances\\n    \u2502   \u2514\u2500\u2500 main.yml\\n    \u2514\u2500\u2500 README.md          # Documentation du r\xf4le\\n```\\n\\n### Cr\xe9er un r\xf4le avec ansible-galaxy\\n\\n```bash\\n# Cr\xe9er la structure d\'un nouveau r\xf4le\\nansible-galaxy init webserver\\n\\n# Cr\xe9er un r\xf4le dans un r\xe9pertoire sp\xe9cifique\\nansible-galaxy init roles/webserver\\n\\n# Voir la structure cr\xe9\xe9e\\ntree roles/webserver\\n```\\n\\n### Exemple de r\xf4le complet : webserver\\n\\n**tasks/main.yml**\\n\\n```yaml\\n---\\n# Installation et configuration de Nginx\\n- name: Installer les paquets requis\\n  apt:\\n    name:\\n      - nginx\\n      - python3-pip\\n    state: present\\n    update_cache: yes\\n\\n- name: Configurer Nginx\\n  template:\\n    src: nginx.conf.j2\\n    dest: /etc/nginx/sites-available/{{ site_name }}\\n    owner: root\\n    group: root\\n    mode: \'0644\'\\n  notify: reload nginx\\n\\n- name: Activer le site\\n  file:\\n    src: /etc/nginx/sites-available/{{ site_name }}\\n    dest: /etc/nginx/sites-enabled/{{ site_name }}\\n    state: link\\n  notify: reload nginx\\n\\n- name: D\xe9ployer le contenu du site\\n  template:\\n    src: index.html.j2\\n    dest: /var/www/{{ site_name }}/index.html\\n    owner: www-data\\n    group: www-data\\n    mode: \'0644\'\\n\\n- name: S\'assurer que Nginx est d\xe9marr\xe9\\n  service:\\n    name: nginx\\n    state: started\\n    enabled: yes\\n```\\n\\n**defaults/main.yml**\\n\\n```yaml\\n---\\n# Variables par d\xe9faut du r\xf4le webserver\\nsite_name: example.com\\ndocument_root: /var/www/{{ site_name }}\\nserver_port: 80\\nserver_name: \\"{{ site_name }}\\"\\n```\\n\\n**vars/main.yml**\\n\\n```yaml\\n---\\n# Variables sp\xe9cifiques au r\xf4le (priorit\xe9 plus haute)\\nnginx_worker_processes: auto\\nnginx_worker_connections: 1024\\n```\\n\\n**handlers/main.yml**\\n\\n```yaml\\n---\\n# Gestionnaires pour Nginx\\n- name: reload nginx\\n  service:\\n    name: nginx\\n    state: reloaded\\n\\n- name: restart nginx\\n  service:\\n    name: nginx\\n    state: restarted\\n```\\n\\n**templates/nginx.conf.j2**\\n\\n```jinja2\\nserver {\\n    listen {{ server_port }};\\n    server_name {{ server_name }};\\n\\n    root {{ document_root }};\\n    index index.html;\\n\\n    location / {\\n        try_files $uri $uri/ =404;\\n    }\\n\\n    access_log /var/log/nginx/{{ site_name }}_access.log;\\n    error_log /var/log/nginx/{{ site_name }}_error.log;\\n}\\n```\\n\\n**meta/main.yml**\\n\\n```yaml\\n---\\n# M\xe9tadonn\xe9es et d\xe9pendances du r\xf4le\\ngalaxy_info:\\n  author: Votre Nom\\n  description: Installation et configuration de Nginx\\n  company: Votre Entreprise\\n  license: MIT\\n  min_ansible_version: 2.9\\n\\n  platforms:\\n    - name: Ubuntu\\n      versions:\\n        - focal\\n        - jammy\\n    - name: Debian\\n      versions:\\n        - bullseye\\n        - bookworm\\n\\n  galaxy_tags:\\n    - nginx\\n    - webserver\\n    - web\\n\\ndependencies: []\\n```\\n\\n### Utiliser un r\xf4le dans un playbook\\n\\n```yaml\\n---\\n- name: Configurer les serveurs web\\n  hosts: webservers\\n  become: yes\\n\\n  roles:\\n    - role: webserver\\n      vars:\\n        site_name: monsite.com\\n        server_port: 8080\\n\\n# Ou avec une syntaxe plus d\xe9taill\xe9e\\n- name: Configurer avec des conditions\\n  hosts: webservers\\n  become: yes\\n\\n  roles:\\n    - role: webserver\\n      when: ansible_os_family == \\"Debian\\"\\n      tags:\\n        - nginx\\n        - web\\n```\\n\\n## Collections Ansible \ud83d\udcda\\n\\nLes collections sont des packages qui regroupent modules, r\xf4les, plugins et playbooks. Elles remplacent progressivement les r\xf4les Galaxy.\\n\\n### Installer une collection\\n\\n```bash\\n# Installer depuis Ansible Galaxy\\nansible-galaxy collection install community.general\\n\\n# Installer depuis un fichier requirements.yml\\nansible-galaxy collection install -r requirements.yml\\n\\n# Installer une version sp\xe9cifique\\nansible-galaxy collection install community.general:5.8.0\\n```\\n\\n### Fichier requirements.yml\\n\\n```yaml\\n---\\ncollections:\\n  # Depuis Ansible Galaxy\\n  - name: community.general\\n    version: \\">=5.0.0\\"\\n\\n  - name: ansible.posix\\n    version: \\"1.5.1\\"\\n\\n  - name: community.docker\\n\\n  # Depuis un d\xe9p\xf4t Git\\n  - name: https://github.com/organisation/ma-collection.git\\n    type: git\\n    version: main\\n```\\n\\n### Utiliser une collection\\n\\n```yaml\\n---\\n- name: Utiliser des modules de collections\\n  hosts: all\\n\\n  tasks:\\n    # M\xe9thode 1 : FQCN (Fully Qualified Collection Name)\\n    - name: Installer un paquet avec community.general\\n      community.general.npm:\\n        name: express\\n        global: yes\\n\\n    # M\xe9thode 2 : Importer la collection\\n    - name: Docker tasks\\n      block:\\n        - community.docker.docker_container:\\n            name: nginx\\n            image: nginx:latest\\n            state: started\\n      collections:\\n        - community.docker\\n```\\n\\n### Cr\xe9er sa propre collection\\n\\n```bash\\n# Cr\xe9er la structure d\'une collection\\nansible-galaxy collection init mon_namespace.ma_collection\\n\\n# Structure cr\xe9\xe9e\\nmon_namespace/\\n\u2514\u2500\u2500 ma_collection/\\n    \u251c\u2500\u2500 docs/\\n    \u251c\u2500\u2500 galaxy.yml          # M\xe9tadonn\xe9es de la collection\\n    \u251c\u2500\u2500 plugins/\\n    \u2502   \u251c\u2500\u2500 modules/        # Modules personnalis\xe9s\\n    \u2502   \u251c\u2500\u2500 inventory/      # Plugins d\'inventaire\\n    \u2502   \u2514\u2500\u2500 lookup/         # Plugins lookup\\n    \u251c\u2500\u2500 roles/              # R\xf4les inclus dans la collection\\n    \u251c\u2500\u2500 playbooks/          # Playbooks d\'exemple\\n    \u2514\u2500\u2500 README.md\\n```\\n\\n## Ansible Vault : g\xe9rer les secrets en toute s\xe9curit\xe9 \ud83d\udd12\\n\\nAnsible Vault permet de chiffrer les fichiers contenant des donn\xe9es sensibles.\\n\\n### Cr\xe9er un fichier chiffr\xe9\\n\\n```bash\\n# Cr\xe9er un nouveau fichier chiffr\xe9\\nansible-vault create secrets.yml\\n\\n# Vous serez invit\xe9 \xe0 entrer un mot de passe\\n# Puis un \xe9diteur s\'ouvrira pour saisir le contenu\\n```\\n\\n**Contenu de secrets.yml (d\xe9chiffr\xe9) :**\\n\\n```yaml\\n---\\ndb_password: \\"SuperSecretPassword123!\\"\\napi_key: \\"abc123def456ghi789\\"\\nssl_certificate_key: |\\n```\\n\\n### Chiffrer un fichier existant\\n\\n```bash\\n# Chiffrer un fichier existant\\nansible-vault encrypt vars/production.yml\\n\\n# Chiffrer plusieurs fichiers\\nansible-vault encrypt vars/*.yml\\n```\\n\\n### Modifier un fichier chiffr\xe9\\n\\n```bash\\n# \xc9diter un fichier chiffr\xe9 (d\xe9chiffrement temporaire)\\nansible-vault edit secrets.yml\\n\\n# Voir le contenu sans \xe9diter\\nansible-vault view secrets.yml\\n```\\n\\n### D\xe9chiffrer un fichier\\n\\n```bash\\n# D\xe9chiffrer un fichier (attention, perte de la protection !)\\nansible-vault decrypt secrets.yml\\n\\n# Rechiffrer avec un nouveau mot de passe\\nansible-vault rekey secrets.yml\\n```\\n\\n### Utiliser Vault dans un playbook\\n\\n```yaml\\n---\\n- name: D\xe9ploiement avec secrets\\n  hosts: production\\n  vars_files:\\n    - vars/common.yml\\n    - secrets.yml  # Fichier chiffr\xe9 avec Vault\\n\\n  tasks:\\n    - name: Configurer la base de donn\xe9es\\n      mysql_user:\\n        name: app_user\\n        password: \\"{{ db_password }}\\"  # Depuis secrets.yml\\n        priv: \\"appdb.*:ALL\\"\\n        state: present\\n\\n    - name: Configurer l\'API\\n      template:\\n        src: api_config.j2\\n        dest: /etc/app/config.json\\n      vars:\\n        api_secret: \\"{{ api_key }}\\"\\n```\\n\\n### Ex\xe9cuter avec Vault\\n\\n```bash\\n# Demander le mot de passe interactivement\\nansible-playbook deploy.yml --ask-vault-pass\\n\\n# Utiliser un fichier de mot de passe\\nansible-playbook deploy.yml --vault-password-file ~/.vault_pass.txt\\n\\n# Utiliser un script pour obtenir le mot de passe\\nansible-playbook deploy.yml --vault-password-file get_vault_pass.sh\\n```\\n\\n### Fichier de mot de passe\\n\\n```bash\\n# Cr\xe9er un fichier de mot de passe\\necho \\"MonMotDePasseVault\\" > ~/.vault_pass.txt\\nchmod 600 ~/.vault_pass.txt\\n\\n# Configurer dans ansible.cfg\\ncat >> ansible.cfg << EOF\\n[defaults]\\nvault_password_file = ~/.vault_pass.txt\\nEOF\\n```\\n\\n### Script pour r\xe9cup\xe9rer le mot de passe\\n\\n```bash\\n#!/bin/bash\\n# get_vault_pass.sh - R\xe9cup\xe8re le mot de passe depuis un gestionnaire de secrets\\n\\n# Exemple avec pass (passwordstore.org)\\npass show ansible/vault\\n\\n# Exemple avec AWS Secrets Manager\\naws secretsmanager get-secret-value \\\\\\n  --secret-id ansible-vault \\\\\\n  --query SecretString \\\\\\n  --output text\\n\\n# Exemple avec 1Password CLI\\nop read \\"op://DevOps/Ansible Vault/password\\"\\n```\\n\\n### Vault IDs : g\xe9rer plusieurs cl\xe9s\\n\\n```bash\\n# Cr\xe9er des fichiers avec diff\xe9rents Vault IDs\\nansible-vault create --vault-id dev@prompt secrets_dev.yml\\nansible-vault create --vault-id prod@prompt secrets_prod.yml\\n\\n# Utiliser avec des fichiers de mots de passe\\nansible-vault create --vault-id dev@.vault_dev secrets_dev.yml\\n\\n# Ex\xe9cuter avec plusieurs Vault IDs\\nansible-playbook deploy.yml \\\\\\n  --vault-id dev@.vault_dev \\\\\\n  --vault-id prod@.vault_prod\\n```\\n\\n### Chiffrer des variables individuelles\\n\\n```yaml\\n---\\n# Au lieu de chiffrer tout le fichier\\ndb_host: localhost\\ndb_user: app_user\\ndb_password: !vault |\\n  $ANSIBLE_VAULT;1.1;AES256\\n  66386439653936393039346235323131386335333132333239336631643366326362333733363264\\n  3939666233316362313938396331626664626134623239360a356430646364633338336564383661\\n  ...\\n\\n# Cr\xe9er une variable chiffr\xe9e\\nansible-vault encrypt_string \'SuperSecretPassword\' --name \'db_password\'\\n```\\n\\n## Bonnes pratiques avanc\xe9es \ud83c\udfc6\\n\\n### 1. Structure de projet recommand\xe9e\\n\\n```\\nansible-project/\\n\u251c\u2500\u2500 ansible.cfg\\n\u251c\u2500\u2500 inventories/\\n\u2502   \u251c\u2500\u2500 production/\\n\u2502   \u2502   \u251c\u2500\u2500 hosts.yml\\n\u2502   \u2502   \u2514\u2500\u2500 group_vars/\\n\u2502   \u2502       \u251c\u2500\u2500 all.yml\\n\u2502   \u2502       \u2514\u2500\u2500 webservers.yml\\n\u2502   \u2514\u2500\u2500 staging/\\n\u2502       \u251c\u2500\u2500 hosts.yml\\n\u2502       \u2514\u2500\u2500 group_vars/\\n\u251c\u2500\u2500 roles/\\n\u2502   \u251c\u2500\u2500 common/\\n\u2502   \u251c\u2500\u2500 webserver/\\n\u2502   \u2514\u2500\u2500 database/\\n\u251c\u2500\u2500 playbooks/\\n\u2502   \u251c\u2500\u2500 deploy.yml\\n\u2502   \u251c\u2500\u2500 rollback.yml\\n\u2502   \u2514\u2500\u2500 maintenance.yml\\n\u251c\u2500\u2500 collections/\\n\u2502   \u2514\u2500\u2500 requirements.yml\\n\u251c\u2500\u2500 group_vars/\\n\u2502   \u2514\u2500\u2500 all/\\n\u2502       \u251c\u2500\u2500 vars.yml\\n\u2502       \u2514\u2500\u2500 vault.yml\\n\u2514\u2500\u2500 README.md\\n```\\n\\n### 2. Utiliser des tags strat\xe9giquement\\n\\n```yaml\\n---\\n- name: Configuration compl\xe8te\\n  hosts: webservers\\n\\n  tasks:\\n    - name: Installer les paquets\\n      apt:\\n        name: \\"{{ item }}\\"\\n        state: present\\n      loop:\\n        - nginx\\n        - python3\\n      tags:\\n        - install\\n        - packages\\n\\n    - name: Configurer Nginx\\n      template:\\n        src: nginx.conf.j2\\n        dest: /etc/nginx/nginx.conf\\n      tags:\\n        - config\\n        - nginx\\n\\n    - name: D\xe9ployer l\'application\\n      copy:\\n        src: app/\\n        dest: /var/www/app/\\n      tags:\\n        - deploy\\n        - app\\n\\n# Ex\xe9cuter uniquement certaines t\xe2ches\\n# ansible-playbook deploy.yml --tags \\"config\\"\\n# ansible-playbook deploy.yml --skip-tags \\"deploy\\"\\n```\\n\\n### 3. Gestion des erreurs robuste\\n\\n```yaml\\n---\\n- name: Gestion d\'erreurs avanc\xe9e\\n  hosts: all\\n\\n  tasks:\\n    - name: T\xe2che qui peut \xe9chouer\\n      command: /opt/script.sh\\n      register: script_result\\n      ignore_errors: yes\\n\\n    - name: Traiter le r\xe9sultat\\n      block:\\n        - debug:\\n            msg: \\"Script r\xe9ussi : {{ script_result.stdout }}\\"\\n      rescue:\\n        - debug:\\n            msg: \\"Script \xe9chou\xe9 : {{ script_result.stderr }}\\"\\n        - include_tasks: rollback.yml\\n      always:\\n        - name: Nettoyage\\n          file:\\n            path: /tmp/script-lock\\n            state: absent\\n```\\n\\n## Conclusion \ud83c\udfaf\\n\\nAnsible offre des fonctionnalit\xe9s avanc\xe9es puissantes pour g\xe9rer des infrastructures complexes de mani\xe8re s\xe9curis\xe9e et automatis\xe9e. Les r\xf4les et collections permettent de cr\xe9er des composants r\xe9utilisables, Vault prot\xe8ge les secrets, et l\'int\xe9gration CI/CD automatise les d\xe9ploiements.\\n\\nPoints cl\xe9s \xe0 retenir :\\n\\n- **R\xf4les** : modulariser et r\xe9utiliser le code\\n- **Collections** : packages complets de fonctionnalit\xe9s\\n- **Vault** : chiffrer les donn\xe9es sensibles\\n- **CI/CD** : automatiser les d\xe9ploiements\\n- **Strat\xe9gies** : blue-green, canary, rollback automatique\\n\\nLa ma\xeetrise de ces concepts permet de cr\xe9er des infrastructures as code robustes, maintenables et s\xe9curis\xe9es.\\n\\n## Ressources utiles \ud83d\udcda\\n\\n- [Ansible Best Practices](https://docs.ansible.com/ansible/latest/user_guide/playbooks_best_practices.html)\\n- [Ansible Galaxy](https://galaxy.ansible.com/)\\n- [Ansible Vault Documentation](https://docs.ansible.com/ansible/latest/user_guide/vault.html)\\n- [Ansible Collections](https://docs.ansible.com/ansible/latest/user_guide/collections_using.html)"},{"id":"/2025/11/21/09-scripting/python-async-await","metadata":{"permalink":"/blog/2025/11/21/09-scripting/python-async-await","source":"@site/blog/09-scripting/2025-11-21-python-async-await.md","title":"Python : async/await","description":"Ma\xeetrisez la programmation asynchrone en Python pour cr\xe9er des applications performantes et r\xe9actives.","date":"2025-11-21T00:00:00.000Z","tags":[{"inline":false,"label":"Scripting","permalink":"/blog/tags/scripting"}],"readingTime":9.92,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Python : async/await","description":"Ma\xeetrisez la programmation asynchrone en Python pour cr\xe9er des applications performantes et r\xe9actives.","tags":["scripting"]},"unlisted":false,"prevItem":{"title":"Ansible : avanc\xe9","permalink":"/blog/2025/11/21/08-iac/ansible-playbooks-avances"},"nextItem":{"title":"API : REST vs GraphQL","permalink":"/blog/2025/08/04/09-scripting/graphql"}},"content":"La programmation asynchrone est devenue essentielle pour cr\xe9er des applications Python performantes, notamment pour les APIs, les web scrapers, ou les applications traitant de nombreuses op\xe9rations I/O. Dans cet article, nous explorerons en profondeur `async`/`await` et `asyncio`, avec des cas d\'usage pratiques notamment avec FastAPI. \ud83d\ude80\\n\\n\x3c!--truncate--\x3e\\n\\n## Comprendre la programmation asynchrone \ud83e\udd14\\n\\n### Le probl\xe8me : l\'attente inutile\\n\\nDans un programme synchrone classique, chaque op\xe9ration attend la fin de la pr\xe9c\xe9dente, m\xeame si elle ne fait rien d\'utile pendant ce temps. C\'est comme faire la queue au supermarch\xe9 : si la caissi\xe8re attend que le client pr\xe9c\xe9dent range ses courses dans son sac, tout le monde attend inutilement.\\n\\n**Exemple concret :** Imaginez une application qui doit r\xe9cup\xe9rer des donn\xe9es depuis 3 APIs diff\xe9rentes. En mode synchrone, le programme attend la r\xe9ponse de l\'API 1 (2 secondes), puis attend l\'API 2 (2 secondes), puis l\'API 3 (2 secondes) = **6 secondes au total**.\\n\\n### La solution : l\'asynchrone\\n\\nLa programmation asynchrone permet de ne pas rester bloqu\xe9 pendant les op\xe9rations d\'attente (I/O). Pendant qu\'une requ\xeate HTTP est en cours, le programme peut lancer d\'autres requ\xeates ou effectuer d\'autres t\xe2ches.\\n\\n**Avec l\'asynchrone :** Les 3 requ\xeates sont lanc\xe9es simultan\xe9ment, et le programme attend seulement le temps de la plus longue = **2 secondes au total**.\\n\\n```python\\nimport asyncio\\n\\nasync def faire_requete(url):\\n    await asyncio.sleep(2)  # Simule une requ\xeate HTTP\\n    return f\\"Donn\xe9es de {url}\\"\\n\\nasync def main():\\n    # Les 3 requ\xeates s\'ex\xe9cutent en parall\xe8le\\n    resultats = await asyncio.gather(\\n        faire_requete(\\"api.example.com/1\\"),\\n        faire_requete(\\"api.example.com/2\\"),\\n        faire_requete(\\"api.example.com/3\\")\\n    )\\n    return resultats\\n\\nasyncio.run(main())\\n```\\n\\n### Quand utiliser l\'asynchrone ?\\n\\nL\'asynchrone est efficace uniquement pour les op\xe9rations **I/O-bound** (limit\xe9es par les entr\xe9es/sorties), pas pour les calculs **CPU-bound**.\\n\\n\u2705 **Bon pour (I/O-bound) :**\\n- Requ\xeates HTTP/API : attente r\xe9seau\\n- Op\xe9rations de base de donn\xe9es : attente disque/r\xe9seau\\n- Lecture/\xe9criture de fichiers : attente disque\\n- WebSockets : attente de messages\\n\\n\u274c **Pas adapt\xe9 pour (CPU-bound) :**\\n- Calculs math\xe9matiques complexes\\n- Traitement d\'images/vid\xe9os\\n- Compression de donn\xe9es\\n- Pour ces cas, utiliser `multiprocessing` ou `threading`\\n\\n## Les bases d\'async/await \ud83d\udcda\\n\\n### Les coroutines : des fonctions \\"pausables\\"\\n\\nUne **coroutine** est une fonction sp\xe9ciale qui peut \xeatre suspendue et reprise. Elle se d\xe9clare avec `async def` au lieu de `def`.\\n\\n**Concept cl\xe9 :** Une coroutine ne s\'ex\xe9cute pas imm\xe9diatement quand on l\'appelle. Elle retourne un objet \\"coroutine\\" qui doit \xeatre `await`\xe9 pour s\'ex\xe9cuter r\xe9ellement.\\n\\n```python\\nasync def fonction_async():\\n    return \\"Hello\\"\\n\\n# \u274c Ceci ne fait RIEN, retourne juste un objet coroutine\\nresultat = fonction_async()\\n\\n# \u2705 Pour ex\xe9cuter, il faut await dans un contexte async\\nasync def main():\\n    resultat = await fonction_async()  # Maintenant \xe7a s\'ex\xe9cute\\n    print(resultat)\\n\\nasyncio.run(main())  # Point d\'entr\xe9e pour d\xe9marrer l\'async\\n```\\n\\n### Le mot-cl\xe9 `await` : point de suspension\\n\\n`await` signifie \\"attends que cette op\xe9ration se termine, mais pendant ce temps, laisse d\'autres t\xe2ches s\'ex\xe9cuter\\".\\n\\n**Analogie :** C\'est comme dire \\"je mets cette t\xe2che en pause, fais autre chose en attendant, et reviens me voir quand c\'est pr\xeat\\".\\n\\n```python\\nasync def operation_longue():\\n    print(\\"D\xe9but\\")\\n    await asyncio.sleep(2)  # \\"Pause ici pendant 2s, fais autre chose\\"\\n    print(\\"Fin\\")\\n    return \\"Termin\xe9\\"\\n```\\n\\n### Ex\xe9cuter plusieurs coroutines en parall\xe8le\\n\\n**Le probl\xe8me :** Comment lancer plusieurs t\xe2ches asynchrones en m\xeame temps ?\\n\\n**Solution 1 : `asyncio.gather()`** - Lance tout en parall\xe8le et attend tous les r\xe9sultats\\n\\n```python\\nasync def tache(nom, duree):\\n    await asyncio.sleep(duree)\\n    return f\\"{nom} termin\xe9e\\"\\n\\nasync def main():\\n    # Les 3 t\xe2ches d\xe9marrent en m\xeame temps\\n    resultats = await asyncio.gather(\\n        tache(\\"T\xe2che 1\\", 2),\\n        tache(\\"T\xe2che 2\\", 1),\\n        tache(\\"T\xe2che 3\\", 3)\\n    )\\n    # Attend que TOUTES soient finies\\n    print(resultats)  # [\'T\xe2che 1 termin\xe9e\', \'T\xe2che 2 termin\xe9e\', \'T\xe2che 3 termin\xe9e\']\\n```\\n\\n**Solution 2 : `asyncio.create_task()`** - Plus de contr\xf4le individuel\\n\\n```python\\nasync def main():\\n    # D\xe9marre la t\xe2che imm\xe9diatement en arri\xe8re-plan\\n    task = asyncio.create_task(tache(\\"A\\", 1))\\n\\n    # Fait autre chose...\\n    print(\\"La t\xe2che tourne en arri\xe8re-plan\\")\\n\\n    # Attend le r\xe9sultat quand n\xe9cessaire\\n    resultat = await task\\n```\\n\\n## asyncio : fonctionnalit\xe9s essentielles \ud83d\udee0\ufe0f\\n\\n### L\'Event Loop : le chef d\'orchestre\\n\\nL\'**event loop** (boucle d\'\xe9v\xe9nements) est le moteur qui g\xe8re l\'ex\xe9cution de toutes les coroutines. C\'est lui qui d\xe9cide quelle t\xe2che ex\xe9cuter et quand.\\n\\n**Analogie :** C\'est comme un chef d\'orchestre qui coordonne tous les musiciens (coroutines). Quand un musicien doit faire une pause (await), le chef donne la parole \xe0 un autre.\\n\\n```python\\nasync def hello():\\n    await asyncio.sleep(1)\\n    print(\\"World\\")\\n\\n# asyncio.run() cr\xe9e l\'event loop, ex\xe9cute la coroutine, puis nettoie\\nasyncio.run(hello())\\n```\\n\\n**Point important :** `asyncio.run()` est le point d\'entr\xe9e principal. C\'est lui qui d\xe9marre l\'event loop et permet \xe0 tout le syst\xe8me asynchrone de fonctionner.\\n\\n### Gestion des erreurs : ne pas tout casser\\n\\n**Le probl\xe8me :** Si une t\xe2che \xe9choue avec `gather()`, par d\xe9faut toutes les autres sont annul\xe9es.\\n\\n**La solution :** `return_exceptions=True` capture les erreurs comme des r\xe9sultats normaux.\\n\\n```python\\n# Sans return_exceptions : si operation_risquee(2) \xe9choue, tout s\'arr\xeate\\nresultats = await asyncio.gather(\\n    operation_risquee(1),  # R\xe9ussit\\n    operation_risquee(2),  # \xc9choue\\n    operation_risquee(3),  # Ne s\'ex\xe9cute jamais\\n)\\n\\n# Avec return_exceptions : toutes s\'ex\xe9cutent, les erreurs sont dans les r\xe9sultats\\nresultats = await asyncio.gather(\\n    operation_risquee(1),\\n    operation_risquee(2),\\n    operation_risquee(3),\\n    return_exceptions=True  # Les exceptions sont retourn\xe9es comme r\xe9sultats\\n)\\n# resultats = [\\"Succ\xe8s 1\\", Exception(...), \\"Succ\xe8s 3\\"]\\n```\\n\\n### Timeouts : limiter le temps d\'attente\\n\\n**Utilit\xe9 :** \xc9viter d\'attendre ind\xe9finiment une op\xe9ration qui ne r\xe9pond plus.\\n\\n```python\\ntry:\\n    # Attend maximum 3 secondes\\n    resultat = await asyncio.wait_for(operation_longue(), timeout=3.0)\\nexcept asyncio.TimeoutError:\\n    print(\\"L\'op\xe9ration a pris trop de temps !\\")\\n```\\n\\n## Requ\xeates HTTP asynchrones \ud83c\udf10\\n\\n### Le cas d\'usage parfait pour l\'asynchrone\\n\\nLes requ\xeates HTTP sont le meilleur exemple d\'op\xe9ration I/O-bound : le programme passe la majorit\xe9 du temps \xe0 attendre la r\xe9ponse du serveur, sans rien faire.\\n\\n**Avantage de l\'async :** Pendant qu\'une requ\xeate attend la r\xe9ponse, on peut en lancer d\'autres. R\xe9sultat : 10 requ\xeates prennent le temps d\'une seule !\\n\\n### Avec httpx : le client HTTP asynchrone\\n\\n`httpx` est l\'\xe9quivalent moderne et asynchrone de `requests`.\\n\\n```python\\nimport httpx\\nimport asyncio\\n\\nasync def fetch_users(usernames: list[str]) -> list[dict]:\\n    # AsyncClient g\xe8re les connexions de mani\xe8re asynchrone\\n    async with httpx.AsyncClient() as client:\\n        # Cr\xe9e une liste de coroutines (pas encore ex\xe9cut\xe9es)\\n        tasks = [\\n            client.get(f\\"https://api.github.com/users/{username}\\")\\n            for username in usernames\\n        ]\\n        # Lance toutes les requ\xeates en parall\xe8le\\n        responses = await asyncio.gather(*tasks)\\n        return [response.json() for response in responses]\\n\\n# 10 utilisateurs r\xe9cup\xe9r\xe9s en parall\xe8le = temps d\'une seule requ\xeate\\nusers = await fetch_users([\\"python\\", \\"microsoft\\", \\"google\\", \\"facebook\\", \\"apple\\"])\\n```\\n\\n**Gain de performance :** Sans async, 10 requ\xeates de 200ms = 2 secondes. Avec async = 200ms !\\n\\n## Int\xe9gration avec FastAPI \ud83d\ude80\\n\\n### Pourquoi FastAPI et async sont faits l\'un pour l\'autre\\n\\nFastAPI est con\xe7u d\xe8s le d\xe9part pour l\'asynchrone. Une API web est l\'exemple parfait d\'application I/O-bound : la plupart du temps est pass\xe9 \xe0 attendre des bases de donn\xe9es, des APIs externes, ou des fichiers.\\n\\n**Avantage :** Avec async, un serveur FastAPI peut g\xe9rer des milliers de requ\xeates simultan\xe9es sans cr\xe9er de threads, simplement en utilisant l\'event loop.\\n\\n### Routes asynchrones\\n\\nD\xe9clarer une route avec `async def` permet \xe0 FastAPI de g\xe9rer plusieurs requ\xeates en parall\xe8le sans blocage.\\n\\n```python\\nfrom fastapi import FastAPI\\nimport httpx\\n\\napp = FastAPI()\\n\\n@app.get(\\"/users/{username}\\")\\nasync def get_user(username: str):\\n    # Pendant que cette requ\xeate attend la r\xe9ponse de GitHub,\\n    # FastAPI peut traiter d\'autres requ\xeates entrantes\\n    async with httpx.AsyncClient() as client:\\n        response = await client.get(f\\"https://api.github.com/users/{username}\\")\\n        return response.json()\\n```\\n\\n**Sans async :** Chaque requ\xeate bloque le serveur pendant l\'appel \xe0 GitHub (100-200ms). Avec async : des centaines de requ\xeates peuvent attendre en parall\xe8le.\\n\\n### Base de donn\xe9es asynchrone avec SQLAlchemy\\n\\nLes requ\xeates SQL sont des op\xe9rations I/O qui b\xe9n\xe9ficient \xe9norm\xe9ment de l\'async.\\n\\n```python\\nfrom sqlalchemy.ext.asyncio import AsyncSession, create_async_engine\\nfrom sqlalchemy import select\\n\\n# asyncpg est le driver PostgreSQL asynchrone\\nengine = create_async_engine(\\"postgresql+asyncpg://user:pass@localhost/db\\")\\n\\n@app.get(\\"/users\\")\\nasync def get_users(db: AsyncSession = Depends(get_db)):\\n    # Requ\xeate SQL non-bloquante\\n    result = await db.execute(select(User))\\n    return result.scalars().all()\\n```\\n\\n**Gain :** Pendant qu\'une requ\xeate SQL s\'ex\xe9cute sur la DB, FastAPI peut traiter d\'autres endpoints.\\n\\n### Cache Redis asynchrone\\n\\nRedis est souvent utilis\xe9 comme cache pour acc\xe9l\xe9rer les r\xe9ponses. L\'async permet de ne pas bloquer pendant les acc\xe8s Redis.\\n\\n```python\\nimport aioredis\\n\\n@app.get(\\"/users/{user_id}\\")\\nasync def get_user_cached(user_id: int):\\n    # V\xe9rifie le cache (op\xe9ration r\xe9seau)\\n    cached = await redis.get(f\\"user:{user_id}\\")\\n    if cached:\\n        return json.loads(cached)\\n\\n    # R\xe9cup\xe8re depuis la DB si pas en cache\\n    user = await fetch_user_from_db(user_id)\\n\\n    # Met en cache pour 1h\\n    await redis.setex(f\\"user:{user_id}\\", 3600, json.dumps(user))\\n    return user\\n```\\n\\n**Architecture typique :** API FastAPI \u2192 Cache Redis \u2192 Base de donn\xe9es PostgreSQL, le tout en asynchrone bout en bout.\\n\\n## Patterns avanc\xe9s \ud83c\udfaf\\n\\n### Limiter la concurrence avec Semaphore\\n\\n**Le probl\xe8me :** Lancer 1000 requ\xeates HTTP en m\xeame temps peut surcharger le serveur ou \xe9puiser les ressources (connexions, m\xe9moire).\\n\\n**La solution :** Un **Semaphore** limite le nombre d\'op\xe9rations simultan\xe9es. C\'est comme un parking avec un nombre limit\xe9 de places : si toutes les places sont prises, les nouvelles voitures doivent attendre qu\'une place se lib\xe8re.\\n\\n```python\\nfrom asyncio import Semaphore\\n\\nasync def operation(numero: int, semaphore: Semaphore):\\n    # Attend qu\'une \\"place\\" soit disponible\\n    async with semaphore:\\n        # Maximum 3 op\xe9rations ici en m\xeame temps\\n        await asyncio.sleep(2)\\n        return numero\\n\\nasync def main():\\n    semaphore = Semaphore(3)  # Maximum 3 op\xe9rations simultan\xe9es\\n    # Lance 10 op\xe9rations, mais seulement 3 \xe0 la fois\\n    tasks = [operation(i, semaphore) for i in range(10)]\\n    resultats = await asyncio.gather(*tasks)\\n```\\n\\n**R\xe9sultat :** 10 op\xe9rations s\'ex\xe9cutent par vagues de 3, au lieu de toutes en m\xeame temps.\\n\\n### Retry avec backoff exponentiel\\n\\n**Le probl\xe8me :** Une API temporairement indisponible ou un timeout r\xe9seau ne doit pas faire \xe9chouer toute l\'op\xe9ration.\\n\\n**La solution :** R\xe9essayer automatiquement avec des d\xe9lais croissants (1s, 2s, 4s, 8s...).\\n\\n```python\\nasync def retry_with_backoff(coro, max_retries=3, initial_delay=1.0, backoff_factor=2.0):\\n    delay = initial_delay\\n    for attempt in range(max_retries):\\n        try:\\n            return await coro()\\n        except Exception as e:\\n            if attempt == max_retries - 1:\\n                raise  # Dernier essai, on abandonne\\n            await asyncio.sleep(delay)  # Attente avant r\xe9essai\\n            delay *= backoff_factor  # Double le d\xe9lai : 1s, 2s, 4s...\\n\\n# Utilisation\\nresultat = await retry_with_backoff(lambda: fetch_data(\\"api.com\\"))\\n```\\n\\n**Avantage :** R\xe9silience face aux erreurs temporaires sans surcharger le serveur avec des r\xe9essais trop fr\xe9quents.\\n\\n### Context Manager asynchrone\\n\\n**Utilit\xe9 :** G\xe9rer automatiquement l\'ouverture et la fermeture de ressources asynchrones (connexions DB, clients HTTP, fichiers...).\\n\\n```python\\nclass AsyncResource:\\n    async def __aenter__(self):\\n        # Initialisation (ex: ouvrir connexion DB)\\n        await self.connect()\\n        return self\\n\\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\\n        # Nettoyage automatique (ex: fermer connexion)\\n        await self.disconnect()\\n\\n# Le nettoyage est garanti, m\xeame en cas d\'erreur\\nasync with AsyncResource() as resource:\\n    await resource.operation()\\n```\\n\\n## Bonnes pratiques \ud83d\udc1b\\n\\n### Erreurs courantes \xe0 \xe9viter\\n\\n#### 1. Oublier le `await`\\n\\n**Erreur fr\xe9quente :** Appeler une coroutine sans `await` ne fait rien, elle ne s\'ex\xe9cute pas !\\n\\n```python\\n# \u274c Mauvais : la fonction ne s\'ex\xe9cute jamais\\nresult = async_function()  # Retourne un objet coroutine non ex\xe9cut\xe9\\nprint(result)  # <coroutine object async_function at 0x...>\\n\\n# \u2705 Bon : la fonction s\'ex\xe9cute vraiment\\nresult = await async_function()\\nprint(result)  # R\xe9sultat attendu\\n```\\n\\n#### 2. Bloquer l\'event loop\\n\\n**Le probl\xe8me le plus grave :** Utiliser des fonctions bloquantes (`time.sleep`, `requests.get`, op\xe9rations CPU lourdes) dans une coroutine paralyse tout le syst\xe8me asynchrone.\\n\\n```python\\n# \u274c CATASTROPHIQUE : bloque TOUT pendant 10 secondes\\nasync def bad():\\n    time.sleep(10)  # Aucune autre coroutine ne peut s\'ex\xe9cuter !\\n    return \\"Done\\"\\n\\n# \u2705 Bon : suspend seulement cette coroutine\\nasync def good():\\n    await asyncio.sleep(10)  # Les autres coroutines continuent\\n    return \\"Done\\"\\n```\\n\\n**R\xe8gle d\'or :** Dans une fonction `async`, toutes les op\xe9rations I/O doivent \xeatre async (avec `await`).\\n\\n#### 3. N\xe9gliger la gestion des ressources\\n\\n**Probl\xe8me :** Les connexions DB, HTTP clients, fichiers doivent \xeatre ferm\xe9s proprement.\\n\\n```python\\n# \u274c Risque de fuite de connexions\\nasync def bad():\\n    client = httpx.AsyncClient()\\n    response = await client.get(url)\\n    # Oubli de fermer le client !\\n\\n# \u2705 Bon : fermeture automatique\\nasync def good():\\n    async with httpx.AsyncClient() as client:\\n        response = await client.get(url)\\n        # Client ferm\xe9 automatiquement, m\xeame en cas d\'erreur\\n```\\n\\n### Mode debug : d\xe9tecter les probl\xe8mes\\n\\nLe mode debug d\'asyncio d\xe9tecte automatiquement les erreurs courantes (coroutines non await\xe9s, event loop bloqu\xe9 trop longtemps...).\\n\\n```python\\n# Active les warnings d\xe9taill\xe9s\\nasyncio.run(main(), debug=True)\\n\\n# Affiche un warning si une coroutine met plus de 100ms sans yield\\n```\\n\\n**Utile pendant le d\xe9veloppement** pour rep\xe9rer les op\xe9rations bloquantes accidentelles.\\n\\n## Conclusion \ud83c\udfaf\\n\\nLa programmation asynchrone en Python avec `async`/`await` et `asyncio` est essentielle pour cr\xe9er des applications performantes et r\xe9actives. Elle brille particuli\xe8rement avec FastAPI pour les APIs modernes.\\n\\nPoints cl\xe9s \xe0 retenir :\\n\\n- **async/await** : syntaxe simple pour la concurrence\\n- **asyncio** : biblioth\xe8que standard puissante\\n- **I/O-bound** : parfait pour les op\xe9rations r\xe9seau/disque\\n- **FastAPI** : framework id\xe9al pour l\'async\\n- **Patterns** : queue, semaphore, retry, etc.\\n\\nCes connaissances permettent de cr\xe9er des applications Python hautement performantes.\\n\\n## Ressources utiles \ud83d\udcda\\n\\n- [Documentation asyncio](https://docs.python.org/3/library/asyncio.html)\\n- [Real Python - Async IO](https://realpython.com/async-io-python/)\\n- [FastAPI Async](https://fastapi.tiangolo.com/async/)\\n- [aiohttp Documentation](https://docs.aiohttp.org/)"},{"id":"/2025/08/04/09-scripting/graphql","metadata":{"permalink":"/blog/2025/08/04/09-scripting/graphql","source":"@site/blog/09-scripting/2025-08-04-graphql.md","title":"API : REST vs GraphQL","description":"Comparaison d\xe9taill\xe9e entre les API GraphQL et REST : principes, avantages, limites et cas d\u2019usage.","date":"2025-08-04T00:00:00.000Z","tags":[{"inline":false,"label":"Scripting","permalink":"/blog/tags/scripting"}],"readingTime":3.45,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"API : REST vs GraphQL","description":"Comparaison d\xe9taill\xe9e entre les API GraphQL et REST : principes, avantages, limites et cas d\u2019usage.","tags":["scripting"]},"unlisted":false,"prevItem":{"title":"Python : async/await","permalink":"/blog/2025/11/21/09-scripting/python-async-await"},"nextItem":{"title":"GraphQL : FastAPI & Strawberry","permalink":"/blog/2025/08/04/09-scripting/strawberry"}},"content":"GraphQL et REST sont deux paradigmes majeurs pour la conception d\u2019API, chacun reposant sur des fondements th\xe9oriques et des choix architecturaux distincts. Comprendre leurs diff\xe9rences est essentiel pour concevoir des syst\xe8mes distribu\xe9s robustes, \xe9volutifs et maintenables.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\u2019est-ce qu\u2019une API REST ? \ud83c\udf10\\n\\nREST (Representational State Transfer), formalis\xe9 par Roy Fielding en 2000, est un style architectural pour les syst\xe8mes distribu\xe9s. Il repose sur l\u2019identification des ressources via des URI, la manipulation de ces ressources \xe0 l\u2019aide de m\xe9thodes HTTP standardis\xe9es (GET, POST, PUT, DELETE), et l\u2019absence d\u2019\xe9tat c\xf4t\xe9 serveur (statelessness).\\n\\nREST favorise une s\xe9paration stricte entre client et serveur, permettant une \xe9volutivit\xe9 horizontale et une interop\xe9rabilit\xe9 accrue. Les ressources sont repr\xe9sent\xe9es sous forme de documents (souvent JSON), et l\u2019API expose un ensemble d\u2019endpoints correspondant \xe0 des entit\xe9s m\xe9tier.\\n\\n### Principes cl\xe9s REST\\n\\n- **Ressources identifi\xe9es par des URLs** : chaque entit\xe9 m\xe9tier poss\xe8de une URI unique\\n- **Stateless** : chaque requ\xeate HTTP est ind\xe9pendante, facilitant la scalabilit\xe9\\n- **Utilisation s\xe9mantique des m\xe9thodes HTTP** : GET (lecture), POST (cr\xe9ation), PUT/PATCH (modification), DELETE (suppression)\\n- **Format de r\xe9ponse standardis\xe9** : JSON, XML, ou autres, selon le header `Accept`\\n- **Cacheabilit\xe9** : possibilit\xe9 d\u2019utiliser le cache HTTP pour optimiser les performances\\n\\n### Exemple d\u2019appel REST\\n\\n```http\\nGET /users/123\\nAccept: application/json\\n```\\n\\nR\xe9ponse typique\u202f:\\n\\n```json\\n{\\n  \\"id\\": 123,\\n  \\"name\\": \\"Alice\\",\\n  \\"email\\": \\"alice@example.com\\"\\n}\\n```\\n\\n## Qu\u2019est-ce que GraphQL ? \ud83e\udde9\\n\\nGraphQL, introduit par Facebook en 2015, est un langage de requ\xeate et un runtime pour les API. Il propose une approche d\xe9clarative\u202f: le client d\xe9crit pr\xe9cis\xe9ment la forme et la structure des donn\xe9es attendues, et le serveur r\xe9pond en cons\xe9quence, via un unique endpoint.\\n\\nGraphQL s\u2019appuie sur un sch\xe9ma fortement typ\xe9, d\xe9fini c\xf4t\xe9 serveur, qui d\xe9crit l\u2019ensemble des types, des relations et des op\xe9rations (queries, mutations, subscriptions) disponibles. Cette introspection permet une documentation automatique et une validation statique des requ\xeates.\\n\\n### Principes cl\xe9s GraphQL\\n\\n- **Un seul endpoint** (g\xe9n\xe9ralement `/graphql`)\u202f: simplifie la gestion r\xe9seau et la s\xe9curit\xe9\\n- **Requ\xeates d\xe9claratives et flexibles**\u202f: le client sp\xe9cifie exactement les champs et relations d\xe9sir\xe9s, limitant l\u2019overfetching et l\u2019underfetching\\n- **Sch\xe9ma fortement typ\xe9**\u202f: chaque type, champ et op\xe9ration est explicitement d\xe9fini, permettant la validation et l\u2019autocompl\xe9tion\\n- **Agr\xe9gation de ressources**\u202f: possibilit\xe9 de r\xe9cup\xe9rer des graphes de donn\xe9es complexes en une seule requ\xeate\\n- **Introspection**\u202f: le sch\xe9ma est auto-document\xe9 et interrogeable dynamiquement\\n\\n### Exemple de requ\xeate GraphQL\\n\\n```graphql\\nquery {\\n  user(id: \\"123\\") {\\n    name\\n    email\\n    posts {\\n      title\\n    }\\n  }\\n}\\n```\\n\\nR\xe9ponse typique\u202f:\\n\\n```json\\n{\\n  \\"data\\": {\\n    \\"user\\": {\\n      \\"name\\": \\"Alice\\",\\n      \\"email\\": \\"alice@example.com\\",\\n      \\"posts\\": [\\n        { \\"title\\": \\"Premier post\\" },\\n        { \\"title\\": \\"Second post\\" }\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n## Mod\xe9lisation et s\xe9mantique des donn\xe9es\\n\\nREST mod\xe9lise les entit\xe9s m\xe9tier comme des ressources ind\xe9pendantes, accessibles via des URI. Les relations entre ressources sont g\xe9n\xe9ralement exprim\xe9es par des liens ou des sous-routes (ex\u202f: `/users/123/posts`).\\n\\nGraphQL mod\xe9lise les donn\xe9es comme un graphe typ\xe9\u202f: chaque type peut r\xe9f\xe9rencer d\u2019autres types, et les requ\xeates peuvent naviguer dans ce graphe de mani\xe8re r\xe9cursive. Cela permet d\u2019exprimer des relations complexes et d\u2019optimiser la r\xe9cup\xe9ration des donn\xe9es.\\n\\n## Comparaison des concepts \ud83d\udd0d\\n\\n| Crit\xe8re                | REST                                 | GraphQL                              |\\n|------------------------|--------------------------------------|--------------------------------------|\\n| Endpoint               | Plusieurs (par ressource)            | Un seul                              |\\n| Format de r\xe9ponse      | Fixe (souvent tout l\u2019objet)          | Flexible (le client choisit)         |\\n| Overfetching           | Oui (donn\xe9es inutiles)               | Non                                  |\\n| Underfetching          | Oui (requ\xeates multiples n\xe9cessaires) | Non                                  |\\n| Documentation          | Swagger, OpenAPI                     | Sch\xe9ma introspectif, autog\xe9n\xe9r\xe9      |\\n| Versioning             | Par URL ou header                    | \xc9volution incr\xe9mentale du sch\xe9ma     |\\n| Erreurs                | Codes HTTP                           | Objet d\u2019erreur structur\xe9 dans la r\xe9ponse |\\n| Typage                 | Faible (contrats implicites)         | Fort (contrats explicites)           |\\n| D\xe9couverte             | Manuelle, via documentation externe  | Automatique, via introspection       |\\n\\n## Gestion des erreurs et robustesse\\n\\nREST s\u2019appuie sur les codes de statut HTTP pour signaler les erreurs (404, 500, etc.), ce qui permet une gestion standardis\xe9e mais parfois peu granulaire.\\n\\nGraphQL encapsule les erreurs dans la r\xe9ponse JSON, permettant de signaler des erreurs partielles (ex\u202f: certains champs en erreur, d\u2019autres valides), ce qui am\xe9liore la r\xe9silience c\xf4t\xe9 client.\\n\\n## Avantages et limites \u2696\ufe0f\\n\\n### REST\\n\\n- \u2705 Simplicit\xe9, standardisation HTTP\\n- \u2705 Large \xe9cosyst\xe8me\\n- \u274c Overfetching/Underfetching\\n- \u274c Multiplication des endpoints\\n\\n### GraphQL\\n\\n- \u2705 Flexibilit\xe9 des requ\xeates\\n- \u2705 Moins de requ\xeates r\xe9seau\\n- \u2705 Typage fort et introspection\\n- \u274c Courbe d\u2019apprentissage\\n- \u274c Complexit\xe9 c\xf4t\xe9 serveur\\n- \u274c Pas de cache HTTP natif\\n\\n## Quand choisir l\u2019un ou l\u2019autre ? \ud83e\udd14\\n\\n- **REST** : API simples, forte compatibilit\xe9, besoin de cache HTTP\\n- **GraphQL** : Applications complexes, besoins mobiles, agr\xe9gation de donn\xe9es, \xe9volutivit\xe9 du sch\xe9ma\\n\\n## Conclusion \ud83c\udfaf\\n\\nREST reste pertinent pour de nombreux cas, mais GraphQL s\u2019impose pour des besoins de flexibilit\xe9 et d\u2019optimisation des \xe9changes. Le choix d\xe9pend du contexte technique et des besoins m\xe9tier."},{"id":"/2025/08/04/09-scripting/strawberry","metadata":{"permalink":"/blog/2025/08/04/09-scripting/strawberry","source":"@site/blog/09-scripting/2025-08-04-strawberry.md","title":"GraphQL : FastAPI & Strawberry","description":"\xc9tapes pratiques pour concevoir, coder et tester une API GraphQL en Python.","date":"2025-08-04T00:00:00.000Z","tags":[{"inline":false,"label":"Scripting","permalink":"/blog/tags/scripting"}],"readingTime":7.31,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"GraphQL : FastAPI & Strawberry","description":"\xc9tapes pratiques pour concevoir, coder et tester une API GraphQL en Python.","tags":["scripting"]},"unlisted":false,"prevItem":{"title":"API : REST vs GraphQL","permalink":"/blog/2025/08/04/09-scripting/graphql"},"nextItem":{"title":"Proxy : Traefik","permalink":"/blog/2025/06/09/02-network/traefik"}},"content":"Ce guide pr\xe9sente, \xe9tape par \xe9tape, la cr\xe9ation d\u2019une API GraphQL en Python avec FastAPI et Strawberry, en expliquant les choix d\u2019outils et les bonnes pratiques \xe0 chaque \xe9tape.\\n\\n\x3c!--truncate--\x3e\\n\\n## Outils utilis\xe9s\\n\\n### FastAPI\\n\\nFastAPI est un framework web moderne pour Python, con\xe7u pour cr\xe9er des APIs performantes, robustes et faciles \xe0 maintenir. Il offre :\\n\\n- Un support natif d\u2019async/await pour la performance\\n- Une documentation automatique (Swagger/OpenAPI)\\n- Une int\xe9gration simple avec les standards Python (type hints, Pydantic)\\n- Id\xe9al pour des APIs REST ou GraphQL modernes\\n\\n### Strawberry\\n\\nStrawberry est une biblioth\xe8que Python pour cr\xe9er des APIs GraphQL. Elle se distingue par :\\n\\n- Une syntaxe moderne bas\xe9e sur les dataclasses et les annotations de type Python\\n- Un support natif de FastAPI et Starlette\\n- La g\xe9n\xe9ration automatique du sch\xe9ma GraphQL et de la documentation interactive (GraphiQL)\\n- La gestion des queries, mutations et subscriptions (WebSocket)\\n\\n## Pourquoi utiliser FastAPI et Strawberry ensemble ?\\n\\nFastAPI et Strawberry sont compl\xe9mentaires dans l\u2019architecture d\u2019une API GraphQL moderne\u202f:\\n\\n- **FastAPI** joue le r\xf4le de serveur web\u202f: il re\xe7oit les requ\xeates HTTP/WS, g\xe8re le routage, la s\xe9curit\xe9, la documentation, et l\u2019int\xe9gration avec l\u2019\xe9cosyst\xe8me Python (middlewares, d\xe9pendances, etc.).\\n- **Strawberry** g\xe8re toute la logique GraphQL\u202f: il d\xe9finit le sch\xe9ma (types, queries, mutations, subscriptions), r\xe9sout les requ\xeates GraphQL, et expose l\u2019interface interactive GraphiQL.\\n\\n**Comment \xe7a s\u2019interconnecte ?**\\n\\n- Strawberry fournit un sch\xe9ma GraphQL Python.\\n- FastAPI expose ce sch\xe9ma sur une route (ex\u202f: `/graphql`) gr\xe2ce \xe0 `GraphQLRouter`.\\n- Toute requ\xeate GraphQL (query, mutation, subscription) passe par FastAPI, qui la transmet \xe0 Strawberry pour ex\xe9cution.\\n\\n**Responsabilit\xe9s dans l\u2019architecture\u202f:**\\n\\n- FastAPI\u202f: transport, s\xe9curit\xe9, configuration serveur, int\xe9gration avec d\u2019autres services (auth, logs, etc.)\\n- Strawberry\u202f: logique m\xe9tier GraphQL, validation des requ\xeates, g\xe9n\xe9ration du sch\xe9ma, documentation GraphQL\\n\\nCette s\xe9paration permet de b\xe9n\xe9ficier du meilleur des deux mondes\u202f: la puissance de FastAPI pour l\u2019API et l\u2019\xe9cosyst\xe8me Python, et la flexibilit\xe9 de Strawberry pour GraphQL.\\n\\n## Initialisation du projet Python\\n\\nPour d\xe9marrer un projet Python proprement, on utilise [Poetry](https://python-poetry.org/) qui g\xe8re les d\xe9pendances et l\u2019environnement virtuel.\\n\\n### 1. Cr\xe9ation du projet et du fichier pyproject.toml\\n\\nDans le terminal\u202f:\\n\\n```bash\\npoetry new exemple-graphql-fastapi\\ncd exemple-graphql-fastapi\\n```\\n\\nCela cr\xe9e la structure de base du projet et un fichier `pyproject.toml` qui centralise la configuration\u202f:\\n\\n```toml\\n[tool.poetry]\\nname = \\"exemple-graphql-fastapi\\"\\nversion = \\"0.1.0\\"\\ndescription = \\"Exemple d\'API GraphQL avec FastAPI et Strawberry\\"\\nauthors = [\\"Votre Nom <email@example.com>\\"]\\n\\n[tool.poetry.dependencies]\\npython = \\">=3.9,<4.0\\"\\nfastapi = \\"^0.110.0\\"\\nuvicorn = \\"^0.29.0\\"\\nstrawberry-graphql = \\"^0.220.0\\"\\nrequests = \\"^2.32.4\\"\\nwebsockets = \\"^15.0.1\\"\\n\\n[build-system]\\nrequires = [\\"poetry-core>=1.0.0\\"]\\nbuild-backend = \\"poetry.core.masonry.api\\"\\n```\\n\\n### 2. Installation des d\xe9pendances\\n\\nToujours dans le dossier du projet\u202f:\\n\\n```bash\\npoetry install\\n```\\n\\nCela cr\xe9e un environnement virtuel isol\xe9 et installe toutes les d\xe9pendances n\xe9cessaires.\\n\\n> **Astuce** : Pour activer l\u2019environnement virtuel Poetry dans votre shell, utilisez `poetry env activate`.\\n\\n## Mise en place du serveur FastAPI (main.py)\\n\\nLe fichier `main.py` est le point d\u2019entr\xe9e de l\u2019application. Il configure FastAPI et expose le sch\xe9ma GraphQL fourni par Strawberry sur une route d\xe9di\xe9e.\\n\\nCr\xe9ez un fichier `main.py` \xe0 la racine du projet avec le contenu suivant\u202f:\\n\\n```python\\nfrom fastapi import FastAPI\\nfrom strawberry.fastapi import GraphQLRouter\\nfrom schema import schema\\n\\napp = FastAPI()\\ngraphql_app = GraphQLRouter(schema)\\napp.include_router(graphql_app, prefix=\\"/graphql\\")\\n```\\n\\n- `FastAPI()` instancie le serveur web.\\n- `GraphQLRouter(schema)` cr\xe9e une route GraphQL \xe0 partir du sch\xe9ma Strawberry.\\n- `app.include_router(...)` expose l\u2019API GraphQL sur `/graphql`.\\n\\n> **Remarque** : Ce fichier ne contient aucune logique m\xe9tier, il sert uniquement \xe0 brancher le sch\xe9ma GraphQL sur le serveur HTTP. Toute la logique (types, queries, mutations, subscriptions) sera d\xe9finie dans `schema.py`.\\n\\n## D\xe9finition du sch\xe9ma GraphQL : les queries (schema.py)\\n\\nPour organiser la logique m\xe9tier, on cr\xe9e un fichier `schema.py` qui contiendra tout le sch\xe9ma GraphQL\u202f: types, queries, mutations, subscriptions.\\n\\n### Cas d\u2019usage fictif : gestion de piscines\\n\\nImaginons une API pour g\xe9rer un parc de piscines publiques. On souhaite exposer en lecture la liste des piscines, avec leurs caract\xe9ristiques principales (nom, localisation, capacit\xe9, horaires, etc.).\\n\\n### Qu\u2019est-ce qu\u2019une query GraphQL\u202f?\\n\\nEn GraphQL, une **query** est une op\xe9ration de lecture\u202f: elle permet au client de demander exactement les donn\xe9es dont il a besoin, sous la forme d\u2019un arbre, en une seule requ\xeate HTTP. Contrairement \xe0 REST o\xf9 chaque endpoint correspond \xe0 une ressource ou une action, GraphQL expose un unique endpoint `/graphql` et c\u2019est la query qui d\xe9crit la forme et la profondeur des donn\xe9es attendues.\\n\\n- Une query interroge le sch\xe9ma GraphQL pour obtenir des objets, des listes ou des champs pr\xe9cis.\\n- Le serveur ex\xe9cute la query et retourne uniquement les champs demand\xe9s, dans la structure voulue.\\n\\nExemple de query c\xf4t\xe9 client\u202f:\\n\\n```graphql\\nquery {\\n  pools {\\n    name\\n    city\\n  }\\n}\\n```\\n\\nR\xe9ponse typique du serveur\u202f:\\n\\n```json\\n{\\n  \\"data\\": {\\n    \\"pools\\": [\\n      {\\"name\\": \\"Aquaparc\\", \\"city\\": \\"Paris\\"},\\n      {\\"name\\": \\"Blue Lagoon\\", \\"city\\": \\"Lyon\\"}\\n    ]\\n  }\\n}\\n```\\n\\n### Exemple minimal de queries dans `schema.py`\\n\\nCr\xe9ez un fichier `schema.py` \xe0 la racine du projet\u202f:\\n\\n```python\\nimport strawberry\\nfrom typing import List\\n\\n@strawberry.type\\nclass Pool:\\n    name: str\\n    city: str\\n    capacity: int\\n\\n# Donn\xe9es fictives pour l\'exemple\\ndata = [\\n    Pool(name=\\"Aquaparc\\", city=\\"Paris\\", capacity=200),\\n    Pool(name=\\"Blue Lagoon\\", city=\\"Lyon\\", capacity=150),\\n]\\n\\n@strawberry.type\\nclass Query:\\n    @strawberry.field\\n    def pools(self) -> List[Pool]:\\n        return data\\n\\nschema = strawberry.Schema(query=Query)\\n```\\n\\n- On d\xe9finit un type `Pool` (nom, ville, capacit\xe9).\\n- On cr\xe9e une liste de piscines fictives.\\n- On expose une query `pools` qui retourne la liste des piscines.\\n\\n> **Remarque** : Ce sch\xe9ma est minimal pour illustrer la structure. On pourra l\u2019enrichir ensuite (filtres, mutations, etc.).\\n\\n## Ajouter des donn\xe9es : les mutations GraphQL\\n\\nApr\xe8s les queries (lecture), GraphQL permet aussi de modifier les donn\xe9es via des **mutations**. Une mutation est l\u2019\xe9quivalent d\u2019une op\xe9ration d\u2019\xe9criture (cr\xe9ation, modification, suppression) dans le sch\xe9ma.\\n\\n### Qu\u2019est-ce qu\u2019une mutation\u202f?\\n\\n- Une mutation GraphQL permet au client de demander une modification de l\u2019\xe9tat du serveur (ajout, mise \xe0 jour, suppression d\u2019un objet).\\n- Comme pour les queries, le client choisit les champs \xe0 retourner dans la r\xe9ponse.\\n- Les mutations sont regroup\xe9es dans une classe `Mutation` dans le sch\xe9ma Strawberry.\\n\\nExemple de mutation c\xf4t\xe9 client\u202f:\\n\\n```graphql\\nmutation {\\n  addPool(name: \\"Piscine Soleil\\", city: \\"Marseille\\", capacity: 120) {\\n    name\\n    city\\n    capacity\\n  }\\n}\\n```\\n\\nR\xe9ponse typique du serveur\u202f:\\n\\n```json\\n{\\n  \\"data\\": {\\n    \\"addPool\\": {\\n      \\"name\\": \\"Piscine Soleil\\",\\n      \\"city\\": \\"Marseille\\",\\n      \\"capacity\\": 120\\n    }\\n  }\\n}\\n```\\n\\n### Exemple minimal de mutation dans `schema.py`\\n\\nOn enrichit le sch\xe9ma pour permettre d\u2019ajouter une piscine\u202f:\\n\\n```python\\nimport strawberry\\nfrom typing import List\\n\\n@strawberry.type\\nclass Pool:\\n    name: str\\n    city: str\\n    capacity: int\\n\\n# Donn\xe9es fictives pour l\'exemple\\ndata = [\\n    Pool(name=\\"Aquaparc\\", city=\\"Paris\\", capacity=200),\\n    Pool(name=\\"Blue Lagoon\\", city=\\"Lyon\\", capacity=150),\\n]\\n\\n@strawberry.type\\nclass Query:\\n    @strawberry.field\\n    def pools(self) -> List[Pool]:\\n        return data\\n\\n@strawberry.type\\nclass Mutation:\\n    @strawberry.mutation\\n    def add_pool(self, name: str, city: str, capacity: int) -> Pool:\\n        pool = Pool(name=name, city=city, capacity=capacity)\\n        data.append(pool)\\n        return pool\\n\\nschema = strawberry.Schema(query=Query, mutation=Mutation)\\n```\\n\\n- On d\xe9finit une classe `Mutation` avec une m\xe9thode `add_pool`.\\n- Cette mutation prend des arguments (name, city, capacity), cr\xe9e une nouvelle piscine, l\u2019ajoute \xe0 la liste, et la retourne.\\n- On passe la mutation au sch\xe9ma Strawberry.\\n\\n> **Remarque** : En production, on utiliserait une base de donn\xe9es au lieu d\u2019une liste Python, mais ce mod\xe8le illustre la m\xe9canique GraphQL.\\n\\n## Temps r\xe9el avec GraphQL : les subscriptions (WebSocket)\\n\\nEn plus des queries (lecture) et des mutations (\xe9criture), GraphQL propose un troisi\xe8me concept\u202f: les **subscriptions**. Les subscriptions permettent au client de s\u2019abonner \xe0 des \xe9v\xe9nements c\xf4t\xe9 serveur et de recevoir des notifications en temps r\xe9el, g\xe9n\xe9ralement via WebSocket.\\n\\n### Qu\u2019est-ce qu\u2019une subscription\u202f?\\n\\n- Une subscription GraphQL permet au client de recevoir automatiquement des mises \xe0 jour d\xe8s qu\u2019un \xe9v\xe9nement se produit (ex\u202f: ajout d\u2019une piscine).\\n- La connexion se fait via WebSocket, ce qui permet au serveur de pousser les donn\xe9es vers le client sans que celui-ci ait \xe0 interroger en boucle.\\n- Les subscriptions sont utiles pour le temps r\xe9el\u202f: notifications, chat, monitoring, etc.\\n\\nExemple de subscription c\xf4t\xe9 client\u202f:\\n\\n```graphql\\nsubscription {\\n  poolAdded {\\n    name\\n    city\\n  }\\n}\\n```\\n\\n\xc0 chaque fois qu\u2019une piscine est ajout\xe9e, le serveur envoie automatiquement les infos de la nouvelle piscine \xe0 tous les clients abonn\xe9s.\\n\\n### Exemple minimal de subscription dans `schema.py`\\n\\nOn enrichit le sch\xe9ma pour notifier en temps r\xe9el l\u2019ajout d\u2019une piscine\u202f:\\n\\n```python\\nimport asyncio\\nimport strawberry\\nfrom typing import List, AsyncGenerator\\n\\n@strawberry.type\\nclass Pool:\\n    name: str\\n    city: str\\n    capacity: int\\n\\n# Donn\xe9es fictives pour l\'exemple\\ndata = [\\n    Pool(name=\\"Aquaparc\\", city=\\"Paris\\", capacity=200),\\n    Pool(name=\\"Blue Lagoon\\", city=\\"Lyon\\", capacity=150),\\n]\\n\\nsubscribers: List[asyncio.Queue] = []\\n\\n@strawberry.type\\nclass Subscription:\\n    @strawberry.subscription\\n    async def pool_added(self) -> AsyncGenerator[Pool, None]:\\n        queue = asyncio.Queue()\\n        subscribers.append(queue)\\n        try:\\n            while True:\\n                pool = await queue.get()\\n                yield pool\\n        finally:\\n            subscribers.remove(queue)\\n\\n@strawberry.type\\nclass Query:\\n    @strawberry.field\\n    def pools(self) -> List[Pool]:\\n        return data\\n\\n@strawberry.type\\nclass Mutation:\\n    @strawberry.mutation\\n    def add_pool(self, name: str, city: str, capacity: int) -> Pool:\\n        pool = Pool(name=name, city=city, capacity=capacity)\\n        data.append(pool)\\n        # Notifier les abonn\xe9s\\n        for queue in subscribers:\\n            queue.put_nowait(pool)\\n        return pool\\n\\nschema = strawberry.Schema(query=Query, mutation=Mutation, subscription=Subscription)\\n```\\n\\n- On d\xe9finit une classe `Subscription` avec une m\xe9thode `pool_added` qui \xe9coute les nouveaux ajouts.\\n- Lorsqu\u2019une piscine est ajout\xe9e via la mutation, tous les abonn\xe9s sont notifi\xe9s en temps r\xe9el.\\n- Le sch\xe9ma Strawberry inclut maintenant la subscription.\\n\\n> **Remarque** : Pour tester les subscriptions, il faut utiliser un client compatible WebSocket (ex\u202f: GraphiQL, Apollo, ou un script Python avec `websockets`)."},{"id":"/2025/06/09/02-network/traefik","metadata":{"permalink":"/blog/2025/06/09/02-network/traefik","source":"@site/blog/02-network/2025-06-09-traefik.md","title":"Proxy : Traefik","description":"D\xe9couverte de Traefik, reverse proxy moderne, dynamique et simple pour vos infrastructures cloud-native.","date":"2025-06-09T00:00:00.000Z","tags":[{"inline":false,"label":"R\xe9seau","permalink":"/blog/tags/network"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":2.72,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Proxy : Traefik","description":"D\xe9couverte de Traefik, reverse proxy moderne, dynamique et simple pour vos infrastructures cloud-native.","tags":["network","devops"]},"unlisted":false,"prevItem":{"title":"GraphQL : FastAPI & Strawberry","permalink":"/blog/2025/08/04/09-scripting/strawberry"},"nextItem":{"title":"Ansible","permalink":"/blog/2025/06/09/08-iac/ansible-introduction"}},"content":"Traefik est un reverse proxy et load balancer open-source de nouvelle g\xe9n\xe9ration, pens\xe9 pour les architectures cloud-native et microservices. Il s\u2019int\xe8gre parfaitement avec Docker, Kubernetes, et bien d\u2019autres orchestrateurs, et automatise la d\xe9couverte, la configuration et la gestion du trafic r\xe9seau. \ud83d\udea6\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce qu\'un reverse proxy ?\\n\\nUn reverse proxy est un serveur interm\xe9diaire qui re\xe7oit les requ\xeates des clients et les achemine vers les serveurs applicatifs appropri\xe9s. Il permet de :\\n\\n- Centraliser l\'acc\xe8s \xe0 plusieurs applications ou services\\n- S\xe9curiser et masquer l\'infrastructure backend\\n- G\xe9rer le chiffrement HTTPS\\n- R\xe9partir la charge (load balancing)\\n- Ajouter des fonctionnalit\xe9s comme l\'authentification, le caching ou la r\xe9\xe9criture d\'URL\\n\\nLes reverse proxies sont essentiels dans les architectures modernes pour am\xe9liorer la s\xe9curit\xe9, la scalabilit\xe9 et la flexibilit\xe9 des d\xe9ploiements.\\n\\n## Pourquoi choisir Traefik ?\\n\\n- **D\xe9couverte automatique des services** : plus besoin de modifier manuellement vos fichiers de configuration \xe0 chaque d\xe9ploiement.\\n- **Support natif de Docker, Kubernetes, Consul, etc.**\\n- **Gestion automatique du HTTPS (Let\'s Encrypt)**\\n- **Dashboard web int\xe9gr\xe9** pour visualiser le routage et l\u2019\xe9tat du proxy\\n- **Configuration dynamique** : changements pris en compte \xe0 chaud, sans red\xe9marrage\\n- **Fonctionnalit\xe9s avanc\xe9es** : load balancing, redirections, middleware, authentification, rate limiting, etc.\\n\\n## Concepts cl\xe9s de Traefik\\n\\n- **Entrypoint** : point d\u2019entr\xe9e r\xe9seau (port, protocole) sur lequel Traefik \xe9coute (ex : HTTP sur 80, HTTPS sur 443)\\n- **Router** : r\xe8gle qui fait le lien entre une requ\xeate entrante et un service backend (ex : Host(`api.monsite.com`))\\n- **Service** : destination finale du trafic (container, pod, etc.)\\n- **Provider** : source de configuration dynamique (Docker, Kubernetes, fichiers, etc.)\\n- **Middleware** : traitement interm\xe9diaire (auth, redirection, header, etc.)\\n\\n## Exemple d\u2019utilisation avec Docker \ud83d\udc33\\n\\nLancez Traefik avec Docker Compose :\\n\\n```yaml\\nversion: \'3.8\'\\nservices:\\n  traefik:\\n    image: traefik:v3.0\\n    command:\\n      - --api.dashboard=true\\n      - --providers.docker=true\\n      - --entrypoints.web.address=:80\\n    ports:\\n      - \\"80:80\\"\\n      - \\"8080:8080\\" # Dashboard\\n    volumes:\\n      - /var/run/docker.sock:/var/run/docker.sock\\n\\n  whoami:\\n    image: traefik/whoami # Petit service de test\\n    labels:\\n      - \\"traefik.enable=true\\"\\n      - \\"traefik.http.routers.whoami.rule=Host(`whoami.localhost`)\\"\\n      - \\"traefik.http.routers.whoami.entrypoints=web\\"\\n```\\n\\nAcc\xe9dez \xe0 [http://whoami.localhost](http://whoami.localhost) et au dashboard sur [http://localhost:8080/dashboard/](http://localhost:8080/dashboard/).\\n\\n## Exemple d\u2019utilisation avec Kubernetes \u2638\ufe0f\\n\\nD\xe9ploiement d\u2019un IngressRoute pour exposer un service :\\n\\n```yaml\\napiVersion: traefik.containo.us/v1alpha1\\nkind: IngressRoute\\nmetadata:\\n  name: my-ingressroute\\nspec:\\n  entryPoints:\\n    - web\\n  routes:\\n    - match: Host(`example.com`)\\n      kind: Rule\\n      services:\\n        - name: my-service\\n          port: 80\\n```\\n\\n## HTTPS automatique avec Let\'s Encrypt \ud83d\udd12\\n\\nTraefik peut g\xe9n\xe9rer et renouveler automatiquement des certificats SSL :\\n\\n```yaml\\n# Extrait de configuration statique\\nentryPoints:\\n  web:\\n    address: \\":80\\"\\n  websecure:\\n    address: \\":443\\"\\ncertificatesResolvers:\\n  letsencrypt:\\n    acme:\\n      email: \\"admin@monsite.com\\"\\n      storage: \\"/etc/traefik/acme.json\\"\\n      httpChallenge:\\n        entryPoint: web\\n```\\n\\nAjoutez simplement `entrypoints=websecure` et `tls.certresolver=letsencrypt` \xe0 vos routers pour b\xe9n\xe9ficier du HTTPS automatique.\\n\\n## Dashboard et monitoring \ud83d\udcca\\n\\nTraefik propose un dashboard web tr\xe8s pratique pour visualiser :\\n\\n- Les routes actives\\n- Les middlewares appliqu\xe9s\\n- L\u2019\xe9tat des services\\n- Les certificats SSL\\n\\nAccessible par d\xe9faut sur le port 8080.\\n\\n## Bonnes pratiques et conseils \u26a1\\n\\n- **S\xe9curisez l\u2019acc\xe8s au dashboard** (authentification, firewall)\\n- **Utilisez des labels clairs** pour vos services Docker/K8s\\n- **Centralisez vos logs** pour le troubleshooting\\n- **Testez vos r\xe8gles de routage** avant la mise en production\\n- **Surveillez l\u2019expiration des certificats** si vous utilisez Let\'s Encrypt\\n\\n## Pour aller plus loin\\n\\n- [Documentation officielle Traefik](https://doc.traefik.io/traefik/)\\n- [Exemples de configurations](https://doc.traefik.io/traefik/getting-started/quick-start/)\\n- [Traefik sur GitHub](https://github.com/traefik/traefik)\\n\\nTraefik s\u2019impose comme un choix moderne, simple et puissant pour g\xe9rer le trafic de vos applications cloud-native. Essayez-le sur un projet personnel ou en entreprise pour d\xe9couvrir tout son potentiel !"},{"id":"/2025/06/09/08-iac/ansible-introduction","metadata":{"permalink":"/blog/2025/06/09/08-iac/ansible-introduction","source":"@site/blog/08-iac/2025-06-09-ansible-introduction.md","title":"Ansible","description":"D\xe9couvrez Ansible, l\'outil d\'automatisation simple mais puissant qui r\xe9volutionne la gestion de l\'infrastructure as code.","date":"2025-06-09T00:00:00.000Z","tags":[{"inline":false,"label":"Infrastructure as Code","permalink":"/blog/tags/iac"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":3.46,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Ansible","description":"D\xe9couvrez Ansible, l\'outil d\'automatisation simple mais puissant qui r\xe9volutionne la gestion de l\'infrastructure as code.","tags":["iac","devops"]},"unlisted":false,"prevItem":{"title":"Proxy : Traefik","permalink":"/blog/2025/06/09/02-network/traefik"},"nextItem":{"title":"Ansible : cas pratique zsh","permalink":"/blog/2025/06/09/08-iac/ansible-zsh-automation"}},"content":"Ansible est devenu un outil incontournable dans le monde DevOps pour l\'automatisation des infrastructures. Sa simplicit\xe9 d\'utilisation et sa puissance en font une solution privil\xe9gi\xe9e pour d\xe9ployer des configurations, orchestrer des syst\xe8mes et g\xe9rer l\'infrastructure as code. \ud83d\ude80\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce qu\'Ansible ? \ud83e\udd14\\n\\nAnsible est un outil open-source d\'automatisation qui simplifie la configuration des syst\xe8mes, le d\xe9ploiement d\'applications et l\'orchestration des t\xe2ches. Contrairement \xe0 d\'autres outils similaires, Ansible ne n\xe9cessite pas l\'installation d\'un agent sur les machines cibles, ce qui facilite grandement son adoption.\\n\\nLes principaux avantages d\'Ansible sont :\\n\\n- **Simplicit\xe9** : utilise YAML comme langage de description, facile \xe0 lire et \xe0 \xe9crire\\n- **Sans agent** : fonctionne via SSH, ne n\xe9cessitant rien sur les machines cibles\\n- **Idempotence** : peut \xeatre ex\xe9cut\xe9 plusieurs fois sans effet secondaire\\n- **Extensibilit\xe9** : plus de 3000 modules disponibles pour interagir avec diff\xe9rents syst\xe8mes\\n- **Multi-plateforme** : compatible avec Linux, macOS, Windows et de nombreux fournisseurs cloud\\n\\n## Architecture d\'Ansible \ud83c\udfd7\ufe0f\\n\\nL\'architecture d\'Ansible est simple mais efficace :\\n\\n1. **Machine de contr\xf4le** : o\xf9 Ansible est install\xe9 et depuis laquelle les playbooks sont ex\xe9cut\xe9s\\n2. **Inventaire** : liste des h\xf4tes \xe0 g\xe9rer, group\xe9s logiquement\\n3. **Modules** : unit\xe9s de code ex\xe9cut\xe9es sur les h\xf4tes cibles\\n4. **Playbooks** : fichiers YAML d\xe9crivant les t\xe2ches \xe0 effectuer\\n5. **R\xf4les** : regroupements r\xe9utilisables de playbooks, variables et fichiers\\n\\nLa communication entre la machine de contr\xf4le et les h\xf4tes se fait g\xe9n\xe9ralement via SSH, ce qui \xe9limine le besoin d\'agents d\xe9di\xe9s et simplifie la gestion.\\n\\n## Les concepts fondamentaux \ud83d\udcda\\n\\n### Inventaire\\n\\nL\'inventaire d\xe9finit les machines cibles et permet de les organiser en groupes :\\n\\n```ini\\n[webservers]\\nweb1.example.com\\nweb2.example.com\\n\\n[databases]\\ndb1.example.com\\ndb2.example.com\\n\\n[production:children]\\nwebservers\\ndatabases\\n```\\n\\n### Playbooks\\n\\nLes playbooks sont des fichiers YAML qui d\xe9crivent les t\xe2ches \xe0 ex\xe9cuter sur les h\xf4tes :\\n\\n```yaml\\n---\\n- name: Installer et configurer un serveur web\\n  hosts: webservers\\n  become: true  # \xc9quivalent de sudo\\n  vars:\\n    http_port: 80\\n\\n  tasks:\\n    - name: Installer nginx\\n      apt:\\n        name: nginx\\n        state: present\\n        update_cache: yes\\n\\n    - name: D\xe9marrer et activer le service nginx\\n      service:\\n        name: nginx\\n        state: started\\n        enabled: yes\\n```\\n\\n### Modules\\n\\nLes modules sont les unit\xe9s de travail d\'Ansible. Voici quelques modules courants :\\n\\n- **apt/yum/dnf** : gestion des paquets\\n- **copy/template** : transfert et g\xe9n\xe9ration de fichiers\\n- **service** : gestion des services\\n- **user/group** : gestion des utilisateurs et groupes\\n- **git** : interaction avec les d\xe9p\xf4ts Git\\n- **file** : manipulation de fichiers et r\xe9pertoires\\n\\n### R\xf4les\\n\\nLes r\xf4les permettent d\'organiser le code Ansible de mani\xe8re modulaire et r\xe9utilisable :\\n\\n```\\nroles/\\n  common/\\n    tasks/\\n      main.yml\\n    handlers/\\n      main.yml\\n    files/\\n    templates/\\n    vars/\\n      main.yml\\n    defaults/\\n      main.yml\\n    meta/\\n      main.yml\\n```\\n\\n## Cas d\'utilisation courants \ud83d\udee0\ufe0f\\n\\nAnsible excelle dans de nombreux sc\xe9narios :\\n\\n1. **Configuration de serveurs** : installation et configuration coh\xe9rente de services\\n2. **D\xe9ploiement d\'applications** : processus de d\xe9ploiement automatis\xe9s et reproductibles\\n3. **Gestion de la configuration** : maintien de l\'\xe9tat souhait\xe9 des syst\xe8mes\\n4. **Orchestration** : coordination d\'actions complexes sur plusieurs syst\xe8mes\\n5. **Provisionnement cloud** : cr\xe9ation et configuration de ressources cloud\\n\\n## Installation et premiers pas \ud83d\udeb6\u200d\u2642\ufe0f\\n\\nL\'installation d\'Ansible est simple :\\n\\n```bash\\n# Sur Debian/Ubuntu\\nsudo apt update\\nsudo apt install ansible\\n\\n# Sur RHEL/CentOS\\nsudo dnf install ansible\\n\\n# Via pip (recommand\xe9 pour les derni\xe8res versions)\\npip install ansible\\n```\\n\\nUne fois install\xe9, vous pouvez v\xe9rifier votre installation :\\n\\n```bash\\nansible --version\\n```\\n\\nPour un test rapide, cr\xe9ez un fichier d\'inventaire et testez la connectivit\xe9 :\\n\\n```bash\\necho \\"localhost ansible_connection=local\\" > inventory\\nansible -i inventory localhost -m ping\\n```\\n\\n## Ansible vs autres outils IaC \ud83e\udd4a\\n\\n| Caract\xe9ristique | Ansible | Puppet | Chef | Terraform |\\n|----------------|---------|--------|------|-----------|\\n| **Agent requis** | Non | Oui | Oui | Non |\\n| **Langage** | YAML | DSL | Ruby | HCL |\\n| **Courbe d\'apprentissage** | Facile | Moyenne | Difficile | Moyenne |\\n| **Idempotence** | Oui | Oui | Oui | Oui |\\n| **Focus** | Config. management | Config. management | Config. management | Provisionnement |\\n| **Mod\xe8le** | Proc\xe9dural | D\xe9claratif | Proc\xe9dural | D\xe9claratif |\\n\\n## Bonnes pratiques \ud83d\udc4d\\n\\n1. **Utiliser des r\xf4les** pour organiser et r\xe9utiliser le code\\n2. **Versionner** les playbooks et l\'inventaire avec Git\\n3. **\xc9viter les commandes shell** brutes, pr\xe9f\xe9rer les modules natifs\\n4. **Utiliser les variables** pour rendre les playbooks flexibles\\n5. **Tester avec `--check`** avant d\'ex\xe9cuter r\xe9ellement les changements\\n6. **Structurer logiquement l\'inventaire** en groupes et sous-groupes\\n\\n## Conclusion \ud83c\udfaf\\n\\nAnsible est un outil puissant mais accessible qui peut consid\xe9rablement am\xe9liorer l\'efficacit\xe9 des \xe9quipes DevOps et des administrateurs syst\xe8me. Sa simplicit\xe9, son absence d\'agents et sa grande communaut\xe9 en font un choix de pr\xe9dilection pour l\'automatisation d\'infrastructure.\\n\\n## Ressources utiles \ud83d\udcd6\\n\\n- [Documentation officielle Ansible](https://docs.ansible.com/)\\n- [Ansible Galaxy](https://galaxy.ansible.com/) - D\xe9p\xf4t de r\xf4les communautaires\\n- [Red Hat Ansible Automation Platform](https://www.redhat.com/fr/technologies/management/ansible) - Version entreprise"},{"id":"/2025/06/09/08-iac/ansible-zsh-automation","metadata":{"permalink":"/blog/2025/06/09/08-iac/ansible-zsh-automation","source":"@site/blog/08-iac/2025-06-09-ansible-zsh-automation.md","title":"Ansible : cas pratique zsh","description":"D\xe9couvrez comment automatiser et versionner votre environnement shell avec Ansible gr\xe2ce au projet zsh_ansible.","date":"2025-06-09T00:00:00.000Z","tags":[{"inline":false,"label":"Infrastructure as Code","permalink":"/blog/tags/iac"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":6.02,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Ansible : cas pratique zsh","description":"D\xe9couvrez comment automatiser et versionner votre environnement shell avec Ansible gr\xe2ce au projet zsh_ansible.","tags":["iac","devops"]},"unlisted":false,"prevItem":{"title":"Ansible","permalink":"/blog/2025/06/09/08-iac/ansible-introduction"},"nextItem":{"title":"Docker : d\xe9bogage","permalink":"/blog/2025/06/06/03-containerization/debugging-docker-containers"}},"content":"Dans l\'[article pr\xe9c\xe9dent](/blog/2025/06/09/08-iac/ansible-introduction), nous avons d\xe9couvert les bases d\'Ansible et ses avantages pour l\'automatisation d\'infrastructure. Aujourd\'hui, nous allons explorer un cas pratique concret : l\'automatisation de la configuration de votre shell zsh avec le projet [zsh_ansible](https://github.com/sedelpeuch/zsh_ansible). \ud83d\udc1a\\n\\n\x3c!--truncate--\x3e\\n\\n## La probl\xe9matique de la configuration du shell \ud83e\udd14\\n\\nQui n\'a jamais pass\xe9 des heures \xe0 configurer son environnement de travail, installer des plugins, personnaliser son prompt, et d\xe9finir des alias utiles ? Et qui n\'a jamais ressenti de la frustration en changeant de machine et en devant tout recommencer ?\\n\\nLa configuration du shell est un \xe9l\xe9ment essentiel de la productivit\xe9 des d\xe9veloppeurs et administrateurs syst\xe8me. Cependant, cette configuration est souvent :\\n\\n- **Complexe** : installation de zsh, oh-my-zsh, plugins, th\xe8mes...\\n- **Fastidieuse** : \xe9dition manuelle de fichiers de configuration\\n- **Non versionn\xe9e** : risque de perte lors d\'un changement de machine\\n- **Non reproductible** : configuration diff\xe9rente entre machines\\n\\nC\'est l\xe0 qu\'Ansible entre en jeu, permettant d\'automatiser ce processus et de le rendre reproductible.\\n\\n## Pr\xe9sentation du projet zsh_ansible \ud83d\udce6\\n\\n[zsh_ansible](https://github.com/sedelpeuch/zsh_ansible) est un playbook Ansible qui permet d\'installer et de configurer automatiquement :\\n\\n- **zsh** comme shell par d\xe9faut\\n- **oh-my-zsh** pour am\xe9liorer l\'exp\xe9rience utilisateur\\n- Des **plugins** populaires comme zsh-autosuggestions et zsh-syntax-highlighting\\n- Une **configuration personnalis\xe9e** via un fichier .zshrc param\xe9trable\\n\\nCe projet suit les bonnes pratiques Ansible et permet de d\xe9ployer rapidement un environnement zsh coh\xe9rent sur n\'importe quelle machine Linux.\\n\\n## Structure du projet \ud83c\udfd7\ufe0f\\n\\nLe projet est organis\xe9 de mani\xe8re modulaire avec plusieurs playbooks sp\xe9cifiques :\\n\\n```\\nzsh_ansible/\\n\u251c\u2500\u2500 README.md                # Documentation du projet\\n\u251c\u2500\u2500 main.yml                 # Playbook principal qui importe les autres playbooks\\n\u251c\u2500\u2500 install_zsh.yml          # Playbook pour l\'installation de zsh\\n\u251c\u2500\u2500 install_oh_my_zsh.yml    # Playbook pour l\'installation d\'oh-my-zsh et ses plugins\\n\u2514\u2500\u2500 install_starship.yml     # Playbook pour l\'installation de Starship prompt\\n```\\n\\nCette approche modulaire permet d\'ex\xe9cuter individuellement chaque composant ou l\'ensemble du processus via le playbook principal.\\n\\n## Fonctionnalit\xe9s principales \u2728\\n\\nLe projet zsh_ansible offre plusieurs fonctionnalit\xe9s r\xe9parties dans ses diff\xe9rents playbooks :\\n\\n1. **Installation de zsh** avec `install_zsh.yml`\\n   - Installation du package zsh\\n   - R\xe9cup\xe9ration d\'une configuration .zshrc personnalis\xe9e depuis un gist GitHub\\n\\n2. **Installation d\'oh-my-zsh** avec `install_oh_my_zsh.yml`\\n   - Installation des pr\xe9requis (git)\\n   - Installation d\'oh-my-zsh\\n   - Installation de plugins populaires :\\n     - zsh-autosuggestions\\n     - zsh-syntax-highlighting\\n     - zsh-completions\\n     - zsh-history-substring-search\\n     - fast-syntax-highlighting\\n     - zsh-bat\\n     - autoupdate\\n     - autojump\\n\\n3. **Installation de Starship prompt** avec `install_starship.yml`\\n   - Installation des pr\xe9requis (curl)\\n   - Installation de Starship (prompteur cross-shell moderne)\\n   - R\xe9cup\xe9ration d\'une configuration Starship personnalis\xe9e depuis un gist GitHub\\n\\n## Utilisation pas \xe0 pas \ud83d\udc63\\n\\n### 1. Cloner le d\xe9p\xf4t\\n\\n```bash\\ngit clone https://github.com/sedelpeuch/zsh_ansible.git\\ncd zsh_ansible\\n```\\n\\n### 2. Ex\xe9cution locale\\n\\nPour ex\xe9cuter le playbook en local, la fa\xe7on la plus simple est d\'ex\xe9cuter :\\n\\n```bash\\nansible-playbook main.yml -c local\\n```\\n\\nCela lancera l\'installation de tous les composants sur votre machine locale sans avoir besoin de configurer un inventaire.\\n\\n### 3. Test dans un environnement Docker (optionnel)\\n\\nUne des forces du projet est la possibilit\xe9 de le tester facilement dans un conteneur Docker :\\n\\n```bash\\n# T\xe9l\xe9charger une image Docker avec Ansible pr\xe9install\xe9\\ndocker pull williamyeh/ansible:ubuntu18.04\\n\\n# Ex\xe9cuter le playbook dans un conteneur Docker\\ndocker run --rm -it -v $(pwd):/ansible/playbooks williamyeh/ansible:ubuntu18.04 \\\\\\n  ansible-playbook /ansible/playbooks/main.yml -c local\\n\\n# Pour examiner le r\xe9sultat (garde le conteneur en vie)\\ndocker run --rm -it -v $(pwd):/ansible/playbooks williamyeh/ansible:ubuntu18.04 \\\\\\n  /bin/bash -c \\"ansible-playbook /ansible/playbooks/main.yml -c local && exec /bin/bash\\"\\n```\\n\\nCette approche vous permet de tester la configuration sans affecter votre environnement actuel.\\n\\n### 4. Ex\xe9cution des playbooks sp\xe9cifiques\\n\\nSi vous souhaitez n\'installer que certains composants, vous pouvez ex\xe9cuter les playbooks individuellement :\\n\\n```bash\\n# Installation de zsh uniquement\\nansible-playbook install_zsh.yml -c local\\n\\n# Installation d\'oh-my-zsh et ses plugins\\nansible-playbook install_oh_my_zsh.yml -c local\\n\\n# Installation de Starship prompt\\nansible-playbook install_starship.yml -c local\\n```\\n\\nSi vous avez besoin de privil\xe8ges d\'administration :\\n\\n```bash\\nansible-playbook main.yml -c local --ask-become-pass\\n```\\n\\n### 5. Profiter de votre nouveau shell\\n\\nApr\xe8s l\'ex\xe9cution du playbook, red\xe9marrez votre terminal ou ex\xe9cutez :\\n\\n```bash\\nzsh\\n```\\n\\nVous devriez maintenant avoir un shell zsh enti\xe8rement configur\xe9 avec :\\n\\n- Une configuration .zshrc r\xe9cup\xe9r\xe9e depuis un gist personnalis\xe9\\n- Oh-my-zsh avec de nombreux plugins utiles\\n- Le prompteur Starship pour une exp\xe9rience visuelle am\xe9lior\xe9e\\n\\n## Code source d\xe9taill\xe9 \ud83d\udd0d\\n\\nExaminons quelques parties cl\xe9s du code du projet.\\n\\n### Playbook principal (main.yml)\\n\\n```yaml\\n- import_playbook: install_zsh.yml\\n- import_playbook: install_oh_my_zsh.yml\\n- import_playbook: install_starship.yml\\n```\\n\\nCe playbook principal importe simplement les trois autres playbooks sp\xe9cifiques.\\n\\n### Installation de zsh (install_zsh.yml)\\n\\n```yaml\\n- name: Ensure zsh is installed\\n  hosts: all\\n  become: yes\\n  tasks:\\n    - name: Ensure zsh is installed\\n      apt:\\n        name: zsh\\n        state: present\\n\\n- name: Configure zsh for user\\n  hosts: all\\n  tasks:\\n    - name: Fetch .zshrc from secret gist\\n      uri:\\n        url: \\"https://gist.githubusercontent.com/sedelpeuch/a595fc7352f803c089534b00cba9e2e7/raw\\"\\n        return_content: yes\\n      register: zshrc_content\\n\\n    - name: Place .zshrc in home directory\\n      copy:\\n        content: \\"{{ zshrc_content.content }}\\"\\n        dest: ~/.zshrc\\n```\\n\\n### Installation des plugins oh-my-zsh (extrait de install_oh_my_zsh.yml)\\n\\n```yaml\\n- name: Ensure oh-my-zsh is installed\\n  hosts: all\\n  become: no\\n  tasks:\\n    - name: Ensure git is installed\\n      become: yes\\n      apt:\\n        name: git\\n        state: present\\n\\n    - name: Check if oh-my-zsh is installed\\n      stat:\\n        path: ~/.oh-my-zsh\\n      register: oh_my_zsh_installed\\n\\n    - name: Download oh-my-zsh installer\\n      get_url:\\n        url: https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh\\n        dest: /tmp/install_oh_my_zsh.sh\\n        mode: \'0755\'\\n      when: not oh_my_zsh_installed.stat.exists\\n\\n    - name: Install oh-my-zsh\\n      shell: /tmp/install_oh_my_zsh.sh --unattended\\n      when: not oh_my_zsh_installed.stat.exists\\n\\n    # Installation de divers plugins\\n    - name: Clone zsh-autosuggestions\\n      git:\\n        repo: https://github.com/zsh-users/zsh-autosuggestions\\n        dest: ~/.oh-my-zsh/custom/plugins/zsh-autosuggestions\\n      when: not zsh_autosuggestions_installed.stat.exists\\n\\n    # Autres plugins...\\n```\\n\\n## Extensibilit\xe9 du projet \ud83d\udd0c\\n\\nVous pouvez facilement \xe9tendre ce projet pour r\xe9pondre \xe0 vos besoins sp\xe9cifiques :\\n\\n1. **Personnalisation des fichiers de configuration**\\n   - Cr\xe9ez vos propres gists GitHub avec vos configurations .zshrc et starship.toml\\n   - Modifiez les URLs dans les playbooks pour pointer vers vos gists\\n\\n2. **Ajout de plugins suppl\xe9mentaires**\\n   - Ajoutez de nouveaux plugins oh-my-zsh en suivant le mod\xe8le des plugins existants\\n   - Installez d\'autres utilitaires en ajoutant des t\xe2ches aux playbooks\\n\\n3. **Support d\'autres distributions**\\n   - Adaptez les commandes d\'installation des packages pour d\'autres distributions Linux\\n   - Ajoutez la d\xe9tection du gestionnaire de paquets pour plus de flexibilit\xe9\\n\\n4. **Int\xe9gration avec d\'autres outils de d\xe9veloppement**\\n   - Ajoutez l\'installation et la configuration d\'outils compl\xe9mentaires (tmux, neovim, etc.)\\n\\n## Bonnes pratiques et conseils \ud83d\udca1\\n\\n1. **Testez vos changements dans Docker** avant de les appliquer sur votre environnement principal\\n2. **Stockez vos configurations sensibles** dans des gists priv\xe9s ou un gestionnaire de secrets\\n3. **Cr\xe9ez un fork** du projet pour l\'adapter \xe0 vos besoins sp\xe9cifiques\\n4. **Maintenez votre propre d\xe9p\xf4t** pour suivre l\'\xe9volution de vos configurations shell\\n5. **Documentez vos personnalisations** pour faciliter la collaboration et le partage\\n\\n## Avantages de cette approche \ud83d\ude80\\n\\nL\'utilisation d\'Ansible pour configurer votre environnement zsh offre plusieurs avantages :\\n\\n- **Reproductibilit\xe9** : m\xeame environnement sur toutes vos machines\\n- **Versionnement** : suivre l\'\xe9volution de votre configuration\\n- **Partage** : faciliter l\'onboarding de nouveaux membres d\'\xe9quipe\\n- **Maintien** : mise \xe0 jour facile de la configuration\\n- **Documentation** : le code Ansible documente votre setup\\n\\n## Conclusion \ud83c\udfaf\\n\\nLe projet zsh_ansible d\xe9montre parfaitement comment Ansible peut \xeatre utilis\xe9 au-del\xe0 de la configuration de serveurs, pour automatiser m\xeame vos environnements de d\xe9veloppement. Cette approche \\"infrastructure as code\\" appliqu\xe9e \xe0 votre environnement de travail personnel vous fait gagner un temps pr\xe9cieux et assure une coh\xe9rence entre vos diff\xe9rentes machines.\\n\\nN\'h\xe9sitez pas \xe0 explorer le [d\xe9p\xf4t GitHub du projet](https://github.com/sedelpeuch/zsh_ansible), \xe0 le forker et \xe0 l\'adapter \xe0 vos besoins sp\xe9cifiques. Et surtout, partagez vos am\xe9liorations avec la communaut\xe9 !\\n\\nVous utilisez d\xe9j\xe0 Ansible pour d\'autres automatisations personnelles ? Partagez vos exp\xe9riences dans les commentaires !"},{"id":"/2025/06/06/03-containerization/debugging-docker-containers","metadata":{"permalink":"/blog/2025/06/06/03-containerization/debugging-docker-containers","source":"@site/blog/03-containerization/2025-06-06-debugging-docker-containers.md","title":"Docker : d\xe9bogage","description":"Guide pour d\xe9boguer les conteneurs Docker en utilisant des commandes de base et des options avanc\xe9es.","date":"2025-06-06T00:00:00.000Z","tags":[{"inline":false,"label":"Conteneurisation","permalink":"/blog/tags/containerization"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":2.28,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Docker : d\xe9bogage","description":"Guide pour d\xe9boguer les conteneurs Docker en utilisant des commandes de base et des options avanc\xe9es.","tags":["containerization","devops"]},"unlisted":false,"prevItem":{"title":"Ansible : cas pratique zsh","permalink":"/blog/2025/06/09/08-iac/ansible-zsh-automation"},"nextItem":{"title":"Kubernetes : certificats","permalink":"/blog/2025/06/06/06-orchestration/renouveller-certificats"}},"content":"Le d\xe9bogage des conteneurs Docker est une comp\xe9tence essentielle pour tout d\xe9veloppeur ou administrateur syst\xe8me travaillant avec des environnements conteneuris\xe9s. Docker offre une vari\xe9t\xe9 de commandes et d\'options pour aider \xe0 identifier et r\xe9soudre les probl\xe8mes qui peuvent survenir dans les conteneurs. Dans cet article, nous allons explorer certaines des commandes de base et des techniques avanc\xe9es pour d\xe9boguer les conteneurs Docker.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Commandes de base pour le d\xe9bogage\\n\\n### docker ps\\n\\nLa commande `docker ps` est utilis\xe9e pour lister les conteneurs en cours d\'ex\xe9cution. Vous pouvez utiliser l\'option `-a` pour afficher tous les conteneurs, qu\'ils soient en cours d\'ex\xe9cution ou arr\xeat\xe9s.\\n\\n```bash\\ndocker ps\\ndocker ps -a\\n```\\n\\n### docker logs\\n\\nLa commande `docker logs` permet de visualiser les journaux d\'un conteneur. Cela peut \xeatre tr\xe8s utile pour identifier les erreurs ou les comportements inattendus.\\n\\n```bash\\ndocker logs <container_id>\\n```\\n\\nVous pouvez \xe9galement utiliser le nom du conteneur \xe0 la place de l\'ID.\\n\\n### docker exec\\n\\nLa commande `docker exec` permet d\'ex\xe9cuter des commandes \xe0 l\'int\xe9rieur d\'un conteneur en cours d\'ex\xe9cution. Cela peut \xeatre utile pour naviguer dans le syst\xe8me de fichiers du conteneur, v\xe9rifier les configurations ou ex\xe9cuter des scripts de diagnostic.\\n\\n```bash\\ndocker exec -it <container_id> /bin/bash\\n```\\n\\n### docker inspect\\n\\nLa commande `docker inspect` fournit des informations d\xe9taill\xe9es sur un conteneur ou une image Docker. Cela inclut des d\xe9tails sur la configuration, les r\xe9seaux, les volumes et plus encore.\\n\\n```bash\\ndocker inspect <container_id>\\n```\\n\\n## Techniques avanc\xe9es de d\xe9bogage\\n\\n### Utilisation de docker run avec des options\\n\\nLa commande `docker run` peut \xeatre utilis\xe9e avec diverses options pour faciliter le d\xe9bogage. Par exemple, l\'option `-d` permet de d\xe9marrer un conteneur en mode d\xe9tach\xe9, tandis que l\'option `-p` permet de mapper les ports entre l\'h\xf4te et le conteneur.\\n\\n```bash\\ndocker run -d -p 8080:80 <image_name>\\n```\\n\\n### Red\xe9marrage des conteneurs\\n\\nLes commandes `docker start` et `docker stop` permettent de red\xe9marrer les conteneurs. Cela peut \xeatre utile si vous avez apport\xe9 des modifications \xe0 la configuration du conteneur et que vous souhaitez les appliquer.\\n\\n```bash\\ndocker stop <container_id>\\ndocker start <container_id>\\n```\\n\\n### Nommage des conteneurs\\n\\nLorsque vous cr\xe9ez un conteneur, vous pouvez lui attribuer un nom pour faciliter son identification. Cela peut \xeatre fait en utilisant l\'option `--name` avec la commande `docker run`.\\n\\n```bash\\ndocker run --name my_container <image_name>\\n```\\n\\n## Conclusion\\n\\nLe d\xe9bogage des conteneurs Docker peut sembler complexe au d\xe9but, mais en utilisant les commandes et techniques appropri\xe9es, vous pouvez rapidement identifier et r\xe9soudre les probl\xe8mes. Les commandes de base comme `docker ps`, `docker logs`, `docker exec` et `docker inspect` sont essentielles pour tout d\xe9veloppeur ou administrateur syst\xe8me travaillant avec Docker. En combinant ces commandes avec des techniques avanc\xe9es comme l\'utilisation de `docker run` avec des options et le red\xe9marrage des conteneurs, vous pouvez am\xe9liorer consid\xe9rablement votre efficacit\xe9 dans le d\xe9bogage des conteneurs Docker."},{"id":"/2025/06/06/06-orchestration/renouveller-certificats","metadata":{"permalink":"/blog/2025/06/06/06-orchestration/renouveller-certificats","source":"@site/blog/06-orchestration/2025-06-06-renouveller-certificats.md","title":"Kubernetes : certificats","description":"Guide pratique pour renouveler les certificats expirants dans un cluster Kubernetes d\xe9ploy\xe9 avec kubeadm.","date":"2025-06-06T00:00:00.000Z","tags":[{"inline":false,"label":"Orchestration","permalink":"/blog/tags/orchestration"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":4.71,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Kubernetes : certificats","description":"Guide pratique pour renouveler les certificats expirants dans un cluster Kubernetes d\xe9ploy\xe9 avec kubeadm.","tags":["orchestration","devops"]},"unlisted":false,"prevItem":{"title":"Docker : d\xe9bogage","permalink":"/blog/2025/06/06/03-containerization/debugging-docker-containers"},"nextItem":{"title":"Python : Poetry","permalink":"/blog/2025/06/06/09-scripting/poetry-python-dependency"}},"content":"Les certificats jouent un r\xf4le crucial dans la s\xe9curit\xe9 de Kubernetes. Ils assurent l\'authentification et le chiffrement des communications entre les diff\xe9rents composants du cluster. Cependant, ces certificats ont une dur\xe9e de vie limit\xe9e et doivent \xeatre renouvel\xe9s avant leur expiration pour maintenir le bon fonctionnement du cluster. \ud83d\udd10\\n\\n\x3c!--truncate--\x3e\\n\\n## La probl\xe9matique des certificats expirants \ud83d\udcc5\\n\\nPar d\xe9faut, les certificats g\xe9n\xe9r\xe9s par kubeadm ont une dur\xe9e de validit\xe9 d\'un an. Lorsqu\'ils expirent, les composants du cluster ne peuvent plus communiquer entre eux de mani\xe8re s\xe9curis\xe9e, ce qui peut entra\xeener une panne compl\xe8te du cluster.\\n\\nLes sympt\xf4mes typiques d\'un certificat expir\xe9 incluent :\\n\\n- Impossibilit\xe9 d\'utiliser `kubectl`\\n- Les nouveaux pods ne sont plus programm\xe9s\\n- Messages d\'erreur du type `x509: certificate has expired or is not yet valid`\\n\\n## V\xe9rification des dates d\'expiration \u23f1\ufe0f\\n\\nAvant de proc\xe9der au renouvellement, il est important de v\xe9rifier la date d\'expiration des certificats actuels. Pour cela, vous pouvez utiliser la commande suivante :\\n\\n```bash\\nkubeadm certs check-expiration\\n```\\n\\nCette commande affiche une liste de tous les certificats avec leurs dates d\'expiration respectives :\\n\\n```text\\nCERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED\\nadmin.conf                 Jun 05, 2026 12:51 UTC   364d            ca                      no\\napiserver                  Jun 05, 2026 12:51 UTC   364d            ca                      no\\napiserver-kubelet-client   Jun 05, 2026 12:51 UTC   364d            ca                      no\\ncontroller-manager.conf    Jun 05, 2026 12:51 UTC   364d            ca                      no\\nkubelet.conf              Jun 05, 2026 12:51 UTC   364d            ca                      no\\nscheduler.conf             Jun 05, 2026 12:51 UTC   364d            ca                      no\\n...\\n```\\n\\n## Processus de renouvellement des certificats \ud83d\udd04\\n\\n### 1. Renouvellement de tous les certificats\\n\\nLa m\xe9thode la plus simple consiste \xe0 renouveler tous les certificats \xe0 la fois :\\n\\n```bash\\nsudo kubeadm certs renew all\\n```\\n\\nCette commande renouvelle tous les certificats g\xe9r\xe9s par kubeadm et les stocke dans le r\xe9pertoire `/etc/kubernetes/pki`.\\n\\n### 2. Renouvellement des certificats sp\xe9cifiques\\n\\nSi vous pr\xe9f\xe9rez renouveler les certificats un par un, vous pouvez sp\xe9cifier le certificat \xe0 renouveler :\\n\\n```bash\\nsudo kubeadm certs renew apiserver\\nsudo kubeadm certs renew apiserver-kubelet-client\\nsudo kubeadm certs renew front-proxy-client\\n# etc.\\n```\\n\\n### 3. Mise \xe0 jour des fichiers kubeconfig\\n\\nApr\xe8s avoir renouvel\xe9 les certificats, il est n\xe9cessaire de mettre \xe0 jour les fichiers kubeconfig :\\n\\n```bash\\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\\n```\\n\\n## Red\xe9marrage des composants \ud83d\udd04\\n\\nPour que les nouveaux certificats soient pris en compte, il faut red\xe9marrer les composants du plan de contr\xf4le :\\n\\n```bash\\nsudo systemctl restart kubelet\\n```\\n\\nSur un cluster multi-n\u0153uds, vous devez \xe9galement red\xe9marrer le kubelet sur chaque n\u0153ud worker :\\n\\n```bash\\n# Sur chaque n\u0153ud worker\\nsudo systemctl restart kubelet\\n```\\n\\n### Forcer le red\xe9marrage en cas de probl\xe8me \u26a0\ufe0f\\n\\nDans certains cas, un simple red\xe9marrage du kubelet peut ne pas suffire pour que les nouveaux certificats soient pris en compte. Si vous rencontrez toujours des probl\xe8mes apr\xe8s le red\xe9marrage normal, deux m\xe9thodes plus radicales peuvent \xeatre utilis\xe9es :\\n\\n**M\xe9thode 1 : Manipulation des manifests statiques**\\n\\n```bash\\n# Sauvegarde et renommage temporaire des manifests\\ncd /etc/kubernetes/manifests\\nsudo mkdir -p /root/manifests_backup\\nsudo cp *.yaml /root/manifests_backup/\\nsudo mv *.yaml /tmp/\\n\\n# Attendre que le cluster s\'arr\xeate (les pods du plan de contr\xf4le dispara\xeetront)\\n# Puis restaurer les manifests pour red\xe9marrer les composants\\nsudo mv /tmp/*.yaml .\\n```\\n\\nCette m\xe9thode force kubelet \xe0 supprimer puis recr\xe9er tous les pods du plan de contr\xf4le, garantissant ainsi l\'utilisation des nouveaux certificats.\\n\\n**M\xe9thode 2 : Suppression manuelle des pods**\\n\\nSi vous avez encore acc\xe8s \xe0 l\'API Kubernetes, vous pouvez supprimer manuellement les pods du plan de contr\xf4le :\\n\\n```bash\\n# Attention : commande \xe0 utiliser avec pr\xe9caution\\nkubectl -n kube-system delete pod -l component=kube-apiserver\\nkubectl -n kube-system delete pod -l component=kube-controller-manager\\nkubectl -n kube-system delete pod -l component=kube-scheduler\\nkubectl -n kube-system delete pod -l k8s-app=kube-proxy\\n```\\n\\n> \u26a0\ufe0f **Attention** : Ces m\xe9thodes provoquent une interruption temporaire du service. Planifiez-les pendant une fen\xeatre de maintenance.\\n\\n## Automatisation du renouvellement \ud83e\udd16\\n\\nPour \xe9viter de devoir g\xe9rer manuellement le renouvellement des certificats, vous pouvez mettre en place une t\xe2che cron qui v\xe9rifie et renouvelle automatiquement les certificats :\\n\\n```bash\\n# Cr\xe9er un script de renouvellement des certificats\\ncat > /usr/local/bin/renew-k8s-certs.sh << \'EOF\'\\n#!/bin/bash\\n# V\xe9rifier si des certificats expirent dans moins de 30 jours\\nEXPIRING_CERTS=$(kubeadm certs check-expiration | grep -B 1 \\"< 30d\\" | grep -v \\"RESIDUAL\\" | awk \'{print $1}\')\\n\\nif [ ! -z \\"$EXPIRING_CERTS\\" ]; then\\n    echo \\"Renouvellement des certificats qui expirent bient\xf4t...\\"\\n    sudo kubeadm certs renew all\\n    sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\\n    sudo chown $(id -u):$(id -g) $HOME/.kube/config\\n    sudo systemctl restart kubelet\\n    echo \\"Certificats renouvel\xe9s avec succ\xe8s !\\"\\nelse\\n    echo \\"Aucun certificat n\'expire dans moins de 30 jours.\\"\\nfi\\nEOF\\n\\nchmod +x /usr/local/bin/renew-k8s-certs.sh\\n\\n# Ajouter une t\xe2che cron pour ex\xe9cuter le script une fois par mois\\n(crontab -l 2>/dev/null; echo \\"0 0 1 * * /usr/local/bin/renew-k8s-certs.sh >> /var/log/renew-k8s-certs.log 2>&1\\") | crontab -\\n```\\n\\n## Bonnes pratiques \ud83d\udee1\ufe0f\\n\\n1. **Planification pr\xe9ventive** : Renouvelez vos certificats au moins un mois avant leur expiration pour \xe9viter toute interruption de service.\\n\\n2. **Sauvegarde** : Avant de proc\xe9der au renouvellement, effectuez une sauvegarde du r\xe9pertoire `/etc/kubernetes/pki`.\\n\\n3. **Documentation** : Documentez clairement les dates de renouvellement et mettez en place des alertes pour \xeatre notifi\xe9 avant l\'expiration.\\n\\n4. **Test** : Testez le processus de renouvellement dans un environnement de d\xe9veloppement avant de l\'appliquer en production.\\n\\n## Conclusion \ud83c\udfaf\\n\\nLe renouvellement des certificats est une t\xe2che de maintenance critique pour garantir la s\xe9curit\xe9 et la disponibilit\xe9 de votre cluster Kubernetes. En suivant ce guide, vous pouvez facilement renouveler vos certificats et \xe9viter les probl\xe8mes li\xe9s \xe0 leur expiration.\\n\\nN\'oubliez pas que la s\xe9curit\xe9 est un processus continu, et la gestion proactive des certificats fait partie int\xe9grante de la maintenance d\'un cluster Kubernetes robuste et s\xe9curis\xe9."},{"id":"/2025/06/06/09-scripting/poetry-python-dependency","metadata":{"permalink":"/blog/2025/06/06/09-scripting/poetry-python-dependency","source":"@site/blog/09-scripting/2025-06-06-poetry-python-dependency.md","title":"Python : Poetry","description":"Un guide complet sur Poetry, l\'outil moderne de gestion de d\xe9pendances et de packaging pour Python.","date":"2025-06-06T00:00:00.000Z","tags":[{"inline":false,"label":"Scripting","permalink":"/blog/tags/scripting"}],"readingTime":3.87,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Python : Poetry","description":"Un guide complet sur Poetry, l\'outil moderne de gestion de d\xe9pendances et de packaging pour Python.","tags":["scripting"]},"unlisted":false,"prevItem":{"title":"Kubernetes : certificats","permalink":"/blog/2025/06/06/06-orchestration/renouveller-certificats"},"nextItem":{"title":"Python : Pydantic","permalink":"/blog/2025/06/06/09-scripting/pydantic-validation-donnees"}},"content":"Poetry est devenu un outil essentiel dans l\'\xe9cosyst\xe8me Python pour g\xe9rer les d\xe9pendances et le packaging de projets. Dans cet article, nous explorerons comment Poetry simplifie la gestion des d\xe9pendances Python, offrant une alternative \xe9l\xe9gante et robuste \xe0 pip et virtualenv. \ud83d\udc0d\\n\\n\x3c!--truncate--\x3e\\n\\n## Pourquoi utiliser Poetry ? \ud83e\udd14\\n\\nAvant de plonger dans les d\xe9tails techniques, voyons pourquoi vous devriez envisager d\'utiliser Poetry pour vos projets Python:\\n\\n1. **Gestion simplifi\xe9e des d\xe9pendances**: Poetry g\xe8re automatiquement les d\xe9pendances et leurs versions compatibles\\n2. **Environnements virtuels int\xe9gr\xe9s**: Cr\xe9ation et gestion des environnements virtuels sans configuration suppl\xe9mentaire\\n3. **R\xe9solution d\xe9terministe des d\xe9pendances**: Lock file garantissant la reproductibilit\xe9 des installations\\n4. **Publication facilit\xe9e**: D\xe9ploiement simplifi\xe9 de packages sur PyPI\\n5. **Interface utilisateur intuitive**: Commandes claires et feedback utile\\n\\n## Installation de Poetry \ud83d\ude80\\n\\nL\'installation de Poetry est simple et directe:\\n\\n```bash\\n# M\xe9thode recommand\xe9e (installation isol\xe9e)\\ncurl -sSL https://install.python-poetry.org | python3 -\\n\\n# V\xe9rifier l\'installation\\npoetry --version\\n```\\n\\nPour les utilisateurs de macOS ou Linux, ajoutez Poetry \xe0 votre PATH:\\n\\n```bash\\n# Ajouter \xe0 votre .zshrc ou .bashrc\\nexport PATH=\\"$HOME/.local/bin:$PATH\\"\\n```\\n\\n## Cr\xe9ation d\'un nouveau projet \ud83d\udcc1\\n\\nPour cr\xe9er un nouveau projet avec Poetry:\\n\\n```bash\\n# Cr\xe9er un nouveau projet\\npoetry new mon-super-projet\\n\\n# Structure g\xe9n\xe9r\xe9e\\nmon-super-projet/\\n\u251c\u2500\u2500 pyproject.toml\\n\u251c\u2500\u2500 README.md\\n\u251c\u2500\u2500 mon_super_projet/\\n\u2502   \u2514\u2500\u2500 __init__.py\\n\u2514\u2500\u2500 tests/\\n    \u2514\u2500\u2500 __init__.py\\n```\\n\\nLe fichier `pyproject.toml` est le c\u0153ur de votre projet, contenant toutes les m\xe9tadonn\xe9es et d\xe9pendances:\\n\\n```toml\\n[tool.poetry]\\nname = \\"mon-super-projet\\"\\nversion = \\"0.1.0\\"\\ndescription = \\"\\"\\nauthors = [\\"Votre Nom <votre.email@example.com>\\"]\\nreadme = \\"README.md\\"\\n\\n[tool.poetry.dependencies]\\npython = \\"^3.10\\"\\n\\n[tool.poetry.dev-dependencies]\\npytest = \\"^7.3.1\\"\\n\\n[build-system]\\nrequires = [\\"poetry-core>=1.0.0\\"]\\nbuild-backend = \\"poetry.core.masonry.api\\"\\n```\\n\\n## Gestion des d\xe9pendances \ud83d\udce6\\n\\n### Ajouter des d\xe9pendances\\n\\n```bash\\n# Ajouter une d\xe9pendance\\npoetry add requests\\n\\n# Ajouter une d\xe9pendance avec une contrainte de version sp\xe9cifique\\npoetry add \\"requests>=2.25.0,<3.0.0\\"\\n\\n# Ajouter une d\xe9pendance de d\xe9veloppement\\npoetry add pytest --group dev\\n```\\n\\n### Le fichier poetry.lock\\n\\nLorsque vous ajoutez des d\xe9pendances, Poetry cr\xe9e un fichier `poetry.lock` qui verrouille les versions exactes. Ce fichier assure que tous les environnements utiliseront exactement les m\xeames versions des packages.\\n\\n```bash\\n# Installer les d\xe9pendances depuis le lock file\\npoetry install\\n```\\n\\n## Utilisation quotidienne \ud83d\udcbb\\n\\n### Ex\xe9cuter des commandes dans l\'environnement virtuel\\n\\n```bash\\n# Ex\xe9cuter un script Python\\npoetry run python mon_script.py\\n\\n# Ex\xe9cuter une commande install\xe9e\\npoetry run pytest\\n\\n# Ouvrir un shell dans l\'environnement virtuel\\npoetry shell\\n```\\n\\n### Mise \xe0 jour des d\xe9pendances\\n\\n```bash\\n# Afficher les d\xe9pendances qui peuvent \xeatre mises \xe0 jour\\npoetry show --outdated\\n\\n# Mettre \xe0 jour toutes les d\xe9pendances\\npoetry update\\n\\n# Mettre \xe0 jour une d\xe9pendance sp\xe9cifique\\npoetry update requests\\n```\\n\\n## Configuration avanc\xe9e \ud83d\udd27\\n\\n### Gestion de plusieurs environnements Python\\n\\nPoetry permet de travailler facilement avec diff\xe9rentes versions de Python:\\n\\n```bash\\n# Sp\xe9cifier une version Python pour le projet\\npoetry env use python3.9\\n\\n# Lister les environnements virtuels associ\xe9s au projet\\npoetry env list\\n\\n# Supprimer un environnement virtuel\\npoetry env remove python3.8\\n```\\n\\n### Configuration des sources de packages\\n\\nVous pouvez configurer des sources de packages personnalis\xe9es:\\n\\n```bash\\n# Ajouter un repository priv\xe9\\npoetry source add mon-repo https://mon-repo-prive.com/simple/\\n\\n# Installer depuis un repository sp\xe9cifique\\npoetry add mon-package --source mon-repo\\n```\\n\\n## Workflows CI/CD avec Poetry \ud83d\udd04\\n\\nPoetry s\'int\xe8gre parfaitement dans les pipelines d\'int\xe9gration continue. Voici un exemple avec GitHub Actions:\\n\\n```yaml\\nname: Tests Python\\n\\non: [push, pull_request]\\n\\njobs:\\n  test:\\n    runs-on: ubuntu-latest\\n    steps:\\n      - uses: actions/checkout@v3\\n      - name: Set up Python\\n        uses: actions/setup-python@v4\\n        with:\\n          python-version: \'3.11\'\\n      - name: Install Poetry\\n        uses: snok/install-poetry@v1\\n        with:\\n          version: 1.6.1\\n      - name: Install dependencies\\n        run: poetry install\\n      - name: Run tests\\n        run: poetry run pytest\\n```\\n\\n## Publication de votre package \ud83d\udea2\\n\\nPoetry facilite \xe9norm\xe9ment la publication de packages sur PyPI:\\n\\n```bash\\n# Construire le package\\npoetry build\\n\\n# Publier sur PyPI\\npoetry publish\\n\\n# Construire et publier en une seule commande\\npoetry publish --build\\n```\\n\\nPour publier sur un index priv\xe9:\\n\\n```bash\\npoetry publish --repository mon-repo\\n```\\n\\n## Comparaison avec d\'autres outils \ud83d\udd0d\\n\\n| Fonctionnalit\xe9 | Poetry | pip + venv | pipenv |\\n|----------------|--------|------------|--------|\\n| Gestion des d\xe9pendances | \u2705 | \u26a0\ufe0f (manuel) | \u2705 |\\n| Lock file | \u2705 | \u274c | \u2705 |\\n| Environnements virtuels | \u2705 | \u2705 (s\xe9par\xe9) | \u2705 |\\n| Publication de package | \u2705 | \u274c (besoin de setuptools) | \u274c |\\n| R\xe9solution des d\xe9pendances | \u2705 (rapide) | \u274c | \u2705 (lent) |\\n| Innovation active | \u2705 | \u2705 | \u26a0\ufe0f |\\n\\n## Bonnes pratiques avec Poetry \ud83d\udc4d\\n\\n1. **Toujours commiter le fichier `poetry.lock`**: Il garantit la reproductibilit\xe9 des installations\\n2. **S\xe9parer clairement d\xe9pendances de production et de d\xe9veloppement**\\n3. **D\xe9finir des contraintes de version pr\xe9cises** pour les biblioth\xe8ques critiques\\n4. **Utiliser `poetry export`** pour g\xe9n\xe9rer un `requirements.txt` quand n\xe9cessaire:\\n\\n   ```bash\\n   poetry export -f requirements.txt --output requirements.txt\\n   ```\\n\\n5. **Mettre \xe0 jour r\xe9guli\xe8rement** vos d\xe9pendances pour des raisons de s\xe9curit\xe9\\n\\n## Conclusion \ud83c\udfaf\\n\\nPoetry a transform\xe9 la fa\xe7on dont les d\xe9veloppeurs Python g\xe8rent leurs projets en offrant une solution tout-en-un pour la gestion des d\xe9pendances, les environnements virtuels et le packaging. Son approche d\xe9clarative et sa simplicit\xe9 d\'utilisation en font un outil incontournable pour tout projet Python moderne.\\n\\nAu-del\xe0 d\'\xeatre un simple gestionnaire de d\xe9pendances, Poetry repr\xe9sente une \xe9volution significative dans l\'\xe9cosyst\xe8me Python, rendant le d\xe9veloppement plus reproductible, plus fiable et plus agr\xe9able."},{"id":"/2025/06/06/09-scripting/pydantic-validation-donnees","metadata":{"permalink":"/blog/2025/06/06/09-scripting/pydantic-validation-donnees","source":"@site/blog/09-scripting/2025-06-06-pydantic-validation-donnees.md","title":"Python : Pydantic","description":"Comment utiliser Pydantic pour valider, s\xe9rialiser et documenter vos mod\xe8les de donn\xe9es en Python.","date":"2025-06-06T00:00:00.000Z","tags":[{"inline":false,"label":"Scripting","permalink":"/blog/tags/scripting"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":6.68,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Python : Pydantic","description":"Comment utiliser Pydantic pour valider, s\xe9rialiser et documenter vos mod\xe8les de donn\xe9es en Python.","tags":["scripting","devops"]},"unlisted":false,"prevItem":{"title":"Python : Poetry","permalink":"/blog/2025/06/06/09-scripting/poetry-python-dependency"},"nextItem":{"title":"Proxy : Nginx Proxy Manager","permalink":"/blog/2025/01/13/02-network/nginx-proxy-manager"}},"content":"Dans un monde o\xf9 les APIs et les microservices se multiplient, la validation des donn\xe9es est devenue une pr\xe9occupation majeure. Pydantic s\'impose comme la solution de r\xe9f\xe9rence en Python pour d\xe9finir et valider des structures de donn\xe9es. D\xe9couvrons ensemble cette biblioth\xe8que puissante qui r\xe9volutionne la fa\xe7on dont nous manipulons les donn\xe9es. \ud83d\udd0d\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que Pydantic? \ud83e\udd14\\n\\nPydantic est une biblioth\xe8que Python qui permet de valider des donn\xe9es et de g\xe9rer les param\xe8tres de configuration en utilisant les annotations de type Python. Elle offre plusieurs avantages :\\n\\n- **Validation forte bas\xe9e sur les types Python**\\n- **Conversion automatique des donn\xe9es d\'entr\xe9e**\\n- **G\xe9n\xe9ration de documentation JSON Schema**\\n- **S\xe9rialisation et d\xe9s\xe9rialisation faciles**\\n- **Performances optimis\xe9es** gr\xe2ce \xe0 l\'utilisation de code compil\xe9 en Rust\\n\\nPydantic est notamment le syst\xe8me de mod\xe8les utilis\xe9 par FastAPI, ce qui en fait un incontournable pour les d\xe9veloppeurs d\'APIs modernes.\\n\\n## Installation de Pydantic \ud83d\ude80\\n\\nL\'installation de Pydantic est simple avec pip :\\n\\n```bash\\npip install pydantic\\n\\n# Pour la version 2.x avec des performances optimis\xe9es\\npip install \\"pydantic>=2.0.0\\"\\n```\\n\\nSi vous utilisez Poetry (comme nous l\'avons vu dans [notre article pr\xe9c\xe9dent](/blog/2025/06/06/09-scripting/poetry-python-dependency)) :\\n\\n```bash\\npoetry add pydantic\\n```\\n\\n## Les bases de Pydantic \ud83d\udcda\\n\\n### D\xe9finition de mod\xe8les\\n\\nLa premi\xe8re \xe9tape avec Pydantic consiste \xe0 d\xe9finir un mod\xe8le en cr\xe9ant une classe qui h\xe9rite de `BaseModel` :\\n\\n```python\\nfrom pydantic import BaseModel\\nfrom typing import Optional, List\\nfrom datetime import date\\n\\nclass User(BaseModel):\\n    id: int\\n    name: str\\n    email: str\\n    birth_date: date\\n    is_active: bool = True\\n    tags: List[str] = []\\n    website: Optional[str] = None\\n```\\n\\n### Validation automatique\\n\\nUne fois le mod\xe8le d\xe9fini, Pydantic valide automatiquement les donn\xe9es lors de la cr\xe9ation d\'une instance :\\n\\n```python\\n# Validation r\xe9ussie\\nuser = User(\\n    id=1,\\n    name=\\"John Doe\\",\\n    email=\\"john@example.com\\",\\n    birth_date=\\"1990-01-01\\",  # Conversion automatique en objet date\\n    tags=[\\"admin\\", \\"user\\"]\\n)\\n\\n# Validation \xe9chou\xe9e\\ntry:\\n    User(\\n        id=\\"not_an_integer\\",  # Erreur: la valeur n\'est pas un entier\\n        name=123,             # Sera converti en string automatiquement\\n        email=\\"invalid_email\\" # Pas d\'erreur par d\xe9faut: ce n\'est pas une validation de format\\n    )\\nexcept ValueError as e:\\n    print(f\\"Erreur de validation: {e}\\")\\n```\\n\\n### S\xe9rialisation et d\xe9s\xe9rialisation\\n\\nPydantic simplifie la conversion des mod\xe8les en dictionnaires, JSON ou d\'autres formats :\\n\\n```python\\n# Conversion en dictionnaire\\nuser_dict = user.model_dump()\\n\\n# Conversion en JSON\\nuser_json = user.model_dump_json()\\n\\n# D\xe9s\xe9rialisation depuis un dictionnaire\\nuser_data = {\\n    \\"id\\": 2,\\n    \\"name\\": \\"Jane Smith\\",\\n    \\"email\\": \\"jane@example.com\\",\\n    \\"birth_date\\": \\"1992-03-15\\"\\n}\\nnew_user = User.model_validate(user_data)\\n\\n# D\xe9s\xe9rialisation depuis JSON\\nuser_from_json = User.model_validate_json(\'{\\"id\\": 3, \\"name\\": \\"Bob\\", \\"email\\": \\"bob@example.com\\", \\"birth_date\\": \\"1985-07-20\\"}\')\\n```\\n\\n## Fonctionnalit\xe9s avanc\xe9es \ud83d\udd27\\n\\n### Validateurs personnalis\xe9s\\n\\nPydantic permet de cr\xe9er des validateurs personnalis\xe9s pour des v\xe9rifications plus complexes :\\n\\n```python\\nfrom pydantic import BaseModel, field_validator, EmailStr\\n\\nclass AdvancedUser(BaseModel):\\n    id: int\\n    name: str\\n    email: EmailStr  # Type sp\xe9cial pour valider les emails\\n    password: str\\n    password_confirm: str\\n\\n    @field_validator(\'name\')\\n    @classmethod\\n    def name_must_contain_space(cls, v):\\n        if \' \' not in v:\\n            raise ValueError(\'Le nom doit contenir un espace (pr\xe9nom et nom)\')\\n        return v.title()  # Convertit le nom en format titre\\n\\n    @field_validator(\'password_confirm\')\\n    @classmethod\\n    def passwords_match(cls, v, info):\\n        if \'password\' in info.data and v != info.data[\'password\']:\\n            raise ValueError(\'Les mots de passe ne correspondent pas\')\\n        return v\\n```\\n\\n### Types complexes\\n\\nPydantic prend en charge une vari\xe9t\xe9 de types complexes :\\n\\n```python\\nfrom pydantic import BaseModel, HttpUrl, conlist, constr\\nfrom typing import Dict, Union\\n\\nclass Product(BaseModel):\\n    name: str\\n    price: float\\n    description: Optional[str] = None\\n\\nclass Order(BaseModel):\\n    order_id: str\\n    # Une liste avec au moins 1 \xe9l\xe9ment\\n    products: conlist(Product, min_length=1)\\n    # Une cha\xeene avec contrainte de longueur\\n    customer_id: constr(min_length=5, max_length=20)\\n    # Union de types possibles\\n    payment_method: Union[str, Dict[str, str]]\\n    # URL valide\\n    store_url: HttpUrl\\n```\\n\\n### Configuration des mod\xe8les\\n\\nPydantic offre de nombreuses options de configuration pour contr\xf4ler le comportement des mod\xe8les :\\n\\n```python\\nclass Settings(BaseModel):\\n    model_config = {\\n        # Permettre les champs suppl\xe9mentaires\\n        \\"extra\\": \\"forbid\\",\\n        # Valider \xe9galement les attributs lors de l\'assignation\\n        \\"validate_assignment\\": True,\\n        # Aliases pour les noms de champs JSON\\n        \\"populate_by_name\\": True,\\n        # Noms JSON en format camelCase\\n        \\"alias_generator\\": lambda s: \'\'.join(\\n            word.capitalize() if i else word\\n            for i, word in enumerate(s.split(\'_\'))\\n        ),\\n    }\\n\\n    database_url: str\\n    api_key: str\\n    debug_mode: bool = False\\n    max_connections: int = 100\\n```\\n\\n## Pydantic et FastAPI : le duo parfait \ud83e\udd1d\\n\\nPydantic est particuli\xe8rement puissant lorsqu\'il est utilis\xe9 avec FastAPI :\\n\\n```python\\nfrom fastapi import FastAPI, Path\\nfrom pydantic import BaseModel, Field\\nfrom typing import List\\n\\napp = FastAPI()\\n\\nclass Item(BaseModel):\\n    name: str = Field(..., example=\\"Smartphone\\")\\n    description: Optional[str] = Field(None, example=\\"Un t\xe9l\xe9phone dernier cri\\")\\n    price: float = Field(..., gt=0, example=899.99)\\n    tax: Optional[float] = Field(None, example=20.0)\\n\\n    model_config = {\\n        \\"json_schema_extra\\": {\\n            \\"examples\\": [\\n                {\\n                    \\"name\\": \\"Smartphone\\",\\n                    \\"description\\": \\"Un t\xe9l\xe9phone dernier cri\\",\\n                    \\"price\\": 899.99,\\n                    \\"tax\\": 20.0,\\n                }\\n            ]\\n        }\\n    }\\n\\n@app.post(\\"/items/\\", response_model=Item)\\nasync def create_item(item: Item):\\n    return item\\n\\n@app.get(\\"/items/{item_id}\\", response_model=Item)\\nasync def read_item(\\n    item_id: int = Path(..., title=\\"L\'ID de l\'item \xe0 r\xe9cup\xe9rer\\", ge=1)\\n):\\n    # Logic to retrieve item\\n    return {\\"name\\": \\"Example Item\\", \\"price\\": 99.99, \\"description\\": \\"A sample item\\"}\\n```\\n\\nAvec cette configuration, FastAPI :\\n\\n- Valide automatiquement les requ\xeates entrantes\\n- Convertit les donn\xe9es en objets Python typ\xe9s\\n- G\xe9n\xe8re une documentation OpenAPI interactive\\n- Effectue la s\xe9rialisation des r\xe9ponses\\n\\n## Pydantic v1 vs v2 : les diff\xe9rences majeures \ud83d\udd04\\n\\nPydantic v2 (sorti en 2023) a introduit plusieurs changements importants :\\n\\n| Fonctionnalit\xe9 | v1 | v2 |\\n|----------------|-----|-----|\\n| Moteur de validation | Python pur | Core en Rust (10-50x plus rapide) |\\n| API | `.dict()`, `.json()` | `.model_dump()`, `.model_dump_json()` |\\n| Validateurs | `@validator`, `@root_validator` | `@field_validator`, `@model_validator` |\\n| Types g\xe9n\xe9riques | Support limit\xe9 | Support am\xe9lior\xe9 |\\n| JSON Schema | G\xe9n\xe9ration basique | Plus complet et personnalisable |\\n\\nExemple de migration :\\n\\n```python\\n# Pydantic v1\\nfrom pydantic import BaseModel, validator\\n\\nclass UserV1(BaseModel):\\n    name: str\\n    age: int\\n\\n    @validator(\'age\')\\n    def check_age(cls, v):\\n        if v < 18:\\n            raise ValueError(\'Doit \xeatre majeur\')\\n        return v\\n\\n    # Conversion en dict/json\\n    data = user.dict()\\n    json_data = user.json()\\n\\n# Pydantic v2\\nfrom pydantic import BaseModel, field_validator\\n\\nclass UserV2(BaseModel):\\n    name: str\\n    age: int\\n\\n    @field_validator(\'age\')\\n    @classmethod  # Maintenant obligatoire\\n    def check_age(cls, v):\\n        if v < 18:\\n            raise ValueError(\'Doit \xeatre majeur\')\\n        return v\\n\\n    # Conversion en dict/json\\n    data = user.model_dump()\\n    json_data = user.model_dump_json()\\n```\\n\\n## Bonnes pratiques avec Pydantic \ud83d\udc4d\\n\\n1. **Utilisez des types pr\xe9cis**: Les types comme `EmailStr`, `HttpUrl`, `conint`, etc. am\xe9liorent la validation\\n\\n2. **Cr\xe9ez une hi\xe9rarchie de mod\xe8les**: Utilisez l\'h\xe9ritage pour les structures complexes\\n\\n   ```python\\n   class BaseUser(BaseModel):\\n       id: int\\n       name: str\\n\\n   class UserIn(BaseUser):\\n       password: str\\n\\n   class UserOut(BaseUser):\\n       is_active: bool\\n   ```\\n\\n3. **Exploitez les validators pour les r\xe8gles m\xe9tier complexes**:\\n\\n   ```python\\n   @field_validator(\\"reservation_date\\")\\n   @classmethod\\n   def validate_date_is_future(cls, v, info):\\n       if v <= datetime.now():\\n           raise ValueError(\\"La r\xe9servation doit \xeatre dans le futur\\")\\n       return v\\n   ```\\n\\n4. **Utilisez FrozenModel pour l\'immutabilit\xe9**:\\n\\n   ```python\\n   from pydantic import BaseModel, ConfigDict\\n\\n   class Config(BaseModel):\\n       model_config = ConfigDict(frozen=True)\\n       api_key: str\\n       debug: bool = False\\n   ```\\n\\n5. **Ajoutez des exemples pour am\xe9liorer la documentation**:\\n\\n   ```python\\n   class Item(BaseModel):\\n       name: str\\n       price: float\\n\\n       model_config = {\\n           \\"json_schema_extra\\": {\\"examples\\": [{\\"name\\": \\"Foo\\", \\"price\\": 35.4}]}\\n       }\\n   ```\\n\\n## Cas d\'utilisation concrets \ud83d\udee0\ufe0f\\n\\n### Validation de configuration\\n\\n```python\\nfrom pydantic import BaseModel, Field, SecretStr\\nimport yaml\\nfrom pathlib import Path\\n\\nclass DatabaseConfig(BaseModel):\\n    host: str = \\"localhost\\"\\n    port: int = 5432\\n    user: str\\n    password: SecretStr\\n    name: str\\n    ssl: bool = False\\n\\nclass ApiConfig(BaseModel):\\n    endpoint: str\\n    timeout: int = 30\\n    retries: int = 3\\n\\nclass AppConfig(BaseModel):\\n    debug: bool = False\\n    log_level: str = \\"INFO\\"\\n    database: DatabaseConfig\\n    api: ApiConfig\\n\\n# Charger la configuration depuis un fichier YAML\\nconfig_path = Path(\\"config.yaml\\")\\nwith open(config_path) as f:\\n    config_dict = yaml.safe_load(f)\\n\\n# Valider la configuration\\ntry:\\n    config = AppConfig.model_validate(config_dict)\\n    print(f\\"Configuration valide: {config.model_dump(exclude={\'database\': {\'password\'}})}\\")\\nexcept ValueError as e:\\n    print(f\\"Configuration invalide: {e}\\")\\n```\\n\\n### Traitement de donn\xe9es d\'API\\n\\n```python\\nimport httpx\\nfrom pydantic import BaseModel, HttpUrl\\nfrom typing import List, Optional\\nfrom datetime import datetime\\n\\nclass Author(BaseModel):\\n    name: str\\n    url: Optional[HttpUrl] = None\\n\\nclass Article(BaseModel):\\n    id: int\\n    title: str\\n    content: str\\n    published: datetime\\n    author: Author\\n    tags: List[str] = []\\n\\nasync def fetch_articles():\\n    async with httpx.AsyncClient() as client:\\n        response = await client.get(\\"https://api.example.com/articles\\")\\n        data = response.json()\\n\\n        # Valider et convertir les donn\xe9es en objets Python\\n        articles = [Article.model_validate(item) for item in data]\\n\\n        # Maintenant on peut travailler avec des objets Python typ\xe9s\\n        for article in articles:\\n            print(f\\"Article: {article.title}, Publi\xe9 le: {article.published.strftime(\'%d/%m/%Y\')}\\")\\n            print(f\\"Auteur: {article.author.name}\\")\\n            print(\\"-\\" * 50)\\n\\n        return articles\\n```\\n\\n## Conclusion \ud83c\udfaf\\n\\nPydantic s\'est impos\xe9 comme un outil indispensable dans l\'\xe9cosyst\xe8me Python moderne, particuli\xe8rement pour le d\xe9veloppement d\'APIs et d\'applications manipulant des donn\xe9es structur\xe9es. Ses points forts :\\n\\n- **Validation robuste** des donn\xe9es bas\xe9e sur les types Python standard\\n- **API intuitive** permettant de d\xe9finir rapidement des mod\xe8les complexes\\n- **Performances impressionnantes** gr\xe2ce au moteur de validation en Rust\\n- **Int\xe9gration harmonieuse** avec FastAPI et d\'autres frameworks"},{"id":"/2025/01/13/02-network/nginx-proxy-manager","metadata":{"permalink":"/blog/2025/01/13/02-network/nginx-proxy-manager","source":"@site/blog/02-network/2025-01-13-nginx-proxy-manager.md","title":"Proxy : Nginx Proxy Manager","description":"Pr\xe9sentation de Nginx Proxy Manager, ses fonctionnalit\xe9s et ses avantages, ainsi qu\'une d\xe9monstration d\'utilisation avec Docker.","date":"2025-01-13T00:00:00.000Z","tags":[{"inline":false,"label":"R\xe9seau","permalink":"/blog/tags/network"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":3.94,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Proxy : Nginx Proxy Manager","description":"Pr\xe9sentation de Nginx Proxy Manager, ses fonctionnalit\xe9s et ses avantages, ainsi qu\'une d\xe9monstration d\'utilisation avec Docker.","tags":["network","devops"]},"unlisted":false,"prevItem":{"title":"Python : Pydantic","permalink":"/blog/2025/06/06/09-scripting/pydantic-validation-donnees"},"nextItem":{"title":"Kubernetes : composants de base","permalink":"/blog/2025/01/12/06-orchestration/k8s-basic-components"}},"content":"Nginx Proxy Manager est une interface utilisateur graphique (GUI) pour g\xe9rer les proxys inverses Nginx. Il simplifie la gestion des proxys inverses, des certificats SSL et des redirections de trafic. Cet article pr\xe9sente Nginx Proxy Manager, explique ses fonctionnalit\xe9s et avantages, et fournit une d\xe9monstration d\'utilisation avec Docker.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que Nginx Proxy Manager ?\\n\\n![Nginx Proxy Manager](/img/nginx-proxy-manager.png)\\n\\n[Nginx Proxy Manager](https://nginxproxymanager.com/) est une interface utilisateur graphique (GUI) pour g\xe9rer les proxys inverses Nginx. Il permet de configurer facilement des proxys inverses, des certificats SSL et des redirections de trafic. Nginx Proxy Manager est con\xe7u pour \xeatre simple \xe0 utiliser et accessible aux utilisateurs non techniques.\\n\\n<details>\\n<summary>Qu\'est-ce qu\'un proxy ?</summary>\\n\\nUn proxy, \xe9galement connu sous le nom de proxy direct ou proxy de transfert, est un serveur qui agit comme un interm\xe9diaire entre un client (par exemple, un utilisateur ou un appareil) et un serveur de destination sur Internet. Voici un aper\xe7u d\xe9taill\xe9 de son fonctionnement :\\n\\n1. **Interception des requ\xeates** : Lorsqu\'un client souhaite acc\xe9der \xe0 une ressource sur Internet, il envoie une requ\xeate au proxy au lieu de se connecter directement au serveur de destination. Le proxy intercepte cette requ\xeate.\\n\\n2. **Filtrage et s\xe9curit\xe9** : Le proxy examine la requ\xeate pour s\'assurer qu\'elle respecte les politiques de s\xe9curit\xe9 et de filtrage d\xe9finies par l\'administrateur r\xe9seau. Il peut bloquer l\'acc\xe8s \xe0 certains sites web, filtrer les contenus inappropri\xe9s ou malveillants, et appliquer des r\xe8gles de s\xe9curit\xe9.\\n\\n3. **Anonymisation** : Le proxy peut masquer l\'adresse IP du client en utilisant sa propre adresse IP pour se connecter au serveur de destination. Cela permet de prot\xe9ger l\'identit\xe9 et la confidentialit\xe9 du client.\\n\\n4. **Mise en cache** : Le proxy peut mettre en cache les r\xe9ponses des serveurs de destination. Si un autre client demande la m\xeame ressource, le proxy peut fournir la r\xe9ponse mise en cache, ce qui r\xe9duit la charge sur le serveur de destination et am\xe9liore les temps de r\xe9ponse.\\n\\n5. **Transmission de la requ\xeate** : Si la requ\xeate est autoris\xe9e, le proxy la transmet au serveur de destination en utilisant sa propre adresse IP. Le serveur de destination r\xe9pond alors au proxy.\\n\\n6. **Retour de la r\xe9ponse** : Le proxy re\xe7oit la r\xe9ponse du serveur de destination, la filtre \xe0 nouveau si n\xe9cessaire, et la renvoie au client. Le client re\xe7oit ainsi la r\xe9ponse comme s\'il avait directement communiqu\xe9 avec le serveur de destination.\\n\\n</details>\\n\\n### Fonctionnalit\xe9s de Nginx Proxy Manager\\n\\n- **Gestion des proxys inverses** : Configurez facilement des proxys inverses pour vos applications web.\\n- **Certificats SSL** : G\xe9rez les certificats SSL pour s\xe9curiser vos sites web.\\n- **Redirections de trafic** : Configurez des redirections de trafic pour vos domaines et sous-domaines.\\n- **Interface utilisateur intuitive** : Utilisez une interface utilisateur graphique pour g\xe9rer vos configurations Nginx.\\n\\n### Avantages de Nginx Proxy Manager\\n\\n- **Simplicit\xe9** : Nginx Proxy Manager simplifie la gestion des proxys inverses et des certificats SSL.\\n- **Accessibilit\xe9** : L\'interface utilisateur graphique rend Nginx Proxy Manager accessible aux utilisateurs non techniques.\\n- **Flexibilit\xe9** : Nginx Proxy Manager prend en charge une vari\xe9t\xe9 de configurations et de sc\xe9narios d\'utilisation.\\n\\n## Utilisation de Nginx Proxy Manager avec Docker\\n\\nDans cette section, une d\xe9monstration est fournie pour montrer comment utiliser Nginx Proxy Manager avec Docker. Un conteneur Docker pour Nginx Proxy Manager sera cr\xe9\xe9 et un proxy inverse pour une application web sera configur\xe9.\\n\\n### Pr\xe9requis\\n\\n- Docker install\xe9 sur la machine\\n- Une application web \xe0 proxyfier\\n\\n### \xc9tapes\\n\\n1. **Cr\xe9er un fichier `docker-compose.yml`**\\n\\n   Cr\xe9ez un fichier `docker-compose.yml` avec le contenu suivant :\\n\\n   ```yaml\\n   version: \'3\'\\n   services:\\n     app:\\n       image: your-app-image\\n       container_name: your-app\\n       ports:\\n         - \\"8080:80\\"\\n     nginx-proxy-manager:\\n       image: jc21/nginx-proxy-manager:latest\\n       container_name: nginx-proxy-manager\\n       ports:\\n         - \\"80:80\\"\\n         - \\"81:81\\"\\n         - \\"443:443\\"\\n       volumes:\\n         - ./data:/data\\n         - ./letsencrypt:/etc/letsencrypt\\n   ```\\n\\n2. **D\xe9marrer les conteneurs Docker**\\n\\n   Ex\xe9cutez la commande suivante pour d\xe9marrer les conteneurs Docker :\\n\\n   ```bash\\n   docker-compose up -d\\n   ```\\n\\n3. **Acc\xe9der \xe0 l\'interface utilisateur de Nginx Proxy Manager**\\n\\n   Ouvrir le navigateur et acc\xe9der \xe0 `http://localhost:81`. Se connecter avec les informations d\'identification par d\xe9faut (`admin@example.com` / `changeme`) et changer le mot de passe.\\n\\n4. **Configurer un proxy inverse**\\n\\n   Dans l\'interface utilisateur de Nginx Proxy Manager, ajouter un nouveau proxy h\xf4te avec les param\xe8tres suivants :\\n\\n   - **Domain Names** : Entrer le nom de domaine ou l\'adresse IP de l\'application web.\\n   - **Forward Hostname / IP** : Entrer `app`.\\n   - **Forward Port** : Entrer `80`.\\n\\n   Enregistrer la configuration et acc\xe9der \xe0 l\'application web via le nom de domaine ou l\'adresse IP configur\xe9e.\\n\\n## Conclusion\\n\\nNginx Proxy Manager est un outil puissant et facile \xe0 utiliser pour g\xe9rer les proxys inverses Nginx, les certificats SSL et les redirections de trafic. En utilisant Docker, il est possible de d\xe9ployer et configurer rapidement Nginx Proxy Manager pour les applications web. Essayer Nginx Proxy Manager d\xe8s aujourd\'hui pour simplifier la gestion des proxys inverses et am\xe9liorer la s\xe9curit\xe9 des sites web."},{"id":"/2025/01/12/06-orchestration/k8s-basic-components","metadata":{"permalink":"/blog/2025/01/12/06-orchestration/k8s-basic-components","source":"@site/blog/06-orchestration/2025-01-12-k8s-basic-components.md","title":"Kubernetes : composants de base","description":"D\xe9couvrez les composants de base de Kubernetes, tels que les Services, Pods, Deployments et StatefulSets.","date":"2025-01-12T00:00:00.000Z","tags":[{"inline":false,"label":"Orchestration","permalink":"/blog/tags/orchestration"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":3.79,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Kubernetes : composants de base","description":"D\xe9couvrez les composants de base de Kubernetes, tels que les Services, Pods, Deployments et StatefulSets.","tags":["orchestration","devops"]},"unlisted":false,"prevItem":{"title":"Proxy : Nginx Proxy Manager","permalink":"/blog/2025/01/13/02-network/nginx-proxy-manager"},"nextItem":{"title":"Kubernetes","permalink":"/blog/2025/01/12/06-orchestration/k8s-introduction"}},"content":"Kubernetes est une plateforme d\'orchestration de conteneurs qui permet de g\xe9rer des clusters de machines ex\xe9cutant des conteneurs. Dans cet article, les composants de base de Kubernetes, notamment les Services, Pods, Deployments et StatefulSets, seront explor\xe9s. \ud83d\ude80\\n\\n\x3c!--truncate--\x3e\\n\\n## Pod\\n\\nUn Pod est l\'unit\xe9 de base de d\xe9ploiement dans Kubernetes. Il repr\xe9sente un ou plusieurs conteneurs qui partagent le m\xeame r\xe9seau et le m\xeame espace de stockage. Les Pods sont \xe9ph\xe9m\xe8res et peuvent \xeatre recr\xe9\xe9s en cas de d\xe9faillance.\\n\\n### Exemple de Pod\\n\\n```yaml\\napiVersion: v1\\nkind: Pod\\nmetadata:\\n  name: my-pod\\nspec:\\n  containers:\\n    - name: my-container\\n      image: nginx:alpine\\n      ports:\\n        - containerPort: 80\\n```\\n\\nLes Pods sont utilis\xe9s pour ex\xe9cuter des applications conteneuris\xe9es sur des n\u0153uds de travail. Ils peuvent contenir un ou plusieurs conteneurs, qui partagent le m\xeame r\xe9seau et le m\xeame espace de stockage. Les Pods sont \xe9ph\xe9m\xe8res, ce qui signifie qu\'ils peuvent \xeatre recr\xe9\xe9s en cas de d\xe9faillance. Les Pods sont \xe9galement utilis\xe9s pour regrouper des conteneurs qui doivent \xeatre ex\xe9cut\xe9s ensemble, par exemple, un conteneur d\'application et un conteneur de base de donn\xe9es.\\n\\n## Service\\n\\nUn Service est une abstraction qui permet d\'exposer une application ex\xe9cut\xe9e sur un ensemble de Pods en tant que service r\xe9seau. Les Services permettent de distribuer le trafic r\xe9seau entre les Pods et de garantir la haute disponibilit\xe9 des applications.\\n\\n### Exemple de Service\\n\\n```yaml\\napiVersion: v1\\nkind: Service\\nmetadata:\\n  name: my-service\\nspec:\\n  selector:\\n    app: my-app\\n  ports:\\n    - protocol: TCP\\n      port: 80\\n      targetPort: 80\\n  type: LoadBalancer\\n```\\n\\nLes Services sont utilis\xe9s pour exposer des applications ex\xe9cut\xe9es sur des Pods en tant que services r\xe9seau. Ils permettent de distribuer le trafic r\xe9seau entre les Pods et de garantir la haute disponibilit\xe9 des applications. Les Services peuvent \xeatre de diff\xe9rents types, tels que ClusterIP, NodePort et LoadBalancer, en fonction des besoins de l\'application.\\n\\n## Deployment\\n\\nUn Deployment est un objet Kubernetes qui g\xe8re le d\xe9ploiement et la mise \xe0 l\'\xe9chelle des applications conteneuris\xe9es. Il d\xe9finit l\'\xe9tat souhait\xe9 de l\'application et Kubernetes s\'occupe de cr\xe9er et de g\xe9rer les instances (Pods) pour atteindre cet \xe9tat.\\n\\n### Exemple de Deployment\\n\\n```yaml\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: my-deployment\\nspec:\\n  replicas: 3\\n  selector:\\n    matchLabels:\\n      app: my-app\\n  template:\\n    metadata:\\n      labels:\\n        app: my-app\\n    spec:\\n      containers:\\n        - name: my-container\\n          image: nginx:alpine\\n          ports:\\n            - containerPort: 80\\n```\\n\\nLes Deployments sont utilis\xe9s pour g\xe9rer le d\xe9ploiement et la mise \xe0 l\'\xe9chelle des applications conteneuris\xe9es. Ils d\xe9finissent l\'\xe9tat souhait\xe9 de l\'application, y compris le nombre de r\xe9plicas, l\'image du conteneur \xe0 utiliser, les ports expos\xe9s et les volumes. Kubernetes s\'occupe de cr\xe9er et de g\xe9rer les instances (Pods) pour atteindre cet \xe9tat. Les Deployments permettent \xe9galement de mettre \xe0 jour les applications de mani\xe8re transparente en effectuant des d\xe9ploiements progressifs.\\n\\n## StatefulSet\\n\\nUn StatefulSet est un objet Kubernetes qui g\xe8re le d\xe9ploiement et la mise \xe0 l\'\xe9chelle des applications avec \xe9tat. Contrairement aux Deployments, les StatefulSets garantissent l\'ordre et l\'unicit\xe9 des Pods, ce qui est essentiel pour les applications n\xe9cessitant un stockage persistant.\\n\\n### Exemple de StatefulSet\\n\\n```yaml\\napiVersion: apps/v1\\nkind: StatefulSet\\nmetadata:\\n  name: my-statefulset\\nspec:\\n  serviceName: \\"my-service\\"\\n  replicas: 3\\n  selector:\\n    matchLabels:\\n      app: my-app\\n  template:\\n    metadata:\\n      labels:\\n        app: my-app\\n    spec:\\n      containers:\\n        - name: my-container\\n          image: nginx:alpine\\n          ports:\\n            - containerPort: 80\\n          volumeMounts:\\n            - name: my-volume\\n              mountPath: /usr/share/nginx/html\\n  volumeClaimTemplates:\\n    - metadata:\\n        name: my-volume\\n      spec:\\n        accessModes: [ \\"ReadWriteOnce\\" ]\\n        resources:\\n          requests:\\n            storage: 1Gi\\n```\\n\\nLes StatefulSets sont utilis\xe9s pour g\xe9rer le d\xe9ploiement et la mise \xe0 l\'\xe9chelle des applications avec \xe9tat. Contrairement aux Deployments, les StatefulSets garantissent l\'ordre et l\'unicit\xe9 des Pods, ce qui est essentiel pour les applications n\xe9cessitant un stockage persistant. Les StatefulSets sont souvent utilis\xe9s pour des applications telles que les bases de donn\xe9es, qui n\xe9cessitent un stockage persistant et une gestion de l\'\xe9tat.\\n\\n## Interactions entre les composants\\n\\nLes composants de base de Kubernetes interagissent entre eux pour assurer le d\xe9ploiement, la mise \xe0 l\'\xe9chelle et la gestion des applications conteneuris\xe9es. Par exemple, un Deployment peut cr\xe9er plusieurs Pods, qui sont ensuite expos\xe9s en tant que service r\xe9seau par un Service. Les StatefulSets garantissent l\'ordre et l\'unicit\xe9 des Pods, ce qui est essentiel pour les applications n\xe9cessitant un stockage persistant. Les Services permettent de distribuer le trafic r\xe9seau entre les Pods et de garantir la haute disponibilit\xe9 des applications.\\n\\n## Conclusion\\n\\nLes composants de base de Kubernetes, tels que les Pods, Services, Deployments et StatefulSets, permettent de d\xe9ployer, g\xe9rer et mettre \xe0 l\'\xe9chelle des applications conteneuris\xe9es de mani\xe8re efficace. En comprenant ces composants et leurs interactions, il est possible de tirer parti de la puissance de Kubernetes pour g\xe9rer les applications.\\n\\nPour en savoir plus sur Kubernetes, consulter la [documentation officielle](https://kubernetes.io/fr/docs/concepts/)."},{"id":"/2025/01/12/06-orchestration/k8s-introduction","metadata":{"permalink":"/blog/2025/01/12/06-orchestration/k8s-introduction","source":"@site/blog/06-orchestration/2025-01-12-k8s-introduction.md","title":"Kubernetes","description":"D\xe9couvrez les concepts de base de Kubernetes, une plateforme d\'orchestration de conteneurs.","date":"2025-01-12T00:00:00.000Z","tags":[{"inline":false,"label":"Orchestration","permalink":"/blog/tags/orchestration"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":2.53,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Kubernetes","description":"D\xe9couvrez les concepts de base de Kubernetes, une plateforme d\'orchestration de conteneurs.","tags":["orchestration","devops"]},"unlisted":false,"prevItem":{"title":"Kubernetes : composants de base","permalink":"/blog/2025/01/12/06-orchestration/k8s-basic-components"},"nextItem":{"title":"Kubernetes : Secrets et ConfigMaps","permalink":"/blog/2025/01/12/06-orchestration/k8s-secrets-configmaps"}},"content":"Kubernetes est une plateforme open-source con\xe7ue pour automatiser le d\xe9ploiement, la mise \xe0 l\'\xe9chelle et la gestion des applications conteneuris\xe9es. Il permet de regrouper des conteneurs qui composent une application en unit\xe9s logiques pour une gestion et une d\xe9couverte plus faciles. \ud83d\ude80\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que Kubernetes ? \ud83e\udd14\\n\\nKubernetes, souvent abr\xe9g\xe9 en K8s, est une plateforme d\'orchestration de conteneurs qui permet de g\xe9rer des clusters de machines ex\xe9cutant des conteneurs. Il a \xe9t\xe9 initialement d\xe9velopp\xe9 par Google et est maintenant maintenu par la Cloud Native Computing Foundation (CNCF).\\n\\n### Architecture de Kubernetes \ud83c\udfd7\ufe0f\\n\\nL\'architecture de Kubernetes est compos\xe9e de plusieurs composants cl\xe9s :\\n\\n- **Master Node** : Le n\u0153ud ma\xeetre est responsable de la gestion du cluster. Il orchestre les t\xe2ches telles que le d\xe9ploiement des applications, la maintenance de l\'\xe9tat souhait\xe9 des applications, la mise \xe0 l\'\xe9chelle des applications et la mise \xe0 jour des applications.\\n- **Worker Nodes** : Les n\u0153uds de travail ex\xe9cutent les applications conteneuris\xe9es. Chaque n\u0153ud de travail contient les services n\xe9cessaires pour ex\xe9cuter les conteneurs et est g\xe9r\xe9 par le n\u0153ud ma\xeetre.\\n\\n![Architecture de Kubernetes](/img/k8s-architecture.png)\\n\\n### Composants principaux de Kubernetes \ud83d\udd27\\n\\n- **API Server** : L\'API Server est le point d\'entr\xe9e pour toutes les commandes Kubernetes. Il expose l\'API Kubernetes.\\n- **etcd** : etcd est un magasin de donn\xe9es cl\xe9-valeur distribu\xe9 qui stocke les donn\xe9es de configuration du cluster et l\'\xe9tat du cluster.\\n- **Scheduler** : Le Scheduler est responsable de la r\xe9partition des conteneurs sur les n\u0153uds de travail en fonction des ressources disponibles et des contraintes d\xe9finies.\\n- **Controller Manager** : Le Controller Manager ex\xe9cute les contr\xf4leurs qui surveillent l\'\xe9tat du cluster et effectuent les ajustements n\xe9cessaires pour atteindre l\'\xe9tat souhait\xe9.\\n- **Kubelet** : Kubelet est un agent qui s\'ex\xe9cute sur chaque n\u0153ud de travail et garantit que les conteneurs sont ex\xe9cut\xe9s dans un Pod.\\n- **Container Runtime** : Le Container Runtime est le logiciel responsable de l\'ex\xe9cution des conteneurs. Kubernetes prend en charge plusieurs runtimes de conteneurs, y compris Docker, containerd et CRI-O.\\n- **Kube-proxy** : Kube-proxy est un proxy r\xe9seau qui g\xe8re la mise en r\xe9seau des conteneurs et assure la communication entre les services.\\n\\n### Avantages de Kubernetes \ud83c\udf1f\\n\\n- **Portabilit\xe9** : Kubernetes est compatible avec plusieurs environnements de cloud, y compris AWS, Azure et Google Cloud, ainsi qu\'avec des environnements sur site.\\n- **Scalabilit\xe9** : Kubernetes permet de mettre \xe0 l\'\xe9chelle les applications de mani\xe8re horizontale (en ajoutant plus de r\xe9plicas) et verticale (en allouant plus de ressources \xe0 un conteneur).\\n- **R\xe9silience** : Kubernetes assure la haute disponibilit\xe9 des applications en red\xe9marrant automatiquement les conteneurs d\xe9faillants, en r\xe9pliquant les conteneurs et en \xe9quilibrant la charge du trafic r\xe9seau.\\n- **Gestion simplifi\xe9e** : Kubernetes automatise de nombreuses t\xe2ches de gestion des conteneurs, y compris le d\xe9ploiement, la mise \xe0 jour et la mise \xe0 l\'\xe9chelle des applications.\\n\\n## Conclusion \ud83c\udfaf\\n\\nKubernetes est une plateforme puissante et flexible pour l\'orchestration des conteneurs. En automatisant de nombreuses t\xe2ches de gestion des conteneurs, Kubernetes permet aux \xe9quipes de d\xe9veloppement et d\'exploitation de se concentrer sur la cr\xe9ation et la maintenance des applications, plut\xf4t que sur la gestion de l\'infrastructure sous-jacente.\\n\\nPour en savoir plus sur Kubernetes, consulter la [documentation officielle](https://kubernetes.io/fr/docs/concepts/)."},{"id":"/2025/01/12/06-orchestration/k8s-secrets-configmaps","metadata":{"permalink":"/blog/2025/01/12/06-orchestration/k8s-secrets-configmaps","source":"@site/blog/06-orchestration/2025-01-12-k8s-secrets-configmaps.md","title":"Kubernetes : Secrets et ConfigMaps","description":"D\xe9couvrez les concepts de Secrets et ConfigMaps dans Kubernetes, et comment les utiliser pour g\xe9rer les configurations et les informations sensibles.","date":"2025-01-12T00:00:00.000Z","tags":[{"inline":false,"label":"Orchestration","permalink":"/blog/tags/orchestration"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":1.61,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Kubernetes : Secrets et ConfigMaps","description":"D\xe9couvrez les concepts de Secrets et ConfigMaps dans Kubernetes, et comment les utiliser pour g\xe9rer les configurations et les informations sensibles.","tags":["orchestration","devops"]},"unlisted":false,"prevItem":{"title":"Kubernetes","permalink":"/blog/2025/01/12/06-orchestration/k8s-introduction"},"nextItem":{"title":"Kubernetes : Stockage","permalink":"/blog/2025/01/12/06-orchestration/k8s-storage"}},"content":"Kubernetes offre des m\xe9canismes pour g\xe9rer les configurations et les informations sensibles de mani\xe8re s\xe9curis\xe9e et efficace. Dans cet article, les concepts de Secrets et ConfigMaps dans Kubernetes seront explor\xe9s, ainsi que leur utilisation pour g\xe9rer les configurations et les informations sensibles. \ud83d\udd12\\n\\n\x3c!--truncate--\x3e\\n\\n## ConfigMap\\n\\nUn ConfigMap est une ressource Kubernetes utilis\xe9e pour stocker des paires cl\xe9-valeur de configuration. Les ConfigMaps permettent de s\xe9parer les configurations des conteneurs, ce qui facilite la gestion et la mise \xe0 jour des configurations sans avoir \xe0 reconstruire les images des conteneurs.\\n\\n### Exemple de ConfigMap\\n\\n```yaml\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: my-config\\ndata:\\n  database_url: \\"postgres://user:password@hostname:5432/dbname\\"\\n  log_level: \\"debug\\"\\n```\\n\\n### Utilisation d\'un ConfigMap dans un Pod\\n\\n```yaml\\napiVersion: v1\\nkind: Pod\\nmetadata:\\n  name: my-pod\\nspec:\\n  containers:\\n    - name: my-container\\n      image: nginx:alpine\\n      env:\\n        - name: DATABASE_URL\\n          valueFrom:\\n            configMapKeyRef:\\n              name: my-config\\n              key: database_url\\n        - name: LOG_LEVEL\\n          valueFrom:\\n            configMapKeyRef:\\n              name: my-config\\n              key: log_level\\n```\\n\\n## Secret\\n\\nUn Secret est une ressource Kubernetes utilis\xe9e pour stocker des informations sensibles, telles que des mots de passe, des cl\xe9s API et des certificats. Les Secrets permettent de g\xe9rer les informations sensibles de mani\xe8re s\xe9curis\xe9e et de les injecter dans les conteneurs sans les exposer dans les fichiers de configuration.\\n\\n### Exemple de Secret\\n\\n```yaml\\napiVersion: v1\\nkind: Secret\\nmetadata:\\n  name: my-secret\\ntype: Opaque\\ndata:\\n  username: dXNlcm5hbWU=\\n  password: cGFzc3dvcmQ=\\n```\\n\\n### Utilisation d\'un Secret dans un Pod\\n\\n```yaml\\napiVersion: v1\\nkind: Pod\\nmetadata:\\n  name: my-pod\\nspec:\\n  containers:\\n    - name: my-container\\n      image: nginx:alpine\\n      env:\\n        - name: USERNAME\\n          valueFrom:\\n            secretKeyRef:\\n              name: my-secret\\n              key: username\\n        - name: PASSWORD\\n          valueFrom:\\n            secretKeyRef:\\n              name: my-secret\\n              key: password\\n```\\n\\n## Conclusion\\n\\nLes Secrets et ConfigMaps dans Kubernetes permettent de g\xe9rer les configurations et les informations sensibles de mani\xe8re s\xe9curis\xe9e et efficace. En utilisant ces ressources, il est possible de s\xe9parer les configurations des conteneurs, de faciliter la gestion des configurations et de prot\xe9ger les informations sensibles. \ud83d\udd10\\n\\nPour en savoir plus sur Kubernetes, consulter la [documentation officielle](https://kubernetes.io/fr/docs/concepts/)."},{"id":"/2025/01/12/06-orchestration/k8s-storage","metadata":{"permalink":"/blog/2025/01/12/06-orchestration/k8s-storage","source":"@site/blog/06-orchestration/2025-01-12-k8s-storage.md","title":"Kubernetes : Stockage","description":"D\xe9couvrez les concepts de stockage dans Kubernetes, tels que PersistentVolume, PersistentVolumeClaim, StorageClass et Volume.","date":"2025-01-12T00:00:00.000Z","tags":[{"inline":false,"label":"Orchestration","permalink":"/blog/tags/orchestration"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":4.42,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Kubernetes : Stockage","description":"D\xe9couvrez les concepts de stockage dans Kubernetes, tels que PersistentVolume, PersistentVolumeClaim, StorageClass et Volume.","tags":["orchestration","devops"]},"unlisted":false,"prevItem":{"title":"Kubernetes : Secrets et ConfigMaps","permalink":"/blog/2025/01/12/06-orchestration/k8s-secrets-configmaps"},"nextItem":{"title":"DevOps Roadmap 2025","permalink":"/blog/2025/01/01/devops-roadmap-2025"}},"content":"Kubernetes offre des m\xe9canismes pour monter et utiliser du stockage dans les pods, mais la gestion des donn\xe9es, y compris la provision, la sauvegarde et la r\xe9plication, est une t\xe2che qui incombe aux administrateurs du cluster. Dans cet article, les concepts de stockage dans Kubernetes, notamment PersistentVolume, PersistentVolumeClaim, StorageClass et Volume, seront explor\xe9s. \ud83d\udce6\\n\\n\x3c!--truncate--\x3e\\n\\n## PersistentVolume (PV)\\n\\nUn PersistentVolume (PV) est une ressource Kubernetes qui repr\xe9sente un volume de stockage dans le cluster. Il peut \xeatre provisionn\xe9 dynamiquement ou statiquement et est utilis\xe9 pour stocker des donn\xe9es de mani\xe8re persistante. Les PVs sont ind\xe9pendants des pods et peuvent \xeatre r\xe9clam\xe9s par des PersistentVolumeClaims (PVCs).\\n\\n### Exemple de PersistentVolume\\n\\n```yaml\\napiVersion: v1\\nkind: PersistentVolume\\nmetadata:\\n  name: my-pv\\nspec:\\n  capacity:\\n    storage: 1Gi\\n  accessModes:\\n    - ReadWriteOnce\\n  persistentVolumeReclaimPolicy: Retain\\n  storageClassName: my-storage-class\\n  hostPath:\\n    path: /mnt/data\\n```\\n\\n## PersistentVolumeClaim (PVC)\\n\\nUn PersistentVolumeClaim (PVC) est une ressource Kubernetes utilis\xe9e par les pods pour demander un certain type et une certaine quantit\xe9 de stockage persistant. Les PVCs sont li\xe9s aux PVs disponibles dans le cluster.\\n\\n### Exemple de PersistentVolumeClaim\\n\\n```yaml\\napiVersion: v1\\nkind: PersistentVolumeClaim\\nmetadata:\\n  name: my-pvc\\nspec:\\n  accessModes:\\n    - ReadWriteOnce\\n  resources:\\n    requests:\\n      storage: 1Gi\\n  storageClassName: my-storage-class\\n```\\n\\n## Cycle de vie des PersistentVolumes (PV) et PersistentVolumeClaims (PVC)\\n\\nLe cycle de vie des PersistentVolumes (PV) et PersistentVolumeClaims (PVC) dans Kubernetes suit plusieurs \xe9tapes, de la cr\xe9ation \xe0 la suppression.\\n\\n### Cycle de vie des PV\\n\\n1. **Provisioning**: Le PV est cr\xe9\xe9 soit statiquement par un administrateur, soit dynamiquement par le contr\xf4leur de stockage.\\n2. **Binding**: Le PV est li\xe9 \xe0 un PVC lorsqu\'un PVC correspondant est cr\xe9\xe9.\\n3. **Using**: Le PV est utilis\xe9 par un pod via le PVC.\\n4. **Reclaiming**: Lorsque le PVC est supprim\xe9, le PV entre dans une phase de r\xe9cup\xe9ration selon sa politique de r\xe9cup\xe9ration (Retain, Recycle, Delete).\\n5. **Releasing**: Le PV est lib\xe9r\xe9 mais reste associ\xe9 au PVC jusqu\'\xe0 ce que la politique de r\xe9cup\xe9ration soit appliqu\xe9e.\\n6. **Recycling/Deleting**: Le PV est soit recycl\xe9 pour \xeatre r\xe9utilis\xe9, soit supprim\xe9.\\n\\n### Cycle de vie des PVC\\n\\n1. **Pending**: Le PVC est cr\xe9\xe9 et attend qu\'un PV correspondant soit disponible.\\n2. **Bound**: Le PVC est li\xe9 \xe0 un PV disponible.\\n3. **Using**: Le PVC est utilis\xe9 par un pod pour acc\xe9der au stockage.\\n4. **Released**: Le PVC est supprim\xe9 et le PV entre dans la phase de r\xe9cup\xe9ration.\\n\\n### Diagramme Mermaid\\n\\n```mermaid\\ngraph TD\\n  subgraph PV\\n    A[Provisioning] --\x3e B[Binding]\\n    B --\x3e C[Using]\\n    C --\x3e D[Reclaiming]\\n    D --\x3e E[Releasing]\\n    E --\x3e F[Recycling/Deleting]\\n  end\\n\\n  subgraph PVC\\n    G[Pending] --\x3e H[Bound]\\n    H --\x3e I[Using]\\n    I --\x3e J[Released]\\n  end\\n\\n  B -.-> H\\n  H -.-> B\\n  J -.-> D\\n```\\n\\n## StorageClass\\n\\nUne StorageClass est une ressource Kubernetes utilis\xe9e pour d\xe9finir les types de stockage disponibles dans le cluster. Elle permet de provisionner dynamiquement des PersistentVolumes en fonction des besoins sp\xe9cifiques des applications.\\n\\n### Provisionnement dynamique\\n\\nLe provisionnement dynamique permet de cr\xe9er automatiquement des PersistentVolumes (PVs) lorsque des PersistentVolumeClaims (PVCs) sont demand\xe9s par les pods. Cela simplifie la gestion du stockage en \xe9liminant la n\xe9cessit\xe9 de cr\xe9er manuellement des PVs. Pour utiliser le provisionnement dynamique, les administrateurs du cluster doivent d\xe9finir des StorageClasses qui sp\xe9cifient les types de stockage disponibles et les param\xe8tres de provisionnement.\\n\\n### Exemple de StorageClass\\n\\n```yaml\\napiVersion: storage.k8s.io/v1\\nkind: StorageClass\\nmetadata:\\n  name: my-storage-class\\nprovisioner: kubernetes.io/no-provisioner\\nvolumeBindingMode: WaitForFirstConsumer\\n```\\n\\n### Exemple de PersistentVolumeClaim utilisant une StorageClass\\n\\n```yaml\\napiVersion: v1\\nkind: PersistentVolumeClaim\\nmetadata:\\n  name: my-pvc\\nspec:\\n  accessModes:\\n    - ReadWriteOnce\\n  resources:\\n    requests:\\n      storage: 1Gi\\n  storageClassName: my-storage-class\\n```\\n\\nEn utilisant une StorageClass avec le provisionnement dynamique, Kubernetes cr\xe9era automatiquement un PV correspondant aux sp\xe9cifications du PVC lorsque celui-ci sera cr\xe9\xe9. Cela est \xe9galement possible on-premise, \xe0 condition que le cluster Kubernetes soit configur\xe9 avec un provisionneur de stockage compatible. Les administrateurs du cluster doivent s\'assurer que les StorageClasses sont correctement d\xe9finies pour le stockage on-premise.\\n\\n## Volume\\n\\nUn Volume Kubernetes est un r\xe9pertoire, potentiellement mont\xe9 \xe0 partir du stockage du n\u0153ud, partag\xe9 entre les conteneurs d\'un pod. Les volumes sont utilis\xe9s pour stocker des donn\xe9es de mani\xe8re temporaire ou persistante.\\n\\n### Exemple de Volume\\n\\n```yaml\\napiVersion: v1\\nkind: Pod\\nmetadata:\\n  name: my-pod\\nspec:\\n  containers:\\n    - name: my-container\\n      image: nginx:alpine\\n      volumeMounts:\\n        - mountPath: /usr/share/nginx/html\\n          name: my-volume\\n  volumes:\\n    - name: my-volume\\n      persistentVolumeClaim:\\n        claimName: my-pvc\\n```\\n\\n## Stockage statique et dynamique\\n\\nLe stockage dans Kubernetes peut \xeatre provisionn\xe9 de mani\xe8re statique ou dynamique.\\n\\n### Stockage statique\\n\\nLe stockage statique implique la cr\xe9ation manuelle de PersistentVolumes (PVs) par les administrateurs du cluster. Les PVs sont d\xe9finis \xe0 l\'avance et sont disponibles pour \xeatre r\xe9clam\xe9s par les PersistentVolumeClaims (PVCs). Cette m\xe9thode est utile lorsque des exigences sp\xe9cifiques de stockage doivent \xeatre respect\xe9es.\\n\\n### Stockage dynamique\\n\\nLe stockage dynamique permet de provisionner automatiquement des PersistentVolumes (PVs) en fonction des besoins des applications. Les administrateurs du cluster d\xe9finissent des StorageClasses qui sp\xe9cifient les types de stockage disponibles. Lorsqu\'un PersistentVolumeClaim (PVC) est cr\xe9\xe9, Kubernetes utilise la StorageClass pour provisionner dynamiquement un PV correspondant aux sp\xe9cifications du PVC. Cette m\xe9thode simplifie la gestion du stockage et permet une allocation plus flexible des ressources.\\n\\n## Conclusion\\n\\nLes concepts de stockage dans Kubernetes, tels que PersistentVolume, PersistentVolumeClaim, StorageClass et Volume, permettent de g\xe9rer efficacement le stockage des donn\xe9es dans les applications conteneuris\xe9es. En comprenant ces concepts, il est possible de tirer parti de la puissance de Kubernetes pour g\xe9rer le stockage des applications. \ud83d\udcca\\n\\nPour en savoir plus sur Kubernetes, consulter la [documentation officielle](https://kubernetes.io/fr/docs/concepts/)."},{"id":"/2025/01/01/devops-roadmap-2025","metadata":{"permalink":"/blog/2025/01/01/devops-roadmap-2025","source":"@site/blog/2025-01-01-devops-roadmap-2025.md","title":"DevOps Roadmap 2025","description":"Pr\xe9sentation de ma roadmap DevOps personnelle 2025","date":"2025-01-01T00:00:00.000Z","tags":[{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":1.98,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"DevOps Roadmap 2025","description":"Pr\xe9sentation de ma roadmap DevOps personnelle 2025","tags":["devops"]},"unlisted":false,"prevItem":{"title":"Kubernetes : Stockage","permalink":"/blog/2025/01/12/06-orchestration/k8s-storage"},"nextItem":{"title":"Proxy : Nginx","permalink":"/blog/2024/12/20/02-network/nginx"}},"content":"Voici un r\xe9sum\xe9 de ma roadmap DevOps personnelle pour 2025. Cette roadmap s\u2019appuie sur les r\xe9alisations de l\u2019ann\xe9e pr\xe9c\xe9dente et vise \xe0 approfondir l\u2019orchestration, l\u2019observabilit\xe9 et l\u2019Infrastructure as Code. Elle \xe9volue au fil des projets, des exp\xe9rimentations et des apprentissages partag\xe9s sur le blog.\\n\\n\x3c!--truncate--\x3e\\n\\n# DevOps Roadmap 2025\\n\\nimport IconTitle from \'@site/src/components/IconTitle\';\\n\\n![DevOps](/img/devops.png)\\n\\n## Roadmap 2025\\n\\n### <IconTitle logo=\\"skill-icons:kubernetes\\" name=\\"06 Orchestration de conteneurs - Kubernetes & Docker Swarm\\"/>\\n\\n[Orchestration](/blog/tags/orchestration) Ma\xeetrise des composants de base (Deployment, Service, ConfigMap, Secret, StatefulSet), utilisation avanc\xe9e de la CLI Kubernetes (kubectl), persistance des donn\xe9es avec les volumes, externalisation des configurations avec ConfigMap et Secret, gestion des acc\xe8s via Ingress (Nginx). Objectif\u202f: piloter des clusters multi-applications, automatiser le d\xe9ploiement et renforcer la s\xe9curit\xe9.\\n\\n### <IconTitle logo=\\"skill-icons:prometheus\\" name=\\"07 Monitoring & Observabilit\xe9\\"/>\\n\\n[Observabilit\xe9](/blog/tags/monitoring) Int\xe9gration de Grafana pour l\u2019analyse et la visualisation interactive, Prometheus pour la surveillance et l\u2019alerte, Loki pour la gestion centralis\xe9e des logs. Mise en place de dashboards, alertes et supervision multi-environnements.\\n\\n### <IconTitle logo=\\"skill-icons:terraform-light\\" name=\\"08 Infrastructure as Code\\"/>\\n\\n[Infrastructure as Code](/blog/tags/iac) Automatisation avanc\xe9e de la configuration et du d\xe9ploiement avec Ansible, exploration de Terraform pour la gestion d\u2019infrastructures cloud et on-premise, documentation des workflows et partage des bonnes pratiques.\\n\\n## Bilan 2024\\n\\n### <IconTitle logo=\\"skill-icons:linux-light\\" name=\\"02 OS & Linux\\"/>\\n\\n[Syst\xe8me & Linux](/blog/tags/linux) Les notions de r\xe9seau, s\xe9curit\xe9, configuration des pare-feu, \xe9quilibreurs de charge, proxies, HTTP/HTTPS et virtualisation ont \xe9t\xe9 approfondies et mises en \u0153uvre dans des projets d\u2019auto-h\xe9bergement et de s\xe9curisation d\u2019infrastructures. Voir [FervantFactory](/docs/projects/personnel/fervantfactory) et [delpeuch.net](/docs/projects/personnel/delpeuch-net).\\n\\n### <IconTitle logo=\\"skill-icons:docker\\" name=\\"03 Conten\xe9risation - Docker\\"/>\\n\\n[Conteneurisation](/blog/tags/containerization) D\xe9ploiement et supervision de stacks Docker Compose et Swarm, gestion centralis\xe9e des configurations, automatisation des mises \xe0 jour, documentation des architectures modulaires. Exp\xe9rimentation de l\u2019orchestration \xe0 l\u2019\xe9chelle domestique, avec un accent sur la reproductibilit\xe9 et la s\xe9curit\xe9. Voir [FervantFactory](/docs/projects/personnel/fervantfactory).\\n\\n### <IconTitle logo=\\"skill-icons:githubactions-light\\" name=\\"04 CI/CD Pipeline\\"/>\\n\\n[CI/CD](/blog/tags/cicd) Modernisation des pipelines CI/CD avec GitHub Actions, conception de workflows r\xe9utilisables, s\xe9curisation des acc\xe8s, documentation technique centralis\xe9e, publication automatique de releases/tags, support des runners personnalis\xe9s et matrices de jobs. Voir [CI/CD GitHub Actions](/docs/projects/professionnel/cicd) et [GitHub ARC Kubeadm](/docs/projects/professionnel/github-arc-kubeadm)."},{"id":"/2024/12/20/02-network/nginx","metadata":{"permalink":"/blog/2024/12/20/02-network/nginx","source":"@site/blog/02-network/2024-12-20-nginx.md","title":"Proxy : Nginx","description":"Pr\xe9sentation de Nginx, son but et ses exemples d\'utilisation dans la vie r\xe9elle.","date":"2024-12-20T00:00:00.000Z","tags":[{"inline":false,"label":"R\xe9seau","permalink":"/blog/tags/network"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":2.55,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Proxy : Nginx","description":"Pr\xe9sentation de Nginx, son but et ses exemples d\'utilisation dans la vie r\xe9elle.","tags":["network","devops"]},"unlisted":false,"prevItem":{"title":"DevOps Roadmap 2025","permalink":"/blog/2025/01/01/devops-roadmap-2025"},"nextItem":{"title":"Proxy : Proxy vs Reverse Proxy","permalink":"/blog/2024/12/20/02-network/proxy-vs-reverse-proxy"}},"content":"Nginx est un serveur web open-source con\xe7u pour g\xe9rer un grand nombre de connexions simultan\xe9es. Il couvre les fonctionnalit\xe9s de Nginx telles que l\'\xe9quilibrage de charge, le caching, la s\xe9curit\xe9 et la compression, ainsi que des exemples d\'utilisation dans la vie r\xe9elle.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que Nginx et pourquoi a-t-il \xe9t\xe9 cr\xe9\xe9 ?\\n\\nNginx est un serveur web open-source qui a \xe9t\xe9 cr\xe9\xe9 pour g\xe9rer un grand nombre de connexions simultan\xe9es. Il a \xe9t\xe9 con\xe7u pour \xeatre rapide, l\xe9ger et efficace. Nginx est souvent utilis\xe9 comme serveur web, mais il peut \xe9galement \xeatre utilis\xe9 comme proxy inverse, \xe9quilibrage de charge, et serveur de cache.\\n\\n### Exemples d\'utilisation de Nginx\\n\\nNginx est souvent utilis\xe9 pour servir des pages web statiques et dynamiques. Il est capable de g\xe9rer des milliers de connexions simultan\xe9es avec une faible utilisation de la m\xe9moire.\\n\\nNginx peut agir comme un proxy inverse pour distribuer les requ\xeates des clients \xe0 plusieurs serveurs backend. Cela permet de r\xe9partir la charge et d\'am\xe9liorer les performances.\\n\\nNginx peut \xeatre utilis\xe9 pour r\xe9partir les requ\xeates entrantes entre plusieurs serveurs, assurant ainsi une r\xe9partition \xe9quilibr\xe9e de la charge.\\n\\nNginx peut mettre en cache les r\xe9ponses des serveurs backend pour r\xe9duire la charge et am\xe9liorer les temps de r\xe9ponse.\\n\\n## Fonctionnalit\xe9s de Nginx\\n\\nL\'\xe9quilibrage de charge est une fonctionnalit\xe9 cl\xe9 de Nginx. Il permet de distribuer les requ\xeates entrantes entre plusieurs serveurs backend. Nginx prend en charge plusieurs algorithmes d\'\xe9quilibrage de charge, tels que le round-robin, le least connections, et l\'IP hash.\\n\\nNginx peut mettre en cache les r\xe9ponses des serveurs backend pour r\xe9duire la charge et am\xe9liorer les temps de r\xe9ponse. Le caching est particuli\xe8rement utile pour les contenus statiques qui ne changent pas fr\xe9quemment.\\n\\nNginx offre plusieurs fonctionnalit\xe9s de s\xe9curit\xe9, telles que la gestion des certificats SSL/TLS, la limitation du nombre de connexions, et la protection contre les attaques DDoS. En utilisant Nginx comme proxy inverse, vous pouvez \xe9galement masquer les d\xe9tails de votre infrastructure backend.\\n\\nNginx peut compresser les r\xe9ponses avant de les envoyer aux clients. Cela permet de r\xe9duire la quantit\xe9 de donn\xe9es transf\xe9r\xe9es et d\'am\xe9liorer les temps de chargement des pages. Nginx prend en charge plusieurs formats de compression, tels que gzip et brotli.\\n\\n## Configuration de Nginx\\n\\nLa configuration de Nginx se fait \xe0 l\'aide de fichiers de configuration. Voici un exemple de configuration simple pour un serveur web :\\n\\n```nginx\\nserver {\\n    listen 80;\\n    server_name example.com;\\n\\n    location / {\\n        root /var/www/html;\\n        index index.html index.htm;\\n    }\\n\\n    location /images/ {\\n        root /data;\\n    }\\n}\\n```\\n\\nDans cet exemple, Nginx \xe9coute sur le port 80 et sert les fichiers du r\xe9pertoire `/var/www/html` pour les requ\xeates \xe0 la racine. Les requ\xeates pour `/images/` sont servies \xe0 partir du r\xe9pertoire `/data`.\\n\\n## Conclusion\\n\\nNginx est un outil puissant et polyvalent qui peut \xeatre utilis\xe9 pour une vari\xe9t\xe9 de t\xe2ches, allant de la simple diffusion de contenu web \xe0 l\'\xe9quilibrage de charge et au caching. Sa flexibilit\xe9 et ses performances en font un choix populaire pour de nombreuses entreprises et d\xe9veloppeurs.\\n\\nPour en savoir plus sur Nginx, vous pouvez consulter la [documentation officielle](https://nginx.org/en/docs/)."},{"id":"/2024/12/20/02-network/proxy-vs-reverse-proxy","metadata":{"permalink":"/blog/2024/12/20/02-network/proxy-vs-reverse-proxy","source":"@site/blog/02-network/2024-12-20-proxy-vs-reverse-proxy.md","title":"Proxy : Proxy vs Reverse Proxy","description":"Explication de la diff\xe9rence entre un proxy et un reverse proxy, inspir\xe9e du transcript de la vid\xe9o \'Proxy vs Reverse Proxy vs Load Balancer | Simply Explained\'.","date":"2024-12-20T00:00:00.000Z","tags":[{"inline":false,"label":"R\xe9seau","permalink":"/blog/tags/network"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":5.04,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Proxy : Proxy vs Reverse Proxy","description":"Explication de la diff\xe9rence entre un proxy et un reverse proxy, inspir\xe9e du transcript de la vid\xe9o \'Proxy vs Reverse Proxy vs Load Balancer | Simply Explained\'.","tags":["network","devops"]},"unlisted":false,"prevItem":{"title":"Proxy : Nginx","permalink":"/blog/2024/12/20/02-network/nginx"},"nextItem":{"title":"Containerization vs Virtualization","permalink":"/blog/2024/12/20/03-containerization/difference-conteneurisation-virtualisation"}},"content":"Dans cet article, nous allons explorer la diff\xe9rence entre un proxy et un reverse proxy.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce qu\'un proxy ?\\n\\nUn proxy, \xe9galement connu sous le nom de proxy direct ou proxy de transfert, est un serveur qui agit comme un interm\xe9diaire entre un client (par exemple, un utilisateur ou un appareil) et un serveur de destination sur Internet. Voici un aper\xe7u d\xe9taill\xe9 de son fonctionnement :\\n\\n1. **Interception des requ\xeates** : Lorsqu\'un client souhaite acc\xe9der \xe0 une ressource sur Internet, il envoie une requ\xeate au proxy au lieu de se connecter directement au serveur de destination. Le proxy intercepte cette requ\xeate.\\n\\n2. **Filtrage et s\xe9curit\xe9** : Le proxy examine la requ\xeate pour s\'assurer qu\'elle respecte les politiques de s\xe9curit\xe9 et de filtrage d\xe9finies par l\'administrateur r\xe9seau. Il peut bloquer l\'acc\xe8s \xe0 certains sites web, filtrer les contenus inappropri\xe9s ou malveillants, et appliquer des r\xe8gles de s\xe9curit\xe9.\\n\\n3. **Anonymisation** : Le proxy peut masquer l\'adresse IP du client en utilisant sa propre adresse IP pour se connecter au serveur de destination. Cela permet de prot\xe9ger l\'identit\xe9 et la confidentialit\xe9 du client.\\n\\n4. **Mise en cache** : Le proxy peut mettre en cache les r\xe9ponses des serveurs de destination. Si un autre client demande la m\xeame ressource, le proxy peut fournir la r\xe9ponse mise en cache, ce qui r\xe9duit la charge sur le serveur de destination et am\xe9liore les temps de r\xe9ponse.\\n\\n5. **Transmission de la requ\xeate** : Si la requ\xeate est autoris\xe9e, le proxy la transmet au serveur de destination en utilisant sa propre adresse IP. Le serveur de destination r\xe9pond alors au proxy.\\n\\n6. **Retour de la r\xe9ponse** : Le proxy re\xe7oit la r\xe9ponse du serveur de destination, la filtre \xe0 nouveau si n\xe9cessaire, et la renvoie au client. Le client re\xe7oit ainsi la r\xe9ponse comme s\'il avait directement communiqu\xe9 avec le serveur de destination.\\n\\n### Exemple d\'utilisation d\'un proxy\\n\\nImaginez que vous planifiez un d\xeener dans un restaurant populaire, mais que vous ne voulez pas interagir directement avec le personnel. Vous avez donc un assistant personnel qui fait la r\xe9servation pour vous. Le personnel du restaurant ne communique qu\'avec votre assistant, pas directement avec vous. Dans ce sc\xe9nario, votre assistant personnel est un proxy.\\n\\nDans un contexte d\'entreprise, un administrateur peut configurer tout le trafic Internet des ordinateurs des employ\xe9s pour qu\'il passe par un proxy. Cela permet de prot\xe9ger le r\xe9seau interne de l\'entreprise en bloquant les sites web malveillants et en filtrant le trafic.\\n\\nUn proxy peut \xe9galement mettre en cache les r\xe9ponses des serveurs backend pour r\xe9duire la charge et am\xe9liorer les temps de r\xe9ponse. Par exemple, si un employ\xe9 regarde une vid\xe9o YouTube, le proxy peut mettre en cache cette vid\xe9o pour que les autres employ\xe9s puissent la regarder sans consommer de bande passante suppl\xe9mentaire.\\n\\n## Qu\'est-ce qu\'un reverse proxy ?\\n\\n\\nUn reverse proxy, \xe9galement connu sous le nom de proxy inverse, est un serveur qui se trouve devant les serveurs internes d\'une entreprise et g\xe8re les requ\xeates entrantes des clients. Voici un aper\xe7u d\xe9taill\xe9 de son fonctionnement :\\n\\n1. **R\xe9ception des requ\xeates** : Lorsqu\'un client envoie une requ\xeate pour acc\xe9der \xe0 une ressource sur un serveur interne, la requ\xeate est d\'abord re\xe7ue par le reverse proxy au lieu d\'\xeatre directement envoy\xe9e au serveur interne.\\n\\n2. **Distribution des requ\xeates** : Le reverse proxy examine la requ\xeate et la distribue au serveur interne appropri\xe9 en fonction de la capacit\xe9, de la charge et des r\xe8gles de routage d\xe9finies. Cela permet de r\xe9partir la charge de mani\xe8re \xe9quilibr\xe9e entre les serveurs internes.\\n\\n3. **S\xe9curit\xe9 et filtrage** : Le reverse proxy peut appliquer des politiques de s\xe9curit\xe9 pour filtrer les requ\xeates malveillantes, bloquer les attaques DDoS, et assurer le chiffrement SSL/TLS pour s\xe9curiser les communications entre les clients et les serveurs internes.\\n\\n4. **Mise en cache** : Le reverse proxy peut mettre en cache les r\xe9ponses des serveurs internes. Si un autre client demande la m\xeame ressource, le reverse proxy peut fournir la r\xe9ponse mise en cache, ce qui r\xe9duit la charge sur les serveurs internes et am\xe9liore les temps de r\xe9ponse.\\n\\n5. **Retour de la r\xe9ponse** : Le serveur interne r\xe9pond au reverse proxy, qui filtre \xe0 nouveau la r\xe9ponse si n\xe9cessaire, et la renvoie au client. Le client re\xe7oit ainsi la r\xe9ponse comme s\'il avait directement communiqu\xe9 avec le serveur interne.\\n\\n6. **Surveillance et journalisation** : Le reverse proxy peut surveiller et journaliser les requ\xeates et les r\xe9ponses pour des raisons de s\xe9curit\xe9, de d\xe9pannage et d\'analyse des performances.\\n\\n### Exemple d\'utilisation d\'un reverse proxy\\n\\nReprenons l\'analogie du restaurant. Lorsque vous arrivez au restaurant, au lieu de chercher une table vous-m\xeame, vous vous enregistrez \xe0 la r\xe9ception. Le r\xe9ceptionniste vous montre la table appropri\xe9e. Ici, le r\xe9ceptionniste est un reverse proxy.\\n\\nUn reverse proxy peut \xe9galement agir comme un bouclier pour prot\xe9ger les serveurs internes en filtrant les requ\xeates et en assurant le chiffrement SSL. Il peut \xe9galement mettre en cache les r\xe9ponses pour acc\xe9l\xe9rer les temps de r\xe9ponse aux clients.\\n\\nUn reverse proxy peut \xe9galement fournir des fonctionnalit\xe9s d\'\xe9quilibrage de charge. Par exemple, si un serveur est surcharg\xe9, le reverse proxy peut rediriger les requ\xeates vers un autre serveur moins occup\xe9. Cela permet d\'assurer une r\xe9partition \xe9quilibr\xe9e de la charge et d\'am\xe9liorer les performances globales du syst\xe8me.\\n\\n## Diff\xe9rences cl\xe9s entre un proxy et un reverse proxy\\n\\n- **Fonctionnalit\xe9** : Un proxy agit comme un interm\xe9diaire pour les requ\xeates sortantes, tandis qu\'un reverse proxy g\xe8re les requ\xeates entrantes.\\n- **S\xe9curit\xe9** : Les deux types de proxy offrent des fonctionnalit\xe9s de s\xe9curit\xe9, mais un reverse proxy prot\xe8ge les serveurs internes en filtrant les requ\xeates entrantes.\\n- **Caching** : Les deux types de proxy peuvent mettre en cache les r\xe9ponses, mais un reverse proxy le fait pour acc\xe9l\xe9rer les temps de r\xe9ponse aux clients.\\n\\nEn r\xe9sum\xe9, un proxy et un reverse proxy ont des r\xf4les diff\xe9rents mais compl\xe9mentaires dans la gestion du trafic r\xe9seau. Un proxy prot\xe8ge les utilisateurs en filtrant le trafic sortant, tandis qu\'un reverse proxy prot\xe8ge les serveurs en g\xe9rant les requ\xeates entrantes.\\n\\n## Sch\xe9ma r\xe9capitulatif\\n\\n![Sch\xe9ma r\xe9capitulatif](https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fwqces5nwe4hb4bydyd13.png)"},{"id":"/2024/12/20/03-containerization/difference-conteneurisation-virtualisation","metadata":{"permalink":"/blog/2024/12/20/03-containerization/difference-conteneurisation-virtualisation","source":"@site/blog/03-containerization/2024-12-20-difference-conteneurisation-virtualisation.md","title":"Containerization vs Virtualization","description":"Comparaison entre Docker et les machines virtuelles (VM) en termes de taille d\'image, de vitesse et de compatibilit\xe9.","date":"2024-12-20T00:00:00.000Z","tags":[{"inline":false,"label":"Conteneurisation","permalink":"/blog/tags/containerization"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":1.38,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Containerization vs Virtualization","description":"Comparaison entre Docker et les machines virtuelles (VM) en termes de taille d\'image, de vitesse et de compatibilit\xe9.","tags":["containerization","devops"]},"unlisted":false,"prevItem":{"title":"Proxy : Proxy vs Reverse Proxy","permalink":"/blog/2024/12/20/02-network/proxy-vs-reverse-proxy"},"nextItem":{"title":"Docker : meilleures pratiques","permalink":"/blog/2024/12/20/03-containerization/docker-best-practices"}},"content":"Docker et les machines virtuelles (VM) sont des outils de virtualisation, mais ils fonctionnent diff\xe9remment. Docker virtualise la couche des applications du syst\xe8me d\'exploitation, utilisant le noyau de l\'h\xf4te, tandis qu\'une VM virtualise l\'ensemble du syst\xe8me d\'exploitation, incluant son propre noyau et sa couche d\'applications. Cette diff\xe9rence entra\xeene plusieurs distinctions majeures.\\n\\n\x3c!--truncate--\x3e\\n\\nDocker et les machines virtuelles (VM) sont des outils de virtualisation, mais ils fonctionnent diff\xe9remment. Docker virtualise la couche des applications du syst\xe8me d\'exploitation, utilisant le noyau de l\'h\xf4te, tandis qu\'une VM virtualise l\'ensemble du syst\xe8me d\'exploitation, incluant son propre noyau et sa couche d\'applications. Cette diff\xe9rence entra\xeene plusieurs distinctions majeures.\\n\\nLes images Docker sont beaucoup plus petites et rapides \xe0 t\xe9l\xe9charger que les images de VM, car elles n\'ont qu\'une seule couche \xe0 impl\xe9menter. Les images Docker sont g\xe9n\xe9ralement de quelques m\xe9gaoctets, tandis que les images de VM peuvent atteindre plusieurs gigaoctets.\\n\\nLes conteneurs Docker d\xe9marrent beaucoup plus rapidement que les VM, car ils n\'ont besoin de d\xe9marrer que la couche des applications, contrairement aux VM qui doivent d\xe9marrer l\'ensemble du syst\xe8me d\'exploitation.\\n\\nDocker pr\xe9sente des probl\xe8mes de compatibilit\xe9. Une image de VM de n\'importe quel syst\xe8me d\'exploitation peut \xeatre ex\xe9cut\xe9e sur n\'importe quel h\xf4te, mais ce n\'est pas le cas pour Docker. Par exemple, une image Docker bas\xe9e sur Linux ne peut pas utiliser le noyau Windows directement. Cependant, Docker Desktop permet de contourner ce probl\xe8me en utilisant une couche hyperviseur avec une distribution Linux l\xe9g\xe8re pour fournir le noyau n\xe9cessaire.\\n\\nEn r\xe9sum\xe9, Docker est plus l\xe9ger et rapide, mais moins compatible que les VM. Docker Desktop permet de d\xe9velopper localement sur Windows ou Mac en ex\xe9cutant des conteneurs bas\xe9s sur Linux."},{"id":"/2024/12/20/03-containerization/docker-best-practices","metadata":{"permalink":"/blog/2024/12/20/03-containerization/docker-best-practices","source":"@site/blog/03-containerization/2024-12-20-docker-best-practices.md","title":"Docker : meilleures pratiques","description":"L\'adoption de Docker augmente constamment et beaucoup le connaissent, mais tout le monde n\'utilise pas Docker selon les meilleures pratiques.","date":"2024-12-20T00:00:00.000Z","tags":[{"inline":false,"label":"Conteneurisation","permalink":"/blog/tags/containerization"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":4.47,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Docker : meilleures pratiques","description":"L\'adoption de Docker augmente constamment et beaucoup le connaissent, mais tout le monde n\'utilise pas Docker selon les meilleures pratiques.","tags":["containerization","devops"]},"unlisted":false,"prevItem":{"title":"Containerization vs Virtualization","permalink":"/blog/2024/12/20/03-containerization/difference-conteneurisation-virtualisation"},"nextItem":{"title":"Docker : conteneurs","permalink":"/blog/2024/12/20/03-containerization/docker-containers"}},"content":"\x3c!--truncate--\x3e\\n\\n## Utilisez une image Docker officielle et v\xe9rifi\xe9e comme image de base, chaque fois disponible\\n\\nDisons que vous d\xe9veloppez une application Node.js et que vous souhaitez la cr\xe9er et l\'ex\xe9cuter en tant qu\'image Docker.\\n\\nAu lieu de prendre une image du syst\xe8me d\'exploitation de base et d\'installer Node.js, NPM et tous les autres outils dont vous avez besoin pour votre application, utilisez l\'image de node officiel pour votre application.\\n\\n## Utilisez des versions d\'image docker sp\xe9cifiques\\n\\nD\'accord, nous avons donc s\xe9lectionn\xe9 l\'image de base, mais maintenant lorsque nous construisons notre image d\'applications \xe0 partir de ce Dockerfile, il utilisera toujours la derni\xe8re balise de l\'image de n\u0153ud.\\n\\nAinsi, au lieu d\'une \xe9tiquette d\'image al\xe9atoire, vous souhaitez fixer la version, et tout comme vous d\xe9ployez votre propre application avec une version sp\xe9cifique, vous souhaitez utiliser l\'image officielle avec une version sp\xe9cifique.\\n\\n## Utiliser des images officielles de petite taille\\n\\nLors du choix d\'une image Node.js, vous verrez qu\'il y a en fait plusieurs images officielles. Non seulement avec diff\xe9rents num\xe9ros de version mais aussi avec diff\xe9rentes distributions de syst\xe8mes d\'exploitation:\\n\\n1) Taille de l\'image : si l\'image est bas\xe9e sur une distribution de syst\xe8me d\'exploitation \xe0 part enti\xe8re comme Ubuntu ou Centos, vous aurez un tas d\'outils d\xe9j\xe0 emball\xe9s dans l\'image. Ainsi, la taille de l\'image sera plus grande, mais vous n\'avez pas besoin de la plupart de ces outils dans vos images d\'application.\\n\\n2) Probl\xe8me de s\xe9curit\xe9 : avec de nombreux outils install\xe9s \xe0 l\'int\xe9rieur, vous devez consid\xe9rer l\'aspect de s\xe9curit\xe9. Parce que ces images de base contiennent g\xe9n\xe9ralement [des centaines de vuln\xe9rabilit\xe9s connues](https://snyk.io/blog/openSourcesEcurity-2020Survey/) et cr\xe9ent essentiellement une plus grande surface d\'attaque \xe0 votre image d\'application.\\n\\nAinsi, la meilleure pratique ici serait de s\xe9lectionner une image avec une version sp\xe9cifique bas\xe9e sur une distribution plus maigre comme Alpine.\\n\\n## Optimiser la mise en cache pour les couches d\'image lors de la construction d\'une image\\n\\n1) Que sont les layer d\'image? Une image Docker est construite sur la base d\'un dockerfile.\\n\\nEt dans un dockerfile, chaque commande ou instruction cr\xe9e un layer d\'image.\\n\\nAinsi, lorsque nous utilisons une image de base d\'alpine, il a d\xe9j\xe0 des layers, car il a d\xe9j\xe0 \xe9t\xe9 construit en utilisant son propre dockerfile. Dans notre dockerfile, nous avons quelques autres commandes qui ajouteront chacune un nouveau layer \xe0 cette image.\\n\\nAinsi, lorsque vous reconstruisez votre image, si votre Dockerfile n\'a pas chang\xe9, Docker n\'utilisera que les layers en cache pour construire l\'image.\\n\\nAvantages des layers d\'image en cache:\\n\\n- Contruction d\'image plus rapide\\n- Push et pull plus rapides de nouvelles versions d\'image: Si je pull une nouvelle version d\'image de la m\xeame application et, disons, 2 nouveaux layers ont \xe9t\xe9 ajout\xe9es dans la nouvelle version: seule la nouvelle version des layers ajout\xe9es seront t\xe9l\xe9charg\xe9es Les autres sont d\xe9j\xe0 mis en cache localement par Docker.\\n\\nOptimiser la mise en cache : une fois qu\'un layer change, tous les layers suivants doivent \xe9galement \xeatre recr\xe9\xe9es. En d\'autres termes: lorsque vous modifiez le contenu d\'une ligne dans le dockerfile, les caches de toutes les lignes ou layers suivantes seront invalid\xe9s.\\n\\nAinsi, la r\xe8gle ici et la meilleure pratique est: placez vos commandes dans le Dockerfile du moins au plus fr\xe9quemment modif\xe9.\\n\\n## \xe0 l\'aide d\'un fichier .dockerignore\\n\\nC\'est assez simple. Nous cr\xe9ons simplement ce fichier .dockerignore et r\xe9pertorions tous les fichiers et dossiers que nous voulons \xeatre ignor\xe9s, et lors de la cr\xe9ation de l\'image, Docker examinera le contenu et ignorera tout ce qui est sp\xe9cifi\xe9 \xe0 l\'int\xe9rieur.\\n\\n## Utilisez des versions multi-\xe9tages\\n\\nMaintenant, disons qu\'il existe un outil dans votre projet dont vous avez besoin pour construire l\'image mais vous n\'en avez pas besoin dans l\'image finale pour ex\xe9cuter leapplication.\\n\\nSupposons que vous conserviez ces artefacts dans votre image finale, m\xeame s\'ils sont absolument inutiles pour ex\xe9cuter l\'application. Dans ce cas, cela entra\xeenera \xe0 nouveau une augmentation de la taille de l\'image et une augmentation de la surface d\'attaque.\\n\\nPour cela, vous pouvez utiliser ce qu\'on appelle les constructions \xe0 plusieurs \xe9tages\\n\\nLa fonction de construction en plusieurs \xe9tapes vous permet d\'utiliser plusieurs images temporaires pendant le processus de construction, mais ne conserve que la derni\xe8re image comme artefact final.\\n\\n## Utilisez l\'utilisateur le moins privil\xe9gi\xe9\\n\\nMaintenant, lorsque nous cr\xe9ons cette image et que nous l\'ex\xe9cutons finalement en tant que conteneur, quel utilisateur du syst\xe8me d\'exploitation sera utilis\xe9 pour d\xe9marrer l\'application \xe0 l\'int\xe9rieur? Par d\xe9faut, lorsqu\'un DockerFile ne sp\xe9cifie pas un utilisateur, il utilise un utilisateur root. Mais en r\xe9alit\xe9, il n\'y a surtout aucune raison d\'ex\xe9cuter des conteneurs avec des privil\xe8ges root.\\n\\nCela introduit essentiellement un probl\xe8me de s\xe9curit\xe9 car lorsque le conteneur commence sur l\'h\xf4te, il aura potentiellement un acc\xe8s root sur l\'h\xf4te Docker.\\n\\nPour \xe9viter cela, la meilleure pratique consiste \xe0 cr\xe9er simplement un utilisateur d\xe9di\xe9 et un groupe d\xe9di\xe9 dans l\'image Docker pour ex\xe9cuter l\'application et \xe9galement ex\xe9cuter l\'application \xe0 l\'int\xe9rieur du conteneur avec cet utilisateur.\\n\\n## Scannez vos images pour les vuln\xe9rabilit\xe9s de s\xe9curit\xe9\\n\\nEnfin, comment s\'assurer et valider que l\'image que vous construisez a peu ou pas de vuln\xe9rabilit\xe9s de s\xe9curit\xe9 ?\\n\\nLa meilleure pratique est, une fois que vous avez construit l\'image, la scannez pour des vuln\xe9rabilit\xe9s de s\xe9curit\xe9 \xe0 l\'aide de la commande docker scan.\\n\\nEn arri\xe8re-plan, Docker utilise en fait un service appel\xe9 SNYK pour faire la num\xe9risation de la vuln\xe9rabilit\xe9 des images. Le scan utilise une base de donn\xe9es de vuln\xe9rabilit\xe9s, qui est constamment mise \xe0 jour."},{"id":"/2024/12/20/03-containerization/docker-containers","metadata":{"permalink":"/blog/2024/12/20/03-containerization/docker-containers","source":"@site/blog/03-containerization/2024-12-20-docker-containers.md","title":"Docker : conteneurs","description":"Pr\xe9sentation des conteneurs Docker, leur fonctionnement et des exemples d\'utilisation.","date":"2024-12-20T00:00:00.000Z","tags":[{"inline":false,"label":"Conteneurisation","permalink":"/blog/tags/containerization"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":2.42,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Docker : conteneurs","description":"Pr\xe9sentation des conteneurs Docker, leur fonctionnement et des exemples d\'utilisation.","tags":["containerization","devops"]},"unlisted":false,"prevItem":{"title":"Docker : meilleures pratiques","permalink":"/blog/2024/12/20/03-containerization/docker-best-practices"},"nextItem":{"title":"Docker","permalink":"/blog/2024/12/20/03-containerization/docker"}},"content":"Les conteneurs Docker sont des unit\xe9s logicielles l\xe9g\xe8res et portables qui encapsulent une application et ses d\xe9pendances dans une image. Ces images sont compos\xe9es de plusieurs couches, souvent bas\xe9es sur une distribution Linux l\xe9g\xe8re comme Alpine, pour minimiser la taille. Les conteneurs permettent de maintenir des applications isol\xe9es et coh\xe9rentes, ind\xe9pendamment de l\'environnement d\'ex\xe9cution.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce qu\'un conteneur Docker ?\\n\\nUn conteneur Docker est une unit\xe9 logicielle l\xe9g\xe8re et portable qui encapsule une application et ses d\xe9pendances dans une image. Ces images sont compos\xe9es de plusieurs couches, souvent bas\xe9es sur une distribution Linux l\xe9g\xe8re comme Alpine, pour minimiser la taille. Les conteneurs permettent de maintenir des applications isol\xe9es et coh\xe9rentes, ind\xe9pendamment de l\'environnement d\'ex\xe9cution.\\n\\n### Structure d\'un conteneur Docker\\n\\nUn conteneur Docker est compos\xe9 de plusieurs couches d\'images empil\xe9es les unes sur les autres. \xc0 la base de la plupart des conteneurs, on trouve une image Linux, souvent Alpine en raison de sa petite taille. Les couches sup\xe9rieures contiennent les d\xe9pendances et l\'application elle-m\xeame. Cette structure en couches permet de r\xe9utiliser les couches communes entre plusieurs conteneurs, r\xe9duisant ainsi la taille et le temps de t\xe9l\xe9chargement.\\n\\n### Diff\xe9rence entre une image Docker et un conteneur Docker\\n\\nUne image Docker est un package statique qui contient tout ce dont une application a besoin pour fonctionner : le code, les biblioth\xe8ques, les d\xe9pendances et les configurations. C\'est un mod\xe8le pr\xeat \xe0 \xeatre ex\xe9cut\xe9. En revanche, un conteneur Docker est une instance en cours d\'ex\xe9cution de cette image. Lorsque vous d\xe9marrez un conteneur, Docker utilise l\'image pour cr\xe9er un environnement isol\xe9 o\xf9 l\'application peut s\'ex\xe9cuter. En d\'autres termes, une image est un mod\xe8le, tandis qu\'un conteneur est une instance active de ce mod\xe8le.\\n\\n## Commandes Docker de base\\n\\nVoici quelques commandes Docker de base pour g\xe9rer les conteneurs :\\n\\n- `docker run` : Cette commande permet de cr\xe9er et de d\xe9marrer un conteneur \xe0 partir d\'une image Docker. Par exemple, `docker run redis` d\xe9marre un conteneur Redis.\\n- `docker ps` : Cette commande affiche la liste des conteneurs en cours d\'ex\xe9cution. Par exemple, `docker ps` montre tous les conteneurs actifs.\\n- `docker stop` : Cette commande arr\xeate un conteneur en cours d\'ex\xe9cution. Par exemple, `docker stop <container_id>` arr\xeate le conteneur sp\xe9cifi\xe9.\\n- `docker start` : Cette commande red\xe9marre un conteneur arr\xeat\xe9. Par exemple, `docker start <container_id>` red\xe9marre le conteneur sp\xe9cifi\xe9.\\n\\n## Exemple pratique : Utilisation de PostgreSQL avec Docker\\n\\nPour illustrer l\'utilisation des conteneurs Docker, prenons l\'exemple de PostgreSQL. En utilisant Docker Hub, un d\xe9p\xf4t public d\'images Docker, on peut rechercher et t\xe9l\xe9charger une version sp\xe9cifique de PostgreSQL. Par exemple, pour obtenir la version 9.6, il suffit d\'ex\xe9cuter la commande `docker pull` suivie de `docker run` pour d\xe9marrer le conteneur. Docker t\xe9l\xe9charge les couches n\xe9cessaires et d\xe9marre l\'application automatiquement.\\n\\n```bash\\n# Rechercher l\'image officielle de PostgreSQL sur Docker Hub\\ndocker search postgres\\n\\n# T\xe9l\xe9charger l\'image de PostgreSQL version 9.6\\ndocker pull postgres:9.6\\n\\n# D\xe9marrer un conteneur PostgreSQL avec la version 9.6\\ndocker run --name my-postgres -e POSTGRES_PASSWORD=mysecretpassword -d postgres:9.6\\n```"},{"id":"/2024/12/20/03-containerization/docker","metadata":{"permalink":"/blog/2024/12/20/03-containerization/docker","source":"@site/blog/03-containerization/2024-12-20-docker.md","title":"Docker","description":"Docker est un outil open source qui permet aux d\xe9veloppeurs de cr\xe9er, d\xe9ployer, ex\xe9cuter, mettre \xe0 jour et g\xe9rer les conteneurs.","date":"2024-12-20T00:00:00.000Z","tags":[{"inline":false,"label":"Conteneurisation","permalink":"/blog/tags/containerization"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":5.09,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Docker","description":"Docker est un outil open source qui permet aux d\xe9veloppeurs de cr\xe9er, d\xe9ployer, ex\xe9cuter, mettre \xe0 jour et g\xe9rer les conteneurs.","tags":["containerization","devops"]},"unlisted":false,"prevItem":{"title":"Docker : conteneurs","permalink":"/blog/2024/12/20/03-containerization/docker-containers"},"nextItem":{"title":"Registry : GitHub GHCR","permalink":"/blog/2024/12/20/03-containerization/ghrc"}},"content":"Docker est de plus en plus populaire car il r\xe9sout des probl\xe8mes courants dans le d\xe9veloppement logiciel, en particulier ceux li\xe9s \xe0 la configuration de l\'environnement et \xe0 la compatibilit\xe9. Les applications modernes utilisent souvent une combinaison de diff\xe9rentes technologies, chacune avec des d\xe9pendances de version sp\xe9cifiques. Ces applications doivent fonctionner de mani\xe8re coh\xe9rente dans divers environnements (d\xe9veloppement, test, production), qui peuvent diff\xe9rer en termes de syst\xe8me d\'exploitation, de version et de mat\xe9riel. Sans Docker, chaque environnement doit \xeatre configur\xe9 avec les versions correctes des services, ce qui entra\xeene des probl\xe8mes de compatibilit\xe9 et des configurations complexes.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce qu\'un conteneur et quels probl\xe8mes r\xe9sout-il?\\n\\nUn conteneur est un **moyen de packager des applications** avec tout ce dont ils ont besoin \xe0 l\'int\xe9rieur de ce package, y compris toutes ses d\xe9pendances et toutes les configurations n\xe9cessaires.\\n\\nLe package est portable comme tout autre artefact, et ce package peut \xeatre facilement partag\xe9 et d\xe9plac\xe9 entre une \xe9quipe de d\xe9veloppement ou une \xe9quipe de d\xe9veloppement et d\'op\xe9rations.\\n\\nLa portabilit\xe9 des conteneurs, ainsi que tout ce qui est packag\xe9 dans un **environnement isol\xe9**, lui donne des avantages qui rendent le processus de d\xe9veloppement et de d\xe9ploiement plus efficace.\\n\\n### Probl\xe8mes r\xe9solus par Docker\\n\\nDocker est de plus en plus populaire car il r\xe9sout des probl\xe8mes courants dans le d\xe9veloppement logiciel, en particulier ceux li\xe9s \xe0 la configuration de l\'environnement et \xe0 la compatibilit\xe9. Les applications modernes utilisent souvent une combinaison de diff\xe9rentes technologies, chacune avec des d\xe9pendances de version sp\xe9cifiques. Ces applications doivent fonctionner de mani\xe8re coh\xe9rente dans divers environnements (d\xe9veloppement, test, production), qui peuvent diff\xe9rer en termes de syst\xe8me d\'exploitation, de version et de mat\xe9riel. Sans Docker, chaque environnement doit \xeatre configur\xe9 avec les versions correctes des services, ce qui entra\xeene des probl\xe8mes de compatibilit\xe9 et des configurations complexes.\\n\\nLes principaux probl\xe8mes que Docker r\xe9sout incluent :\\n1. La compatibilit\xe9 des services avec le syst\xe8me d\'exploitation sous-jacent et ses biblioth\xe8ques.\\n2. La gestion des diff\xe9rentes versions des services et de leurs d\xe9pendances.\\n3. La simplification du processus de configuration pour les nouveaux d\xe9veloppeurs.\\n\\nLa solution de Docker consiste \xe0 regrouper chaque service avec ses d\xe9pendances syst\xe8me requises dans des conteneurs isol\xe9s. Cela permet de changer des composants sans affecter les autres services et de modifier le syst\xe8me d\'exploitation sous-jacent sans impacter les services. Docker garantit que les applications fonctionnent de mani\xe8re coh\xe9rente dans diff\xe9rents environnements, \xe9vitant ainsi le probl\xe8me du \\"\xe7a fonctionne sur ma machine\\".\\n\\nDe plus, Docker fournit des images pr\xeates \xe0 l\'emploi pour divers environnements dans son d\xe9p\xf4t officiel, ce qui facilite la configuration et l\'ex\xe9cution des services localement pour les d\xe9veloppeurs. Par exemple, les d\xe9veloppeurs peuvent r\xe9cup\xe9rer une version sp\xe9cifique d\'une image de base de donn\xe9es Postgres et l\'ex\xe9cuter avec une seule commande. Cette flexibilit\xe9 s\'\xe9tend \xe0 l\'ex\xe9cution de plusieurs versions du m\xeame service pour diff\xe9rentes applications.\\n\\nEn r\xe9sum\xe9, Docker simplifie la configuration des environnements, assure la compatibilit\xe9 et offre une flexibilit\xe9 dans la gestion des services et de leurs d\xe9pendances.\\n\\n## D\xe9veloppement d\'applications avant / apr\xe8s conteneur\\n\\nVoyons maintenant comment les conteneurs am\xe9liorent le processus de d\xe9veloppement par des exemples sp\xe9cifiques.\\n\\nComment avons-nous d\xe9velopp\xe9 des applications avant les conteneurs?\\n\\nHabituellement, lorsque vous avez une \xe9quipe de d\xe9veloppeurs travaillant sur une application, vous devez installer directement la plupart des services sur votre syst\xe8me d\'exploitation.\\n\\nChaque d\xe9veloppeur de l\'\xe9quipe devrait alors aller installer les binaires de ces services, les configurer et les ex\xe9cuter sur son environnement de d\xe9veloppement local. Le processus d\'installation sera diff\xe9rent en fonction du syst\xe8me d\'exploitation qu\'ils utilisent.\\n\\nVous avez donc quelques commandes \xe0 ex\xe9cuter, et les **chances qu\'une erreur se produise sont \xe9lev\xe9es**, en raison du nombre d\'\xe9tapes n\xe9cessaires pour installer chaque service.\\n\\nMaintenant, voyons comment les conteneurs r\xe9solvent certains de ces probl\xe8mes.\\n\\nVous n\'avez pas \xe0 installer des services directement sur votre syst\xe8me d\'exploitation, car le conteneur poss\xe8de **sa propre couche de syst\xe8me d\'exploitation isol\xe9e** avec une image de base Linux.\\n\\nVous avez tout packag\xe9 dans un environnement isol\xe9, en tant que d\xe9veloppeur, vous n\'avez pas chercher les binaires \xe0 t\xe9l\xe9charger sur votre machine. Au lieu de cela, vous allez consulter le registre de conteneurs pour trouver le conteneur sp\xe9cifique \xe0 votre application et le t\xe9l\xe9charger sur votre machine locale.\\n\\n## D\xe9ploiement d\'application avant / apr\xe8s conteneur\\n\\n### Avant les conteneurs\\n\\nUn processus de d\xe9ploiement traditionnel ressemblera \xe0 ceci:\\n\\nL\'\xe9quipe de d\xe9veloppeur cr\xe9era des artefacts, qui sont essentiellement des fichiers, ainsi que des instructions sur l\'installation et les configurer sur le serveur. Tous ces artefacts et instructions seront fournis par l\'\xe9quipe de d\xe9veloppement:\\n\\n![alt text](/img/image.png)\\n\\nL\'\xe9quipe de d\xe9veloppement donnerait donc ces artefacts \xe0 l\'\xe9quipe des op\xe9rations, et l\'\xe9quipe d\'op\xe9ration mettrait en place les environnements pour d\xe9ployer ces applications:\\n\\n![Texte alt](/img/image-1.png)\\n\\n- **D\xe9pendances externes sur le syst\xe8me d\'exploitation du serveur**: Le probl\xe8me avec cette approche est que vous devez d\'abord configurer tout et tout installer directement sur le syst\xe8me d\'exploitation du serveur. Cela pourrait entra\xeener des conflits avec les versions de d\xe9pendance.\\n- **Mauvaise communication**: un autre probl\xe8me qui pourrait r\xe9sulter de ce processus est un malentendu entre l\'\xe9quipe de d\xe9veloppement et les op\xe9rations. Parce que tout est dans un guide textuel, il pourrait y avoir des cas, o\xf9 les d\xe9veloppeurs manquent de mentionner certains points critiques sur la configuration et en cas d\'\xe9chec, l\'\xe9quipe d\'op\xe9rations doit retourner aux d\xe9veloppeurs et demander plus de d\xe9tails.\\n\\n### Avec les Conteneurs\\n\\nAvec les conteneurs, ce processus est simplifi\xe9, car maintenant les d\xe9veloppeurs et les op\xe9rations fonctionnent dans une \xe9quipe pour former toutes les d\xe9pendances de configuration dans l\'application.\\n\\n![Texte alt](/img/image-2.png)\\n\\nCela signifie que si vous utilisez un conteneur Docker, vous n\'avez pas besoin de configurer quoi que ce soit directement sur le serveur, car tout est d\xe9j\xe0 encapsul\xe9 dans le conteneur. Au lieu de cela, il vous suffit d\'ex\xe9cuter une commande docker qui r\xe9cup\xe8re le conteneur que vous avez stock\xe9 dans le registre, puis l\'ex\xe9cute.\\n\\nC\'est donc beaucoup plus simple et aucune configuration environnementale n\'est n\xe9cessaire sur le serveur. La seule chose bien s\xfbr est que vous devez installer et configurer le runtime docker sur le serveur avant de pouvoir y ex\xe9cuter des conteneurs. Mais ce n\'est qu\'un effort unique."},{"id":"/2024/12/20/03-containerization/ghrc","metadata":{"permalink":"/blog/2024/12/20/03-containerization/ghrc","source":"@site/blog/03-containerization/2024-12-20-ghrc.md","title":"Registry : GitHub GHCR","description":"GitHub Container Registry (GHCR) est un service d\'h\xe9bergement de packages logiciels propos\xe9 par GitHub, permettant aux utilisateurs de stocker des packages priv\xe9s ou publics et de les utiliser comme d\xe9pendances dans leurs projets. Compatible avec plusieurs langages de programmation, GitHub Packages propose des registres pour des gestionnaires de packages tels que npm, RubyGems, Maven, Gradle, Docker, et NuGet. L\'authentification sur GitHub Packages se fait exclusivement via un \\"personal access token (classic)\\". Les utilisateurs doivent disposer de ce token pour effectuer des op\xe9rations telles que la publication, l\'installation et la suppression de packages, qu\'ils soient publics, priv\xe9s ou internes. Pour les packages priv\xe9s, GitHub Packages applique des limites de stockage et de transfert de donn\xe9es en fonction du plan du compte. La gestion des packages peut \xeatre r\xe9alis\xe9e \xe0 travers l\'interface utilisateur GitHub ou via l\'API REST. Des webhooks peuvent \xe9galement \xeatre configur\xe9s pour suivre des \xe9v\xe9nements li\xe9s aux packages, comme la publication ou la mise \xe0 jour.","date":"2024-12-20T00:00:00.000Z","tags":[{"inline":false,"label":"Conteneurisation","permalink":"/blog/tags/containerization"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":4.21,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Registry : GitHub GHCR","tags":["containerization","devops"]},"unlisted":false,"prevItem":{"title":"Docker","permalink":"/blog/2024/12/20/03-containerization/docker"},"nextItem":{"title":"GitHub Actions : action r\xe9utilisable","permalink":"/blog/2024/12/20/04-ci-cd/action"}},"content":"GitHub Container Registry (GHCR) est un service d\'h\xe9bergement de packages logiciels propos\xe9 par GitHub, permettant aux utilisateurs de stocker des packages priv\xe9s ou publics et de les utiliser comme d\xe9pendances dans leurs projets. Compatible avec plusieurs langages de programmation, GitHub Packages propose des registres pour des gestionnaires de packages tels que npm, RubyGems, Maven, Gradle, Docker, et NuGet. L\'authentification sur GitHub Packages se fait exclusivement via un \\"personal access token (classic)\\". Les utilisateurs doivent disposer de ce token pour effectuer des op\xe9rations telles que la publication, l\'installation et la suppression de packages, qu\'ils soient publics, priv\xe9s ou internes. Pour les packages priv\xe9s, GitHub Packages applique des limites de stockage et de transfert de donn\xe9es en fonction du plan du compte. La gestion des packages peut \xeatre r\xe9alis\xe9e \xe0 travers l\'interface utilisateur GitHub ou via l\'API REST. Des webhooks peuvent \xe9galement \xeatre configur\xe9s pour suivre des \xe9v\xe9nements li\xe9s aux packages, comme la publication ou la mise \xe0 jour.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que GitHub GHCR?\\n\\nGitHub Container Registry (GHCR) est un service d\'h\xe9bergement de conteneurs Docker propos\xe9 par GitHub. Il permet aux utilisateurs de stocker, g\xe9rer et distribuer des images Docker en toute s\xe9curit\xe9. GHCR est int\xe9gr\xe9 \xe0 GitHub, ce qui facilite l\'utilisation des conteneurs dans les workflows de d\xe9veloppement et de d\xe9ploiement.\\n\\n## Pourquoi utiliser GitHub GHCR?\\n\\nL\'utilisation de GitHub GHCR pr\xe9sente plusieurs avantages :\\n\\n1. **S\xe9curit\xe9** : GHCR offre des fonctionnalit\xe9s de s\xe9curit\xe9 avanc\xe9es, telles que l\'authentification et l\'autorisation bas\xe9es sur les tokens d\'acc\xe8s personnels (PAT). Les images peuvent \xeatre priv\xe9es ou publiques, et les utilisateurs peuvent contr\xf4ler l\'acc\xe8s aux images en fonction de leurs besoins.\\n\\n2. **Int\xe9gration avec GitHub** : GHCR est \xe9troitement int\xe9gr\xe9 \xe0 GitHub, ce qui permet aux utilisateurs de g\xe9rer leurs images Docker directement depuis leurs d\xe9p\xf4ts GitHub. Les workflows GitHub Actions peuvent \xeatre utilis\xe9s pour automatiser la cr\xe9ation, le test et le d\xe9ploiement des images Docker.\\n\\n3. **Gestion des versions** : GHCR prend en charge la gestion des versions des images Docker, ce qui permet aux utilisateurs de suivre les modifications apport\xe9es aux images et de revenir \xe0 des versions ant\xe9rieures si n\xe9cessaire.\\n\\n4. **Suivi des \xe9v\xe9nements** : GHCR permet de configurer des webhooks pour suivre les \xe9v\xe9nements li\xe9s aux images Docker, tels que la publication, la mise \xe0 jour et la suppression. Cela permet aux utilisateurs de rester inform\xe9s des modifications apport\xe9es aux images et de r\xe9agir en cons\xe9quence.\\n\\n## Exemple de workflow pour utiliser GitHub GHCR\\n\\nLe workflow suppose que vous avez un `Dockerfile` \xe0 la racine du d\xe9p\xf4t. Ce `Dockerfile` doit r\xe9ussir la commande de `build` avec succ\xe8s\\n\\n### Cr\xe9ez un fichier YAML pour le Workflow\\n\\nCr\xe9ez un fichier YAML (par exemple, `docker-publish.yml`) dans le r\xe9pertoire `.github/workflows/` de votre d\xe9p\xf4t avec le contenu suivant :\\n\\n```yaml\\nname: Create and publish a Docker image\\n\\non:\\n    push:\\n    branches: [\'release\']\\n\\nenv:\\n    REGISTRY: ghcr.io\\n    IMAGE_NAME: ${{ github.repository }}\\n\\njobs:\\n    build-and-push-image:\\n    runs-on: ubuntu-latest\\n\\n    permissions:\\n        contents: read\\n        packages: write\\n\\n    steps:\\n        - name: Checkout repository\\n        uses: actions/checkout@v4\\n\\n        - name: Log in to the Container registry\\n        uses: docker/login-action@65b78e6e13532edd9afa3aa52ac7964289d1a9c1\\n        with:\\n            registry: ${{ env.REGISTRY }}\\n            username: ${{ github.actor }}\\n            password: ${{ secrets.GITHUB_TOKEN }}\\n\\n        - name: Extract metadata (tags, labels) for Docker\\n        id: meta\\n        uses: docker/metadata-action@9ec57ed1fcdbf14dcef7dfbe97b2010124a938b7\\n        with:\\n            images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\\n\\n        - name: Build and push Docker image\\n        uses: docker/build-push-action@f2a1d5e99d037542a71f64918e516c093c6f3fc4\\n        with:\\n            context: .\\n            push: true\\n            tags: ${{ steps.meta.outputs.tags }}\\n            labels: ${{ steps.meta.outputs.labels }}\\n```\\n\\n### Configurez les Options du Workflow\\n\\nDans le fichier YAML, vous pouvez personnaliser les options suivantes selon vos besoins :\\n\\n- `branches`: Modifiez la branche d\xe9clenchant le workflow.\\n- `REGISTRY` et `IMAGE_NAME`: Modifiez-les si vous souhaitez utiliser un autre registre ou nom d\'image.\\n- `permissions`: Ajustez les autorisations en fonction de vos besoins.\\n\\n**Enregistrez et Poussez vos Modifications**\\nEnregistrez les modifications dans le fichier YAML et poussez-les vers la branche \\"release\\" de votre d\xe9p\xf4t GitHub.\\n\\n```shell\\ngit add .github/workflows/docker-publish.yml\\ngit commit -m \\"Ajout du workflow de publication Docker\\"\\ngit push origin release\\n```\\n\\n### Utilisation d\u2019un package GHCR\\n\\nUne fois d\xe9ploy\xe9, le package s\u2019utilise comme n\u2019importe quel docker\\n\\n```shell\\ndocker pull ghcr.io/{USER}/{REPO-NAME}:master\\n```\\n\\n\ud83d\udca1 L\u2019utilisation des Github GHCR entraine des consommations d\u2019espace. Le CATIE a le droit \xe0 2Gb de stockage sur GHCR et 10Gb de transit par mois. Au del\xe0 de ces limites, nous sommes factur\xe9s.\\nL\u2019utilisation (sous n\u2019importe quelle forme) de GHCR sur des d\xe9p\xf4ts **publics** est totalement gratuite Sur des d\xe9p\xf4ts priv\xe9s : le pull via des actions est gratuit. Pour les actions `self-hosted` le pull est gratuit si l\u2019action est authentifi\xe9e par le `GITHUB_TOKEN` et non un PAT.\\n\\nVoici un exemple d\u2019utilisation sans co\xfbt associ\xe9\\n\\n```yaml\\nname: Run in container from GHCR\\n\\non: [ push ]\\n\\njobs:\\n    myJob:\\n    runs-on: ubuntu-latest\\n    container:\\n        image: ghcr.io/sedelpeuch/github-ghcr-test:master\\n    steps:\\n\\n        - name: Checkout code\\n        uses: actions/checkout@v2\\n\\n        - name: Run a command\\n        run: echo \\"Running inside the container\\"\\n```\\n\\nL\u2019image [ghcr.io/sedelpeuch/github-ghcr-test:master](<http://ghcr.io/sedelpeuch/github-ghcr-test:master>) est priv\xe9e, l\u2019acc\xe8s est possible sans donner de PAT gr\xe2ce \xe0 l\u2019authentification par jeton automatique qui poss\xe8de la lecture des packages priv\xe9s [https://docs.github.com/fr/actions/security-guides/automatic-token-authentication#permissions-for-the-github_token](https://docs.github.com/fr/actions/security-guides/automatic-token-authentication#permissions-for-the-github_token)"},{"id":"/2024/12/20/04-ci-cd/action","metadata":{"permalink":"/blog/2024/12/20/04-ci-cd/action","source":"@site/blog/04-ci-cd/2024-12-20-action.md","title":"GitHub Actions : action r\xe9utilisable","description":"Cr\xe9er une action r\xe9utilisable","date":"2024-12-20T00:00:00.000Z","tags":[{"inline":false,"label":"CI/CD","permalink":"/blog/tags/cicd"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":4.68,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"GitHub Actions : action r\xe9utilisable","description":"Cr\xe9er une action r\xe9utilisable","tags":["cicd","devops"]},"unlisted":false,"prevItem":{"title":"Registry : GitHub GHCR","permalink":"/blog/2024/12/20/03-containerization/ghrc"},"nextItem":{"title":"GitHub Actions : architecture","permalink":"/blog/2024/12/20/04-ci-cd/exemple"}},"content":"GitHub Actions permet de cr\xe9er des actions r\xe9utilisables, qui sont des blocs de code personnalis\xe9s pouvant \xeatre utilis\xe9s dans plusieurs workflows. Ces actions peuvent \xeatre partag\xe9es au sein d\'une organisation ou rendues publiques pour que d\'autres utilisateurs puissent les utiliser. Les actions r\xe9utilisables sont particuli\xe8rement utiles pour automatiser des t\xe2ches courantes, telles que le d\xe9ploiement, les tests ou la gestion des secrets, tout en assurant une coh\xe9rence et une maintenabilit\xe9 \xe0 travers diff\xe9rents projets.\\n\\n\x3c!--truncate--\x3e\\n\\n## Exemple de cr\xe9ation et d\'utilisation d\'une action GitHub\\n\\nVoici un exemple de cr\xe9ation et d\'utilisation d\'une action GitHub pour automatiser le d\xe9ploiement d\'une application Node.js.\\n\\n1. Cr\xe9ez un fichier `action.yml` dans le r\xe9pertoire `.github/actions/deploy` de votre d\xe9p\xf4t avec le contenu suivant :\\n\\n```yaml\\nname: \'Deploy Node.js App\'\\ndescription: \'Deploy a Node.js application to a remote server\'\\ninputs:\\n  server:\\n    description: \'The remote server to deploy to\'\\n    required: true\\n  username:\\n    description: \'The username to use for the deployment\'\\n    required: true\\n  password:\\n    description: \'The password to use for the deployment\'\\n    required: true\\nruns:\\n  using: \'composite\'\\n  steps:\\n    - name: Checkout code\\n      uses: actions/checkout@v4\\n    - name: Install dependencies\\n      run: npm install\\n    - name: Build application\\n      run: npm run build\\n    - name: Deploy application\\n      run: |\\n        sshpass -p ${{ inputs.password }} ssh ${{ inputs.username }}@${{ inputs.server }} \'mkdir -p /var/www/myapp\'\\n        sshpass -p ${{ inputs.password }} scp -r ./build/* ${{ inputs.username }}@${{ inputs.server }}:/var/www/myapp\\n```\\n\\n2. Cr\xe9ez un fichier `deploy.yml` dans le r\xe9pertoire `.github/workflows` de votre d\xe9p\xf4t avec le contenu suivant :\\n\\n```yaml\\nname: Deploy Node.js App\\n\\non:\\n  push:\\n    branches:\\n      - main\\n\\njobs:\\n  deploy:\\n    runs-on: ubuntu-latest\\n    steps:\\n      - name: Deploy application\\n        uses: ./.github/actions/deploy\\n        with:\\n          server: ${{ secrets.DEPLOY_SERVER }}\\n          username: ${{ secrets.DEPLOY_USERNAME }}\\n          password: ${{ secrets.DEPLOY_PASSWORD }}\\n```\\n\\nDans cet exemple, l\'action `Deploy Node.js App` est utilis\xe9e pour d\xe9ployer une application Node.js sur un serveur distant. L\'action est d\xe9clench\xe9e \xe0 chaque fois qu\'un push est effectu\xe9 sur la branche `main`. Les informations de d\xe9ploiement (serveur, nom d\'utilisateur et mot de passe) sont stock\xe9es dans les secrets du d\xe9p\xf4t pour des raisons de s\xe9curit\xe9.\\n\\nLes actions GitHub permettent d\'automatiser, personnaliser et ex\xe9cuter un flux de travail directement depuis votre d\xe9p\xf4t. Avec les actions GitHub, il est possible de cr\xe9er des t\xe2ches personnalis\xe9es pour automatiser un flux de travail, partager et d\xe9couvrir des actions pour effectuer des t\xe2ches sp\xe9cifiques.\\n\\n\x3c!--truncate--\x3e\\n\\n## Comment cr\xe9er ses propres actions\\n\\nDocumentation compl\xe8te : [https://docs.github.com/fr/actions/creating-actions](https://docs.github.com/fr/actions/creating-actions)\\n\\nLa cr\xe9ation d\'actions personnalis\xe9es offre la possibilit\xe9 de concevoir du code sp\xe9cifique qui interagit avec le d\xe9p\xf4t selon les besoins. Ces actions peuvent s\'int\xe9grer aux API de GitHub ou \xe0 toute API tierce accessible publiquement. Par exemple, une action pourrait \xeatre configur\xe9e pour publier des modules npm, envoyer des alertes par SMS en cas de cr\xe9ation de probl\xe8mes urgents, ou encore d\xe9ployer du code pr\xeat pour la production.\\nCe guide expose les \xe9l\xe9ments fondamentaux requis pour la cr\xe9ation et l\'utilisation d\'une action composite empaquet\xe9e.\\n\\n:::warning\\nLors de la cr\xe9ation de flux de travail et d\'actions, il est imp\xe9ratif d\'\xe9valuer constamment la possibilit\xe9 d\'ex\xe9cution d\'une entr\xe9e non fiable provenant de sources potentiellement malveillantes. Certains contextes doivent \xeatre trait\xe9s comme des entr\xe9es non fiables, car un attaquant pourrait ins\xe9rer son propre contenu malveillant. Pour de plus amples informations, veuillez consulter la section \xab [Durcissement de la s\xe9curit\xe9 pour GitHub Actions](https://docs.github.com/fr/actions/security-guides/security-hardening-for-github-actions#understanding-the-risk-of-script-injections) \xbb.\\n:::\\n\\n## Cr\xe9ation d\u2019une action\\n\\nUn d\xe9p\xf4t doit \xeatre cr\xe9\xe9 sur [GitHub.com](http://GitHub.com).\\n\\n- Cr\xe9ez un nouveau d\xe9p\xf4t sur [GitHub](http://GitHub.com), en choisissant n\'importe quel nom de d\xe9p\xf4t ou en utilisant l\'exemple suivant : `hello-world-composite-action`. Les fichiers peuvent \xeatre ajout\xe9s une fois que le projet est pouss\xe9 sur GitHub. Pour plus d\'informations, veuillez vous r\xe9f\xe9rer \xe0 la section [Cr\xe9ation d\'un d\xe9p\xf4t](https://docs.github.com/fr/repositories/creating-and-managing-repositories/creating-a-new-repository).\\n- Dans le d\xe9p\xf4t `hello-world-composite-action`, cr\xe9ez un fichier nomm\xe9 `goodbye.sh` et ajoutez le code `echo \\"Goodbye\\"\\n- Rendez `goodbye.sh` ex\xe9cutable depuis votre terminal.\\n- Dans le d\xe9p\xf4t `hello-world-composite-action`, cr\xe9ez un fichier nomm\xe9 `action.yml` et ajoutez le code suivant en exemple. Pour plus d\'informations sur cette syntaxe, consultez la section [Syntaxe des m\xe9tadonn\xe9es pour les actions GitHub](https://docs.github.com/fr/actions/creating-actions/metadata-syntax-for-github-actions#runs-for-composite-actions) .\\n\\n```yaml\\n    name: \'Hello World\'\\n    description: \'Greet someone\'\\n    inputs:\\n      who-to-greet:  # id of input\\n        description: \'Who to greet\'\\n        required: true\\n        default: \'World\'\\n    outputs:\\n      random-number:\\n        description: \\"Random number\\"\\n        value: ${{ steps.random-number-generator.outputs.random-number }}\\n    runs:\\n      using: \\"composite\\"\\n      steps:\\n        - run: echo Hello ${{ inputs.who-to-greet }}.\\n          shell: bash\\n        - id: random-number-generator\\n          run: echo \\"random-number=$(echo $RANDOM)\\" >> $GITHUB_OUTPUT\\n          shell: bash\\n        - run: echo \\"${{ github.action_path }}\\" >> $GITHUB_PATH\\n          shell: bash\\n        - run: goodbye.sh\\n          shell: bash\\n```\\n\\n- Ce fichier d\xe9finit l\'entr\xe9e `who-to-greet`, mappe le nombre g\xe9n\xe9r\xe9 al\xe9atoirement \xe0 la variable de sortie `random-number`, ajoute le chemin d\'acc\xe8s de l\'action au chemin d\'acc\xe8s du syst\xe8me de l\'ex\xe9cuteur (pour localiser le script `goodbye.sh` lors de l\'ex\xe9cution) et ex\xe9cute le script .\\n- Effectuez le commit de votre fichier `action.yml` depuis votre terminal.\\n\\n```shell\\n    git add action.yml\\n    git commit -m \\"Add action\\"\\n    git push\\n```\\n\\n- Ajoutez une \xe9tiquette depuis votre terminal. Cet exemple utilise une \xe9tiquette nomm\xe9e `v1`.\\n\\n```shell\\n    git tag -a -m \\"Description of this release\\" v1\\n    git push --follow-tags\\n```\\n\\n## Tester l\u2019action dans un workflow\\n\\nCopiez le code de workflow dans un fichier `.github/workflows/main.yml` d\'un autre d\xe9p\xf4t\\n\\n```yaml\\n    on: [push]\\n\\n    jobs:\\n      hello_world_job:\\n        runs-on: ubuntu-latest\\n        name: A job to say hello\\n        steps:\\n          - uses: actions/checkout@v4\\n          - id: foo\\n            uses: actions/hello-world-composite-action@v1\\n            with:\\n              who-to-greet: \'Mona the Octocat\'\\n          - run: echo random-number ${{ steps.foo.outputs.random-number }}\\n            shell: bash\\n```\\n\\n## Action dans un workflow priv\xe9\\n\\nDans les param\xe8tres des actions, il est n\xe9cessaire de la partager \xe0 l\u2019organisation\\n\\n![AllowAction](/img/allow_action.png)"},{"id":"/2024/12/20/04-ci-cd/exemple","metadata":{"permalink":"/blog/2024/12/20/04-ci-cd/exemple","source":"@site/blog/04-ci-cd/2024-12-20-exemple.md","title":"GitHub Actions : architecture","description":"Exemple complet d\'architecture CI/CD r\xe9utilisable","date":"2024-12-20T00:00:00.000Z","tags":[{"inline":false,"label":"CI/CD","permalink":"/blog/tags/cicd"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":2.77,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"GitHub Actions : architecture","description":"Exemple complet d\'architecture CI/CD r\xe9utilisable","tags":["cicd","devops"]},"unlisted":false,"prevItem":{"title":"GitHub Actions : action r\xe9utilisable","permalink":"/blog/2024/12/20/04-ci-cd/action"},"nextItem":{"title":"GitHub Actions","permalink":"/blog/2024/12/20/04-ci-cd/github-actions"}},"content":"L\'objectif est de cr\xe9er une architecture CI/CD compl\xe8te pour un projet de d\xe9veloppement adressant une technologie (par exemple ROS). Cette architecture doit \xeatre :\\n\\n- facilement r\xe9utilisable dans d\'autres projets\\n- \xe9viter la duplication de code\\n- maintenable et \xe9volutive ais\xe9ment\\n- applicable \xe0 d\'autres projets\\n\\n\x3c!--truncate--\x3e\\n\\n## Cr\xe9ation d\'une architecture CI/CD\\n\\nL\'id\xe9e de l\'architecture est de cr\xe9er un d\xe9p\xf4t contenant tous les workflows et les actions propres \xe0 une technologie / projet (par exemple ROS). Ce d\xe9p\xf4t sera ensuite utilis\xe9 comme cible pour les workflows des projets utilisant cette technologie.\\n\\n```mermaid\\ngraph LR\\n    subgraph Repositories ROS1\\n        repo1[ros_package_1/.github/workflows/ci.yml]\\n        repo2[ros_package_2/.github/workflows/ci.yml]\\n        repo3[ros_package_n/.github/workflows/ci.yml]\\n    end\\n    subgraph ros_workflows\\n        ros.yml[.github/workflows/ros1.yml]\\n        ros2.yml[.github/workflows/ros2.yml]\\n        ros_build.yml[ros_build/action.yml]\\n        ros.yml --\x3e ros_build.yml\\n        ros2.yml --\x3e ros_build.yml\\n    end\\n    subgraph generic_workflows\\n        pre-commit.yml[.github/workflows/pre-commit.yml]\\n\\n    end\\n\\n    ros.yml --\x3e pre-commit.yml\\n\\n    repo1 --\x3e ros.yml\\n    repo2 --\x3e ros.yml\\n    repo3 --\x3e ros.yml\\n```\\n\\nDans cet exemple, nous avons un d\xe9p\xf4t `ros_workflows` contenant les workflows et les actions propres \xe0 la technologie ROS. Ce d\xe9p\xf4t est ensuite utilis\xe9 par les d\xe9p\xf4ts `ros_package_1`, `ros_package_2`, `ros_package_n` pour ex\xe9cuter les workflows. Les diff\xe9rents workflows pr\xe9sents dans `ros_workflows` sont les **uniques** points d\'entr\xe9e pour les workflows des d\xe9p\xf4ts `ros_package_1`, `ros_package_2`, `ros_package_n`. Ainsi s\'il est n\xe9cessaire de modifier un workflow, il suffit de le faire dans le d\xe9p\xf4t `ros_workflows` et tous les d\xe9p\xf4ts utilisant ce workflow seront mis \xe0 jour.\\n\\nDe plus le d\xe9p\xf4t `ros_workflows` peut d\xe9finir des `actions-composites` pour \xe9viter la duplication de code entre leurs propres workflows. Ces actions sont utilis\xe9es par les workflows du d\xe9p\xf4t `ros_workflows` et par cons\xe9quent des d\xe9p\xf4ts `ros_package_1`, `ros_package_2`, `ros_package_n`. Elles peuvent aussi \xeatre appel\xe9es directement au besoin.\\n\\nFinalemet, le d\xe9p\xf4t `ros_workflows` peut aussi utiliser des workflows g\xe9n\xe9riques (par exemple `pre-commit.yml`) pour automatiser des t\xe2ches communes \xe0 toutes les technologies.\\n\\n### Exemple de workflow `ros1.yml`\\n\\n```yaml\\nname: Build & Test ROS Packages\\n\\non:\\n  workflow_call:\\n    inputs:\\n      package-name:\\n        description: \'The name of the ROS package to build and test.\'\\n        required: true\\n        type: string\\n    secrets:\\n      PAT:\\n        required: false\\n        description: \'A GitHub Personal Access Token (PAT) used to import the private repository into the container.\'\\n\\n\\njobs:\\n  pre-commit:\\n    uses: catie-aq/generic_workflows/.github/workflows/pre-commit.yaml@main\\n  build_and_test_ros_package:\\n    runs-on: self-hosted # Use self-hosted runner\\n    strategy: # Define a matrix of ROS distributions and Docker images\\n      matrix:\\n        include:\\n          - docker_image: osrf/ros:noetic-desktop-full\\n            ros_distribution: noetic\\n    container: # Use the Docker image defined in the matrix\\n      image: ${{ matrix.docker_image }}\\n    steps:\\n      - name: Setup ROS environment\\n        uses: ros-tooling/setup-ros@v0.7\\n        with:\\n          required-ros-distributions: ${{ matrix.ros_distribution }}\\n\\n      - name: Build and test ROS\\n        uses: ros-tooling/action-ros-ci@v0.2\\n        with:\\n          package-name: ${{ inputs.package-name }}\\n          target-ros1-distro: ${{ matrix.ros_distribution }}\\n          import-token: ${{ secrets.PAT }}\\n```\\n\\n### Exemple de workflow `ci.yml`\\n\\n```yaml\\nname: \\"ROS CI/CD\\"\\n\\non:\\n  push:\\n\\njobs:\\n  ros:\\n    uses: {user}/ros_workflows/.github/workflows/ros.yml@main\\n```\\n\\n### Exemple d\'action composite `ros_build/action.yml`\\n\\n```yaml\\nname: \'Build and Test ROS\'\\ndescription: \'Build and test a ROS package\'\\n\\ninputs:\\n  package-name:\\n    description: \'The name of the ROS package to build and test.\'\\n    required: true\\n    type: string\\n  ros-distribution:\\n    description: \'The ROS distribution to use for building and testing.\'\\n    required: true\\n    type: string\\n  import-token:\\n    description: \'A GitHub Personal Access Token (PAT) used to import the private repository into the container.\'\\n    required: false\\n    type: string\\n\\nruns:\\n    using: \\"composite\\"\\n    steps:\\n        - run: echo \\"Building and testing ROS package ${{ inputs.package-name }} for ROS ${{ inputs.ros-distribution }}.\\"\\n        shell: bash\\n```"},{"id":"/2024/12/20/04-ci-cd/github-actions","metadata":{"permalink":"/blog/2024/12/20/04-ci-cd/github-actions","source":"@site/blog/04-ci-cd/2024-12-20-github-actions.md","title":"GitHub Actions","description":"D\xe9couvrez comment GitHub Actions peut automatiser vos workflows de d\xe9veloppement et de d\xe9ploiement.","date":"2024-12-20T00:00:00.000Z","tags":[{"inline":false,"label":"CI/CD","permalink":"/blog/tags/cicd"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":3.4,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"GitHub Actions","description":"D\xe9couvrez comment GitHub Actions peut automatiser vos workflows de d\xe9veloppement et de d\xe9ploiement.","tags":["cicd","devops"]},"unlisted":false,"prevItem":{"title":"GitHub Actions : architecture","permalink":"/blog/2024/12/20/04-ci-cd/exemple"},"nextItem":{"title":"GitHub Actions : ARC","permalink":"/blog/2024/12/20/04-ci-cd/github-arc"}},"content":"Dans le monde du d\xe9veloppement logiciel, l\'automatisation est devenue une n\xe9cessit\xe9 pour am\xe9liorer l\'efficacit\xe9 et r\xe9duire les erreurs humaines. GitHub Actions est une plateforme puissante qui permet d\'automatiser les workflows de d\xe9veloppement et de d\xe9ploiement. Dans cet article, nous allons explorer les concepts de base de GitHub Actions, ses avantages, et fournir des exemples concrets pour vous aider \xe0 d\xe9marrer.\\n\\n\x3c!--truncate--\x3e\\n\\n### Qu\'est-ce que GitHub Actions ?\\n\\nGitHub Actions est une plateforme d\'automatisation des workflows de d\xe9veloppement et de d\xe9ploiement. Elle permet aux d\xe9veloppeurs d\'automatiser des t\xe2ches r\xe9p\xe9titives, telles que les tests, les builds et les d\xe9ploiements, en utilisant des fichiers de configuration YAML.\\n\\n### Pourquoi utiliser GitHub Actions ?\\n\\nGitHub Actions offre plusieurs avantages pour les d\xe9veloppeurs et les \xe9quipes DevOps :\\n\\n1. **Automatisation des workflows** : GitHub Actions permet d\'automatiser les t\xe2ches r\xe9p\xe9titives, ce qui r\xe9duit les erreurs humaines et am\xe9liore l\'efficacit\xe9.\\n2. **Int\xe9gration continue (CI)** : Les workflows peuvent \xeatre configur\xe9s pour s\'ex\xe9cuter automatiquement \xe0 chaque commit, garantissant que le code est toujours test\xe9 et pr\xeat \xe0 \xeatre d\xe9ploy\xe9.\\n3. **D\xe9ploiement continu (CD)** : GitHub Actions facilite le d\xe9ploiement automatique des applications sur diff\xe9rents environnements, tels que les serveurs de production, les environnements de test et les conteneurs Docker.\\n4. **Flexibilit\xe9** : Les workflows peuvent \xeatre personnalis\xe9s pour r\xe9pondre aux besoins sp\xe9cifiques de chaque projet, en utilisant des actions pr\xe9d\xe9finies ou en cr\xe9ant des actions personnalis\xe9es.\\n5. **Communaut\xe9 et \xe9cosyst\xe8me** : GitHub Actions b\xe9n\xe9ficie d\'une large communaut\xe9 de d\xe9veloppeurs et d\'un \xe9cosyst\xe8me riche en actions pr\xe9d\xe9finies, ce qui facilite l\'int\xe9gration avec d\'autres outils et services.\\n\\n### Marketplace et r\xe9utilisation\\n\\nLe GitHub Marketplace est une ressource pr\xe9cieuse pour trouver des actions pr\xe9d\xe9finies cr\xe9\xe9es par la communaut\xe9. Vous pouvez r\xe9utiliser ces actions dans vos workflows pour automatiser des t\xe2ches courantes sans avoir \xe0 les coder vous-m\xeame. Cela permet de gagner du temps et de b\xe9n\xe9ficier des meilleures pratiques de la communaut\xe9.\\n\\n## Concepts de base de GitHub Actions\\n\\n### \xc9v\xe9nements\\n\\nLes \xe9v\xe9nements sont des d\xe9clencheurs qui activent l\'ex\xe9cution des workflows. Les \xe9v\xe9nements courants incluent les commits, les pull requests, les issues et les releases. Par exemple, un workflow peut \xeatre configur\xe9 pour s\'ex\xe9cuter \xe0 chaque commit sur la branche principale.\\n\\n### Actions\\n\\nLes actions sont des t\xe2ches individuelles qui composent un workflow. Elles peuvent \xeatre pr\xe9d\xe9finies ou personnalis\xe9es. Les actions pr\xe9d\xe9finies sont disponibles dans le GitHub Marketplace et couvrent une large gamme de t\xe2ches, telles que l\'installation de d\xe9pendances, l\'ex\xe9cution de tests et le d\xe9ploiement d\'applications.\\n\\n### Workflows\\n\\nLes workflows sont des fichiers de configuration YAML qui d\xe9finissent les actions \xe0 ex\xe9cuter en r\xe9ponse \xe0 des \xe9v\xe9nements sp\xe9cifiques. Un workflow peut contenir plusieurs jobs, chacun compos\xe9 de plusieurs \xe9tapes. Les workflows sont stock\xe9s dans le r\xe9pertoire `.github/workflows` du d\xe9p\xf4t.\\n\\n## Exemple de workflow GitHub Actions\\n\\nVoici un exemple de workflow GitHub Actions pour une application Node.js. Ce workflow s\'ex\xe9cute \xe0 chaque commit sur la branche principale, installe les d\xe9pendances, ex\xe9cute les tests et d\xe9ploie l\'application sur un serveur de production.\\n\\n```yaml\\nname: CI/CD Pipeline\\n\\non:\\n  push:\\n    branches:\\n      - main\\n\\njobs:\\n  build:\\n    runs-on: ubuntu-latest\\n\\n    steps:\\n      - name: Checkout code\\n        uses: actions/checkout@v2\\n\\n      - name: Set up Node.js\\n        uses: actions/setup-node@v2\\n        with:\\n          node-version: \'14\'\\n\\n      - name: Install dependencies\\n        run: npm install\\n\\n      - name: Run tests\\n        run: npm test\\n\\n      - name: Deploy to production\\n        run: |\\n          ssh user@server \'cd /path/to/app && git pull && npm install && pm2 restart app\'\\n```\\n\\n## Les runners GitHub Actions\\n\\nLes runners sont des machines virtuelles ou physiques qui ex\xe9cutent les jobs d\xe9finis dans les workflows. GitHub propose des runners h\xe9berg\xe9s, mais vous pouvez \xe9galement configurer vos propres runners auto-h\xe9berg\xe9s pour r\xe9pondre \xe0 des besoins sp\xe9cifiques. Les runners auto-h\xe9berg\xe9s offrent plus de contr\xf4le sur l\'environnement d\'ex\xe9cution et peuvent \xeatre utilis\xe9s pour des t\xe2ches n\xe9cessitant des ressources sp\xe9cifiques.\\n\\n## Conclusion\\n\\nGitHub Actions est un outil puissant pour automatiser les workflows de d\xe9veloppement et de d\xe9ploiement. En utilisant des fichiers de configuration YAML, les d\xe9veloppeurs peuvent cr\xe9er des workflows personnalis\xe9s pour r\xe9pondre aux besoins sp\xe9cifiques de leurs projets. Avec GitHub Actions, les \xe9quipes DevOps peuvent am\xe9liorer l\'efficacit\xe9, r\xe9duire les erreurs humaines et acc\xe9l\xe9rer le cycle de d\xe9veloppement.\\n\\nPour en savoir plus sur GitHub Actions, consultez la [documentation officielle](https://docs.github.com/en/actions)."},{"id":"/2024/12/20/04-ci-cd/github-arc","metadata":{"permalink":"/blog/2024/12/20/04-ci-cd/github-arc","source":"@site/blog/04-ci-cd/2024-12-20-github-arc.md","title":"GitHub Actions : ARC","description":"Explication de l\'installation et de l\'utilisation de l\'Action Runner Controller GitHub","date":"2024-12-20T00:00:00.000Z","tags":[{"inline":false,"label":"CI/CD","permalink":"/blog/tags/cicd"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":3.52,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"GitHub Actions : ARC","description":"Explication de l\'installation et de l\'utilisation de l\'Action Runner Controller GitHub","tags":["cicd","devops"]},"unlisted":false,"prevItem":{"title":"GitHub Actions","permalink":"/blog/2024/12/20/04-ci-cd/github-actions"},"nextItem":{"title":"GitHub Actions : Self-Host Runner","permalink":"/blog/2024/12/20/04-ci-cd/self-host-runner"}},"content":"Actions Runner Controller (ARC) est un op\xe9rateur de Kubernetes qui orchestre et g\xe8re les runners auto-h\xe9berg\xe9s pour les actions GitHub.\\n\\n\x3c!--truncate--\x3e\\n\\n## GitHub ARC\\n\\nLes runners auto-h\xe9berg\xe9s offrent un contr\xf4le total sur l\'environnement d\'ex\xe9cution, permettant de personnaliser les configurations et d\'optimiser les performances selon les besoins sp\xe9cifiques. Ils sont \xe9galement plus rentables \xe0 long terme, car ils n\'entra\xeenent pas de co\xfbts suppl\xe9mentaires li\xe9s \xe0 l\'utilisation des ressources de GitHub. Cependant, ils n\xe9cessitent une maintenance r\xe9guli\xe8re et une gestion de la s\xe9curit\xe9 pour garantir leur bon fonctionnement et leur protection contre les menaces potentielles. En revanche, GitHub Actions Runner Controller (ARC) est une solution \xe9volutive g\xe9r\xe9e par GitHub, qui permet de g\xe9rer automatiquement les runners dans un environnement Kubernetes. ARC offre une gestion simplifi\xe9e et une mise \xe0 l\'\xe9chelle automatique des runners en fonction des besoins, ce qui est id\xe9al pour les grandes organisations avec des charges de travail variables. Cependant, l\'utilisation de GitHub ARC peut entra\xeener des co\xfbts plus \xe9lev\xe9s pour les d\xe9ploiements \xe0 grande \xe9chelle, et les utilisateurs ont moins de contr\xf4le sur l\'environnement d\'ex\xe9cution par rapport aux runners auto-h\xe9berg\xe9s.\\n\\nAvec ARC, il est possible de cr\xe9er des ensembles de runners qui \xe9voluent automatiquement en fonction du nombre de workflows ex\xe9cut\xe9s dans votre d\xe9p\xf4t, organisation ou entreprise.\\n\\nLe diagramme suivant illustre l\'architecture du mode Scaleset Runner Autoscaling d\'Arc.\\n\\n[Documentation compl\xe8te](https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/quickstart-for-actions-runner-controller)\\n\\n![alt text](/img/arc.png)\\n\\n:::danger\\nSur GitHub les ARC sont identifi\xe9s par leur nom d\'installation. Il est important de choisir un nom unique pour chaque installation. De plus pour simplifier l\'\xe9criture des workflows il est consill\xe9 de g\xe9rer les runners par des groupes de runners. La cl\xe9 `runs-on` des jobs des workflows doit \xeatre \xe9gale \xe0 un groupe de runners.\\n:::\\n\\n## Pr\xe9requis\\n\\nPour utiliser l\'ARC, il est n\xe9cessaire de disposer des \xe9l\xe9ments suivants :\\n\\n- Un cluster Kubernetes\\n- Helm 3.0 ou version ult\xe9rieure\\n\\n## Installation rapide\\n\\n:::warning\\nLa suite du guide permet de rapidement installer ARC. Les diff\xe9rents concepts et la configuration avanc\xe9e ne sont pas abord\xe9s. Pour une installation plus compl\xe8te, regarder la [documentation officielle](https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/quickstart-for-actions-runner-controller).\\n:::\\n\\n- Le pod de contr\xf4le est en charge de la gestion des pods de runner. Il s\'occupe de la cr\xe9ation, de la mise \xe0 l\'\xe9chelle et de la suppression des pods de runner.\\n- Le pod de runner est d\xe9di\xe9 \xe0 l\'ex\xe9cution des workflows GitHub Actions. Il se compose de deux conteneurs : un conteneur DinD et un conteneur runner. Le conteneur DinD fournit un environnement d\'ex\xe9cution Docker pour le conteneur runner. Le conteneur runner est utilis\xe9 pour ex\xe9cuter les workflows GitHub Actions.\\n\\n## Usage\\n\\nPour lancer le pod de contr\xf4le :\\n\\n```shell\\nNAMESPACE=\\"arc-systems\\"\\nhelm install arc \\\\\\n    --namespace \\"${NAMESPACE}\\" \\\\\\n    --create-namespace \\\\\\n    oci://ghcr.io/actions/actions-runner-controller-charts/gha-runner-scale-set-controller\\n```\\n\\nPour lancer le pod de runner :\\n\\n```shell\\nINSTALLATION_NAME=\\"elegantencoder\\"\\nNAMESPACE=\\"arc-runners\\"\\nhelm install \\"${INSTALLATION_NAME}\\" \\\\\\n    --namespace \\"${NAMESPACE}\\" \\\\\\n    --create-namespace \\\\\\n    -f value.yaml \\\\\\n    oci://ghcr.io/actions/actions-runner-controller-charts/gha-runner-scale-set;\\n```\\n\\n## Authentification\\n\\nPour que le pod de contr\xf4le puisse cr\xe9er des pods de runner, il faut lui donner les droits n\xe9cessaires. Pour cela, il faut cr\xe9er un secret contenant un token d\'authentification. Les diff\xe9rents \xe9l\xe9ments proviennent de l\'enregistrement d\'une application GitHub au niveau de l\'organisation concern\xe9e.\\n\\n```shell\\nkubectl create secret generic pre-defined-secret \\\\\\n   --namespace=arc-runners \\\\\\n   --from-literal=github_app_id=xxx \\\\\\n   --from-literal=github_app_installation_id=xxx \\\\\\n   --from-literal=github_app_private_key=\'xxx\'\\n```\\n\\n## Monitoring\\n\\nDashboard Helm\\n\\n```shell\\nhelm dashboard --bind 0.0.0.0\\n```\\n\\nPortainer\\n\\n## Docker cache\\n\\nNous avons rencontr\xe9 un probl\xe8me de lenteur lors de la construction des images Docker. Pour y rem\xe9dier, nous avons mis en place la mutualisation des couches des images Docker entre les diff\xe9rents pods et l\'h\xf4te. Cela implique la cr\xe9ation d\'un volume partag\xe9 entre les diff\xe9rents pods et l\'h\xf4te. Ces volumes sont mont\xe9s dans le conteneur DinD du pod qui les utilise pour fournir les images Docker au conteneur du runner. Chaque pod de runner contient un conteneur DinD qui est utilis\xe9 pour construire les images Docker.\\n\\n```yaml\\n- name: overlay2\\n    hostPath:\\n    path: /var/lib/docker/overlay2\\n- name: image-overlay2\\n    hostPath:\\n    path: /var/lib/docker/image/overlay2\\n```"},{"id":"/2024/12/20/04-ci-cd/self-host-runner","metadata":{"permalink":"/blog/2024/12/20/04-ci-cd/self-host-runner","source":"@site/blog/04-ci-cd/2024-12-20-self-host-runner.md","title":"GitHub Actions : Self-Host Runner","description":"Explication de la cr\xe9ation et de l\'installation d\'un nouveau runner au niveau de l\'organisation","date":"2024-12-20T00:00:00.000Z","tags":[{"inline":false,"label":"CI/CD","permalink":"/blog/tags/cicd"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":3.74,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"GitHub Actions : Self-Host Runner","description":"Explication de la cr\xe9ation et de l\'installation d\'un nouveau runner au niveau de l\'organisation","tags":["cicd","devops"]},"unlisted":false,"prevItem":{"title":"GitHub Actions : ARC","permalink":"/blog/2024/12/20/04-ci-cd/github-arc"},"nextItem":{"title":"GitHub Actions : Workflow","permalink":"/blog/2024/12/20/04-ci-cd/workflow"}},"content":"Un `runner` est une machine virtuelle ou physique qui ex\xe9cute des `jobs` dans un `workflow`. Les `runners` peuvent \xeatre h\xe9berg\xe9s par GitHub ou auto-h\xe9berg\xe9s. Les `runners` h\xe9berg\xe9s par GitHub sont ex\xe9cut\xe9s dans un environnement de cloud partag\xe9 et sont g\xe9r\xe9s par GitHub et peuvent entrainer des surcouts. Les `runners` auto-h\xe9berg\xe9s sont ex\xe9cut\xe9s sur une machine que vous poss\xe9dez et g\xe9rez.\\n\\n\x3c!--truncate--\x3e\\n\\n## Comparaison entre les runners auto-h\xe9berg\xe9s et les runners cloud-h\xe9berg\xe9s de GitHub\\n\\nLes runners auto-h\xe9berg\xe9s offrent un contr\xf4le total sur l\'environnement d\'ex\xe9cution, ce qui permet de personnaliser les configurations et d\'optimiser les performances selon les besoins sp\xe9cifiques. Ils sont \xe9galement plus rentables \xe0 long terme, car ils n\'entra\xeenent pas de co\xfbts suppl\xe9mentaires li\xe9s \xe0 l\'utilisation des ressources de GitHub. Cependant, ils n\xe9cessitent une maintenance r\xe9guli\xe8re et une gestion de la s\xe9curit\xe9 pour garantir leur bon fonctionnement et leur protection contre les menaces potentielles.\\n\\nLes runners cloud-h\xe9berg\xe9s de GitHub sont g\xe9r\xe9s par GitHub, ce qui signifie que les utilisateurs n\'ont pas \xe0 se soucier de la maintenance, de la s\xe9curit\xe9 ou de la mise \xe0 jour des runners. Ils sont \xe9galement facilement \xe9volutifs, car GitHub peut ajouter des ressources suppl\xe9mentaires en fonction des besoins. Cependant, les runners cloud-h\xe9berg\xe9s peuvent entra\xeener des co\xfbts suppl\xe9mentaires pour les utilisateurs, en particulier pour les projets de grande envergure ou les charges de travail intensives.\\n\\nEn r\xe9sum\xe9, les runners auto-h\xe9berg\xe9s sont id\xe9aux pour les \xe9quipes ou les projets avec des besoins sp\xe9cifiques en mati\xe8re de configuration et de performances, tandis que les runners cloud-h\xe9berg\xe9s de GitHub sont mieux adapt\xe9s aux utilisateurs qui pr\xe9f\xe8rent une solution g\xe9r\xe9e et \xe9volutive sans avoir \xe0 se soucier de la maintenance et de la s\xe9curit\xe9. Le choix entre les deux d\xe9pend des besoins sp\xe9cifiques de l\'\xe9quipe et des ressources disponibles.\\n\\n## Cr\xe9\xe9r un runner auto-h\xe9berg\xe9s\\n\\nPour t\xe9l\xe9charger un nouveau `runner`, ex\xe9cutez les lignes suivantes\\n\\n```shell\\n# Create a folder\\nmkdir actions-runner && cd actions-runner\\n# Download the latest runner package\\ncurl -o actions-runner-linux-x64-2.312.0.tar.gz -L <https://github.com/actions/runner/releases/download/v2.312.0/actions-runner-linux-x64-2.312.0.tar.gz> # ! update this documentation with the latest release\\n# Optional: Validate the hash\\necho \\"85c1bbd104d539f666a89edef70a18db2596df374a1b51670f2af1578ecbe031  actions-runner-linux-x64-2.312.0.tar.gz\\" | shasum -a 256 -c\\n# Extract the installer\\ntar xzf ./actions-runner-linux-x64-2.312.0.tar.gz\\n```\\n\\nIl est ensuite n\xe9cessaire de configurer votre `runner`\\n\\n```shell\\n# Create the runner and start the configuration experience\\n./config.sh --url <https://github.com/><org>/<repo> --token <token># Last step, run it!\\n./run.sh\\n```\\n\\n:::info\\nLe token est \xe0 obtenir au pr\xe8s d\u2019un `owner` de l\u2019organisation accessible sur le lien suivant [https://github.com/organizations/](https://github.com/organizations/org/settings/actions/runners/new?arch=x64&os=linux)\\n:::\\n\\n\u27a1\ufe0f Lors de la configuration, il est possible d\'ajouter des **labels** pour identifier la machine (par exemple `GPU`).\\n\\n## Cr\xe9er une action `self-hosted`\\n\\nIl n\u2019est pas possible de cr\xe9er une action visant une machine `self-hosted` particuli\xe8re (\xe0 confirmer). Chaque `repository` d\u2019une organisation peut acc\xe9der \xe0 :\\n\\n- Toutes les machines dans le groupe `D\xe9faut` qui sont automatiquement partag\xe9es \xe0 tous les d\xe9p\xf4ts.\\n- Toutes les machines dans un groupe `Name` qui sont manuellement partag\xe9es au d\xe9p\xf4t concern\xe9 (l\u2019affectation manuelle des d\xe9p\xf4ts \xe0 des groupes de machines nous encourage \xe0 ne pas utiliser ceci sauf cas particulier)\\n\\nParmi les machines disponibles le `repository` peut demander d\u2019utiliser une machine en fonction de son `label` par exemple l\u2019action ci-dessous, permettant de v\xe9rifier que le d\xe9p\xf4t est compilable sous ROS, r\xe9quisitionne une machine ayant le label `Robotics`. Ceci est modifiable \xe0 la ligne `runs-on: Robotics`.\\n\\n```yaml\\nname: CI\\n\\non: [pull_request]\\n\\njobs:\\n  industrial_ci:\\n    strategy:\\n      matrix:\\n        env:\\n          - {ROS_DISTRO: melodic, ROS_REPO: main}\\n    runs-on: Robotics\\n    steps:\\n      - uses: actions/checkout@v3\\n      - uses: \'ros-industrial/industrial_ci@master\'\\n        env: ${{matrix.env}}\\n```\\n\\nLors de la premi\xe8re utilisation, si vous rencontrez un erreur `docker` sp\xe9cifiant un manque de permission, il est n\xe9cessaire de taper la commande suivante sur la machine distance `sudo setfacl --modify user:<user>:rw /var/run/docker.sock`\\nLorsqu\u2019une action est cr\xe9\xe9 en `self-hosted` il est fortement conseill\xe9 de mettre les actions dans un `container`. Lorsque c\u2019est impossible (comme `tailscale`) il est n\xe9cessaire d\u2019ajouer un clean de l\u2019environnement \xe0 la fin de l\u2019action en ajoutant cette `step`\\n\\n```yaml\\n- name: Clean runner\\n  if: always()\\n  run: rm -rf ${{ github.workspace }}/*\\n```\\n\\n## Mettre en place le runner sous forme de service\\n\\nDans le dossier de votre `runnner` sur la machine, transformer le `./run.sh` en service, tapez simplement les lignes ci-dessous pour que le `runner` s\u2019active au d\xe9marrage de la machine.\\n\\n```shell\\nsudo ./svc.sh install\\nsudo ./svc.sh start\\n```"},{"id":"/2024/12/20/04-ci-cd/workflow","metadata":{"permalink":"/blog/2024/12/20/04-ci-cd/workflow","source":"@site/blog/04-ci-cd/2024-12-20-workflow.md","title":"GitHub Actions : Workflow","description":"Cr\xe9er un workflow avec GitHub Actions","date":"2024-12-20T00:00:00.000Z","tags":[{"inline":false,"label":"CI/CD","permalink":"/blog/tags/cicd"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":5.52,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"GitHub Actions : Workflow","description":"Cr\xe9er un workflow avec GitHub Actions","tags":["cicd","devops"]},"unlisted":false,"prevItem":{"title":"GitHub Actions : Self-Host Runner","permalink":"/blog/2024/12/20/04-ci-cd/self-host-runner"},"nextItem":{"title":"Docker Compose","permalink":"/blog/2024/12/20/06-orchestration/docker-compose"}},"content":"## Exemple d\'int\xe9gration des actions GitHub dans les workflows\\n\\nVoici un exemple d\'int\xe9gration des actions GitHub dans un workflow pour automatiser le d\xe9ploiement d\'une application Node.js.\\n\\nUn workflow est l\'\xe9l\xe9ment central de GitHub Actions. Il s\'agit d\'un processus automatis\xe9 compos\xe9 de `jobs` et de `steps` qui s\'ex\xe9cutent sur des `runners`. Les workflows sont d\xe9clench\xe9s par des \xe9v\xe9nements, tels que des pushs, des pull requests, des forks, etc.\\n\\n\x3c!--truncate--\x3e\\n\\nPour cr\xe9er un fichier de workflow, il faut cr\xe9er un fichier `.yml` dans le dossier `.github/workflows` du d\xe9p\xf4t. Un workflow est compos\xe9 de `jobs` et de `steps`. Un `job` est une suite d\'\xe9tapes qui s\'ex\xe9cutent sur le m\xeame runner, tandis qu\'un `step` est une t\xe2che individuelle qui peut s\'ex\xe9cuter dans un `job`. Chaque `job` est ex\xe9cut\xe9 dans un environnement d\xe9di\xe9 d\xe9fini par [`runs-on`](#type-de-machine).\\n\\n```yml\\nname: CI\\n\\non: [push]\\n\\njobs:\\n  build:\\n    runs-on: ubuntu-latest\\n    steps:\\n      - uses: actions/checkout@v2\\n      - name: Run a one-line script\\n        run: echo Hello, world!\\n      - name: Run a multi-line script\\n        run: |\\n          echo Add other actions to build,\\n          echo test, and deploy your project.\\n```\\n\\nDocumentation Compl\xe8te  : [https://docs.github.com/en/actions/learn-github-actions/introduction-to-github-actions](https://docs.github.com/en/actions/learn-github-actions/introduction-to-github-actions)\\n\\n## D\xe9clenchement des actions\\n\\nLes d\xe9clencheurs de workflow sont des \xe9v\xe9nements qui entra\xeenent l\u2019ex\xe9cution d\u2019un workflow. La syntaxe d\xe9pend du niveau de pr\xe9cision\\n\\n- Pour tout ce qui concerne un \xe9v\xe9nement :\\n\\n```yaml\\n    on: [push] # pull_request, fork etc\\n```\\n\\n- Pour plus de finesse sur l\u2019\xe9v\xe9nement :\\n\\n```yaml\\n    on: # trigger\\n      label: # type d\'event (push, fork, pull_request)\\n        types:\\n          - created # trigger \xe0 chaque fois qu\'un label est cr\xe9\xe9\\n      push:\\n        branches:\\n          - main # tous les push sur la branche main\\n```\\n\\n- D\xe9clenchement manuel de l\u2019op\xe9ration (avec prise d\u2019argument)\\n\\n```yaml\\n    on:\\n      workflow_dispatch:\\n        inputs:\\n          test_mode:\\n            description: \'True or False\'\\n            required: true\\n```\\n\\nLa liste compl\xe8te des d\xe9clencheurs est disponible dans la [Documentation Github](https://docs.github.com/fr/actions/using-workflows/events-that-trigger-workflows)\\n\\nUne ex\xe9cution de workflow est compos\xe9e d\u2019un ou de plusieurs `jobs`, qui s\u2019ex\xe9cutent en parall\xe8le par d\xe9faut. Chaque job est constitu\xe9 d\u2019un `name` et d\u2019au moins un `step` pour \xeatre ex\xe9cutable et peut \xeatre configur\xe9.\\nLa documentation pr\xe9cise des job est disponible dans la [Documentation Github](https://docs.github.com/fr/actions/using-workflows/workflow-syntax-for-github-actions#jobs)\\n\\n## Marketplace\\n\\nChaque `job` permet d\u2019ex\xe9cuter un script. Le script le plus basique est un simple `run` avec des commandes `bash` derri\xe8re. Cependant, il est possible de r\xe9utiliser des actions d\xe9finies dans le marketplace. Par exemple le `steps` ci-dessous permet d\u2019ex\xe9cuter l\u2019action [https://github.com/ros-tooling/action-ros-ci](https://github.com/ros-tooling/action-ros-ci). Le mot cl\xe9 `with` permet de passer des param\xe8tres \xe0 l\u2019action.\\n\\n:::danger\\nLe marketplace permet de r\xe9utiliser des actions d\xe9j\xe0 d\xe9finies par la communaut\xe9. Il est important de v\xe9rifier la source de l\u2019action avant de l\u2019utiliser.\\n:::\\n\\n```yaml\\nsteps:\\n    - name: build and test ROS 2\\n    uses: ros-tooling/action-ros-ci@v0.2\\n    with:\\n        package-name: github-action-test\\n        target-ros2-distro: ${{ matrix.ros_distribution }}\\n        import-token: ${{ secrets.GITHUB_TOKEN }} # token autogenerated par github\\n```\\n\\n## R\xe9utiliser les Workflows et Actions\\n\\nIl est possible de r\xe9utiliser des `workflows` et des `actions` dans un workflow. Pour cela, il est possible de cr\xe9er des `workflows` et des `actions` dans des fichiers s\xe9par\xe9s et de les appeler dans le workflow principal.\\n\\n```yaml\\njobs:\\n    workflow: # r\xe9utilisation du workflow\\n      uses: path/to/your-workflow.yml@v1\\n    action: # r\xe9utilisation d\'une action\\n      runs-on: ubuntu-latest\\n      container: ubuntu:latest\\n      steps:\\n        - uses: path/to/your-action@v1\\n```\\n\\n[Documentation des wokflows r\xe9utilisables](https://docs.github.com/en/actions/learn-github-actions/reusing-workflows)\\n\\n[Documentation des actions r\xe9utilisables](https://docs.github.com/en/actions/creating-actions/creating-a-composite-action)\\n\\n:::info\\n\\nLorsqu\'un workflow est r\xe9utilis\xe9 il d\xe9fini son propre environnement (runner, container, etc). De plus il n\'est pas utilisable dans une `step`.\\n\\n\xc0 l\'inverse, une action est utilisable dans une `step` et fonctionne dans l\'environnement du `job` qui l\'appelle.\\n:::\\n\\n## Type de machine\\n\\nUtilisez `jobs.<job_id>.runs-on` pour d\xe9finir le type de machine sur laquelle le travail doit \xeatre ex\xe9cut\xe9. La configuration prend en argument un `tag` d\xe9fini pour les runners\\n\\n```yaml\\njobs:\\n    name-job:\\n    runs-on: ubuntu-latest # runner distant sur les serveur de Github\\n    runs-on: self-hosted # runner local\\n    steps:\\n        - run: echo \\"Hello World !\\"\\n```\\n\\nLes `runners` distants fourni par Github consomment du temps pour l\u2019organisation dans les limites de 2 000 minutes gratuites par mois. Il est pr\xe9f\xe9rable d\u2019utiliser des `runners self hosted` (voir [https://docs.github.com/fr/actions/hosting-your-own-runners/managing-self-hosted-runners/about-self-hosted-runners](https://docs.github.com/fr/actions/hosting-your-own-runners/managing-self-hosted-runners/about-self-hosted-runners))\\n\\nLe choix du `runner` se fait via les tags. Toutes les machines auto-h\xe9berg\xe9es partagent le tag `self-hosted` , le tag de leur syst\xe8me d\u2019exploitation (`Linux`, `Windows`), leur architecture (`x64`) et des tags personnalis\xe9s par machine.\\n\\n## Container\\n\\nL\u2019utilisation d\u2019un `container` permet de cr\xe9er un nouveau conteneur permettant d\u2019ex\xe9cuter les \xe9tapes d\u2019un travail dans un conteneur sp\xe9cifif\xe9. Si vous ne d\xe9finissez pas de `container`, toutes les \xe9tapes s\u2019ex\xe9cutent directement sur l\u2019h\xf4te sp\xe9cifi\xe9 par `runs-on` dans le cas d\u2019une machine auto-h\xe9berg\xe9es, il n\u2019y a donc acc\xe8s qu\u2019aux packages install\xe9s sur la machine. Un `container` est rattach\xe9 \xe0 un `job`.\\n\\n```yaml\\njobs:\\n    name-job:\\n    runs-on: self-hosted\\n    container:\\n    image: ubuntu:jammy # run job with ubuntu:jammy docker\\n        steps:\\n            - run: echo \\"Hello World !\\"\\n```\\n\\n## Strategy\\n\\nL\u2019utilisation de `strategy` permet cr\xe9er automatiquement plusieurs ex\xe9cutions de travaux bas\xe9es sur des combinaisons de variables. Une strat\xe9gie de matrice est utile pour tester du code dans diff\xe9rentes versions d\'un langage ou sur diff\xe9rents syst\xe8mes d\'exploitation.\\nPar exemple\\n\\n```yaml\\njobs:\\n    example_matrix:\\n    strategy:\\n        matrix:\\n        version: [10, 12, 14]\\n        os: [ubuntu-latest, windows-latest]\\n        steps:\\n            - run : echo \\"${{ matrix.version }} ${{ matrix.os }}\\"\\n```\\n\\nUn travail s\u2019ex\xe9cute pour chaque combinaison possible des variables. Dans cet exemple, le workflow ex\xe9cute six travaux, un pour chaque combinaison des variables `os` et `version`.\\n\\n## Art\xe9fact\\n\\nLes artefacts permettent de conserver des donn\xe9es une fois un travail termin\xe9 et de les partager avec une autre action. Un artefact est un fichier ou une collection de fichiers g\xe9n\xe9r\xe9s pendant l\u2019ex\xe9cution d\u2019un workflow. Cet exemple permet de stocker un fichier comme artefact.\\n\\n```yaml\\n- name: Archive code coverage results\\n    uses: actions/upload-artifact@v3\\n    with:\\n        name: code-coverage-report\\n        path: output/test/code-coverage.html\\n```\\n\\nPour r\xe9cup\xe9rer un artefact\\n\\n```yaml\\n- name: Download math result for job 2\\n    uses: actions/download-artifact@v3\\n    with:\\n        name: homework\\n```\\n\\n## Vrac\\n\\n- `needs` le job actuel ne commencera que quand le job mentionn\xe9 sera termin\xe9\\n- `if` condition de lancement du job\\n- `permission` permet d\u2019augmenter les droits du `GITHUB_TOKEN` (voir [https://docs.github.com/fr/actions/security-guides/automatic-token-authentication#permissions-for-the-github_token](https://docs.github.com/fr/actions/security-guides/automatic-token-authentication#permissions-for-the-github_token))\\n- `environnement` permet de d\xe9finir des variables d\u2019environnement"},{"id":"/2024/12/20/06-orchestration/docker-compose","metadata":{"permalink":"/blog/2024/12/20/06-orchestration/docker-compose","source":"@site/blog/06-orchestration/2024-12-20-docker-compose.md","title":"Docker Compose","description":"Explication de Docker Compose","date":"2024-12-20T00:00:00.000Z","tags":[{"inline":false,"label":"Orchestration","permalink":"/blog/tags/orchestration"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":10.2,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Docker Compose","description":"Explication de Docker Compose","tags":["orchestration","devops"]},"unlisted":false,"prevItem":{"title":"GitHub Actions : Workflow","permalink":"/blog/2024/12/20/04-ci-cd/workflow"},"nextItem":{"title":"Dokku","permalink":"/blog/2024/12/20/06-orchestration/orchestration-dokku"}},"content":"Docker Compose est un outil puissant qui permet de d\xe9finir et de g\xe9rer des applications multi-conteneurs Docker. Il utilise un fichier YAML pour configurer les services de l\'application. Ensuite, avec une seule commande, vous pouvez cr\xe9er et d\xe9marrer tous les services \xe0 partir de votre configuration.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que Docker Compose ?\\n\\nDocker Compose est un outil qui permet de d\xe9finir et de g\xe9rer des applications multi-conteneurs Docker. Il utilise un fichier YAML pour configurer les services de l\'application. Ensuite, avec une seule commande, vous pouvez cr\xe9er et d\xe9marrer tous les services \xe0 partir de votre configuration.\\n\\n## Exemple de fichier Docker Compose\\n\\nVoici un exemple de fichier `docker-compose.yml` pour une application web simple avec un service web et une base de donn\xe9es :\\n\\n```yaml\\nversion: \'3\'\\nservices:\\n  web:\\n    image: nginx:alpine\\n    ports:\\n      - \\"80:80\\"\\n  db:\\n    image: postgres:alpine\\n    environment:\\n      POSTGRES_DB: exampledb\\n      POSTGRES_USER: exampleuser\\n      POSTGRES_PASSWORD: examplepass\\n```\\n\\nDans cet exemple, nous avons deux services : `web` et `db`. Le service `web` utilise l\'image `nginx:alpine` et mappe le port 80 du conteneur au port 80 de l\'h\xf4te. Le service `db` utilise l\'image `postgres:alpine` et d\xe9finit quelques variables d\'environnement pour configurer la base de donn\xe9es.\\n\\n## Commandes Docker Compose\\n\\nVoici quelques commandes Docker Compose couramment utilis\xe9es :\\n\\n- `docker-compose up` : Cr\xe9e et d\xe9marre les conteneurs d\xe9finis dans le fichier `docker-compose.yml`.\\n- `docker-compose down` : Arr\xeate et supprime les conteneurs, les r\xe9seaux et les volumes cr\xe9\xe9s par `docker-compose up`.\\n- `docker-compose ps` : Affiche l\'\xe9tat des conteneurs d\xe9finis dans le fichier `docker-compose.yml`.\\n- `docker-compose logs` : Affiche les logs des conteneurs.\\n\\n## Sch\xe9ma explicatif\\n\\nVoici un sch\xe9ma expliquant comment Docker Compose fonctionne :\\n\\n![Sch\xe9ma Docker Compose](https://www.biaudelle.fr/wp-content/uploads/2021/07/docker-compose-archi.png)\\n\\n## D\xe9monstration pratique\\n\\nPour mieux comprendre l\'utilisation de Docker Compose, voici une d\xe9monstration pratique :\\n\\n```bash\\ndocker network create mynetwork\\ndocker-compose up -d\\ndocker-compose ps\\n```\\n\\nOuvrez votre navigateur et acc\xe9dez \xe0 `http://localhost`.\\n\\n```bash\\ndocker-compose down\\n```\\n\\n## Avantages cl\xe9s de Docker Compose\\n\\nL\'utilisation de Docker Compose offre plusieurs avantages qui simplifient le d\xe9veloppement, le d\xe9ploiement et la gestion des applications conteneuris\xe9es :\\n\\n- **Contr\xf4le simplifi\xe9** : Docker Compose vous permet de d\xe9finir et de g\xe9rer des applications multi-conteneurs dans un seul fichier YAML. Cela simplifie la t\xe2che complexe d\'orchestrer et de coordonner divers services, rendant plus facile la gestion et la r\xe9plication de votre environnement applicatif.\\n- **Collaboration efficace** : Les fichiers de configuration Docker Compose sont faciles \xe0 partager, facilitant la collaboration entre les d\xe9veloppeurs, les \xe9quipes d\'exploitation et les autres parties prenantes. Cette approche collaborative conduit \xe0 des flux de travail plus fluides, une r\xe9solution des probl\xe8mes plus rapide et une efficacit\xe9 globale accrue.\\n- **D\xe9veloppement rapide d\'applications** : Compose met en cache la configuration utilis\xe9e pour cr\xe9er un conteneur. Lorsque vous red\xe9marrez un service qui n\'a pas chang\xe9, Compose r\xe9utilise les conteneurs existants. La r\xe9utilisation des conteneurs signifie que vous pouvez apporter des modifications \xe0 votre environnement tr\xe8s rapidement.\\n- **Portabilit\xe9 entre les environnements** : Compose prend en charge les variables dans le fichier Compose. Vous pouvez utiliser ces variables pour personnaliser votre composition pour diff\xe9rents environnements ou diff\xe9rents utilisateurs.\\n- **Communaut\xe9 et support \xe9tendus** : Docker Compose b\xe9n\xe9ficie d\'une communaut\xe9 dynamique et active, ce qui signifie des ressources abondantes, des tutoriels et un support. Cet \xe9cosyst\xe8me communautaire contribue \xe0 l\'am\xe9lioration continue de Docker Compose et aide les utilisateurs \xe0 r\xe9soudre efficacement les probl\xe8mes.\\n\\nCompose peut \xeatre utilis\xe9 de nombreuses mani\xe8res diff\xe9rentes. Voici quelques cas d\'utilisation courants.\\n\\n### Environnements de d\xe9veloppement\\n\\nLorsque vous d\xe9veloppez des logiciels, la capacit\xe9 \xe0 ex\xe9cuter une application dans un environnement isol\xe9 et \xe0 interagir avec elle est cruciale. L\'outil en ligne de commande Compose peut \xeatre utilis\xe9 pour cr\xe9er l\'environnement et interagir avec lui.\\n\\nLe fichier Compose fournit un moyen de documenter et de configurer toutes les d\xe9pendances de service de l\'application (bases de donn\xe9es, files d\'attente, caches, API de services web, etc.). En utilisant l\'outil en ligne de commande Compose, vous pouvez cr\xe9er et d\xe9marrer un ou plusieurs conteneurs pour chaque d\xe9pendance avec une seule commande (`docker compose up`).\\n\\nEnsemble, ces fonctionnalit\xe9s offrent un moyen pratique de d\xe9marrer un projet. Compose peut r\xe9duire un \\"guide de d\xe9marrage pour les d\xe9veloppeurs\\" de plusieurs pages \xe0 un seul fichier Compose lisible par machine et quelques commandes.\\n\\n### Environnements de test automatis\xe9s\\n\\nUne partie importante de tout processus de d\xe9ploiement continu ou d\'int\xe9gration continue est la suite de tests automatis\xe9s. Les tests automatis\xe9s de bout en bout n\xe9cessitent un environnement dans lequel ex\xe9cuter les tests. Compose fournit un moyen pratique de cr\xe9er et de d\xe9truire des environnements de test isol\xe9s pour votre suite de tests. En d\xe9finissant l\'environnement complet dans un fichier Compose, vous pouvez cr\xe9er et d\xe9truire ces environnements en quelques commandes seulement.\\n\\n### D\xe9ploiements sur un seul h\xf4te\\n\\nCompose a traditionnellement \xe9t\xe9 ax\xe9 sur les flux de travail de d\xe9veloppement et de test, mais \xe0 chaque nouvelle version, nous progressons sur des fonctionnalit\xe9s plus orient\xe9es vers la production.\\n\\nPour plus de d\xe9tails sur l\'utilisation des fonctionnalit\xe9s orient\xe9es production, consultez [Compose en production](https://docs.docker.com/compose/production/).\\n\\n## Utilisation des secrets avec Docker Compose\\n\\nDocker Compose permet \xe9galement de g\xe9rer les secrets de mani\xe8re s\xe9curis\xe9e. Les secrets sont des informations sensibles telles que des mots de passe, des cl\xe9s API, etc., qui ne doivent pas \xeatre expos\xe9es dans le code source.\\n\\nVoici un exemple de configuration de secrets dans un fichier `docker-compose.yml` :\\n\\n```yaml\\nversion: \'3.7\'\\nservices:\\n  web:\\n    image: nginx:alpine\\n    secrets:\\n      - my_secret\\nsecrets:\\n  my_secret:\\n    file: ./my_secret.txt\\n```\\n\\nDans cet exemple, le service `web` utilise un secret nomm\xe9 `my_secret` qui est d\xe9fini dans le fichier `my_secret.txt`.\\n\\n## Support des GPU avec Docker Compose\\n\\nDocker Compose prend \xe9galement en charge l\'utilisation des GPU pour les applications n\xe9cessitant des capacit\xe9s de calcul intensif, telles que l\'apprentissage automatique et le traitement d\'images.\\n\\nVoici un exemple de configuration pour utiliser un GPU avec Docker Compose :\\n\\n```yaml\\nversion: \'3.8\'\\nservices:\\n  gpu_service:\\n    image: nvidia/cuda:10.2-base\\n    deploy:\\n      resources:\\n        reservations:\\n          devices:\\n            - capabilities: [gpu]\\n```\\n\\nDans cet exemple, le service `gpu_service` utilise l\'image `nvidia/cuda:10.2-base` et r\xe9serve un GPU pour le conteneur.\\n\\n\\n## Utilisation de la surveillance des fichiers avec Docker Compose\\n\\nDocker Compose permet \xe9galement de surveiller les modifications des fichiers et de red\xe9marrer automatiquement les services concern\xe9s. Cela est particuli\xe8rement utile pour les environnements de d\xe9veloppement.\\n\\nVoici un exemple de configuration de surveillance des fichiers dans un fichier `docker-compose.yml` :\\n\\n```yaml\\nversion: \'3.8\'\\nservices:\\n  web:\\n    image: nginx:alpine\\n    volumes:\\n      - ./src:/usr/share/nginx/html\\n    command: sh -c \\"nginx -g \'daemon off;\'\\"\\n    file_watch:\\n      watch: ./src\\n      action: restart\\n```\\n\\nDans cet exemple, le service `web` surveille les modifications dans le r\xe9pertoire `./src` et red\xe9marre automatiquement le service lorsque des modifications sont d\xe9tect\xe9es.\\n\\n## R\xe9seau dans Compose\\n\\n> **Important**\\n>\\n> La documentation de Docker se r\xe9f\xe8re et d\xe9crit les fonctionnalit\xe9s de Compose V2.\\n>\\n> \xc0 partir de juillet 2023, Compose V1 a cess\xe9 de recevoir des mises \xe0 jour et n\'est plus inclus dans les nouvelles versions de Docker Desktop. Compose V2 l\'a remplac\xe9 et est maintenant int\xe9gr\xe9 dans toutes les versions actuelles de Docker Desktop. Pour plus d\'informations, consultez [Migrer vers Compose V2](https://docs.docker.com/compose/migrate).\\n\\nPar d\xe9faut, Compose configure un seul [r\xe9seau](https://docs.docker.com/reference/cli/docker/network/create/) pour votre application. Chaque conteneur pour un service rejoint le r\xe9seau par d\xe9faut et est \xe0 la fois accessible par d\'autres conteneurs sur ce r\xe9seau et d\xe9couvrable par le nom du service.\\n\\n> **Remarque**\\n>\\n> Le r\xe9seau de votre application re\xe7oit un nom bas\xe9 sur le \\"nom du projet\\", qui est bas\xe9 sur le nom du r\xe9pertoire dans lequel il se trouve. Vous pouvez remplacer le nom du projet avec soit le [flag `--project-name`](https://docs.docker.com/reference/) soit la [variable d\'environnement `COMPOSE_PROJECT_NAME`](https://docs.docker.com/compose/environment-variables/envvars/#compose_project_name).\\n\\nPar exemple, supposons que votre application se trouve dans un r\xe9pertoire appel\xe9 `myapp`, et que votre `compose.yml` ressemble \xe0 ceci :\\n\\nLorsque vous ex\xe9cutez `docker compose up`, les actions suivantes se produisent :\\n\\n1.  Un r\xe9seau appel\xe9 `myapp_default` est cr\xe9\xe9.\\n2.  Un conteneur est cr\xe9\xe9 en utilisant la configuration de `web`. Il rejoint le r\xe9seau `myapp_default` sous le nom `web`.\\n3.  Un conteneur est cr\xe9\xe9 en utilisant la configuration de `db`. Il rejoint le r\xe9seau `myapp_default` sous le nom `db`.\\n\\nChaque conteneur peut maintenant rechercher le nom du service `web` ou `db` et obtenir l\'adresse IP appropri\xe9e du conteneur. Par exemple, le code de l\'application de `web` pourrait se connecter \xe0 l\'URL `postgres://db:5432` et commencer \xe0 utiliser la base de donn\xe9es Postgres.\\n\\nIl est important de noter la distinction entre `HOST_PORT` et `CONTAINER_PORT`. Dans l\'exemple ci-dessus, pour `db`, le `HOST_PORT` est `8001` et le port du conteneur est `5432` (par d\xe9faut pour postgres). La communication de service \xe0 service en r\xe9seau utilise le `CONTAINER_PORT`. Lorsque `HOST_PORT` est d\xe9fini, le service est \xe9galement accessible en dehors du swarm.\\n\\nDans le conteneur `web`, votre cha\xeene de connexion \xe0 `db` ressemblerait \xe0 `postgres://db:5432`, et depuis la machine h\xf4te, la cha\xeene de connexion ressemblerait \xe0 `postgres://{DOCKER_IP}:8001`, par exemple `postgres://localhost:8001` si votre conteneur s\'ex\xe9cute localement.\\n\\n### Mise \xe0 jour des conteneurs sur le r\xe9seau\\n\\nSi vous apportez une modification de configuration \xe0 un service et ex\xe9cutez `docker compose up` pour le mettre \xe0 jour, l\'ancien conteneur est supprim\xe9 et le nouveau rejoint le r\xe9seau sous une adresse IP diff\xe9rente mais avec le m\xeame nom. Les conteneurs en cours d\'ex\xe9cution peuvent rechercher ce nom et se connecter \xe0 la nouvelle adresse, mais l\'ancienne adresse cesse de fonctionner.\\n\\nSi des conteneurs ont des connexions ouvertes vers l\'ancien conteneur, elles sont ferm\xe9es. Il incombe au conteneur de d\xe9tecter cette condition, de rechercher \xe0 nouveau le nom et de se reconnecter.\\n\\n> **Astuce**\\n>\\n> R\xe9f\xe9rencez les conteneurs par nom, et non par IP, chaque fois que possible. Sinon, vous devrez constamment mettre \xe0 jour l\'adresse IP que vous utilisez.\\n\\n### R\xe9seau multi-h\xf4te\\n\\nLors du d\xe9ploiement d\'une application Compose sur un moteur Docker avec [le mode Swarm activ\xe9](https://docs.docker.com/engine/swarm/), vous pouvez utiliser le pilote int\xe9gr\xe9 `overlay` pour activer la communication multi-h\xf4te.\\n\\nLes r\xe9seaux overlay sont toujours cr\xe9\xe9s comme `attachable`. Vous pouvez \xe9ventuellement d\xe9finir la propri\xe9t\xe9 [`attachable`](https://docs.docker.com/reference/compose-file/networks/#attachable) sur `false`.\\n\\nConsultez la [section mode Swarm](https://docs.docker.com/engine/swarm/) pour savoir comment configurer un cluster Swarm, et le [guide de d\xe9marrage avec le r\xe9seau multi-h\xf4te](https://docs.docker.com/engine/network/tutorials/overlay/) pour en savoir plus sur les r\xe9seaux overlay multi-h\xf4te.\\n\\n### Sp\xe9cifier des r\xe9seaux personnalis\xe9s\\n\\nAu lieu d\'utiliser simplement le r\xe9seau d\'application par d\xe9faut, vous pouvez sp\xe9cifier vos propres r\xe9seaux avec la cl\xe9 de niveau sup\xe9rieur `networks`. Cela vous permet de cr\xe9er des topologies plus complexes et de sp\xe9cifier des [pilotes de r\xe9seau personnalis\xe9s](https://docs.docker.com/engine/extend/plugins_network/) et des options. Vous pouvez \xe9galement l\'utiliser pour connecter des services \xe0 des r\xe9seaux cr\xe9\xe9s en externe qui ne sont pas g\xe9r\xe9s par Compose.\\n\\nChaque service peut sp\xe9cifier \xe0 quels r\xe9seaux se connecter avec la cl\xe9 de niveau service `networks`, qui est une liste de noms r\xe9f\xe9rencant des entr\xe9es sous la cl\xe9 de niveau sup\xe9rieur `networks`.\\n\\nL\'exemple suivant montre un fichier Compose qui d\xe9finit deux r\xe9seaux personnalis\xe9s. Le service `proxy` est isol\xe9 du service `db`, car ils ne partagent pas de r\xe9seau en commun. Seul `app` peut parler aux deux.\\n\\nLes r\xe9seaux peuvent \xeatre configur\xe9s avec des adresses IP statiques en d\xe9finissant l\'[adresse ipv4 et/ou ipv6](https://docs.docker.com/reference/compose-file/services/#ipv4_address-ipv6_address) pour chaque r\xe9seau attach\xe9.\\n\\nLes r\xe9seaux peuvent \xe9galement recevoir un [nom personnalis\xe9](https://docs.docker.com/reference/compose-file/networks/#name) :\\n\\n### Configurer le r\xe9seau par d\xe9faut\\n\\nAu lieu de, ou en plus de, sp\xe9cifier vos propres r\xe9seaux, vous pouvez \xe9galement modifier les param\xe8tres du r\xe9seau par d\xe9faut de l\'application en d\xe9finissant une entr\xe9e sous `networks` nomm\xe9e `default` :\\n\\n### Utiliser un r\xe9seau pr\xe9existant\\n\\nSi vous souhaitez que vos conteneurs rejoignent un r\xe9seau pr\xe9existant, utilisez l\'option [`external`](https://docs.docker.com/reference/compose-file/networks/#external)\\n\\nAu lieu de tenter de cr\xe9er un r\xe9seau appel\xe9 `[projectname]_default`, Compose recherche un r\xe9seau appel\xe9 `my-pre-existing-network` et connecte les conteneurs de votre application \xe0 celui-ci.\\n\\n\\n## Conclusion\\n\\nDocker Compose est un outil puissant pour g\xe9rer des applications multi-conteneurs. Il simplifie la configuration, l\'isolation des environnements et la portabilit\xe9 des applications. En utilisant Docker Compose, vous pouvez facilement d\xe9finir et g\xe9rer des environnements de d\xe9veloppement, de test et de mise en sc\xe8ne, ainsi que des d\xe9ploiements de production simples.\\n\\nPour en savoir plus sur Docker Compose, vous pouvez consulter la [documentation officielle](https://docs.docker.com/compose/)."},{"id":"/2024/12/20/06-orchestration/orchestration-dokku","metadata":{"permalink":"/blog/2024/12/20/06-orchestration/orchestration-dokku","source":"@site/blog/06-orchestration/2024-12-20-orchestration-dokku.md","title":"Dokku","description":"Dokku est une plateforme open-source permettant le d\xe9ploiement, la gestion et la mise \xe0 l\'\xe9chelle des applications sur un serveur.","date":"2024-12-20T00:00:00.000Z","tags":[{"inline":false,"label":"Orchestration","permalink":"/blog/tags/orchestration"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":4.13,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Dokku","description":"Dokku est une plateforme open-source permettant le d\xe9ploiement, la gestion et la mise \xe0 l\'\xe9chelle des applications sur un serveur.","tags":["orchestration","devops"]},"unlisted":false,"prevItem":{"title":"Docker Compose","permalink":"/blog/2024/12/20/06-orchestration/docker-compose"},"nextItem":{"title":"Python : FastAPI","permalink":"/blog/2024/12/20/09-scripting/fastapi"}},"content":"Une alternative PAAS open source \xe0 Heroku [https://dokku.com/](https://dokku.com/)\\nDokku est une plateforme open-source permettant le d\xe9ploiement, la gestion et la mise \xe0 l\'\xe9chelle des applications sur un serveur. Inspir\xe9 par Heroku, il utilise une approche similaire pour le d\xe9ploiement d\'applications : le code se d\xe9ploie en effectuant un \\"push\\" vers un d\xe9p\xf4t Git sur le serveur. \xc0 la diff\xe9rence de Heroku, Dokku offre un contr\xf4le total sur l\'environnement de d\xe9ploiement. Ainsi, l\'infrastructure, le syst\xe8me d\'exploitation et les services (tels que les bases de donn\xe9es ou les files d\'attente de t\xe2ches) peuvent \xeatre personnalis\xe9s selon les besoins. Dokku s\'appuie sur Docker pour g\xe9rer les applications dans des conteneurs isol\xe9s, ce qui simplifie la gestion des applications et de leurs d\xe9pendances. Chaque \\"push\\" d\'une application \xe0 Dokku cr\xe9e un nouveau conteneur Docker.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Installation\\n\\n```shell\\n# download the installation script\\nwget -NP . <https://dokku.com/bootstrap.sh>\\n# run the installer\\nsudo DOKKU_TAG=v0.32.3 bash bootstrap.sh\\n# and your ssh key to the dokku user\\nPUBLIC_KEY=\\"your-public-key-contents-here\\"\\necho \\"$PUBLIC_KEY\\" | dokku ssh-keys:add admin\\n```\\n\\n## Premi\xe8re application\\n\\n```shell\\n# define global domains\\ndokku domains:set-global <your-domain>\\n# <your-domain> can be a rd party domain or a local domain like sonu-dev-gzsim.local\\n```\\n\\nSur la machine o\xf9 `dokku` est install\xe9\\n\\n```shell\\ndokku apps:create <app-name>\\nsudo dokku plugin:install <https://github.com/dokku/dokku-postgres.git>\\ndokku postgres:create railsdatabase\\ndokku postgres:link railsdatabase <app-name>\\n```\\n\\nSur la machine locale\\n\\n```shell\\ncd <app-name>\\ngit remote add dokku dokku@<your-domain>:<app-name>\\ngit push dokku main\\n```\\n\\n## Construire sa propre application\\n\\nDokku supporte plusieurs m\xe9thodes de build pour cr\xe9er des applications, chacun avec ses propres avantages sp\xe9cifiques :\\n\\n1. [**builder-dockerfile**](https://dokku.com/docs/deployment/builders/dockerfiles/): Cette m\xe9thode utilise un Dockerfile pour construire des applications via la commande `docker build`. Il donne un contr\xf4le maximal sur l\'environnement d\'ex\xe9cution de l\'application et sur la mani\xe8re dont l\'application est assembl\xe9e.\\n2. [**builder-herokuish**](https://dokku.com/docs/deployment/builders/herokuish-buildpacks/): Avec cette m\xe9thode, Dokku cr\xe9e des applications en utilisant la sp\xe9cification v2a Buildpack de Heroku via `gliderlabs/herokuish`. Il vous permet de profiter du m\xeame pipeline de build que Heroku, qui inclut le support pour de nombreux langages de programmation par d\xe9faut.\\n3. builder-lambda: Ce g\xe9n\xe9rateur construit des fonctions AWS Lambda dans un environnement simulant les temps d\'ex\xe9cution d\'AWS Lambda.\\n4. **builder-null**: Cette m\xe9thode ne fait rien pendant la phase de construction. C\'est utile pour les sc\xe9narios o\xf9 aucune construction n\'est n\xe9cessaire, comme le d\xe9ploiement d\'applications d\xe9j\xe0 compil\xe9es ou de conteneurs Docker.\\n5. **builder-pack**: Cette m\xe9thode utilise les Cloud Native Buildpacks pour construire des applications via l\'outil pack-cli. Les Cloud Native Buildpacks sont une norme ouverte qui \xe9tend les capacit\xe9s des Buildpacks classiques.\\n\\n## Automatiser le d\xe9ploiement via Github Actions\\n\\n```yaml\\nname: Deploy to Dokku (sonu-dev-gzsim)\\non:\\n    schedule:\\n    - cron: \'0 0 * * *\'\\n    workflow_dispatch:\\n    workflow_run:\\n    workflows: [ \\"Test build\\" ]\\n    types:\\n        - completed\\njobs:\\n    deploy:\\n    runs-on:\\n        group: default\\n    steps:\\n        - name: Cloning repo\\n        uses: actions/checkout@v4\\n        with:\\n            fetch-depth: 0\\n\\n        - name: Tailscale\\n        uses: tailscale/github-action@v2\\n        with:\\n            oauth-client-id: ${{ secrets.TS_OAUTH_CLIENT_ID }}\\n            oauth-secret: ${{ secrets.TS_OAUTH_SECRET }}\\n            tags: tag:server\\n\\n        - name: Push to dokku\\n        uses: dokku/github-action@master\\n        with:\\n            git_remote_url: \'ssh://dokku@100.65.237.90:22/rd25-robotics\'\\n            ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}\\n            branch: main\\n            git_push_flags: \'--force\'\\n\\n    if: ${{ github.event.workflow_run.conclusion == \'success\' }}\\n```\\n\\n## Astuces\\n\\n \u26a0\ufe0f Les astuces ci dessous correspondent **tr\xe8s certainement** \xe0 une incompr\xe9hension des m\xe9canismes de domain, proxy et reverse proxy\\n\\nPar d\xe9faut `dokku` d\xe9ploie l\u2019application sur une url construite comme suit : `http://<app-name>.<your-domain>` visiblement si le domaine est local (comme `sonu-dev-gzsim.local`) le reverse proxy ne fonctionne pas (la configuration `nginx` est \xe0 creuser) il est donc n\xe9cessaire de `disable` les domains avec la commande\\n\\n```shell\\ndokku domains:disable <app-name>\\n```\\n\\nCela aura pour effet de d\xe9sactiver le domaine pour l\u2019application en question. Elle tournera donc directement sur le port d\xe9fini al\xe9atoirement par `dokku`.\\n\xc0 chaque d\xe9ploiement, `dokku` construit un `dokker` pour g\xe9rer les applications de mani\xe8re isol\xe9e. Par d\xe9faut, les applications de type web doivent fournir leurs services sur le port `5000`. Par la suite, `dokku` s\u2019occupe de faire la redirection de port entre la machine et le container. Pour \xe9viter d\u2019avoir un port al\xe9atoire, il est possible de faire\\n\\n```shell\\ndokku ports:set <app-name> http:<machine-port>:<docker-port>\\n```\\n\\nAinsi, \xe0 chaque d\xe9ploiement, `dokku` redirigera le port de la machine vers le port du docker.\\nFinalement si vous souhaitez mettre en place une redirection comme `http://<your-domain>/<app-name>` vers l\u2019application il suffit de faire les modifications suivantes dans `nginx`\\nModifiez le fichier de configuration de Nginx pour votre site :\\n\\n```shell\\nsudo nano /etc/nginx/sites-available/your-config-file\\n```\\n\\nAjoutez la directive location dans votre configuration :\\n\\n```txt\\nserver { listen 80; server_name <your-domain>; location = <app-name> { return 301 http://$host:<machine-port>; } }\\n```\\n\\nCr\xe9ez un lien symbolique vers le fichier de configuration :\\n\\n```shell\\nsudo ln -s /etc/nginx/sites-available/your-config-file /etc/nginx/sites-enabled/\\n```\\n\\nV\xe9rifiez la configuration de Nginx :\\n\\n```shell\\nsudo nginx -t\\n```\\n\\nRed\xe9marrez Nginx pour appliquer les modifications :\\n\\n```shell\\nsudo systemctl restart nginx\\n```"},{"id":"/2024/12/20/09-scripting/fastapi","metadata":{"permalink":"/blog/2024/12/20/09-scripting/fastapi","source":"@site/blog/09-scripting/2024-12-20-fastapi.md","title":"Python : FastAPI","description":"FastAPI est un framework web moderne et rapide (hautes performances) pour la cr\xe9ation d\'API avec Python, bas\xe9 sur les annotations de types standard de Python.","date":"2024-12-20T00:00:00.000Z","tags":[{"inline":false,"label":"Scripting","permalink":"/blog/tags/scripting"}],"readingTime":3.51,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Python : FastAPI","description":"FastAPI est un framework web moderne et rapide (hautes performances) pour la cr\xe9ation d\'API avec Python, bas\xe9 sur les annotations de types standard de Python.","tags":["scripting"]},"unlisted":false,"prevItem":{"title":"Dokku","permalink":"/blog/2024/12/20/06-orchestration/orchestration-dokku"},"nextItem":{"title":"DevOps Roadmap 2024","permalink":"/blog/2024/01/01/devops-roadmap-2024"}},"content":"FastAPI est un framework web moderne et rapide (hautes performances) pour la cr\xe9ation d\'API avec Python, bas\xe9 sur les annotations de types standard de Python.\\n\\n\x3c!--truncate--\x3e\\n\\n## Aper\xe7u\\n\\nFastAPI est un framework web moderne et rapide (hautes performances) pour la cr\xe9ation d\'API avec Python, bas\xe9 sur les annotations de types standard de Python. Il offre des performances \xe9lev\xe9es, comparables \xe0 celles de NodeJS et Go, gr\xe2ce \xe0 Starlette et Pydantic, ce qui en fait l\'un des frameworks Python les plus rapides disponibles. FastAPI permet d\'augmenter la vitesse de d\xe9veloppement des fonctionnalit\xe9s de 200% \xe0 300%, de r\xe9duire d\'environ 40% les erreurs humaines des d\xe9veloppeurs, et propose un excellent support des \xe9diteurs avec des compl\xe9tions.\\n\\n|                         |                                 |\\n| ----------------------- | ------------------------------- |\\n| Site Web                | [https://fastapi.tiangolo.com/](https://fastapi.tiangolo.com/) |\\n| GitHub Stars            | > 75k \u2b50                         |\\n| Nombre de contributeurs | 700                             |\\n| Licence                 | MIT                             |\\n\\n- Finalit\xe9 : Cr\xe9ation des API web avec Python\\n- Int\xe9r\xeat : FastAPI est facile \xe0 utiliser et \xe0 apprendre, r\xe9duit la duplication de code, et produit du code pr\xeat pour la production avec une documentation interactive bas\xe9e sur les standards OpenAPI et JSON Schema.\\n- Gouvernance : Assur\xe9e par une \xe9quipe de mainteneurs dont [tiangolo](https://github.com/tiangolo) est le cr\xe9ateur et mainteneurs principal. A cela s\'ajoute des contributeurs individuels, le projet est soutenu par la communaut\xe9.\\n\\n### FastAPI vs Flask\\n\\n**FastAPI** est reconnu pour sa rapidit\xe9 et ses performances \xe9lev\xe9es, gr\xe2ce \xe0 Starlette et Pydantic. Il utilise les annotations de types standard de Python, ce qui am\xe9liore la validation et la s\xe9rialisation des donn\xe9es. FastAPI g\xe9n\xe8re automatiquement une documentation interactive et est bas\xe9 sur les standards OpenAPI et JSON Schema. Il est id\xe9al pour les projets n\xe9cessitant des performances \xe9lev\xe9es et une validation stricte des donn\xe9es.\\n\\n**Flask**, en revanche, est un micro-framework l\xe9ger et flexible, facile \xe0 apprendre et \xe0 utiliser. Il offre une grande libert\xe9 aux d\xe9veloppeurs pour structurer leurs applications comme ils le souhaitent. Flask est extensible via de nombreuses extensions tierces, ce qui le rend adapt\xe9 aux projets de toutes tailles. Cependant, il ne fournit pas de validation de donn\xe9es int\xe9gr\xe9e ni de documentation automatique comme FastAPI.\\n\\nEn r\xe9sum\xe9, FastAPI est plus adapt\xe9 pour les projets n\xe9cessitant des performances \xe9lev\xe9es et une validation stricte des donn\xe9es, tandis que Flask est con\xe7u pour les projets n\xe9cessitant flexibilit\xe9 et simplicit\xe9.\\n\\n## Utilisation\\n\\nPour installer FastAPI, vous pouvez utiliser pip :\\n\\n```bash\\npip install \\"fastapi[standard]\\"\\n```\\n\\nL\'exemple ci dessous est une API simpliste de gestion des To-Do List permettant aux utilisateurs de cr\xe9\xe9r, lire, mettre \xe0 jour et supprimer des t\xe2ches. Les sp\xe9cifications sont les suivantes :\\n\\n1. Cr\xe9er une t\xe2che : Permettre aux utilisateurs de cr\xe9er une nouvelle t\xe2che avec un titre et une description.\\n2. Lire les t\xe2ches : R\xe9cup\xe9rer la liste de toutes les t\xe2ches ou une t\xe2che sp\xe9cifique par son identifiant.\\n3. Mettre \xe0 jour une t\xe2che : Modifier les d\xe9tails d\'une t\xe2che existante.\\n4. Supprimer une t\xe2che : Supprimer une t\xe2che par son identifiant.\\n\\nL\'exemple ci dessous m\xe9lange plusieurs fonctionnalit\xe9s de FastAPI.\\n\\n```python\\nfrom datetime import date\\nfrom typing import Optional\\nfrom fastapi import FastAPI, Query\\nfrom pydantic import BaseModel\\nimport uvicorn\\n\\napp = FastAPI()\\n\\n\\nclass Task(BaseModel):\\n    id: int\\n    title: str\\n    description: str\\n    date: date\\n\\n\\ntasks: list[Task] = []\\n\\n\\n@app.post(\\"/tasks/\\", response_model=Task)\\ndef create_task(task: Task):\\n    tasks.append(task)\\n    return task\\n\\n\\n@app.get(\\"/tasks/\\", response_model=list[Task])\\ndef read_tasks(skip: int = 0, limit: int = 10):\\n    return tasks[skip : skip + limit]\\n\\n\\n@app.get(\\"/tasks/{task_id}\\", response_model=Task)\\ndef read_task(task_id: int):\\n    for task in tasks:\\n        if task.id == task_id:\\n            return task\\n    return {\\"error\\": \\"Task not found\\"}\\n\\n\\n@app.put(\\"/tasks/{task_id}\\", response_model=Task)\\ndef update_task(task_id: int, updated_task: Task):\\n    for task in tasks:\\n        if task.id == task_id:\\n            task.title = updated_task.title\\n            task.description = updated_task.description\\n            task.date = updated_task.date\\n            return task\\n    return {\\"error\\": \\"Task not found\\"}\\n\\n\\n@app.delete(\\"/tasks/{task_id}\\")\\ndef delete_task(task_id: int):\\n    global tasks\\n    tasks = [task for task in tasks if task.id != task_id]\\n    return {\\"message\\": \\"Task deleted\\"}\\n\\n\\n@app.get(\\"/search_tasks\\", response_model=list[Task])\\ndef search_tasks(\\n    title: Optional[str] = Query(None), date: Optional[date] = Query(None)\\n):\\n    results = tasks\\n    if title:\\n        results = [task for task in results if title.lower() in task.title.lower()]\\n    if date:\\n        results = [task for task in results if task.date == date]\\n    return results\\n```\\n\\nPour lancer l\'application :\\n\\n```bash\\nfastapi run /path/to/file.py # production mode\\nfastapi dev /path/to/file.py # development mode\\n```\\n\\nEn plus de l\'API, FastAPI g\xe9n\xe8re automatiquement une documentation interactive accessible \xe0 l\'adresse `http://127.0.0.1:8000/docs`\\n\\n![documentation](/img/fast-api-documentation.png)"},{"id":"/2024/01/01/devops-roadmap-2024","metadata":{"permalink":"/blog/2024/01/01/devops-roadmap-2024","source":"@site/blog/2024-01-01-devops-roadmap-2024.md","title":"DevOps Roadmap 2024","description":"Pr\xe9sentation de ma roadmap DevOps personnelle 2024","date":"2024-01-01T00:00:00.000Z","tags":[{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":2.64,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"DevOps Roadmap 2024","description":"Pr\xe9sentation de ma roadmap DevOps personnelle 2024","tags":["devops"]},"unlisted":false,"prevItem":{"title":"Python : FastAPI","permalink":"/blog/2024/12/20/09-scripting/fastapi"},"nextItem":{"title":"DevOps Roadmap","permalink":"/blog/2024/01/01/devops-roadmap"}},"content":"Voici un r\xe9sum\xe9 de ma roadmap DevOps personnelle pour 2024. Cette roadmap s\u2019appuie sur mon parcours d\u2019ing\xe9nieur informatique, mes exp\xe9riences en robotique, DevOps, auto-h\xe9bergement, CI/CD, et veille technologique. Elle \xe9volue au fil des projets, des exp\xe9rimentations et des apprentissages partag\xe9s sur le blog.\\n\\n\x3c!--truncate--\x3e\\n\\n# DevOps Roadmap 2024\\n\\nimport IconTitle from \'@site/src/components/IconTitle\';\\n\\n![DevOps](/img/devops.png)\\n\\n## Roadmap 2024\\n\\n### <IconTitle logo=\\"skill-icons:linux-light\\" name=\\"02 OS & Linux\\"/>\\n\\n[Syst\xe8me & Linux](/blog/tags/linux) Approfondissement des notions de r\xe9seau et de s\xe9curit\xe9, configuration avanc\xe9e des pare-feu, gestion des \xe9quilibreurs de charge et des proxies, ma\xeetrise des protocoles HTTP/HTTPS et de la virtualisation. L\u2019objectif est de fiabiliser l\u2019infrastructure, d\u2019automatiser la gestion des acc\xe8s et d\u2019optimiser la s\xe9curit\xe9 sur des environnements multi-plateformes.\\n\\n### <IconTitle logo=\\"skill-icons:docker\\" name=\\"03 Conten\xe9risation - Docker\\"/>\\n\\n[Conteneurisation](/blog/tags/containerization) D\xe9ploiement et supervision de stacks Docker Compose et Swarm, gestion centralis\xe9e des configurations, automatisation des mises \xe0 jour, documentation des architectures modulaires (Home Assistant, Dashy, n8n, Uptime Kuma\u2026). Exp\xe9rimentation de l\u2019orchestration \xe0 l\u2019\xe9chelle domestique, avec un accent sur la reproductibilit\xe9 et la s\xe9curit\xe9.\\n\\n### <IconTitle logo=\\"skill-icons:githubactions-light\\" name=\\"04 CI/CD Pipeline\\"/>\\n\\n[CI/CD](/blog/tags/cicd) Modernisation des pipelines CI/CD avec GitHub Actions, conception de workflows r\xe9utilisables pour build, test, publish, deploy, s\xe9curisation des acc\xe8s, documentation technique centralis\xe9e, publication automatique de releases/tags, support des runners personnalis\xe9s et matrices de jobs. Int\xe9gration de la supervision et de la gestion des artefacts.\\n\\n## Bilan 2023\\n\\n### <IconTitle logo=\\"mdi:code-braces\\" name=\\"01 Concepts du d\xe9veloppement logiciel\\"/>\\n\\n[D\xe9veloppement logiciel](/blog/tags/devops) La ma\xeetrise des m\xe9thodes de collaboration (Agile, Jira), de la gestion de versions avec Git, de la configuration des applications via des outils de build, du cycle de vie du d\xe9veloppement logiciel et des tests automatis\xe9s d\xe9coule naturellement d\u2019un parcours d\u2019ing\xe9nieur informatique, enrichi par des exp\xe9riences en entreprise et des projets personnels. Ces comp\xe9tences sont mobilis\xe9es au quotidien dans la conduite de projets, la veille technologique et la r\xe9daction d\u2019articles.\\n\\n### <IconTitle logo=\\"skill-icons:linux-light\\" name=\\"02 OS & Linux\\"/>\\n\\n[Syst\xe8me & Linux](/blog/tags/linux) L\u2019utilisation avanc\xe9e des commandes Shell, la gestion du syst\xe8me de fichiers et des permissions, la gestion des cl\xe9s SSH, la compr\xe9hension des adresses IP, ports et DNS sont des fondamentaux acquis lors de la formation d\u2019ing\xe9nieur, puis consolid\xe9s par la pratique sur des serveurs, clusters et environnements cloud, notamment dans des projets comme FervantFactory ou delpeuch.net.\\n\\n### <IconTitle logo=\\"skill-icons:python-light\\" name=\\"09 Langages de script - Python\\"/>\\n\\n[Scripting](/blog/tags/scripting) La ma\xeetrise de Python s\u2019explique par une sp\xe9cialisation en d\xe9veloppement logiciel et robotique, o\xf9 ce langage est central. Les scripts utilitaires pour automatiser les t\xe2ches de build, d\xe9ploiement, monitoring ou packaging sont issus de projets professionnels, associatifs et personnels, et sont r\xe9guli\xe8rement document\xe9s sur le blog.\\n\\n### <IconTitle logo=\\"skill-icons:git\\" name=\\"10 Contr\xf4le de version - Git\\"/>\\n\\n[Git](/blog/tags/devops) L\u2019usage de Git pour organiser, collaborer et versionner les projets applicatifs et d\u2019automatisation est une comp\xe9tence essentielle pour tout ing\xe9nieur informatique. Elle est mise en \u0153uvre dans la gestion de workflows, de pull requests et de revues de code sur GitHub et GitLab, aussi bien dans le cadre professionnel que pour les side-projects open source."},{"id":"/2024/01/01/devops-roadmap","metadata":{"permalink":"/blog/2024/01/01/devops-roadmap","source":"@site/blog/2024-01-01-devops-roadmap.md","title":"DevOps Roadmap","description":"Pr\xe9sentation de ma roadmap DevOps personnelle","date":"2024-01-01T00:00:00.000Z","tags":[{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops"}],"readingTime":3.09,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"DevOps Roadmap","description":"Pr\xe9sentation de ma roadmap DevOps personnelle","tags":["devops"]},"unlisted":false,"prevItem":{"title":"DevOps Roadmap 2024","permalink":"/blog/2024/01/01/devops-roadmap-2024"}},"content":"Ing\xe9nieur en informatique au [CATIE](http://catie.fr/) sp\xe9cialis\xe9 en Robotique, je travaille sur des projets de d\xe9veloppement logiciel et d\'int\xe9gration sur diff\xe9rentes plateformes. Intrigu\xe9 par l\'int\xe9gration et l\'automatisation, j\'ai d\xe9cid\xe9 d\'approfondir mes connaissances en DevOps.\\n\\n\x3c!--truncate--\x3e\\n\\nCette roadmap DevOps personnelle \xe9volue au fil de mes exp\xe9riences et objectifs. Elle est r\xe9guli\xe8rement mise \xe0 jour. Suggestions et commentaires sont les bienvenus.\\n\\n# DevOps Roadmap\\n\\nimport IconTitle from \'@site/src/components/IconTitle\';\\n\\n![DevOps](/img/devops.png)\\n\\n## <IconTitle logo=\\"mdi:code-braces\\" name=\\"01 Concepts du d\xe9veloppement logiciel\\"/>\\n\\n[D\xe9veloppement logiciel](/blog/tags/devops) Pour collaborer efficacement avec une \xe9quipe de d\xe9veloppement et automatiser les t\xe2ches, il est utile de comprendre les m\xe9thodes agiles, l\'utilisation d\'outils comme Jira, la gestion de versions avec Git, la configuration des applications via des outils de build, le cycle de vie du d\xe9veloppement logiciel et l\'int\xe9r\xeat des tests automatis\xe9s.\\n\\n## <IconTitle logo=\\"skill-icons:linux-light\\" name=\\"02 OS & Linux\\"/>\\n\\n[Syst\xe8me & Linux](/blog/tags/linux) Pr\xe9parer et maintenir l\'infrastructure sur laquelle une application est d\xe9ploy\xe9e implique de ma\xeetriser l\'administration d\'un serveur, l\'installation d\'outils, la gestion des permissions et des cl\xe9s SSH, la configuration des pare-feu, ainsi que les notions de r\xe9seau, s\xe9curit\xe9, virtualisation et protocoles comme HTTP/HTTPS.\\n\\n## <IconTitle logo=\\"skill-icons:docker\\" name=\\"03 Conten\xe9risation - Docker\\"/>\\n\\n[Conteneurisation](/blog/tags/containerization) La conteneurisation est devenue le standard pour l\'emballage logiciel. Comprendre Docker, ses r\xe9seaux, la persistance des donn\xe9es, la cr\xe9ation de Dockerfiles, l\'utilisation de Docker-Compose et la gestion des d\xe9p\xf4ts permet de d\xe9ployer et g\xe9rer des applications de fa\xe7on moderne.\\n\\n## <IconTitle logo=\\"skill-icons:githubactions-light\\" name=\\"04 CI/CD Pipeline\\"/>\\n\\n[CI/CD](/blog/tags/cicd) L\'int\xe9gration et le d\xe9ploiement continus (CI/CD) sont au c\u0153ur du DevOps. Configurer un serveur CI/CD, automatiser les pipelines, g\xe9rer les tests et les artefacts, et int\xe9grer le d\xe9p\xf4t de code sont des pratiques qui facilitent la livraison rapide et fiable des applications.\\n\\n## <IconTitle logo=\\"skill-icons:aws-light\\" name=\\"05 Cloud\\"/>\\n\\n[Cloud](/blog/tags/cloud) L\'infrastructure cloud est aujourd\'hui omnipr\xe9sente. Se familiariser avec les services propos\xe9s par AWS, Azure ou Google Cloud, comme la gestion des utilisateurs (IAM), des r\xe9seaux priv\xe9s (VPC) et des serveurs virtuels (EC2), permet d\'administrer des environnements complexes et \xe9volutifs.\\n\\n## <IconTitle logo=\\"skill-icons:kubernetes\\" name=\\"06 Orchestration de conteneurs - Kubernetes & Docker Swarm\\"/>\\n\\n[Orchestration](/blog/tags/orchestration) L\'orchestration de conteneurs avec Kubernetes ou Docker Swarm facilite la gestion de centaines de conteneurs sur plusieurs serveurs. Ma\xeetriser les composants de base, la CLI kubectl, la persistance des donn\xe9es et les namespaces est essentiel pour piloter des infrastructures modernes.\\n\\n## <IconTitle logo=\\"skill-icons:prometheus\\" name=\\"07 Monitoring & Observabilit\xe9\\"/>\\n\\n[Observabilit\xe9](/blog/tags/monitoring) La surveillance des applications en production repose sur des outils comme Prometheus, Grafana ou l\'ELK Stack. Ces solutions permettent de suivre les performances, d\xe9tecter les probl\xe8mes et visualiser les donn\xe9es pour garantir la fiabilit\xe9 des syst\xe8mes.\\n\\n## <IconTitle logo=\\"skill-icons:terraform-light\\" name=\\"08 Infrastructure as Code\\"/>\\n\\n[Infrastructure as Code](/blog/tags/iac) Automatiser la cr\xe9ation et la gestion de l\'infrastructure gr\xe2ce \xe0 des outils comme Terraform ou Ansible r\xe9duit les erreurs et acc\xe9l\xe8re le d\xe9ploiement. L\'approche Infrastructure as Code favorise la reproductibilit\xe9 et la gestion des environnements.\\n\\n## <IconTitle logo=\\"skill-icons:python-light\\" name=\\"09 Langages de script - Python\\"/>\\n\\n[Scripting](/blog/tags/scripting) L\'automatisation des t\xe2ches de d\xe9veloppement et d\'op\xe9rations passe souvent par l\'\xe9criture de scripts. Python, accessible et polyvalent, permet de cr\xe9er des utilitaires pour g\xe9rer les builds, les d\xe9ploiements ou le nettoyage des environnements.\\n\\n<IconTitle logo=\\"skill-icons:git\\" name=\\"10 Contr\xf4le de version - Git\\"/>\\n\\n[Git](/blog/tags/devops) Le contr\xf4le de version est indispensable pour collaborer sur du code, suivre les modifications et g\xe9rer les branches. Git, via des plateformes comme GitHub ou GitLab, offre une base solide pour organiser et partager les projets, qu\'ils soient applicatifs ou li\xe9s \xe0 l\'automatisation."}]}}')}}]);