"use strict";(self.webpackChunksedelpeuch_net=self.webpackChunksedelpeuch_net||[]).push([[8130],{77735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/2024/08/26/09-scripting/fastapi","metadata":{"permalink":"/blog/2024/08/26/09-scripting/fastapi","source":"@site/blog/09-scripting/2024-08-26-fastapi.md","title":"FastAPI","description":"FastAPI est un framework web moderne et rapide (hautes performances) pour la cr\xe9ation d\'API avec Python, bas\xe9 sur les annotations de types standard de Python.","date":"2024-08-26T00:00:00.000Z","tags":[{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"},{"inline":true,"label":"Python","permalink":"/blog/tags/python"}],"readingTime":3.58,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"FastAPI","description":"FastAPI est un framework web moderne et rapide (hautes performances) pour la cr\xe9ation d\'API avec Python, bas\xe9 sur les annotations de types standard de Python.","tags":["Devops","Python"]},"unlisted":false,"nextItem":{"title":"Diff\xe9rence entre un proxy et un reverse proxy","permalink":"/blog/2024/05/12/02-network/proxy-vs-reverse-proxy"}},"content":"FastAPI est un framework web moderne et rapide (hautes performances) pour la cr\xe9ation d\'API avec Python, bas\xe9 sur les annotations de types standard de Python.\\n\\n\x3c!--truncate--\x3e\\n\\n## Aper\xe7u\\n\\nFastAPI est un framework web moderne et rapide (hautes performances) pour la cr\xe9ation d\'API avec Python, bas\xe9 sur les annotations de types standard de Python. Il offre des performances \xe9lev\xe9es, comparables \xe0 celles de NodeJS et Go, gr\xe2ce \xe0 Starlette et Pydantic, ce qui en fait l\'un des frameworks Python les plus rapides disponibles. FastAPI permet d\'augmenter la vitesse de d\xe9veloppement des fonctionnalit\xe9s de 200% \xe0 300%, de r\xe9duire d\'environ 40% les erreurs humaines des d\xe9veloppeurs, et propose un excellent support des \xe9diteurs avec des compl\xe9tions.\\n\\n|                         |                                 |\\n| ----------------------- | ------------------------------- |\\n| Site Web                | [https://fastapi.tiangolo.com/](https://fastapi.tiangolo.com/) |\\n| GitHub Stars            | > 75k \u2b50                         |\\n| Nombre de contributeurs | 700                             |\\n| Licence                 | MIT                             |\\n\\n- Finalit\xe9 : Cr\xe9ation des API web avec Python\\n- Int\xe9r\xeat : FastAPI est facile \xe0 utiliser et \xe0 apprendre, r\xe9duit la duplication de code, et produit du code pr\xeat pour la production avec une documentation interactive bas\xe9e sur les standards OpenAPI et JSON Schema.\\n- Gouvernance : Assur\xe9e par une \xe9quipe de mainteneurs dont [tiangolo](https://github.com/tiangolo) est le cr\xe9ateur et mainteneurs principal. A cela s\'ajoute des contributeurs individuels, le projet est soutenu par la communaut\xe9.\\n\\n### FastAPI vs Flask\\n\\n**FastAPI** est reconnu pour sa rapidit\xe9 et ses performances \xe9lev\xe9es, gr\xe2ce \xe0 Starlette et Pydantic. Il utilise les annotations de types standard de Python, ce qui am\xe9liore la validation et la s\xe9rialisation des donn\xe9es. FastAPI g\xe9n\xe8re automatiquement une documentation interactive et est bas\xe9 sur les standards OpenAPI et JSON Schema. Il est id\xe9al pour les projets n\xe9cessitant des performances \xe9lev\xe9es et une validation stricte des donn\xe9es.\\n\\n**Flask**, en revanche, est un micro-framework l\xe9ger et flexible, facile \xe0 apprendre et \xe0 utiliser. Il offre une grande libert\xe9 aux d\xe9veloppeurs pour structurer leurs applications comme ils le souhaitent. Flask est extensible via de nombreuses extensions tierces, ce qui le rend adapt\xe9 aux projets de toutes tailles. Cependant, il ne fournit pas de validation de donn\xe9es int\xe9gr\xe9e ni de documentation automatique comme FastAPI.\\n\\nEn r\xe9sum\xe9, FastAPI est plus adapt\xe9 pour les projets n\xe9cessitant des performances \xe9lev\xe9es et une validation stricte des donn\xe9es, tandis que Flask est con\xe7u pour les projets n\xe9cessitant flexibilit\xe9 et simplicit\xe9.\\n\\n## Utilisation\\n\\nPour installer FastAPI, vous pouvez utiliser pip :\\n\\n```bash\\npip install \\"fastapi[standard]\\"\\n```\\n\\nL\'exemple ci dessous est une API simpliste de gestion des To-Do List permettant aux utilisateurs de cr\xe9\xe9r, lire, mettre \xe0 jour et supprimer des t\xe2ches. Les sp\xe9cifications sont les suivantes :\\n\\n1. Cr\xe9er une t\xe2che : Permettre aux utilisateurs de cr\xe9er une nouvelle t\xe2che avec un titre et une description.\\n2. Lire les t\xe2ches : R\xe9cup\xe9rer la liste de toutes les t\xe2ches ou une t\xe2che sp\xe9cifique par son identifiant.\\n3. Mettre \xe0 jour une t\xe2che : Modifier les d\xe9tails d\'une t\xe2che existante.\\n4. Supprimer une t\xe2che : Supprimer une t\xe2che par son identifiant.\\n\\nL\'exemple ci dessous m\xe9lange plusieurs fonctionnalit\xe9s de FastAPI.\\n\\n```python\\nfrom datetime import date\\nfrom typing import Optional\\nfrom fastapi import FastAPI, Query\\nfrom pydantic import BaseModel\\nimport uvicorn\\n\\napp = FastAPI()\\n\\n\\nclass Task(BaseModel):\\n    id: int\\n    title: str\\n    description: str\\n    date: date\\n\\n\\ntasks: list[Task] = []\\n\\n\\n@app.post(\\"/tasks/\\", response_model=Task)\\ndef create_task(task: Task):\\n    tasks.append(task)\\n    return task\\n\\n\\n@app.get(\\"/tasks/\\", response_model=list[Task])\\ndef read_tasks(skip: int = 0, limit: int = 10):\\n    return tasks[skip : skip + limit]\\n\\n\\n@app.get(\\"/tasks/{task_id}\\", response_model=Task)\\ndef read_task(task_id: int):\\n    for task in tasks:\\n        if task.id == task_id:\\n            return task\\n    return {\\"error\\": \\"Task not found\\"}\\n\\n\\n@app.put(\\"/tasks/{task_id}\\", response_model=Task)\\ndef update_task(task_id: int, updated_task: Task):\\n    for task in tasks:\\n        if task.id == task_id:\\n            task.title = updated_task.title\\n            task.description = updated_task.description\\n            task.date = updated_task.date\\n            return task\\n    return {\\"error\\": \\"Task not found\\"}\\n\\n\\n@app.delete(\\"/tasks/{task_id}\\")\\ndef delete_task(task_id: int):\\n    global tasks\\n    tasks = [task for task in tasks if task.id != task_id]\\n    return {\\"message\\": \\"Task deleted\\"}\\n\\n\\n@app.get(\\"/search_tasks\\", response_model=list[Task])\\ndef search_tasks(\\n    title: Optional[str] = Query(None), date: Optional[date] = Query(None)\\n):\\n    results = tasks\\n    if title:\\n        results = [task for task in results if title.lower() in task.title.lower()]\\n    if date:\\n        results = [task for task in results if task.date == date]\\n    return results\\n```\\n\\nPour lancer l\'application :\\n\\n```bash\\nfastapi run /path/to/file.py # production mode\\nfastapi dev /path/to/file.py # development mode\\n```\\n\\nEn plus de l\'API, FastAPI g\xe9n\xe8re automatiquement une documentation interactive accessible \xe0 l\'adresse `http://127.0.0.1:8000/docs`\\n\\n![documentation](/img/fast-api-documentation.png)"},{"id":"/2024/05/12/02-network/proxy-vs-reverse-proxy","metadata":{"permalink":"/blog/2024/05/12/02-network/proxy-vs-reverse-proxy","source":"@site/blog/02-network/2024-05-12-proxy-vs-reverse-proxy.md","title":"Diff\xe9rence entre un proxy et un reverse proxy","description":"Explication de la diff\xe9rence entre un proxy et un reverse proxy, inspir\xe9e du transcript de la vid\xe9o \'Proxy vs Reverse Proxy vs Load Balancer | Simply Explained\'.","date":"2024-05-12T00:00:00.000Z","tags":[{"inline":true,"label":"Proxy","permalink":"/blog/tags/proxy"},{"inline":true,"label":"Reverse Proxy","permalink":"/blog/tags/reverse-proxy"},{"inline":true,"label":"Network","permalink":"/blog/tags/network"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":5.03,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Diff\xe9rence entre un proxy et un reverse proxy","description":"Explication de la diff\xe9rence entre un proxy et un reverse proxy, inspir\xe9e du transcript de la vid\xe9o \'Proxy vs Reverse Proxy vs Load Balancer | Simply Explained\'.","tags":["Proxy","Reverse Proxy","Network","Devops"]},"unlisted":false,"prevItem":{"title":"FastAPI","permalink":"/blog/2024/08/26/09-scripting/fastapi"},"nextItem":{"title":"Pr\xe9sentation de Nginx","permalink":"/blog/2024/05/05/02-network/nginx"}},"content":"Dans cet article, nous allons explorer la diff\xe9rence entre un proxy et un reverse proxy.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce qu\'un proxy ?\\n\\nUn proxy, \xe9galement connu sous le nom de proxy direct ou proxy de transfert, est un serveur qui agit comme un interm\xe9diaire entre un client (par exemple, un utilisateur ou un appareil) et un serveur de destination sur Internet. Voici un aper\xe7u d\xe9taill\xe9 de son fonctionnement :\\n\\n1. **Interception des requ\xeates** : Lorsqu\'un client souhaite acc\xe9der \xe0 une ressource sur Internet, il envoie une requ\xeate au proxy au lieu de se connecter directement au serveur de destination. Le proxy intercepte cette requ\xeate.\\n\\n2. **Filtrage et s\xe9curit\xe9** : Le proxy examine la requ\xeate pour s\'assurer qu\'elle respecte les politiques de s\xe9curit\xe9 et de filtrage d\xe9finies par l\'administrateur r\xe9seau. Il peut bloquer l\'acc\xe8s \xe0 certains sites web, filtrer les contenus inappropri\xe9s ou malveillants, et appliquer des r\xe8gles de s\xe9curit\xe9.\\n\\n3. **Anonymisation** : Le proxy peut masquer l\'adresse IP du client en utilisant sa propre adresse IP pour se connecter au serveur de destination. Cela permet de prot\xe9ger l\'identit\xe9 et la confidentialit\xe9 du client.\\n\\n4. **Mise en cache** : Le proxy peut mettre en cache les r\xe9ponses des serveurs de destination. Si un autre client demande la m\xeame ressource, le proxy peut fournir la r\xe9ponse mise en cache, ce qui r\xe9duit la charge sur le serveur de destination et am\xe9liore les temps de r\xe9ponse.\\n\\n5. **Transmission de la requ\xeate** : Si la requ\xeate est autoris\xe9e, le proxy la transmet au serveur de destination en utilisant sa propre adresse IP. Le serveur de destination r\xe9pond alors au proxy.\\n\\n6. **Retour de la r\xe9ponse** : Le proxy re\xe7oit la r\xe9ponse du serveur de destination, la filtre \xe0 nouveau si n\xe9cessaire, et la renvoie au client. Le client re\xe7oit ainsi la r\xe9ponse comme s\'il avait directement communiqu\xe9 avec le serveur de destination.\\n\\n### Exemple d\'utilisation d\'un proxy\\n\\nImaginez que vous planifiez un d\xeener dans un restaurant populaire, mais que vous ne voulez pas interagir directement avec le personnel. Vous avez donc un assistant personnel qui fait la r\xe9servation pour vous. Le personnel du restaurant ne communique qu\'avec votre assistant, pas directement avec vous. Dans ce sc\xe9nario, votre assistant personnel est un proxy.\\n\\nDans un contexte d\'entreprise, un administrateur peut configurer tout le trafic Internet des ordinateurs des employ\xe9s pour qu\'il passe par un proxy. Cela permet de prot\xe9ger le r\xe9seau interne de l\'entreprise en bloquant les sites web malveillants et en filtrant le trafic.\\n\\nUn proxy peut \xe9galement mettre en cache les r\xe9ponses des serveurs backend pour r\xe9duire la charge et am\xe9liorer les temps de r\xe9ponse. Par exemple, si un employ\xe9 regarde une vid\xe9o YouTube, le proxy peut mettre en cache cette vid\xe9o pour que les autres employ\xe9s puissent la regarder sans consommer de bande passante suppl\xe9mentaire.\\n\\n## Qu\'est-ce qu\'un reverse proxy ?\\n\\n\\nUn reverse proxy, \xe9galement connu sous le nom de proxy inverse, est un serveur qui se trouve devant les serveurs internes d\'une entreprise et g\xe8re les requ\xeates entrantes des clients. Voici un aper\xe7u d\xe9taill\xe9 de son fonctionnement :\\n\\n1. **R\xe9ception des requ\xeates** : Lorsqu\'un client envoie une requ\xeate pour acc\xe9der \xe0 une ressource sur un serveur interne, la requ\xeate est d\'abord re\xe7ue par le reverse proxy au lieu d\'\xeatre directement envoy\xe9e au serveur interne.\\n\\n2. **Distribution des requ\xeates** : Le reverse proxy examine la requ\xeate et la distribue au serveur interne appropri\xe9 en fonction de la capacit\xe9, de la charge et des r\xe8gles de routage d\xe9finies. Cela permet de r\xe9partir la charge de mani\xe8re \xe9quilibr\xe9e entre les serveurs internes.\\n\\n3. **S\xe9curit\xe9 et filtrage** : Le reverse proxy peut appliquer des politiques de s\xe9curit\xe9 pour filtrer les requ\xeates malveillantes, bloquer les attaques DDoS, et assurer le chiffrement SSL/TLS pour s\xe9curiser les communications entre les clients et les serveurs internes.\\n\\n4. **Mise en cache** : Le reverse proxy peut mettre en cache les r\xe9ponses des serveurs internes. Si un autre client demande la m\xeame ressource, le reverse proxy peut fournir la r\xe9ponse mise en cache, ce qui r\xe9duit la charge sur les serveurs internes et am\xe9liore les temps de r\xe9ponse.\\n\\n5. **Retour de la r\xe9ponse** : Le serveur interne r\xe9pond au reverse proxy, qui filtre \xe0 nouveau la r\xe9ponse si n\xe9cessaire, et la renvoie au client. Le client re\xe7oit ainsi la r\xe9ponse comme s\'il avait directement communiqu\xe9 avec le serveur interne.\\n\\n6. **Surveillance et journalisation** : Le reverse proxy peut surveiller et journaliser les requ\xeates et les r\xe9ponses pour des raisons de s\xe9curit\xe9, de d\xe9pannage et d\'analyse des performances.\\n\\n### Exemple d\'utilisation d\'un reverse proxy\\n\\nReprenons l\'analogie du restaurant. Lorsque vous arrivez au restaurant, au lieu de chercher une table vous-m\xeame, vous vous enregistrez \xe0 la r\xe9ception. Le r\xe9ceptionniste vous montre la table appropri\xe9e. Ici, le r\xe9ceptionniste est un reverse proxy.\\n\\nUn reverse proxy peut \xe9galement agir comme un bouclier pour prot\xe9ger les serveurs internes en filtrant les requ\xeates et en assurant le chiffrement SSL. Il peut \xe9galement mettre en cache les r\xe9ponses pour acc\xe9l\xe9rer les temps de r\xe9ponse aux clients.\\n\\nUn reverse proxy peut \xe9galement fournir des fonctionnalit\xe9s d\'\xe9quilibrage de charge. Par exemple, si un serveur est surcharg\xe9, le reverse proxy peut rediriger les requ\xeates vers un autre serveur moins occup\xe9. Cela permet d\'assurer une r\xe9partition \xe9quilibr\xe9e de la charge et d\'am\xe9liorer les performances globales du syst\xe8me.\\n\\n## Diff\xe9rences cl\xe9s entre un proxy et un reverse proxy\\n\\n- **Fonctionnalit\xe9** : Un proxy agit comme un interm\xe9diaire pour les requ\xeates sortantes, tandis qu\'un reverse proxy g\xe8re les requ\xeates entrantes.\\n- **S\xe9curit\xe9** : Les deux types de proxy offrent des fonctionnalit\xe9s de s\xe9curit\xe9, mais un reverse proxy prot\xe8ge les serveurs internes en filtrant les requ\xeates entrantes.\\n- **Caching** : Les deux types de proxy peuvent mettre en cache les r\xe9ponses, mais un reverse proxy le fait pour acc\xe9l\xe9rer les temps de r\xe9ponse aux clients.\\n\\nEn r\xe9sum\xe9, un proxy et un reverse proxy ont des r\xf4les diff\xe9rents mais compl\xe9mentaires dans la gestion du trafic r\xe9seau. Un proxy prot\xe8ge les utilisateurs en filtrant le trafic sortant, tandis qu\'un reverse proxy prot\xe8ge les serveurs en g\xe9rant les requ\xeates entrantes.\\n\\n## Sch\xe9ma r\xe9capitulatif\\n\\n![Sch\xe9ma r\xe9capitulatif](https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fwqces5nwe4hb4bydyd13.png)"},{"id":"/2024/05/05/02-network/nginx","metadata":{"permalink":"/blog/2024/05/05/02-network/nginx","source":"@site/blog/02-network/2024-05-05-nginx.md","title":"Pr\xe9sentation de Nginx","description":"Pr\xe9sentation de Nginx, son but et ses exemples d\'utilisation dans la vie r\xe9elle.","date":"2024-05-05T00:00:00.000Z","tags":[{"inline":true,"label":"Nginx","permalink":"/blog/tags/nginx"},{"inline":true,"label":"Network","permalink":"/blog/tags/network"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":2.55,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Pr\xe9sentation de Nginx","description":"Pr\xe9sentation de Nginx, son but et ses exemples d\'utilisation dans la vie r\xe9elle.","tags":["Nginx","Network","Devops"]},"unlisted":false,"prevItem":{"title":"Diff\xe9rence entre un proxy et un reverse proxy","permalink":"/blog/2024/05/12/02-network/proxy-vs-reverse-proxy"},"nextItem":{"title":"Dokku","permalink":"/blog/2024/04/07/06-orchestration/orchestration-dokku"}},"content":"Nginx est un serveur web open-source con\xe7u pour g\xe9rer un grand nombre de connexions simultan\xe9es. Il couvre les fonctionnalit\xe9s de Nginx telles que l\'\xe9quilibrage de charge, le caching, la s\xe9curit\xe9 et la compression, ainsi que des exemples d\'utilisation dans la vie r\xe9elle.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que Nginx et pourquoi a-t-il \xe9t\xe9 cr\xe9\xe9 ?\\n\\nNginx est un serveur web open-source qui a \xe9t\xe9 cr\xe9\xe9 pour g\xe9rer un grand nombre de connexions simultan\xe9es. Il a \xe9t\xe9 con\xe7u pour \xeatre rapide, l\xe9ger et efficace. Nginx est souvent utilis\xe9 comme serveur web, mais il peut \xe9galement \xeatre utilis\xe9 comme proxy inverse, \xe9quilibrage de charge, et serveur de cache.\\n\\n### Exemples d\'utilisation de Nginx\\n\\nNginx est souvent utilis\xe9 pour servir des pages web statiques et dynamiques. Il est capable de g\xe9rer des milliers de connexions simultan\xe9es avec une faible utilisation de la m\xe9moire.\\n\\nNginx peut agir comme un proxy inverse pour distribuer les requ\xeates des clients \xe0 plusieurs serveurs backend. Cela permet de r\xe9partir la charge et d\'am\xe9liorer les performances.\\n\\nNginx peut \xeatre utilis\xe9 pour r\xe9partir les requ\xeates entrantes entre plusieurs serveurs, assurant ainsi une r\xe9partition \xe9quilibr\xe9e de la charge.\\n\\nNginx peut mettre en cache les r\xe9ponses des serveurs backend pour r\xe9duire la charge et am\xe9liorer les temps de r\xe9ponse.\\n\\n## Fonctionnalit\xe9s de Nginx\\n\\nL\'\xe9quilibrage de charge est une fonctionnalit\xe9 cl\xe9 de Nginx. Il permet de distribuer les requ\xeates entrantes entre plusieurs serveurs backend. Nginx prend en charge plusieurs algorithmes d\'\xe9quilibrage de charge, tels que le round-robin, le least connections, et l\'IP hash.\\n\\nNginx peut mettre en cache les r\xe9ponses des serveurs backend pour r\xe9duire la charge et am\xe9liorer les temps de r\xe9ponse. Le caching est particuli\xe8rement utile pour les contenus statiques qui ne changent pas fr\xe9quemment.\\n\\nNginx offre plusieurs fonctionnalit\xe9s de s\xe9curit\xe9, telles que la gestion des certificats SSL/TLS, la limitation du nombre de connexions, et la protection contre les attaques DDoS. En utilisant Nginx comme proxy inverse, vous pouvez \xe9galement masquer les d\xe9tails de votre infrastructure backend.\\n\\nNginx peut compresser les r\xe9ponses avant de les envoyer aux clients. Cela permet de r\xe9duire la quantit\xe9 de donn\xe9es transf\xe9r\xe9es et d\'am\xe9liorer les temps de chargement des pages. Nginx prend en charge plusieurs formats de compression, tels que gzip et brotli.\\n\\n## Configuration de Nginx\\n\\nLa configuration de Nginx se fait \xe0 l\'aide de fichiers de configuration. Voici un exemple de configuration simple pour un serveur web :\\n\\n```nginx\\nserver {\\n    listen 80;\\n    server_name example.com;\\n\\n    location / {\\n        root /var/www/html;\\n        index index.html index.htm;\\n    }\\n\\n    location /images/ {\\n        root /data;\\n    }\\n}\\n```\\n\\nDans cet exemple, Nginx \xe9coute sur le port 80 et sert les fichiers du r\xe9pertoire `/var/www/html` pour les requ\xeates \xe0 la racine. Les requ\xeates pour `/images/` sont servies \xe0 partir du r\xe9pertoire `/data`.\\n\\n## Conclusion\\n\\nNginx est un outil puissant et polyvalent qui peut \xeatre utilis\xe9 pour une vari\xe9t\xe9 de t\xe2ches, allant de la simple diffusion de contenu web \xe0 l\'\xe9quilibrage de charge et au caching. Sa flexibilit\xe9 et ses performances en font un choix populaire pour de nombreuses entreprises et d\xe9veloppeurs.\\n\\nPour en savoir plus sur Nginx, vous pouvez consulter la [documentation officielle](https://nginx.org/en/docs/)."},{"id":"/2024/04/07/06-orchestration/orchestration-dokku","metadata":{"permalink":"/blog/2024/04/07/06-orchestration/orchestration-dokku","source":"@site/blog/06-orchestration/2024-04-07-orchestration-dokku.md","title":"Dokku","description":"Dokku est une plateforme open-source permettant le d\xe9ploiement, la gestion et la mise \xe0 l\'\xe9chelle des applications sur un serveur.","date":"2024-04-07T00:00:00.000Z","tags":[{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"},{"inline":true,"label":"Orchestration","permalink":"/blog/tags/orchestration"},{"inline":true,"label":"Alternatives","permalink":"/blog/tags/alternatives"}],"readingTime":3.9,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Dokku","description":"Dokku est une plateforme open-source permettant le d\xe9ploiement, la gestion et la mise \xe0 l\'\xe9chelle des applications sur un serveur.","tags":["Devops","Orchestration","Alternatives"]},"unlisted":false,"prevItem":{"title":"Pr\xe9sentation de Nginx","permalink":"/blog/2024/05/05/02-network/nginx"},"nextItem":{"title":"GitHub GHCR","permalink":"/blog/2024/03/24/03-containerization/ghrc"}},"content":"Une alternative PAAS open source \xe0 Heroku [https://dokku.com/](https://dokku.com/)\\nDokku est une plateforme open-source permettant le d\xe9ploiement, la gestion et la mise \xe0 l\'\xe9chelle des applications sur un serveur. Inspir\xe9 par Heroku, il utilise une approche similaire pour le d\xe9ploiement d\'applications : le code se d\xe9ploie en effectuant un \\"push\\" vers un d\xe9p\xf4t Git sur le serveur. \xc0 la diff\xe9rence de Heroku, Dokku offre un contr\xf4le total sur l\'environnement de d\xe9ploiement. Ainsi, l\'infrastructure, le syst\xe8me d\'exploitation et les services (tels que les bases de donn\xe9es ou les files d\'attente de t\xe2ches) peuvent \xeatre personnalis\xe9s selon les besoins. Dokku s\'appuie sur Docker pour g\xe9rer les applications dans des conteneurs isol\xe9s, ce qui simplifie la gestion des applications et de leurs d\xe9pendances. Chaque \\"push\\" d\'une application \xe0 Dokku cr\xe9e un nouveau conteneur Docker.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Installation\\n\\n```shell\\n# download the installation script\\nwget -NP . <https://dokku.com/bootstrap.sh>\\n# run the installer\\nsudo DOKKU_TAG=v0.32.3 bash bootstrap.sh\\n# and your ssh key to the dokku user\\nPUBLIC_KEY=\\"your-public-key-contents-here\\"\\necho \\"$PUBLIC_KEY\\" | dokku ssh-keys:add admin\\n```\\n\\n## Premi\xe8re application\\n\\n```shell\\n# define global domains\\ndokku domains:set-global <your-domain>\\n# <your-domain> can be a rd party domain or a local domain like sonu-dev-gzsim.local\\n```\\n\\nSur la machine o\xf9 `dokku` est install\xe9\\n\\n```shell\\ndokku apps:create <app-name>\\nsudo dokku plugin:install <https://github.com/dokku/dokku-postgres.git>\\ndokku postgres:create railsdatabase\\ndokku postgres:link railsdatabase <app-name>\\n```\\n\\nSur la machine locale\\n\\n```shell\\ncd <app-name>\\ngit remote add dokku dokku@<your-domain>:<app-name>\\ngit push dokku main\\n```\\n\\n## Construire sa propre application\\n\\nDokku supporte plusieurs m\xe9thodes de build pour cr\xe9er des applications, chacun avec ses propres avantages sp\xe9cifiques :\\n\\n1. [**builder-dockerfile**](https://dokku.com/docs/deployment/builders/dockerfiles/): Cette m\xe9thode utilise un Dockerfile pour construire des applications via la commande `docker build`. Il donne un contr\xf4le maximal sur l\'environnement d\'ex\xe9cution de l\'application et sur la mani\xe8re dont l\'application est assembl\xe9e.\\n2. [**builder-herokuish**](https://dokku.com/docs/deployment/builders/herokuish-buildpacks/): Avec cette m\xe9thode, Dokku cr\xe9e des applications en utilisant la sp\xe9cification v2a Buildpack de Heroku via `gliderlabs/herokuish`. Il vous permet de profiter du m\xeame pipeline de build que Heroku, qui inclut le support pour de nombreux langages de programmation par d\xe9faut.\\n3. builder-lambda: Ce g\xe9n\xe9rateur construit des fonctions AWS Lambda dans un environnement simulant les temps d\'ex\xe9cution d\'AWS Lambda.\\n4. **builder-null**: Cette m\xe9thode ne fait rien pendant la phase de construction. C\'est utile pour les sc\xe9narios o\xf9 aucune construction n\'est n\xe9cessaire, comme le d\xe9ploiement d\'applications d\xe9j\xe0 compil\xe9es ou de conteneurs Docker.\\n5. **builder-pack**: Cette m\xe9thode utilise les Cloud Native Buildpacks pour construire des applications via l\'outil pack-cli. Les Cloud Native Buildpacks sont une norme ouverte qui \xe9tend les capacit\xe9s des Buildpacks classiques.\\n\\n## Automatiser le d\xe9ploiement via Github Actions\\n\\n```yaml\\nname: Deploy to Dokku (sonu-dev-gzsim)\\non:\\n    schedule:\\n    - cron: \'0 0 * * *\'\\n    workflow_dispatch:\\n    workflow_run:\\n    workflows: [ \\"Test build\\" ]\\n    types:\\n        - completed\\njobs:\\n    deploy:\\n    runs-on:\\n        group: default\\n    steps:\\n        - name: Cloning repo\\n        uses: actions/checkout@v4\\n        with:\\n            fetch-depth: 0\\n\\n        - name: Tailscale\\n        uses: tailscale/github-action@v2\\n        with:\\n            oauth-client-id: ${{ secrets.TS_OAUTH_CLIENT_ID }}\\n            oauth-secret: ${{ secrets.TS_OAUTH_SECRET }}\\n            tags: tag:server\\n\\n        - name: Push to dokku\\n        uses: dokku/github-action@master\\n        with:\\n            git_remote_url: \'ssh://dokku@100.65.237.90:22/rd25-robotics\'\\n            ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}\\n            branch: main\\n            git_push_flags: \'--force\'\\n\\n    if: ${{ github.event.workflow_run.conclusion == \'success\' }}\\n```\\n\\n## Astuces\\n\\n \u26a0\ufe0f Les astuces ci dessous correspondent **tr\xe8s certainement** \xe0 une incompr\xe9hension des m\xe9canismes de domain, proxy et reverse proxy\\n\\nPar d\xe9faut `dokku` d\xe9ploie l\u2019application sur une url construite comme suit : `http://<app-name>.<your-domain>` visiblement si le domaine est local (comme `sonu-dev-gzsim.local`) le reverse proxy ne fonctionne pas (la configuration `nginx` est \xe0 creuser) il est donc n\xe9cessaire de `disable` les domains avec la commande\\n\\n```shell\\ndokku domains:disable <app-name>\\n```\\n\\nCela aura pour effet de d\xe9sactiver le domaine pour l\u2019application en question. Elle tournera donc directement sur le port d\xe9fini al\xe9atoirement par `dokku`.\\n\xc0 chaque d\xe9ploiement, `dokku` construit un `dokker` pour g\xe9rer les applications de mani\xe8re isol\xe9e. Par d\xe9faut, les applications de type web doivent fournir leurs services sur le port `5000`. Par la suite, `dokku` s\u2019occupe de faire la redirection de port entre la machine et le container. Pour \xe9viter d\u2019avoir un port al\xe9atoire, il est possible de faire\\n\\n```shell\\ndokku ports:set <app-name> http:<machine-port>:<docker-port>\\n```\\n\\nAinsi, \xe0 chaque d\xe9ploiement, `dokku` redirigera le port de la machine vers le port du docker.\\nFinalement si vous souhaitez mettre en place une redirection comme `http://<your-domain>/<app-name>` vers l\u2019application il suffit de faire les modifications suivantes dans `nginx`\\nModifiez le fichier de configuration de Nginx pour votre site :\\n\\n```shell\\nsudo nano /etc/nginx/sites-available/your-config-file\\n```\\n\\nAjoutez la directive location dans votre configuration :\\n\\n```txt\\nserver { listen 80; server_name <your-domain>; location = <app-name> { return 301 http://$host:<machine-port>; } }\\n```\\n\\nCr\xe9ez un lien symbolique vers le fichier de configuration :\\n\\n```shell\\nsudo ln -s /etc/nginx/sites-available/your-config-file /etc/nginx/sites-enabled/\\n```\\n\\nV\xe9rifiez la configuration de Nginx :\\n\\n```shell\\nsudo nginx -t\\n```\\n\\nRed\xe9marrez Nginx pour appliquer les modifications :\\n\\n```shell\\nsudo systemctl restart nginx\\n```"},{"id":"/2024/03/24/03-containerization/ghrc","metadata":{"permalink":"/blog/2024/03/24/03-containerization/ghrc","source":"@site/blog/03-containerization/2024-03-24-ghrc.md","title":"GitHub GHCR","description":"GitHub Container Registry (GHCR) est un service d\'h\xe9bergement de packages logiciels propos\xe9 par GitHub, permettant aux utilisateurs de stocker des packages priv\xe9s ou publics et de les utiliser comme d\xe9pendances dans leurs projets. Compatible avec plusieurs langages de programmation, GitHub Packages propose des registres pour des gestionnaires de packages tels que npm, RubyGems, Maven, Gradle, Docker, et NuGet. L\'authentification sur GitHub Packages se fait exclusivement via un \\"personal access token (classic)\\". Les utilisateurs doivent disposer de ce token pour effectuer des op\xe9rations telles que la publication, l\'installation et la suppression de packages, qu\'ils soient publics, priv\xe9s ou internes. Pour les packages priv\xe9s, GitHub Packages applique des limites de stockage et de transfert de donn\xe9es en fonction du plan du compte. La gestion des packages peut \xeatre r\xe9alis\xe9e \xe0 travers l\'interface utilisateur GitHub ou via l\'API REST. Des webhooks peuvent \xe9galement \xeatre configur\xe9s pour suivre des \xe9v\xe9nements li\xe9s aux packages, comme la publication ou la mise \xe0 jour.","date":"2024-03-24T00:00:00.000Z","tags":[{"inline":true,"label":"Containerization","permalink":"/blog/tags/containerization"},{"inline":true,"label":"Registry","permalink":"/blog/tags/registry"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":4.07,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"GitHub GHCR","tags":["Containerization","Registry","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Dokku","permalink":"/blog/2024/04/07/06-orchestration/orchestration-dokku"},"nextItem":{"title":"Docker Compose","permalink":"/blog/2024/03/17/03-containerization/docker-compose"}},"content":"GitHub Container Registry (GHCR) est un service d\'h\xe9bergement de packages logiciels propos\xe9 par GitHub, permettant aux utilisateurs de stocker des packages priv\xe9s ou publics et de les utiliser comme d\xe9pendances dans leurs projets. Compatible avec plusieurs langages de programmation, GitHub Packages propose des registres pour des gestionnaires de packages tels que npm, RubyGems, Maven, Gradle, Docker, et NuGet. L\'authentification sur GitHub Packages se fait exclusivement via un \\"personal access token (classic)\\". Les utilisateurs doivent disposer de ce token pour effectuer des op\xe9rations telles que la publication, l\'installation et la suppression de packages, qu\'ils soient publics, priv\xe9s ou internes. Pour les packages priv\xe9s, GitHub Packages applique des limites de stockage et de transfert de donn\xe9es en fonction du plan du compte. La gestion des packages peut \xeatre r\xe9alis\xe9e \xe0 travers l\'interface utilisateur GitHub ou via l\'API REST. Des webhooks peuvent \xe9galement \xeatre configur\xe9s pour suivre des \xe9v\xe9nements li\xe9s aux packages, comme la publication ou la mise \xe0 jour.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que GitHub GHCR?\\n\\nGitHub Container Registry (GHCR) est un service d\'h\xe9bergement de conteneurs Docker propos\xe9 par GitHub. Il permet aux utilisateurs de stocker, g\xe9rer et distribuer des images Docker en toute s\xe9curit\xe9. GHCR est int\xe9gr\xe9 \xe0 GitHub, ce qui facilite l\'utilisation des conteneurs dans les workflows de d\xe9veloppement et de d\xe9ploiement.\\n\\n## Pourquoi utiliser GitHub GHCR?\\n\\nL\'utilisation de GitHub GHCR pr\xe9sente plusieurs avantages :\\n\\n1. **S\xe9curit\xe9** : GHCR offre des fonctionnalit\xe9s de s\xe9curit\xe9 avanc\xe9es, telles que l\'authentification et l\'autorisation bas\xe9es sur les tokens d\'acc\xe8s personnels (PAT). Les images peuvent \xeatre priv\xe9es ou publiques, et les utilisateurs peuvent contr\xf4ler l\'acc\xe8s aux images en fonction de leurs besoins.\\n\\n2. **Int\xe9gration avec GitHub** : GHCR est \xe9troitement int\xe9gr\xe9 \xe0 GitHub, ce qui permet aux utilisateurs de g\xe9rer leurs images Docker directement depuis leurs d\xe9p\xf4ts GitHub. Les workflows GitHub Actions peuvent \xeatre utilis\xe9s pour automatiser la cr\xe9ation, le test et le d\xe9ploiement des images Docker.\\n\\n3. **Gestion des versions** : GHCR prend en charge la gestion des versions des images Docker, ce qui permet aux utilisateurs de suivre les modifications apport\xe9es aux images et de revenir \xe0 des versions ant\xe9rieures si n\xe9cessaire.\\n\\n4. **Suivi des \xe9v\xe9nements** : GHCR permet de configurer des webhooks pour suivre les \xe9v\xe9nements li\xe9s aux images Docker, tels que la publication, la mise \xe0 jour et la suppression. Cela permet aux utilisateurs de rester inform\xe9s des modifications apport\xe9es aux images et de r\xe9agir en cons\xe9quence.\\n\\n## Exemple de workflow pour utiliser GitHub GHCR\\n\\nLe workflow suppose que vous avez un `Dockerfile` \xe0 la racine du d\xe9p\xf4t. Ce `Dockerfile` doit r\xe9ussir la commande de `build` avec succ\xe8s\\n\\n### Cr\xe9ez un fichier YAML pour le Workflow\\n\\nCr\xe9ez un fichier YAML (par exemple, `docker-publish.yml`) dans le r\xe9pertoire `.github/workflows/` de votre d\xe9p\xf4t avec le contenu suivant :\\n\\n```yaml\\nname: Create and publish a Docker image\\n\\non:\\n    push:\\n    branches: [\'release\']\\n\\nenv:\\n    REGISTRY: ghcr.io\\n    IMAGE_NAME: ${{ github.repository }}\\n\\njobs:\\n    build-and-push-image:\\n    runs-on: ubuntu-latest\\n\\n    permissions:\\n        contents: read\\n        packages: write\\n\\n    steps:\\n        - name: Checkout repository\\n        uses: actions/checkout@v4\\n\\n        - name: Log in to the Container registry\\n        uses: docker/login-action@65b78e6e13532edd9afa3aa52ac7964289d1a9c1\\n        with:\\n            registry: ${{ env.REGISTRY }}\\n            username: ${{ github.actor }}\\n            password: ${{ secrets.GITHUB_TOKEN }}\\n\\n        - name: Extract metadata (tags, labels) for Docker\\n        id: meta\\n        uses: docker/metadata-action@9ec57ed1fcdbf14dcef7dfbe97b2010124a938b7\\n        with:\\n            images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\\n\\n        - name: Build and push Docker image\\n        uses: docker/build-push-action@f2a1d5e99d037542a71f64918e516c093c6f3fc4\\n        with:\\n            context: .\\n            push: true\\n            tags: ${{ steps.meta.outputs.tags }}\\n            labels: ${{ steps.meta.outputs.labels }}\\n```\\n\\n### Configurez les Options du Workflow\\n\\nDans le fichier YAML, vous pouvez personnaliser les options suivantes selon vos besoins :\\n\\n- `branches`: Modifiez la branche d\xe9clenchant le workflow.\\n- `REGISTRY` et `IMAGE_NAME`: Modifiez-les si vous souhaitez utiliser un autre registre ou nom d\'image.\\n- `permissions`: Ajustez les autorisations en fonction de vos besoins.\\n\\n**Enregistrez et Poussez vos Modifications**\\nEnregistrez les modifications dans le fichier YAML et poussez-les vers la branche \\"release\\" de votre d\xe9p\xf4t GitHub.\\n\\n```shell\\ngit add .github/workflows/docker-publish.yml\\ngit commit -m \\"Ajout du workflow de publication Docker\\"\\ngit push origin release\\n```\\n\\n### Utilisation d\u2019un package GHCR\\n\\nUne fois d\xe9ploy\xe9, le package s\u2019utilise comme n\u2019importe quel docker\\n\\n```shell\\ndocker pull ghcr.io/{USER}/{REPO-NAME}:master\\n```\\n\\n\ud83d\udca1 L\u2019utilisation des Github GHCR entraine des consommations d\u2019espace. Le CATIE a le droit \xe0 2Gb de stockage sur GHCR et 10Gb de transit par mois. Au del\xe0 de ces limites, nous sommes factur\xe9s.\\nL\u2019utilisation (sous n\u2019importe quelle forme) de GHCR sur des d\xe9p\xf4ts **publics** est totalement gratuite Sur des d\xe9p\xf4ts priv\xe9s : le pull via des actions est gratuit. Pour les actions `self-hosted` le pull est gratuit si l\u2019action est authentifi\xe9e par le `GITHUB_TOKEN` et non un PAT.\\n\\nVoici un exemple d\u2019utilisation sans co\xfbt associ\xe9\\n\\n```yaml\\nname: Run in container from GHCR\\n\\non: [ push ]\\n\\njobs:\\n    myJob:\\n    runs-on: ubuntu-latest\\n    container:\\n        image: ghcr.io/sedelpeuch/github-ghcr-test:master\\n    steps:\\n\\n        - name: Checkout code\\n        uses: actions/checkout@v2\\n\\n        - name: Run a command\\n        run: echo \\"Running inside the container\\"\\n```\\n\\nL\u2019image [ghcr.io/sedelpeuch/github-ghcr-test:master](<http://ghcr.io/sedelpeuch/github-ghcr-test:master>) est priv\xe9e, l\u2019acc\xe8s est possible sans donner de PAT gr\xe2ce \xe0 l\u2019authentification par jeton automatique qui poss\xe8de la lecture des packages priv\xe9s [https://docs.github.com/fr/actions/security-guides/automatic-token-authentication#permissions-for-the-github_token](https://docs.github.com/fr/actions/security-guides/automatic-token-authentication#permissions-for-the-github_token)"},{"id":"/2024/03/17/03-containerization/docker-compose","metadata":{"permalink":"/blog/2024/03/17/03-containerization/docker-compose","source":"@site/blog/03-containerization/2024-03-17-docker-compose.md","title":"Docker Compose","description":"Explication de Docker Compose","date":"2024-03-17T00:00:00.000Z","tags":[{"inline":true,"label":"Docker","permalink":"/blog/tags/docker"},{"inline":true,"label":"Docker Compose","permalink":"/blog/tags/docker-compose"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"},{"inline":true,"label":"Containerization","permalink":"/blog/tags/containerization"}],"readingTime":9.87,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Docker Compose","description":"Explication de Docker Compose","tags":["Docker","Docker Compose","Devops","Containerization"]},"unlisted":false,"prevItem":{"title":"GitHub GHCR","permalink":"/blog/2024/03/24/03-containerization/ghrc"},"nextItem":{"title":"Docker pratiques de production","permalink":"/blog/2024/03/10/03-containerization/docker-best-practices"}},"content":"Docker Compose est un outil puissant qui permet de d\xe9finir et de g\xe9rer des applications multi-conteneurs Docker. Il utilise un fichier YAML pour configurer les services de l\'application. Ensuite, avec une seule commande, vous pouvez cr\xe9er et d\xe9marrer tous les services \xe0 partir de votre configuration.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que Docker Compose ?\\n\\nDocker Compose est un outil qui permet de d\xe9finir et de g\xe9rer des applications multi-conteneurs Docker. Il utilise un fichier YAML pour configurer les services de l\'application. Ensuite, avec une seule commande, vous pouvez cr\xe9er et d\xe9marrer tous les services \xe0 partir de votre configuration.\\n\\n## Exemple de fichier Docker Compose\\n\\nVoici un exemple de fichier `docker-compose.yml` pour une application web simple avec un service web et une base de donn\xe9es :\\n\\n```yaml\\nversion: \'3\'\\nservices:\\n  web:\\n    image: nginx:alpine\\n    ports:\\n      - \\"80:80\\"\\n  db:\\n    image: postgres:alpine\\n    environment:\\n      POSTGRES_DB: exampledb\\n      POSTGRES_USER: exampleuser\\n      POSTGRES_PASSWORD: examplepass\\n```\\n\\nDans cet exemple, nous avons deux services : `web` et `db`. Le service `web` utilise l\'image `nginx:alpine` et mappe le port 80 du conteneur au port 80 de l\'h\xf4te. Le service `db` utilise l\'image `postgres:alpine` et d\xe9finit quelques variables d\'environnement pour configurer la base de donn\xe9es.\\n\\n## Commandes Docker Compose\\n\\nVoici quelques commandes Docker Compose couramment utilis\xe9es :\\n\\n- `docker-compose up` : Cr\xe9e et d\xe9marre les conteneurs d\xe9finis dans le fichier `docker-compose.yml`.\\n- `docker-compose down` : Arr\xeate et supprime les conteneurs, les r\xe9seaux et les volumes cr\xe9\xe9s par `docker-compose up`.\\n- `docker-compose ps` : Affiche l\'\xe9tat des conteneurs d\xe9finis dans le fichier `docker-compose.yml`.\\n- `docker-compose logs` : Affiche les logs des conteneurs.\\n\\n## Sch\xe9ma explicatif\\n\\nVoici un sch\xe9ma expliquant comment Docker Compose fonctionne :\\n\\n![Sch\xe9ma Docker Compose](https://www.biaudelle.fr/wp-content/uploads/2021/07/docker-compose-archi.png)\\n\\n## D\xe9monstration pratique\\n\\nPour mieux comprendre l\'utilisation de Docker Compose, voici une d\xe9monstration pratique :\\n\\n```bash\\ndocker network create mynetwork\\ndocker-compose up -d\\ndocker-compose ps\\n```\\n\\nOuvrez votre navigateur et acc\xe9dez \xe0 `http://localhost`.\\n\\n```bash\\ndocker-compose down\\n```\\n\\n## Avantages cl\xe9s de Docker Compose\\n\\nL\'utilisation de Docker Compose offre plusieurs avantages qui simplifient le d\xe9veloppement, le d\xe9ploiement et la gestion des applications conteneuris\xe9es :\\n\\n- **Contr\xf4le simplifi\xe9** : Docker Compose vous permet de d\xe9finir et de g\xe9rer des applications multi-conteneurs dans un seul fichier YAML. Cela simplifie la t\xe2che complexe d\'orchestrer et de coordonner divers services, rendant plus facile la gestion et la r\xe9plication de votre environnement applicatif.\\n- **Collaboration efficace** : Les fichiers de configuration Docker Compose sont faciles \xe0 partager, facilitant la collaboration entre les d\xe9veloppeurs, les \xe9quipes d\'exploitation et les autres parties prenantes. Cette approche collaborative conduit \xe0 des flux de travail plus fluides, une r\xe9solution des probl\xe8mes plus rapide et une efficacit\xe9 globale accrue.\\n- **D\xe9veloppement rapide d\'applications** : Compose met en cache la configuration utilis\xe9e pour cr\xe9er un conteneur. Lorsque vous red\xe9marrez un service qui n\'a pas chang\xe9, Compose r\xe9utilise les conteneurs existants. La r\xe9utilisation des conteneurs signifie que vous pouvez apporter des modifications \xe0 votre environnement tr\xe8s rapidement.\\n- **Portabilit\xe9 entre les environnements** : Compose prend en charge les variables dans le fichier Compose. Vous pouvez utiliser ces variables pour personnaliser votre composition pour diff\xe9rents environnements ou diff\xe9rents utilisateurs.\\n- **Communaut\xe9 et support \xe9tendus** : Docker Compose b\xe9n\xe9ficie d\'une communaut\xe9 dynamique et active, ce qui signifie des ressources abondantes, des tutoriels et un support. Cet \xe9cosyst\xe8me communautaire contribue \xe0 l\'am\xe9lioration continue de Docker Compose et aide les utilisateurs \xe0 r\xe9soudre efficacement les probl\xe8mes.\\n\\nCompose peut \xeatre utilis\xe9 de nombreuses mani\xe8res diff\xe9rentes. Voici quelques cas d\'utilisation courants.\\n\\n### Environnements de d\xe9veloppement\\n\\nLorsque vous d\xe9veloppez des logiciels, la capacit\xe9 \xe0 ex\xe9cuter une application dans un environnement isol\xe9 et \xe0 interagir avec elle est cruciale. L\'outil en ligne de commande Compose peut \xeatre utilis\xe9 pour cr\xe9er l\'environnement et interagir avec lui.\\n\\nLe fichier Compose fournit un moyen de documenter et de configurer toutes les d\xe9pendances de service de l\'application (bases de donn\xe9es, files d\'attente, caches, API de services web, etc.). En utilisant l\'outil en ligne de commande Compose, vous pouvez cr\xe9er et d\xe9marrer un ou plusieurs conteneurs pour chaque d\xe9pendance avec une seule commande (`docker compose up`).\\n\\nEnsemble, ces fonctionnalit\xe9s offrent un moyen pratique de d\xe9marrer un projet. Compose peut r\xe9duire un \\"guide de d\xe9marrage pour les d\xe9veloppeurs\\" de plusieurs pages \xe0 un seul fichier Compose lisible par machine et quelques commandes.\\n\\n### Environnements de test automatis\xe9s\\n\\nUne partie importante de tout processus de d\xe9ploiement continu ou d\'int\xe9gration continue est la suite de tests automatis\xe9s. Les tests automatis\xe9s de bout en bout n\xe9cessitent un environnement dans lequel ex\xe9cuter les tests. Compose fournit un moyen pratique de cr\xe9er et de d\xe9truire des environnements de test isol\xe9s pour votre suite de tests. En d\xe9finissant l\'environnement complet dans un fichier Compose, vous pouvez cr\xe9er et d\xe9truire ces environnements en quelques commandes seulement.\\n\\n### D\xe9ploiements sur un seul h\xf4te\\n\\nCompose a traditionnellement \xe9t\xe9 ax\xe9 sur les flux de travail de d\xe9veloppement et de test, mais \xe0 chaque nouvelle version, nous progressons sur des fonctionnalit\xe9s plus orient\xe9es vers la production.\\n\\nPour plus de d\xe9tails sur l\'utilisation des fonctionnalit\xe9s orient\xe9es production, consultez [Compose en production](https://docs.docker.com/compose/production/).\\n\\n## Utilisation des secrets avec Docker Compose\\n\\nDocker Compose permet \xe9galement de g\xe9rer les secrets de mani\xe8re s\xe9curis\xe9e. Les secrets sont des informations sensibles telles que des mots de passe, des cl\xe9s API, etc., qui ne doivent pas \xeatre expos\xe9es dans le code source.\\n\\nVoici un exemple de configuration de secrets dans un fichier `docker-compose.yml` :\\n\\n```yaml\\nversion: \'3.7\'\\nservices:\\n  web:\\n    image: nginx:alpine\\n    secrets:\\n      - my_secret\\nsecrets:\\n  my_secret:\\n    file: ./my_secret.txt\\n```\\n\\nDans cet exemple, le service `web` utilise un secret nomm\xe9 `my_secret` qui est d\xe9fini dans le fichier `my_secret.txt`.\\n\\n## Support des GPU avec Docker Compose\\n\\nDocker Compose prend \xe9galement en charge l\'utilisation des GPU pour les applications n\xe9cessitant des capacit\xe9s de calcul intensif, telles que l\'apprentissage automatique et le traitement d\'images.\\n\\nVoici un exemple de configuration pour utiliser un GPU avec Docker Compose :\\n\\n```yaml\\nversion: \'3.8\'\\nservices:\\n  gpu_service:\\n    image: nvidia/cuda:10.2-base\\n    deploy:\\n      resources:\\n        reservations:\\n          devices:\\n            - capabilities: [gpu]\\n```\\n\\nDans cet exemple, le service `gpu_service` utilise l\'image `nvidia/cuda:10.2-base` et r\xe9serve un GPU pour le conteneur.\\n\\n\\n## Utilisation de la surveillance des fichiers avec Docker Compose\\n\\nDocker Compose permet \xe9galement de surveiller les modifications des fichiers et de red\xe9marrer automatiquement les services concern\xe9s. Cela est particuli\xe8rement utile pour les environnements de d\xe9veloppement.\\n\\nVoici un exemple de configuration de surveillance des fichiers dans un fichier `docker-compose.yml` :\\n\\n```yaml\\nversion: \'3.8\'\\nservices:\\n  web:\\n    image: nginx:alpine\\n    volumes:\\n      - ./src:/usr/share/nginx/html\\n    command: sh -c \\"nginx -g \'daemon off;\'\\"\\n    file_watch:\\n      watch: ./src\\n      action: restart\\n```\\n\\nDans cet exemple, le service `web` surveille les modifications dans le r\xe9pertoire `./src` et red\xe9marre automatiquement le service lorsque des modifications sont d\xe9tect\xe9es.\\n\\n## R\xe9seau dans Compose\\n\\n> **Important**\\n>\\n> La documentation de Docker se r\xe9f\xe8re et d\xe9crit les fonctionnalit\xe9s de Compose V2.\\n>\\n> \xc0 partir de juillet 2023, Compose V1 a cess\xe9 de recevoir des mises \xe0 jour et n\'est plus inclus dans les nouvelles versions de Docker Desktop. Compose V2 l\'a remplac\xe9 et est maintenant int\xe9gr\xe9 dans toutes les versions actuelles de Docker Desktop. Pour plus d\'informations, consultez [Migrer vers Compose V2](https://docs.docker.com/compose/migrate).\\n\\nPar d\xe9faut, Compose configure un seul [r\xe9seau](https://docs.docker.com/reference/cli/docker/network/create/) pour votre application. Chaque conteneur pour un service rejoint le r\xe9seau par d\xe9faut et est \xe0 la fois accessible par d\'autres conteneurs sur ce r\xe9seau et d\xe9couvrable par le nom du service.\\n\\n> **Remarque**\\n>\\n> Le r\xe9seau de votre application re\xe7oit un nom bas\xe9 sur le \\"nom du projet\\", qui est bas\xe9 sur le nom du r\xe9pertoire dans lequel il se trouve. Vous pouvez remplacer le nom du projet avec soit le [flag `--project-name`](https://docs.docker.com/reference/) soit la [variable d\'environnement `COMPOSE_PROJECT_NAME`](https://docs.docker.com/compose/environment-variables/envvars/#compose_project_name).\\n\\nPar exemple, supposons que votre application se trouve dans un r\xe9pertoire appel\xe9 `myapp`, et que votre `compose.yml` ressemble \xe0 ceci :\\n\\nLorsque vous ex\xe9cutez `docker compose up`, les actions suivantes se produisent :\\n\\n1.  Un r\xe9seau appel\xe9 `myapp_default` est cr\xe9\xe9.\\n2.  Un conteneur est cr\xe9\xe9 en utilisant la configuration de `web`. Il rejoint le r\xe9seau `myapp_default` sous le nom `web`.\\n3.  Un conteneur est cr\xe9\xe9 en utilisant la configuration de `db`. Il rejoint le r\xe9seau `myapp_default` sous le nom `db`.\\n\\nChaque conteneur peut maintenant rechercher le nom du service `web` ou `db` et obtenir l\'adresse IP appropri\xe9e du conteneur. Par exemple, le code de l\'application de `web` pourrait se connecter \xe0 l\'URL `postgres://db:5432` et commencer \xe0 utiliser la base de donn\xe9es Postgres.\\n\\nIl est important de noter la distinction entre `HOST_PORT` et `CONTAINER_PORT`. Dans l\'exemple ci-dessus, pour `db`, le `HOST_PORT` est `8001` et le port du conteneur est `5432` (par d\xe9faut pour postgres). La communication de service \xe0 service en r\xe9seau utilise le `CONTAINER_PORT`. Lorsque `HOST_PORT` est d\xe9fini, le service est \xe9galement accessible en dehors du swarm.\\n\\nDans le conteneur `web`, votre cha\xeene de connexion \xe0 `db` ressemblerait \xe0 `postgres://db:5432`, et depuis la machine h\xf4te, la cha\xeene de connexion ressemblerait \xe0 `postgres://{DOCKER_IP}:8001`, par exemple `postgres://localhost:8001` si votre conteneur s\'ex\xe9cute localement.\\n\\n### Mise \xe0 jour des conteneurs sur le r\xe9seau\\n\\nSi vous apportez une modification de configuration \xe0 un service et ex\xe9cutez `docker compose up` pour le mettre \xe0 jour, l\'ancien conteneur est supprim\xe9 et le nouveau rejoint le r\xe9seau sous une adresse IP diff\xe9rente mais avec le m\xeame nom. Les conteneurs en cours d\'ex\xe9cution peuvent rechercher ce nom et se connecter \xe0 la nouvelle adresse, mais l\'ancienne adresse cesse de fonctionner.\\n\\nSi des conteneurs ont des connexions ouvertes vers l\'ancien conteneur, elles sont ferm\xe9es. Il incombe au conteneur de d\xe9tecter cette condition, de rechercher \xe0 nouveau le nom et de se reconnecter.\\n\\n> **Astuce**\\n>\\n> R\xe9f\xe9rencez les conteneurs par nom, et non par IP, chaque fois que possible. Sinon, vous devrez constamment mettre \xe0 jour l\'adresse IP que vous utilisez.\\n\\n### R\xe9seau multi-h\xf4te\\n\\nLors du d\xe9ploiement d\'une application Compose sur un moteur Docker avec [le mode Swarm activ\xe9](https://docs.docker.com/engine/swarm/), vous pouvez utiliser le pilote int\xe9gr\xe9 `overlay` pour activer la communication multi-h\xf4te.\\n\\nLes r\xe9seaux overlay sont toujours cr\xe9\xe9s comme `attachable`. Vous pouvez \xe9ventuellement d\xe9finir la propri\xe9t\xe9 [`attachable`](https://docs.docker.com/reference/compose-file/networks/#attachable) sur `false`.\\n\\nConsultez la [section mode Swarm](https://docs.docker.com/engine/swarm/) pour savoir comment configurer un cluster Swarm, et le [guide de d\xe9marrage avec le r\xe9seau multi-h\xf4te](https://docs.docker.com/engine/network/tutorials/overlay/) pour en savoir plus sur les r\xe9seaux overlay multi-h\xf4te.\\n\\n### Sp\xe9cifier des r\xe9seaux personnalis\xe9s\\n\\nAu lieu d\'utiliser simplement le r\xe9seau d\'application par d\xe9faut, vous pouvez sp\xe9cifier vos propres r\xe9seaux avec la cl\xe9 de niveau sup\xe9rieur `networks`. Cela vous permet de cr\xe9er des topologies plus complexes et de sp\xe9cifier des [pilotes de r\xe9seau personnalis\xe9s](https://docs.docker.com/engine/extend/plugins_network/) et des options. Vous pouvez \xe9galement l\'utiliser pour connecter des services \xe0 des r\xe9seaux cr\xe9\xe9s en externe qui ne sont pas g\xe9r\xe9s par Compose.\\n\\nChaque service peut sp\xe9cifier \xe0 quels r\xe9seaux se connecter avec la cl\xe9 de niveau service `networks`, qui est une liste de noms r\xe9f\xe9rencant des entr\xe9es sous la cl\xe9 de niveau sup\xe9rieur `networks`.\\n\\nL\'exemple suivant montre un fichier Compose qui d\xe9finit deux r\xe9seaux personnalis\xe9s. Le service `proxy` est isol\xe9 du service `db`, car ils ne partagent pas de r\xe9seau en commun. Seul `app` peut parler aux deux.\\n\\nLes r\xe9seaux peuvent \xeatre configur\xe9s avec des adresses IP statiques en d\xe9finissant l\'[adresse ipv4 et/ou ipv6](https://docs.docker.com/reference/compose-file/services/#ipv4_address-ipv6_address) pour chaque r\xe9seau attach\xe9.\\n\\nLes r\xe9seaux peuvent \xe9galement recevoir un [nom personnalis\xe9](https://docs.docker.com/reference/compose-file/networks/#name) :\\n\\n### Configurer le r\xe9seau par d\xe9faut\\n\\nAu lieu de, ou en plus de, sp\xe9cifier vos propres r\xe9seaux, vous pouvez \xe9galement modifier les param\xe8tres du r\xe9seau par d\xe9faut de l\'application en d\xe9finissant une entr\xe9e sous `networks` nomm\xe9e `default` :\\n\\n### Utiliser un r\xe9seau pr\xe9existant\\n\\nSi vous souhaitez que vos conteneurs rejoignent un r\xe9seau pr\xe9existant, utilisez l\'option [`external`](https://docs.docker.com/reference/compose-file/networks/#external)\\n\\nAu lieu de tenter de cr\xe9er un r\xe9seau appel\xe9 `[projectname]_default`, Compose recherche un r\xe9seau appel\xe9 `my-pre-existing-network` et connecte les conteneurs de votre application \xe0 celui-ci.\\n\\n\\n## Conclusion\\n\\nDocker Compose est un outil puissant pour g\xe9rer des applications multi-conteneurs. Il simplifie la configuration, l\'isolation des environnements et la portabilit\xe9 des applications. En utilisant Docker Compose, vous pouvez facilement d\xe9finir et g\xe9rer des environnements de d\xe9veloppement, de test et de mise en sc\xe8ne, ainsi que des d\xe9ploiements de production simples.\\n\\nPour en savoir plus sur Docker Compose, vous pouvez consulter la [documentation officielle](https://docs.docker.com/compose/)."},{"id":"/2024/03/10/03-containerization/docker-best-practices","metadata":{"permalink":"/blog/2024/03/10/03-containerization/docker-best-practices","source":"@site/blog/03-containerization/2024-03-10-docker-best-practices.md","title":"Docker pratiques de production","description":"L\'adoption de Docker augmente constamment et beaucoup le connaissent, mais tout le monde n\'utilise pas Docker selon les meilleures pratiques.","date":"2024-03-10T00:00:00.000Z","tags":[{"inline":true,"label":"Containerization","permalink":"/blog/tags/containerization"},{"inline":true,"label":"Docker","permalink":"/blog/tags/docker"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":4.505,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Docker pratiques de production","description":"L\'adoption de Docker augmente constamment et beaucoup le connaissent, mais tout le monde n\'utilise pas Docker selon les meilleures pratiques.","tags":["Containerization","Docker","Devops"]},"unlisted":false,"prevItem":{"title":"Docker Compose","permalink":"/blog/2024/03/17/03-containerization/docker-compose"},"nextItem":{"title":"Pr\xe9sentation des conteneurs Docker","permalink":"/blog/2024/03/05/03-containerization/docker-containers"}},"content":"\x3c!--truncate--\x3e\\n\\n## Utilisez une image Docker officielle et v\xe9rifi\xe9e comme image de base, chaque fois disponible\\n\\nDisons que vous d\xe9veloppez une application Node.js et que vous souhaitez la cr\xe9er et l\'ex\xe9cuter en tant qu\'image Docker.\\n\\nAu lieu de prendre une image du syst\xe8me d\'exploitation de base et d\'installer Node.js, NPM et tous les autres outils dont vous avez besoin pour votre application, utilisez l\'image de node officiel pour votre application.\\n\\n## Utilisez des versions d\'image docker sp\xe9cifiques\\n\\nD\'accord, nous avons donc s\xe9lectionn\xe9 l\'image de base, mais maintenant lorsque nous construisons notre image d\'applications \xe0 partir de ce Dockerfile, il utilisera toujours la derni\xe8re balise de l\'image de n\u0153ud.\\n\\nAinsi, au lieu d\'une \xe9tiquette d\'image al\xe9atoire, vous souhaitez fixer la version, et tout comme vous d\xe9ployez votre propre application avec une version sp\xe9cifique, vous souhaitez utiliser l\'image officielle avec une version sp\xe9cifique.\\n\\n## Utiliser des images officielles de petite taille\\n\\nLors du choix d\'une image Node.js, vous verrez qu\'il y a en fait plusieurs images officielles. Non seulement avec diff\xe9rents num\xe9ros de version mais aussi avec diff\xe9rentes distributions de syst\xe8mes d\'exploitation:\\n\\n1) Taille de l\'image : si l\'image est bas\xe9e sur une distribution de syst\xe8me d\'exploitation \xe0 part enti\xe8re comme Ubuntu ou Centos, vous aurez un tas d\'outils d\xe9j\xe0 emball\xe9s dans l\'image. Ainsi, la taille de l\'image sera plus grande, mais vous n\'avez pas besoin de la plupart de ces outils dans vos images d\'application.\\n\\n2) Probl\xe8me de s\xe9curit\xe9 : avec de nombreux outils install\xe9s \xe0 l\'int\xe9rieur, vous devez consid\xe9rer l\'aspect de s\xe9curit\xe9. Parce que ces images de base contiennent g\xe9n\xe9ralement [des centaines de vuln\xe9rabilit\xe9s connues](https://snyk.io/blog/openSourcesEcurity-2020Survey/) et cr\xe9ent essentiellement une plus grande surface d\'attaque \xe0 votre image d\'application.\\n\\nAinsi, la meilleure pratique ici serait de s\xe9lectionner une image avec une version sp\xe9cifique bas\xe9e sur une distribution plus maigre comme Alpine.\\n\\n## Optimiser la mise en cache pour les couches d\'image lors de la construction d\'une image\\n\\n1) Que sont les layer d\'image? Une image Docker est construite sur la base d\'un dockerfile.\\n\\nEt dans un dockerfile, chaque commande ou instruction cr\xe9e un layer d\'image.\\n\\nAinsi, lorsque nous utilisons une image de base d\'alpine, il a d\xe9j\xe0 des layers, car il a d\xe9j\xe0 \xe9t\xe9 construit en utilisant son propre dockerfile. Dans notre dockerfile, nous avons quelques autres commandes qui ajouteront chacune un nouveau layer \xe0 cette image.\\n\\nAinsi, lorsque vous reconstruisez votre image, si votre Dockerfile n\'a pas chang\xe9, Docker n\'utilisera que les layers en cache pour construire l\'image.\\n\\nAvantages des layers d\'image en cache:\\n\\n- Contruction d\'image plus rapide\\n- Push et pull plus rapides de nouvelles versions d\'image: Si je pull une nouvelle version d\'image de la m\xeame application et, disons, 2 nouveaux layers ont \xe9t\xe9 ajout\xe9es dans la nouvelle version: seule la nouvelle version des layers ajout\xe9es seront t\xe9l\xe9charg\xe9es Les autres sont d\xe9j\xe0 mis en cache localement par Docker.\\n\\nOptimiser la mise en cache : une fois qu\'un layer change, tous les layers suivants doivent \xe9galement \xeatre recr\xe9\xe9es. En d\'autres termes: lorsque vous modifiez le contenu d\'une ligne dans le dockerfile, les caches de toutes les lignes ou layers suivantes seront invalid\xe9s.\\n\\nAinsi, la r\xe8gle ici et la meilleure pratique est: placez vos commandes dans le Dockerfile du moins au plus fr\xe9quemment modif\xe9.\\n\\n## \xe0 l\'aide d\'un fichier .dockerignore\\n\\nC\'est assez simple. Nous cr\xe9ons simplement ce fichier .dockerignore et r\xe9pertorions tous les fichiers et dossiers que nous voulons \xeatre ignor\xe9s, et lors de la cr\xe9ation de l\'image, Docker examinera le contenu et ignorera tout ce qui est sp\xe9cifi\xe9 \xe0 l\'int\xe9rieur.\\n\\n## Utilisez des versions multi-\xe9tages\\n\\nMaintenant, disons qu\'il existe un outil dans votre projet dont vous avez besoin pour construire l\'image mais vous n\'en avez pas besoin dans l\'image finale pour ex\xe9cuter leapplication.\\n\\nSupposons que vous conserviez ces artefacts dans votre image finale, m\xeame s\'ils sont absolument inutiles pour ex\xe9cuter l\'application. Dans ce cas, cela entra\xeenera \xe0 nouveau une augmentation de la taille de l\'image et une augmentation de la surface d\'attaque.\\n\\nPour cela, vous pouvez utiliser ce qu\'on appelle les constructions \xe0 plusieurs \xe9tages\\n\\nLa fonction de construction en plusieurs \xe9tapes vous permet d\'utiliser plusieurs images temporaires pendant le processus de construction, mais ne conserve que la derni\xe8re image comme artefact final.\\n\\n## Utilisez l\'utilisateur le moins privil\xe9gi\xe9\\n\\nMaintenant, lorsque nous cr\xe9ons cette image et que nous l\'ex\xe9cutons finalement en tant que conteneur, quel utilisateur du syst\xe8me d\'exploitation sera utilis\xe9 pour d\xe9marrer l\'application \xe0 l\'int\xe9rieur? Par d\xe9faut, lorsqu\'un DockerFile ne sp\xe9cifie pas un utilisateur, il utilise un utilisateur root. Mais en r\xe9alit\xe9, il n\'y a surtout aucune raison d\'ex\xe9cuter des conteneurs avec des privil\xe8ges root.\\n\\nCela introduit essentiellement un probl\xe8me de s\xe9curit\xe9 car lorsque le conteneur commence sur l\'h\xf4te, il aura potentiellement un acc\xe8s root sur l\'h\xf4te Docker.\\n\\nPour \xe9viter cela, la meilleure pratique consiste \xe0 cr\xe9er simplement un utilisateur d\xe9di\xe9 et un groupe d\xe9di\xe9 dans l\'image Docker pour ex\xe9cuter l\'application et \xe9galement ex\xe9cuter l\'application \xe0 l\'int\xe9rieur du conteneur avec cet utilisateur.\\n\\n## Scannez vos images pour les vuln\xe9rabilit\xe9s de s\xe9curit\xe9\\n\\nEnfin, comment s\'assurer et valider que l\'image que vous construisez a peu ou pas de vuln\xe9rabilit\xe9s de s\xe9curit\xe9 ?\\n\\nLa meilleure pratique est, une fois que vous avez construit l\'image, la scannez pour des vuln\xe9rabilit\xe9s de s\xe9curit\xe9 \xe0 l\'aide de la commande docker scan.\\n\\nEn arri\xe8re-plan, Docker utilise en fait un service appel\xe9 SNYK pour faire la num\xe9risation de la vuln\xe9rabilit\xe9 des images. Le scan utilise une base de donn\xe9es de vuln\xe9rabilit\xe9s, qui est constamment mise \xe0 jour."},{"id":"/2024/03/05/03-containerization/docker-containers","metadata":{"permalink":"/blog/2024/03/05/03-containerization/docker-containers","source":"@site/blog/03-containerization/2024-03-05-docker-containers.md","title":"Pr\xe9sentation des conteneurs Docker","description":"Pr\xe9sentation des conteneurs Docker, leur fonctionnement et des exemples d\'utilisation.","date":"2024-03-05T00:00:00.000Z","tags":[{"inline":true,"label":"Docker","permalink":"/blog/tags/docker"},{"inline":true,"label":"Containerization","permalink":"/blog/tags/containerization"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":1.955,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Pr\xe9sentation des conteneurs Docker","description":"Pr\xe9sentation des conteneurs Docker, leur fonctionnement et des exemples d\'utilisation.","tags":["Docker","Containerization","Devops"]},"unlisted":false,"prevItem":{"title":"Docker pratiques de production","permalink":"/blog/2024/03/10/03-containerization/docker-best-practices"},"nextItem":{"title":"Le concept de conteneur Docker","permalink":"/blog/2024/03/03/03-containerization/docker"}},"content":"Les conteneurs Docker sont des unit\xe9s logicielles l\xe9g\xe8res et portables qui encapsulent une application et ses d\xe9pendances dans une image. Ces images sont compos\xe9es de plusieurs couches, souvent bas\xe9es sur une distribution Linux l\xe9g\xe8re comme Alpine, pour minimiser la taille. Les conteneurs permettent de maintenir des applications isol\xe9es et coh\xe9rentes, ind\xe9pendamment de l\'environnement d\'ex\xe9cution.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce qu\'un conteneur Docker ?\\n\\nUn conteneur Docker est une unit\xe9 logicielle l\xe9g\xe8re et portable qui encapsule une application et ses d\xe9pendances dans une image. Ces images sont compos\xe9es de plusieurs couches, souvent bas\xe9es sur une distribution Linux l\xe9g\xe8re comme Alpine, pour minimiser la taille. Les conteneurs permettent de maintenir des applications isol\xe9es et coh\xe9rentes, ind\xe9pendamment de l\'environnement d\'ex\xe9cution.\\n\\n### Structure d\'un conteneur Docker\\n\\nUn conteneur Docker est compos\xe9 de plusieurs couches d\'images empil\xe9es les unes sur les autres. \xc0 la base de la plupart des conteneurs, on trouve une image Linux, souvent Alpine en raison de sa petite taille. Les couches sup\xe9rieures contiennent les d\xe9pendances et l\'application elle-m\xeame. Cette structure en couches permet de r\xe9utiliser les couches communes entre plusieurs conteneurs, r\xe9duisant ainsi la taille et le temps de t\xe9l\xe9chargement.\\n\\n## Exemple pratique : Utilisation de PostgreSQL avec Docker\\n\\nPour illustrer l\'utilisation des conteneurs Docker, prenons l\'exemple de PostgreSQL. En utilisant Docker Hub, un d\xe9p\xf4t public d\'images Docker, on peut rechercher et t\xe9l\xe9charger une version sp\xe9cifique de PostgreSQL. Par exemple, pour obtenir la version 9.6, il suffit d\'ex\xe9cuter la commande `docker pull` suivie de `docker run` pour d\xe9marrer le conteneur. Docker t\xe9l\xe9charge les couches n\xe9cessaires et d\xe9marre l\'application automatiquement.\\n\\n```bash\\n# Rechercher l\'image officielle de PostgreSQL sur Docker Hub\\ndocker search postgres\\n\\n# T\xe9l\xe9charger l\'image de PostgreSQL version 9.6\\ndocker pull postgres:9.6\\n\\n# D\xe9marrer un conteneur PostgreSQL avec la version 9.6\\ndocker run --name my-postgres -e POSTGRES_PASSWORD=mysecretpassword -d postgres:9.6\\n```\\n\\n### Diff\xe9rence entre une image Docker et un conteneur Docker\\n\\nUne image Docker est un package statique qui contient tout ce dont une application a besoin pour fonctionner : le code, les biblioth\xe8ques, les d\xe9pendances et les configurations. C\'est un mod\xe8le pr\xeat \xe0 \xeatre ex\xe9cut\xe9. En revanche, un conteneur Docker est une instance en cours d\'ex\xe9cution de cette image. Lorsque vous d\xe9marrez un conteneur, Docker utilise l\'image pour cr\xe9er un environnement isol\xe9 o\xf9 l\'application peut s\'ex\xe9cuter. En d\'autres termes, une image est un mod\xe8le, tandis qu\'un conteneur est une instance active de ce mod\xe8le."},{"id":"/2024/03/03/03-containerization/docker","metadata":{"permalink":"/blog/2024/03/03/03-containerization/docker","source":"@site/blog/03-containerization/2024-03-03-docker.md","title":"Le concept de conteneur Docker","description":"Docker est un outil open source qui permet aux d\xe9veloppeurs de cr\xe9er, d\xe9ployer, ex\xe9cuter, mettre \xe0 jour et g\xe9rer les conteneurs.","date":"2024-03-03T00:00:00.000Z","tags":[{"inline":true,"label":"Containerization","permalink":"/blog/tags/containerization"},{"inline":true,"label":"Docker","permalink":"/blog/tags/docker"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":3.095,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Le concept de conteneur Docker","description":"Docker est un outil open source qui permet aux d\xe9veloppeurs de cr\xe9er, d\xe9ployer, ex\xe9cuter, mettre \xe0 jour et g\xe9rer les conteneurs.","tags":["Containerization","Docker","Devops"]},"unlisted":false,"prevItem":{"title":"Pr\xe9sentation des conteneurs Docker","permalink":"/blog/2024/03/05/03-containerization/docker-containers"},"nextItem":{"title":"Architecture compl\xe8te","permalink":"/blog/2024/02/25/04-ci-cd/exemple"}},"content":"\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce qu\'un conteneur et quels probl\xe8mes r\xe9sout-il?\\n\\nUn conteneur est un **moyen de packager des applications** avec tout ce dont ils ont besoin \xe0 l\'int\xe9rieur de ce package, y compris toutes ses d\xe9pendances et toutes les configurations n\xe9cessaires.\\n\\nLe package est portable comme tout autre artefact, et ce package peut \xeatre facilement partag\xe9 et d\xe9plac\xe9 entre une \xe9quipe de d\xe9veloppement ou une \xe9quipe de d\xe9veloppement et d\'op\xe9rations.\\n\\nLa portabilit\xe9 des conteneurs, ainsi que tout ce qui est packag\xe9 dans un **environnement isol\xe9**, lui donne des avantages qui rendent le processus de d\xe9veloppement et de d\xe9ploiement plus efficace.\\n\\n## D\xe9veloppement d\'applications avant / apr\xe8s conteneur\\n\\nVoyons maintenant comment les conteneurs am\xe9liorent le processus de d\xe9veloppement par des exemples sp\xe9cifiques.\\n\\nComment avons-nous d\xe9velopp\xe9 des applications avant les conteneurs?\\n\\nHabituellement, lorsque vous avez une \xe9quipe de d\xe9veloppeurs travaillant sur une application, vous devez installer directement la plupart des services sur votre syst\xe8me d\'exploitation.\\n\\nChaque d\xe9veloppeur de l\'\xe9quipe devrait alors aller installer les binaires de ces services, les configurer et les ex\xe9cuter sur son environnement de d\xe9veloppement local. Le processus d\'installation sera diff\xe9rent en fonction du syst\xe8me d\'exploitation qu\'ils utilisent.\\n\\nVous avez donc quelques commandes \xe0 ex\xe9cuter, et les **chances qu\'une erreur se produise sont \xe9lev\xe9es**, en raison du nombre d\'\xe9tapes n\xe9cessaires pour installer chaque service.\\n\\nMaintenant, voyons comment les conteneurs r\xe9solvent certains de ces probl\xe8mes.\\n\\nVous n\'avez pas \xe0 installer des services directement sur votre syst\xe8me d\'exploitation, car le conteneur poss\xe8de **sa propre couche de syst\xe8me d\'exploitation isol\xe9e** avec une image de base Linux.\\n\\nVous avez tout packag\xe9 dans un environnement isol\xe9, en tant que d\xe9veloppeur, vous n\'avez pas chercher les binaires \xe0 t\xe9l\xe9charger sur votre machine. Au lieu de cela, vous allez consulter le registre de conteneurs pour trouver le conteneur sp\xe9cifique \xe0 votre application et le t\xe9l\xe9charger sur votre machine locale.\\n\\n## D\xe9ploiement d\'application avant / apr\xe8s conteneur\\n\\n### Avant les conteneurs\\n\\nUn processus de d\xe9ploiement traditionnel ressemblera \xe0 ceci:\\n\\nL\'\xe9quipe de d\xe9veloppeur cr\xe9era des artefacts, qui sont essentiellement des fichiers, ainsi que des instructions sur l\'installation et les configurer sur le serveur. Tous ces artefacts et instructions seront fournis par l\'\xe9quipe de d\xe9veloppement:\\n\\n![alt text](/img/image.png)\\n\\nL\'\xe9quipe de d\xe9veloppement donnerait donc ces artefacts \xe0 l\'\xe9quipe des op\xe9rations, et l\'\xe9quipe d\'op\xe9ration mettrait en place les environnements pour d\xe9ployer ces applications:\\n\\n![Texte alt](/img/image-1.png)\\n\\n- **D\xe9pendances externes sur le syst\xe8me d\'exploitation du serveur**: Le probl\xe8me avec cette approche est que vous devez d\'abord configurer tout et tout installer directement sur le syst\xe8me d\'exploitation du serveur. Cela pourrait entra\xeener des conflits avec les versions de d\xe9pendance.\\n- **Mauvaise communication**: un autre probl\xe8me qui pourrait r\xe9sulter de ce processus est un malentendu entre l\'\xe9quipe de d\xe9veloppement et les op\xe9rations. Parce que tout est dans un guide textuel, il pourrait y avoir des cas, o\xf9 les d\xe9veloppeurs manquent de mentionner certains points critiques sur la configuration et en cas d\'\xe9chec, l\'\xe9quipe d\'op\xe9rations doit retourner aux d\xe9veloppeurs et demander plus de d\xe9tails.\\n\\n### Avec les Conteneurs\\n\\nAvec les conteneurs, ce processus est simplifi\xe9, car maintenant les d\xe9veloppeurs et les op\xe9rations fonctionnent dans une \xe9quipe pour former toutes les d\xe9pendances de configuration dans l\'application.\\n\\n![Texte alt](/img/image-2.png)\\n\\nCela signifie que si vous utilisez un conteneur Docker, vous n\'avez pas besoin de configurer quoi que ce soit directement sur le serveur, car tout est d\xe9j\xe0 encapsul\xe9 dans le conteneur. Au lieu de cela, il vous suffit d\'ex\xe9cuter une commande docker qui r\xe9cup\xe8re le conteneur que vous avez stock\xe9 dans le registre, puis l\'ex\xe9cute.\\n\\nC\'est donc beaucoup plus simple et aucune configuration environnementale n\'est n\xe9cessaire sur le serveur. La seule chose bien s\xfbr est que vous devez installer et configurer le runtime docker sur le serveur avant de pouvoir y ex\xe9cuter des conteneurs. Mais ce n\'est qu\'un effort unique."},{"id":"/2024/02/25/04-ci-cd/exemple","metadata":{"permalink":"/blog/2024/02/25/04-ci-cd/exemple","source":"@site/blog/04-ci-cd/2024-02-25-exemple.md","title":"Architecture compl\xe8te","description":"Exemple complet d\'architecture CI/CD r\xe9utilisable","date":"2024-02-25T00:00:00.000Z","tags":[{"inline":true,"label":"CI/CD","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":2.585,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Architecture compl\xe8te","description":"Exemple complet d\'architecture CI/CD r\xe9utilisable","tags":["CI/CD","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Le concept de conteneur Docker","permalink":"/blog/2024/03/03/03-containerization/docker"},"nextItem":{"title":"Action Runner Controller GitHub","permalink":"/blog/2024/02/18/04-ci-cd/github-arc"}},"content":"L\'objectif est de cr\xe9er une architecture CI/CD compl\xe8te pour un projet de d\xe9veloppement adressant une technologie (par exemple ROS). Cette architecture doit \xeatre :\\n\\n- facilement r\xe9utilisable dans d\'autres projets\\n- \xe9viter la duplication de code\\n- maintenable et \xe9volutive ais\xe9ment\\n- applicable \xe0 d\'autres projets\\n\\n\x3c!--truncate--\x3e\\n\\n## Cr\xe9ation d\'une architecture CI/CD\\n\\nL\'id\xe9e de l\'architecture est de cr\xe9er un d\xe9p\xf4t contenant tous les workflows et les actions propres \xe0 une technologie / projet (par exemple ROS). Ce d\xe9p\xf4t sera ensuite utilis\xe9 comme cible pour les workflows des projets utilisant cette technologie.\\n\\n```mermaid\\ngraph LR\\n    subgraph Repositories ROS1\\n        repo1[ros_package_1/.github/workflows/ci.yml]\\n        repo2[ros_package_2/.github/workflows/ci.yml]\\n        repo3[ros_package_n/.github/workflows/ci.yml]\\n    end\\n    subgraph ros_workflows\\n        ros.yml[.github/workflows/ros1.yml]\\n        ros2.yml[.github/workflows/ros2.yml]\\n        ros_build.yml[ros_build/action.yml]\\n        ros.yml --\x3e ros_build.yml\\n        ros2.yml --\x3e ros_build.yml\\n    end\\n    subgraph generic_workflows\\n        pre-commit.yml[.github/workflows/pre-commit.yml]\\n\\n    end\\n\\n    ros.yml --\x3e pre-commit.yml\\n\\n    repo1 --\x3e ros.yml\\n    repo2 --\x3e ros.yml\\n    repo3 --\x3e ros.yml\\n```\\n\\nDans cet exemple, nous avons un d\xe9p\xf4t `ros_workflows` contenant les workflows et les actions propres \xe0 la technologie ROS. Ce d\xe9p\xf4t est ensuite utilis\xe9 par les d\xe9p\xf4ts `ros_package_1`, `ros_package_2`, `ros_package_n` pour ex\xe9cuter les workflows. Les diff\xe9rents workflows pr\xe9sents dans `ros_workflows` sont les **uniques** points d\'entr\xe9e pour les workflows des d\xe9p\xf4ts `ros_package_1`, `ros_package_2`, `ros_package_n`. Ainsi s\'il est n\xe9cessaire de modifier un workflow, il suffit de le faire dans le d\xe9p\xf4t `ros_workflows` et tous les d\xe9p\xf4ts utilisant ce workflow seront mis \xe0 jour.\\n\\nDe plus le d\xe9p\xf4t `ros_workflows` peut d\xe9finir des `actions-composites` pour \xe9viter la duplication de code entre leurs propres workflows. Ces actions sont utilis\xe9es par les workflows du d\xe9p\xf4t `ros_workflows` et par cons\xe9quent des d\xe9p\xf4ts `ros_package_1`, `ros_package_2`, `ros_package_n`. Elles peuvent aussi \xeatre appel\xe9es directement au besoin.\\n\\nFinalemet, le d\xe9p\xf4t `ros_workflows` peut aussi utiliser des workflows g\xe9n\xe9riques (par exemple `pre-commit.yml`) pour automatiser des t\xe2ches communes \xe0 toutes les technologies.\\n\\n### Exemple de workflow `ros1.yml`\\n\\n```yaml\\nname: Build & Test ROS Packages\\n\\non:\\n  workflow_call:\\n    inputs:\\n      package-name:\\n        description: \'The name of the ROS package to build and test.\'\\n        required: true\\n        type: string\\n    secrets:\\n      PAT:\\n        required: false\\n        description: \'A GitHub Personal Access Token (PAT) used to import the private repository into the container.\'\\n\\n\\njobs:\\n  pre-commit:\\n    uses: catie-aq/generic_workflows/.github/workflows/pre-commit.yaml@main\\n  build_and_test_ros_package:\\n    runs-on: self-hosted # Use self-hosted runner\\n    strategy: # Define a matrix of ROS distributions and Docker images\\n      matrix:\\n        include:\\n          - docker_image: osrf/ros:noetic-desktop-full\\n            ros_distribution: noetic\\n    container: # Use the Docker image defined in the matrix\\n      image: ${{ matrix.docker_image }}\\n    steps:\\n      - name: Setup ROS environment\\n        uses: ros-tooling/setup-ros@v0.7\\n        with:\\n          required-ros-distributions: ${{ matrix.ros_distribution }}\\n\\n      - name: Build and test ROS\\n        uses: ros-tooling/action-ros-ci@v0.2\\n        with:\\n          package-name: ${{ inputs.package-name }}\\n          target-ros1-distro: ${{ matrix.ros_distribution }}\\n          import-token: ${{ secrets.PAT }}\\n```\\n\\n### Exemple de workflow `ci.yml`\\n\\n```yaml\\nname: \\"ROS CI/CD\\"\\n\\non:\\n  push:\\n\\njobs:\\n  ros:\\n    uses: {user}/ros_workflows/.github/workflows/ros.yml@main\\n```\\n\\n### Exemple d\'action composite `ros_build/action.yml`\\n\\n```yaml\\nname: \'Build and Test ROS\'\\ndescription: \'Build and test a ROS package\'\\n\\ninputs:\\n  package-name:\\n    description: \'The name of the ROS package to build and test.\'\\n    required: true\\n    type: string\\n  ros-distribution:\\n    description: \'The ROS distribution to use for building and testing.\'\\n    required: true\\n    type: string\\n  import-token:\\n    description: \'A GitHub Personal Access Token (PAT) used to import the private repository into the container.\'\\n    required: false\\n    type: string\\n\\nruns:\\n    using: \\"composite\\"\\n    steps:\\n        - run: echo \\"Building and testing ROS package ${{ inputs.package-name }} for ROS ${{ inputs.ros-distribution }}.\\"\\n        shell: bash\\n```"},{"id":"/2024/02/18/04-ci-cd/github-arc","metadata":{"permalink":"/blog/2024/02/18/04-ci-cd/github-arc","source":"@site/blog/04-ci-cd/2024-02-18-github-arc.md","title":"Action Runner Controller GitHub","description":"Explication de l\'installation et de l\'utilisation de l\'Action Runner Controller GitHub","date":"2024-02-18T00:00:00.000Z","tags":[{"inline":true,"label":"CI/CD","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":3.21,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Action Runner Controller GitHub","description":"Explication de l\'installation et de l\'utilisation de l\'Action Runner Controller GitHub","tags":["CI/CD","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Architecture compl\xe8te","permalink":"/blog/2024/02/25/04-ci-cd/exemple"},"nextItem":{"title":"Runner GitHub Self-Hosted","permalink":"/blog/2024/02/11/04-ci-cd/self-host-runner"}},"content":"Actions Runner Controller (ARC) est un op\xe9rateur de Kubernetes qui orchestre et g\xe8re les runners auto-h\xe9berg\xe9s pour les actions GitHub.\\n\\n\x3c!--truncate--\x3e\\n\\n## GitHub ARC\\n\\nLes runners auto-h\xe9berg\xe9s offrent un contr\xf4le total sur l\'environnement d\'ex\xe9cution, permettant de personnaliser les configurations et d\'optimiser les performances selon les besoins sp\xe9cifiques. Ils sont \xe9galement plus rentables \xe0 long terme, car ils n\'entra\xeenent pas de co\xfbts suppl\xe9mentaires li\xe9s \xe0 l\'utilisation des ressources de GitHub. Cependant, ils n\xe9cessitent une maintenance r\xe9guli\xe8re et une gestion de la s\xe9curit\xe9 pour garantir leur bon fonctionnement et leur protection contre les menaces potentielles. En revanche, GitHub Actions Runner Controller (ARC) est une solution \xe9volutive g\xe9r\xe9e par GitHub, qui permet de g\xe9rer automatiquement les runners dans un environnement Kubernetes. ARC offre une gestion simplifi\xe9e et une mise \xe0 l\'\xe9chelle automatique des runners en fonction des besoins, ce qui est id\xe9al pour les grandes organisations avec des charges de travail variables. Cependant, l\'utilisation de GitHub ARC peut entra\xeener des co\xfbts plus \xe9lev\xe9s pour les d\xe9ploiements \xe0 grande \xe9chelle, et les utilisateurs ont moins de contr\xf4le sur l\'environnement d\'ex\xe9cution par rapport aux runners auto-h\xe9berg\xe9s.\\n\\nAvec ARC, il est possible de cr\xe9er des ensembles de runners qui \xe9voluent automatiquement en fonction du nombre de workflows ex\xe9cut\xe9s dans votre d\xe9p\xf4t, organisation ou entreprise.\\n\\nLe diagramme suivant illustre l\'architecture du mode Scaleset Runner Autoscaling d\'Arc.\\n\\n[Documentation compl\xe8te](https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/quickstart-for-actions-runner-controller)\\n\\n![alt text](/img/arc.png)\\n\\n:::danger\\nSur GitHub les ARC sont identifi\xe9s par leur nom d\'installation. Il est important de choisir un nom unique pour chaque installation. De plus pour simplifier l\'\xe9criture des workflows il est consill\xe9 de g\xe9rer les runners par des groupes de runners. La cl\xe9 `runs-on` des jobs des workflows doit \xeatre \xe9gale \xe0 un groupe de runners.\\n:::\\n\\n## Pr\xe9requis\\n\\nPour utiliser l\'ARC, il est n\xe9cessaire de disposer des \xe9l\xe9ments suivants :\\n\\n- Un cluster Kubernetes\\n- Helm 3.0 ou version ult\xe9rieure\\n\\n## Installation rapide\\n\\n:::warning\\nLa suite du guide permet de rapidement installer ARC. Les diff\xe9rents concepts et la configuration avanc\xe9e ne sont pas abord\xe9s. Pour une installation plus compl\xe8te, regarder la [documentation officielle](https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/quickstart-for-actions-runner-controller).\\n:::\\n\\n- Le pod de contr\xf4le est en charge de la gestion des pods de runner. Il s\'occupe de la cr\xe9ation, de la mise \xe0 l\'\xe9chelle et de la suppression des pods de runner.\\n- Le pod de runner est d\xe9di\xe9 \xe0 l\'ex\xe9cution des workflows GitHub Actions. Il se compose de deux conteneurs : un conteneur DinD et un conteneur runner. Le conteneur DinD fournit un environnement d\'ex\xe9cution Docker pour le conteneur runner. Le conteneur runner est utilis\xe9 pour ex\xe9cuter les workflows GitHub Actions.\\n\\n## Usage\\n\\nPour lancer le pod de contr\xf4le :\\n\\n```shell\\nNAMESPACE=\\"arc-systems\\"\\nhelm install arc \\\\\\n    --namespace \\"${NAMESPACE}\\" \\\\\\n    --create-namespace \\\\\\n    oci://ghcr.io/actions/actions-runner-controller-charts/gha-runner-scale-set-controller\\n```\\n\\nPour lancer le pod de runner :\\n\\n```shell\\nINSTALLATION_NAME=\\"elegantencoder\\"\\nNAMESPACE=\\"arc-runners\\"\\nhelm install \\"${INSTALLATION_NAME}\\" \\\\\\n    --namespace \\"${NAMESPACE}\\" \\\\\\n    --create-namespace \\\\\\n    -f value.yaml \\\\\\n    oci://ghcr.io/actions/actions-runner-controller-charts/gha-runner-scale-set;\\n```\\n\\n## Authentification\\n\\nPour que le pod de contr\xf4le puisse cr\xe9er des pods de runner, il faut lui donner les droits n\xe9cessaires. Pour cela, il faut cr\xe9er un secret contenant un token d\'authentification. Les diff\xe9rents \xe9l\xe9ments proviennent de l\'enregistrement d\'une application GitHub au niveau de l\'organisation concern\xe9e.\\n\\n```shell\\nkubectl create secret generic pre-defined-secret \\\\\\n   --namespace=arc-runners \\\\\\n   --from-literal=github_app_id=xxx \\\\\\n   --from-literal=github_app_installation_id=xxx \\\\\\n   --from-literal=github_app_private_key=\'xxx\'\\n```\\n\\n## Monitoring\\n\\nDashboard Helm\\n\\n```shell\\nhelm dashboard --bind 0.0.0.0\\n```\\n\\nPortainer\\n\\n## Docker cache\\n\\nNous avons rencontr\xe9 un probl\xe8me de lenteur lors de la construction des images Docker. Pour y rem\xe9dier, nous avons mis en place la mutualisation des couches des images Docker entre les diff\xe9rents pods et l\'h\xf4te. Cela implique la cr\xe9ation d\'un volume partag\xe9 entre les diff\xe9rents pods et l\'h\xf4te. Ces volumes sont mont\xe9s dans le conteneur DinD du pod qui les utilise pour fournir les images Docker au conteneur du runner. Chaque pod de runner contient un conteneur DinD qui est utilis\xe9 pour construire les images Docker.\\n\\n```yaml\\n- name: overlay2\\n    hostPath:\\n    path: /var/lib/docker/overlay2\\n- name: image-overlay2\\n    hostPath:\\n    path: /var/lib/docker/image/overlay2\\n```"},{"id":"/2024/02/11/04-ci-cd/self-host-runner","metadata":{"permalink":"/blog/2024/02/11/04-ci-cd/self-host-runner","source":"@site/blog/04-ci-cd/2024-02-11-self-host-runner.md","title":"Runner GitHub Self-Hosted","description":"Explication de la cr\xe9ation et de l\'installation d\'un nouveau runner au niveau de l\'organisation","date":"2024-02-11T00:00:00.000Z","tags":[{"inline":true,"label":"CI/CD","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":3.52,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Runner GitHub Self-Hosted","description":"Explication de la cr\xe9ation et de l\'installation d\'un nouveau runner au niveau de l\'organisation","tags":["CI/CD","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Action Runner Controller GitHub","permalink":"/blog/2024/02/18/04-ci-cd/github-arc"},"nextItem":{"title":"Actions Composites","permalink":"/blog/2024/02/04/04-ci-cd/action"}},"content":"Un `runner` est une machine virtuelle ou physique qui ex\xe9cute des `jobs` dans un `workflow`. Les `runners` peuvent \xeatre h\xe9berg\xe9s par GitHub ou auto-h\xe9berg\xe9s. Les `runners` h\xe9berg\xe9s par GitHub sont ex\xe9cut\xe9s dans un environnement de cloud partag\xe9 et sont g\xe9r\xe9s par GitHub et peuvent entrainer des surcouts. Les `runners` auto-h\xe9berg\xe9s sont ex\xe9cut\xe9s sur une machine que vous poss\xe9dez et g\xe9rez.\\n\\n\x3c!--truncate--\x3e\\n\\n## Comparaison entre les runners auto-h\xe9berg\xe9s et les runners cloud-h\xe9berg\xe9s de GitHub\\n\\nLes runners auto-h\xe9berg\xe9s offrent un contr\xf4le total sur l\'environnement d\'ex\xe9cution, ce qui permet de personnaliser les configurations et d\'optimiser les performances selon les besoins sp\xe9cifiques. Ils sont \xe9galement plus rentables \xe0 long terme, car ils n\'entra\xeenent pas de co\xfbts suppl\xe9mentaires li\xe9s \xe0 l\'utilisation des ressources de GitHub. Cependant, ils n\xe9cessitent une maintenance r\xe9guli\xe8re et une gestion de la s\xe9curit\xe9 pour garantir leur bon fonctionnement et leur protection contre les menaces potentielles.\\n\\nLes runners cloud-h\xe9berg\xe9s de GitHub sont g\xe9r\xe9s par GitHub, ce qui signifie que les utilisateurs n\'ont pas \xe0 se soucier de la maintenance, de la s\xe9curit\xe9 ou de la mise \xe0 jour des runners. Ils sont \xe9galement facilement \xe9volutifs, car GitHub peut ajouter des ressources suppl\xe9mentaires en fonction des besoins. Cependant, les runners cloud-h\xe9berg\xe9s peuvent entra\xeener des co\xfbts suppl\xe9mentaires pour les utilisateurs, en particulier pour les projets de grande envergure ou les charges de travail intensives.\\n\\nEn r\xe9sum\xe9, les runners auto-h\xe9berg\xe9s sont id\xe9aux pour les \xe9quipes ou les projets avec des besoins sp\xe9cifiques en mati\xe8re de configuration et de performances, tandis que les runners cloud-h\xe9berg\xe9s de GitHub sont mieux adapt\xe9s aux utilisateurs qui pr\xe9f\xe8rent une solution g\xe9r\xe9e et \xe9volutive sans avoir \xe0 se soucier de la maintenance et de la s\xe9curit\xe9. Le choix entre les deux d\xe9pend des besoins sp\xe9cifiques de l\'\xe9quipe et des ressources disponibles.\\n\\n## Cr\xe9\xe9r un runner auto-h\xe9berg\xe9s\\n\\nPour t\xe9l\xe9charger un nouveau `runner`, ex\xe9cutez les lignes suivantes\\n\\n```shell\\n# Create a folder\\nmkdir actions-runner && cd actions-runner\\n# Download the latest runner package\\ncurl -o actions-runner-linux-x64-2.312.0.tar.gz -L <https://github.com/actions/runner/releases/download/v2.312.0/actions-runner-linux-x64-2.312.0.tar.gz> # ! update this documentation with the latest release\\n# Optional: Validate the hash\\necho \\"85c1bbd104d539f666a89edef70a18db2596df374a1b51670f2af1578ecbe031  actions-runner-linux-x64-2.312.0.tar.gz\\" | shasum -a 256 -c\\n# Extract the installer\\ntar xzf ./actions-runner-linux-x64-2.312.0.tar.gz\\n```\\n\\nIl est ensuite n\xe9cessaire de configurer votre `runner`\\n\\n```shell\\n# Create the runner and start the configuration experience\\n./config.sh --url <https://github.com/><org>/<repo> --token <token># Last step, run it!\\n./run.sh\\n```\\n\\n:::info\\nLe token est \xe0 obtenir au pr\xe8s d\u2019un `owner` de l\u2019organisation accessible sur le lien suivant [https://github.com/organizations/](https://github.com/organizations/org/settings/actions/runners/new?arch=x64&os=linux)\\n:::\\n\\n\u27a1\ufe0f Lors de la configuration, il est possible d\'ajouter des **labels** pour identifier la machine (par exemple `GPU`).\\n\\n## Cr\xe9er une action `self-hosted`\\n\\nIl n\u2019est pas possible de cr\xe9er une action visant une machine `self-hosted` particuli\xe8re (\xe0 confirmer). Chaque `repository` d\u2019une organisation peut acc\xe9der \xe0 :\\n\\n- Toutes les machines dans le groupe `D\xe9faut` qui sont automatiquement partag\xe9es \xe0 tous les d\xe9p\xf4ts.\\n- Toutes les machines dans un groupe `Name` qui sont manuellement partag\xe9es au d\xe9p\xf4t concern\xe9 (l\u2019affectation manuelle des d\xe9p\xf4ts \xe0 des groupes de machines nous encourage \xe0 ne pas utiliser ceci sauf cas particulier)\\n\\nParmi les machines disponibles le `repository` peut demander d\u2019utiliser une machine en fonction de son `label` par exemple l\u2019action ci-dessous, permettant de v\xe9rifier que le d\xe9p\xf4t est compilable sous ROS, r\xe9quisitionne une machine ayant le label `Robotics`. Ceci est modifiable \xe0 la ligne `runs-on: Robotics`.\\n\\n```yaml\\nname: CI\\n\\non: [pull_request]\\n\\njobs:\\n  industrial_ci:\\n    strategy:\\n      matrix:\\n        env:\\n          - {ROS_DISTRO: melodic, ROS_REPO: main}\\n    runs-on: Robotics\\n    steps:\\n      - uses: actions/checkout@v3\\n      - uses: \'ros-industrial/industrial_ci@master\'\\n        env: ${{matrix.env}}\\n```\\n\\nLors de la premi\xe8re utilisation, si vous rencontrez un erreur `docker` sp\xe9cifiant un manque de permission, il est n\xe9cessaire de taper la commande suivante sur la machine distance `sudo setfacl --modify user:<user>:rw /var/run/docker.sock`\\nLorsqu\u2019une action est cr\xe9\xe9 en `self-hosted` il est fortement conseill\xe9 de mettre les actions dans un `container`. Lorsque c\u2019est impossible (comme `tailscale`) il est n\xe9cessaire d\u2019ajouer un clean de l\u2019environnement \xe0 la fin de l\u2019action en ajoutant cette `step`\\n\\n```yaml\\n- name: Clean runner\\n  if: always()\\n  run: rm -rf ${{ github.workspace }}/*\\n```\\n\\n## Mettre en place le runner sous forme de service\\n\\nDans le dossier de votre `runnner` sur la machine, transformer le `./run.sh` en service, tapez simplement les lignes ci-dessous pour que le `runner` s\u2019active au d\xe9marrage de la machine.\\n\\n```shell\\nsudo ./svc.sh install\\nsudo ./svc.sh start\\n```"},{"id":"/2024/02/04/04-ci-cd/action","metadata":{"permalink":"/blog/2024/02/04/04-ci-cd/action","source":"@site/blog/04-ci-cd/2024-02-04-action.md","title":"Actions Composites","description":"Cr\xe9\xe9er une action r\xe9utilisable","date":"2024-02-04T00:00:00.000Z","tags":[{"inline":true,"label":"CI/CD","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":4.075,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Actions Composites","description":"Cr\xe9\xe9er une action r\xe9utilisable","tags":["CI/CD","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Runner GitHub Self-Hosted","permalink":"/blog/2024/02/11/04-ci-cd/self-host-runner"},"nextItem":{"title":"Workflows","permalink":"/blog/2024/02/03/04-ci-cd/workflow"}},"content":"## Exemple de cr\xe9ation et d\'utilisation d\'une action GitHub\\n\\nVoici un exemple de cr\xe9ation et d\'utilisation d\'une action GitHub pour automatiser le d\xe9ploiement d\'une application Node.js.\\n\\n1. Cr\xe9ez un fichier `action.yml` dans le r\xe9pertoire `.github/actions/deploy` de votre d\xe9p\xf4t avec le contenu suivant :\\n\\n```yaml\\nname: \'Deploy Node.js App\'\\ndescription: \'Deploy a Node.js application to a remote server\'\\ninputs:\\n  server:\\n    description: \'The remote server to deploy to\'\\n    required: true\\n  username:\\n    description: \'The username to use for the deployment\'\\n    required: true\\n  password:\\n    description: \'The password to use for the deployment\'\\n    required: true\\nruns:\\n  using: \'composite\'\\n  steps:\\n    - name: Checkout code\\n      uses: actions/checkout@v4\\n    - name: Install dependencies\\n      run: npm install\\n    - name: Build application\\n      run: npm run build\\n    - name: Deploy application\\n      run: |\\n        sshpass -p ${{ inputs.password }} ssh ${{ inputs.username }}@${{ inputs.server }} \'mkdir -p /var/www/myapp\'\\n        sshpass -p ${{ inputs.password }} scp -r ./build/* ${{ inputs.username }}@${{ inputs.server }}:/var/www/myapp\\n```\\n\\n2. Cr\xe9ez un fichier `deploy.yml` dans le r\xe9pertoire `.github/workflows` de votre d\xe9p\xf4t avec le contenu suivant :\\n\\n```yaml\\nname: Deploy Node.js App\\n\\non:\\n  push:\\n    branches:\\n      - main\\n\\njobs:\\n  deploy:\\n    runs-on: ubuntu-latest\\n    steps:\\n      - name: Deploy application\\n        uses: ./.github/actions/deploy\\n        with:\\n          server: ${{ secrets.DEPLOY_SERVER }}\\n          username: ${{ secrets.DEPLOY_USERNAME }}\\n          password: ${{ secrets.DEPLOY_PASSWORD }}\\n```\\n\\nDans cet exemple, l\'action `Deploy Node.js App` est utilis\xe9e pour d\xe9ployer une application Node.js sur un serveur distant. L\'action est d\xe9clench\xe9e \xe0 chaque fois qu\'un push est effectu\xe9 sur la branche `main`. Les informations de d\xe9ploiement (serveur, nom d\'utilisateur et mot de passe) sont stock\xe9es dans les secrets du d\xe9p\xf4t pour des raisons de s\xe9curit\xe9.\\n\\nLes actions GitHub permettent d\'automatiser, personnaliser et ex\xe9cuter un flux de travail directement depuis votre d\xe9p\xf4t. Avec les actions GitHub, il est possible de cr\xe9er des t\xe2ches personnalis\xe9es pour automatiser un flux de travail, partager et d\xe9couvrir des actions pour effectuer des t\xe2ches sp\xe9cifiques.\\n\\n\x3c!--truncate--\x3e\\n\\n## Comment cr\xe9er ses propres actions\\n\\nDocumentation compl\xe8te : [https://docs.github.com/fr/actions/creating-actions](https://docs.github.com/fr/actions/creating-actions)\\n\\nLa cr\xe9ation d\'actions personnalis\xe9es offre la possibilit\xe9 de concevoir du code sp\xe9cifique qui interagit avec le d\xe9p\xf4t selon les besoins. Ces actions peuvent s\'int\xe9grer aux API de GitHub ou \xe0 toute API tierce accessible publiquement. Par exemple, une action pourrait \xeatre configur\xe9e pour publier des modules npm, envoyer des alertes par SMS en cas de cr\xe9ation de probl\xe8mes urgents, ou encore d\xe9ployer du code pr\xeat pour la production.\\nCe guide expose les \xe9l\xe9ments fondamentaux requis pour la cr\xe9ation et l\'utilisation d\'une action composite empaquet\xe9e.\\n\\n:::warning\\nLors de la cr\xe9ation de flux de travail et d\'actions, il est imp\xe9ratif d\'\xe9valuer constamment la possibilit\xe9 d\'ex\xe9cution d\'une entr\xe9e non fiable provenant de sources potentiellement malveillantes. Certains contextes doivent \xeatre trait\xe9s comme des entr\xe9es non fiables, car un attaquant pourrait ins\xe9rer son propre contenu malveillant. Pour de plus amples informations, veuillez consulter la section \xab [Durcissement de la s\xe9curit\xe9 pour GitHub Actions](https://docs.github.com/fr/actions/security-guides/security-hardening-for-github-actions#understanding-the-risk-of-script-injections) \xbb.\\n:::\\n\\n## Cr\xe9ation d\u2019une action\\n\\nUn d\xe9p\xf4t doit \xeatre cr\xe9\xe9 sur [GitHub.com](http://GitHub.com).\\n\\n- Cr\xe9ez un nouveau d\xe9p\xf4t sur [GitHub](http://GitHub.com), en choisissant n\'importe quel nom de d\xe9p\xf4t ou en utilisant l\'exemple suivant : `hello-world-composite-action`. Les fichiers peuvent \xeatre ajout\xe9s une fois que le projet est pouss\xe9 sur GitHub. Pour plus d\'informations, veuillez vous r\xe9f\xe9rer \xe0 la section [Cr\xe9ation d\'un d\xe9p\xf4t](https://docs.github.com/fr/repositories/creating-and-managing-repositories/creating-a-new-repository).\\n- Dans le d\xe9p\xf4t `hello-world-composite-action`, cr\xe9ez un fichier nomm\xe9 `goodbye.sh` et ajoutez le code `echo \\"Goodbye`\\n- Rendez `goodbye.sh` ex\xe9cutable depuis votre terminal.\\n- Dans le d\xe9p\xf4t `hello-world-composite-action`, cr\xe9ez un fichier nomm\xe9 `action.yml` et ajoutez le code suivant en exemple. Pour plus d\'informations sur cette syntaxe, consultez la section [Syntaxe des m\xe9tadonn\xe9es pour les actions GitHub](https://docs.github.com/fr/actions/creating-actions/metadata-syntax-for-github-actions#runs-for-composite-actions) .\\n\\n```yaml\\n    name: \'Hello World\'\\n    description: \'Greet someone\'\\n    inputs:\\n      who-to-greet:  # id of input\\n        description: \'Who to greet\'\\n        required: true\\n        default: \'World\'\\n    outputs:\\n      random-number:\\n        description: \\"Random number\\"\\n        value: ${{ steps.random-number-generator.outputs.random-number }}\\n    runs:\\n      using: \\"composite\\"\\n      steps:\\n        - run: echo Hello ${{ inputs.who-to-greet }}.\\n          shell: bash\\n        - id: random-number-generator\\n          run: echo \\"random-number=$(echo $RANDOM)\\" >> $GITHUB_OUTPUT\\n          shell: bash\\n        - run: echo \\"${{ github.action_path }}\\" >> $GITHUB_PATH\\n          shell: bash\\n        - run: goodbye.sh\\n          shell: bash\\n```\\n\\n- Ce fichier d\xe9finit l\'entr\xe9e `who-to-greet`, mappe le nombre g\xe9n\xe9r\xe9 al\xe9atoirement \xe0 la variable de sortie `random-number`, ajoute le chemin d\'acc\xe8s de l\'action au chemin d\'acc\xe8s du syst\xe8me de l\'ex\xe9cuteur (pour localiser le script `goodbye.sh` lors de l\'ex\xe9cution) et ex\xe9cute le script .\\n- Effectuez le commit de votre fichier `action.yml` depuis votre terminal.\\n\\n```shell\\n    git add action.yml\\n    git commit -m \\"Add action\\"\\n    git push\\n```\\n\\n- Ajoutez une \xe9tiquette depuis votre terminal. Cet exemple utilise une \xe9tiquette nomm\xe9e `v1`.\\n\\n```shell\\n    git tag -a -m \\"Description of this release\\" v1\\n    git push --follow-tags\\n```\\n\\n## Tester l\u2019action dans un workflow\\n\\nCopiez le code de workflow dans un fichier `.github/workflows/main.yml` d\'un autre d\xe9p\xf4t\\n\\n```yaml\\n    on: [push]\\n\\n    jobs:\\n      hello_world_job:\\n        runs-on: ubuntu-latest\\n        name: A job to say hello\\n        steps:\\n          - uses: actions/checkout@v4\\n          - id: foo\\n            uses: actions/hello-world-composite-action@v1\\n            with:\\n              who-to-greet: \'Mona the Octocat\'\\n          - run: echo random-number ${{ steps.foo.outputs.random-number }}\\n            shell: bash\\n```\\n\\n## Action dans un workflow priv\xe9\\n\\nDans les param\xe8tres des actions, il est n\xe9cessaire de la partager \xe0 l\u2019organisation\\n\\n![AllowAction](/img/allow_action.png)"},{"id":"/2024/02/03/04-ci-cd/workflow","metadata":{"permalink":"/blog/2024/02/03/04-ci-cd/workflow","source":"@site/blog/04-ci-cd/2024-02-03-workflow.md","title":"Workflows","description":"Cr\xe9\xe9er un workflow avec GitHub Actions","date":"2024-02-03T00:00:00.000Z","tags":[{"inline":true,"label":"CI/CD","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":4.895,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Workflows","description":"Cr\xe9\xe9er un workflow avec GitHub Actions","tags":["CI/CD","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Actions Composites","permalink":"/blog/2024/02/04/04-ci-cd/action"},"nextItem":{"title":"Introduction \xe0 GitHub Actions","permalink":"/blog/2024/02/02/04-ci-cd/github-actions"}},"content":"## Exemple d\'int\xe9gration des actions GitHub dans les workflows\\n\\nVoici un exemple d\'int\xe9gration des actions GitHub dans un workflow pour automatiser le d\xe9ploiement d\'une application Node.js.\\n\\nUn workflow est l\'\xe9l\xe9ment central de GitHub Actions. Il s\'agit d\'un processus automatis\xe9 compos\xe9 de `jobs` et de `steps` qui s\'ex\xe9cutent sur des `runners`. Les workflows sont d\xe9clench\xe9s par des \xe9v\xe9nements, tels que des pushs, des pull requests, des forks, etc.\\n\\n\x3c!--truncate--\x3e\\n\\nPour cr\xe9er un fichier de workflow, il faut cr\xe9er un fichier `.yml` dans le dossier `.github/workflows` du d\xe9p\xf4t. Un workflow est compos\xe9 de `jobs` et de `steps`. Un `job` est une suite d\'\xe9tapes qui s\'ex\xe9cutent sur le m\xeame runner, tandis qu\'un `step` est une t\xe2che individuelle qui peut s\'ex\xe9cuter dans un `job`. Chaque `job` est ex\xe9cut\xe9 dans un environnement d\xe9di\xe9 d\xe9fini par [`runs-on`](#type-de-machine).\\n\\n```yml\\nname: CI\\n\\non: [push]\\n\\njobs:\\n  build:\\n    runs-on: ubuntu-latest\\n    steps:\\n      - uses: actions/checkout@v2\\n      - name: Run a one-line script\\n        run: echo Hello, world!\\n      - name: Run a multi-line script\\n        run: |\\n          echo Add other actions to build,\\n          echo test, and deploy your project.\\n```\\n\\nDocumentation Compl\xe8te  : [https://docs.github.com/en/actions/learn-github-actions/introduction-to-github-actions](https://docs.github.com/en/actions/learn-github-actions/introduction-to-github-actions)\\n\\n## D\xe9clenchement des actions\\n\\nLes d\xe9clencheurs de workflow sont des \xe9v\xe9nements qui entra\xeenent l\u2019ex\xe9cution d\u2019un workflow. La syntaxe d\xe9pend du niveau de pr\xe9cision\\n\\n- Pour tout ce qui concerne un \xe9v\xe9nement :\\n\\n```yaml\\n    on: [push] # pull_request, fork etc\\n```\\n\\n- Pour plus de finesse sur l\u2019\xe9v\xe9nement :\\n\\n```yaml\\n    on: # trigger\\n      label: # type d\'event (push, fork, pull_request)\\n        types:\\n          - created # trigger \xe0 chaque fois qu\'un label est cr\xe9\xe9\\n      push:\\n        branches:\\n          - main # tous les push sur la branche main\\n```\\n\\n- D\xe9clenchement manuel de l\u2019op\xe9ration (avec prise d\u2019argument)\\n\\n```yaml\\n    on:\\n      workflow_dispatch:\\n        inputs:\\n          test_mode:\\n            description: \'True or False\'\\n            required: true\\n```\\n\\nLa liste compl\xe8te des d\xe9clencheurs est disponible dans la [Documentation Github](https://docs.github.com/fr/actions/using-workflows/events-that-trigger-workflows)\\n\\nUne ex\xe9cution de workflow est compos\xe9e d\u2019un ou de plusieurs `jobs`, qui s\u2019ex\xe9cutent en parall\xe8le par d\xe9faut. Chaque job est constitu\xe9 d\u2019un `name` et d\u2019au moins un `step` pour \xeatre ex\xe9cutable et peut \xeatre configur\xe9.\\nLa documentation pr\xe9cise des job est disponible dans la [Documentation Github](https://docs.github.com/fr/actions/using-workflows/workflow-syntax-for-github-actions#jobs)\\n\\n## Marketplace\\n\\nChaque `job` permet d\u2019ex\xe9cuter un script. Le script le plus basique est un simple `run` avec des commandes `bash` derri\xe8re. Cependant, il est possible de r\xe9utiliser des actions d\xe9finies dans le marketplace. Par exemple le `steps` ci-dessous permet d\u2019ex\xe9cuter l\u2019action [https://github.com/ros-tooling/action-ros-ci](https://github.com/ros-tooling/action-ros-ci). Le mot cl\xe9 `with` permet de passer des param\xe8tres \xe0 l\u2019action.\\n\\n:::danger\\nLe marketplace permet de r\xe9utiliser des actions d\xe9j\xe0 d\xe9finies par la communaut\xe9. Il est important de v\xe9rifier la source de l\u2019action avant de l\u2019utiliser.\\n:::\\n\\n```yaml\\nsteps:\\n    - name: build and test ROS 2\\n    uses: ros-tooling/action-ros-ci@v0.2\\n    with:\\n        package-name: github-action-test\\n        target-ros2-distro: ${{ matrix.ros_distribution }}\\n        import-token: ${{ secrets.GITHUB_TOKEN }} # token autogenerated par github\\n```\\n\\n## R\xe9utiliser les Workflows et Actions\\n\\nIl est possible de r\xe9utiliser des `workflows` et des `actions` dans un workflow. Pour cela, il est possible de cr\xe9er des `workflows` et des `actions` dans des fichiers s\xe9par\xe9s et de les appeler dans le workflow principal.\\n\\n```yaml\\njobs:\\n    workflow: # r\xe9utilisation du workflow\\n      uses: path/to/your-workflow.yml@v1\\n    action: # r\xe9utilisation d\'une action\\n      runs-on: ubuntu-latest\\n      container: ubuntu:latest\\n      steps:\\n        - uses: path/to/your-action@v1\\n```\\n\\n[Documentation des wokflows r\xe9utilisables](https://docs.github.com/en/actions/learn-github-actions/reusing-workflows)\\n\\n[Documentation des actions r\xe9utilisables](https://docs.github.com/en/actions/creating-actions/creating-a-composite-action)\\n\\n:::info\\n\\nLorsqu\'un workflow est r\xe9utilis\xe9 il d\xe9fini son propre environnement (runner, container, etc). De plus il n\'est pas utilisable dans une `step`.\\n\\n\xc0 l\'inverse, une action est utilisable dans une `step` et fonctionne dans l\'environnement du `job` qui l\'appelle.\\n:::\\n\\n## Type de machine\\n\\nUtilisez `jobs.<job_id>.runs-on` pour d\xe9finir le type de machine sur laquelle le travail doit \xeatre ex\xe9cut\xe9. La configuration prend en argument un `tag` d\xe9fini pour les runners\\n\\n```yaml\\njobs:\\n    name-job:\\n    runs-on: ubuntu-latest # runner distant sur les serveur de Github\\n    runs-on: self-hosted # runner local\\n    steps:\\n        - run: echo \\"Hello World !\\"\\n```\\n\\nLes `runners` distants fourni par Github consomment du temps pour l\u2019organisation dans les limites de 2 000 minutes gratuites par mois. Il est pr\xe9f\xe9rable d\u2019utiliser des `runners self hosted` (voir [https://docs.github.com/fr/actions/hosting-your-own-runners/managing-self-hosted-runners/about-self-hosted-runners](https://docs.github.com/fr/actions/hosting-your-own-runners/managing-self-hosted-runners/about-self-hosted-runners))\\n\\nLe choix du `runner` se fait via les tags. Toutes les machines auto-h\xe9berg\xe9es partagent le tag `self-hosted` , le tag de leur syst\xe8me d\u2019exploitation (`Linux`, `Windows`), leur architecture (`x64`) et des tags personnalis\xe9s par machine.\\n\\n## Container\\n\\nL\u2019utilisation d\u2019un `container` permet de cr\xe9er un nouveau conteneur permettant d\u2019ex\xe9cuter les \xe9tapes d\u2019un travail dans un conteneur sp\xe9cifif\xe9. Si vous ne d\xe9finissez pas de `container`, toutes les \xe9tapes s\u2019ex\xe9cutent directement sur l\u2019h\xf4te sp\xe9cifi\xe9 par `runs-on` dans le cas d\u2019une machine auto-h\xe9berg\xe9es, il n\u2019y a donc acc\xe8s qu\u2019aux packages install\xe9s sur la machine. Un `container` est rattach\xe9 \xe0 un `job`.\\n\\n```yaml\\njobs:\\n    name-job:\\n    runs-on: self-hosted\\n    container:\\n    image: ubuntu:jammy # run job with ubuntu:jammy docker\\n        steps:\\n            - run: echo \\"Hello World !\\"\\n```\\n\\n## Strategy\\n\\nL\u2019utilisation de `strategy` permet cr\xe9er automatiquement plusieurs ex\xe9cutions de travaux bas\xe9es sur des combinaisons de variables. Une strat\xe9gie de matrice est utile pour tester du code dans diff\xe9rentes versions d\'un langage ou sur diff\xe9rents syst\xe8mes d\'exploitation.\\nPar exemple\\n\\n```yaml\\njobs:\\n    example_matrix:\\n    strategy:\\n        matrix:\\n        version: [10, 12, 14]\\n        os: [ubuntu-latest, windows-latest]\\n        steps:\\n            - run : echo \\"${{ matrix.version }} ${{ matrix.os }}\\"\\n```\\n\\nUn travail s\u2019ex\xe9cute pour chaque combinaison possible des variables. Dans cet exemple, le workflow ex\xe9cute six travaux, un pour chaque combinaison des variables `os` et `version`.\\n\\n## Art\xe9fact\\n\\nLes artefacts permettent de conserver des donn\xe9es une fois un travail termin\xe9 et de les partager avec une autre action. Un artefact est un fichier ou une collection de fichiers g\xe9n\xe9r\xe9s pendant l\u2019ex\xe9cution d\u2019un workflow. Cet exemple permet de stocker un fichier comme artefact.\\n\\n```yaml\\n- name: Archive code coverage results\\n    uses: actions/upload-artifact@v3\\n    with:\\n        name: code-coverage-report\\n        path: output/test/code-coverage.html\\n```\\n\\nPour r\xe9cup\xe9rer un artefact\\n\\n```yaml\\n- name: Download math result for job 2\\n    uses: actions/download-artifact@v3\\n    with:\\n        name: homework\\n```\\n\\n## Vrac\\n\\n- `needs` le job actuel ne commencera que quand le job mentionn\xe9 sera termin\xe9\\n- `if` condition de lancement du job\\n- `permission` permet d\u2019augmenter les droits du `GITHUB_TOKEN` (voir [https://docs.github.com/fr/actions/security-guides/automatic-token-authentication#permissions-for-the-github_token](https://docs.github.com/fr/actions/security-guides/automatic-token-authentication#permissions-for-the-github_token))\\n- `environnement` permet de d\xe9finir des variables d\u2019environnement"},{"id":"/2024/02/02/04-ci-cd/github-actions","metadata":{"permalink":"/blog/2024/02/02/04-ci-cd/github-actions","source":"@site/blog/04-ci-cd/2024-02-02-github-actions.md","title":"Introduction \xe0 GitHub Actions","description":"D\xe9couvrez comment GitHub Actions peut automatiser vos workflows de d\xe9veloppement et de d\xe9ploiement.","date":"2024-02-02T00:00:00.000Z","tags":[{"inline":true,"label":"CI/CD","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":3.44,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Introduction \xe0 GitHub Actions","description":"D\xe9couvrez comment GitHub Actions peut automatiser vos workflows de d\xe9veloppement et de d\xe9ploiement.","tags":["CI/CD","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Workflows","permalink":"/blog/2024/02/03/04-ci-cd/workflow"},"nextItem":{"title":"DevOps Roadmap","permalink":"/blog/2024/01/01/devops-roadmap"}},"content":"Dans le monde du d\xe9veloppement logiciel, l\'automatisation est devenue une n\xe9cessit\xe9 pour am\xe9liorer l\'efficacit\xe9 et r\xe9duire les erreurs humaines. GitHub Actions est une plateforme puissante qui permet d\'automatiser les workflows de d\xe9veloppement et de d\xe9ploiement. Dans cet article, nous allons explorer les concepts de base de GitHub Actions, ses avantages, et fournir des exemples concrets pour vous aider \xe0 d\xe9marrer.\\n\\n\x3c!--truncate--\x3e\\n\\n### Qu\'est-ce que GitHub Actions ?\\n\\nGitHub Actions est une plateforme d\'automatisation des workflows de d\xe9veloppement et de d\xe9ploiement. Elle permet aux d\xe9veloppeurs d\'automatiser des t\xe2ches r\xe9p\xe9titives, telles que les tests, les builds et les d\xe9ploiements, en utilisant des fichiers de configuration YAML.\\n\\n### Pourquoi utiliser GitHub Actions ?\\n\\nGitHub Actions offre plusieurs avantages pour les d\xe9veloppeurs et les \xe9quipes DevOps :\\n\\n1. **Automatisation des workflows** : GitHub Actions permet d\'automatiser les t\xe2ches r\xe9p\xe9titives, ce qui r\xe9duit les erreurs humaines et am\xe9liore l\'efficacit\xe9.\\n2. **Int\xe9gration continue (CI)** : Les workflows peuvent \xeatre configur\xe9s pour s\'ex\xe9cuter automatiquement \xe0 chaque commit, garantissant que le code est toujours test\xe9 et pr\xeat \xe0 \xeatre d\xe9ploy\xe9.\\n3. **D\xe9ploiement continu (CD)** : GitHub Actions facilite le d\xe9ploiement automatique des applications sur diff\xe9rents environnements, tels que les serveurs de production, les environnements de test et les conteneurs Docker.\\n4. **Flexibilit\xe9** : Les workflows peuvent \xeatre personnalis\xe9s pour r\xe9pondre aux besoins sp\xe9cifiques de chaque projet, en utilisant des actions pr\xe9d\xe9finies ou en cr\xe9ant des actions personnalis\xe9es.\\n5. **Communaut\xe9 et \xe9cosyst\xe8me** : GitHub Actions b\xe9n\xe9ficie d\'une large communaut\xe9 de d\xe9veloppeurs et d\'un \xe9cosyst\xe8me riche en actions pr\xe9d\xe9finies, ce qui facilite l\'int\xe9gration avec d\'autres outils et services.\\n\\n### Marketplace et r\xe9utilisation\\n\\nLe GitHub Marketplace est une ressource pr\xe9cieuse pour trouver des actions pr\xe9d\xe9finies cr\xe9\xe9es par la communaut\xe9. Vous pouvez r\xe9utiliser ces actions dans vos workflows pour automatiser des t\xe2ches courantes sans avoir \xe0 les coder vous-m\xeame. Cela permet de gagner du temps et de b\xe9n\xe9ficier des meilleures pratiques de la communaut\xe9.\\n\\n## Concepts de base de GitHub Actions\\n\\n### \xc9v\xe9nements\\n\\nLes \xe9v\xe9nements sont des d\xe9clencheurs qui activent l\'ex\xe9cution des workflows. Les \xe9v\xe9nements courants incluent les commits, les pull requests, les issues et les releases. Par exemple, un workflow peut \xeatre configur\xe9 pour s\'ex\xe9cuter \xe0 chaque commit sur la branche principale.\\n\\n### Actions\\n\\nLes actions sont des t\xe2ches individuelles qui composent un workflow. Elles peuvent \xeatre pr\xe9d\xe9finies ou personnalis\xe9es. Les actions pr\xe9d\xe9finies sont disponibles dans le GitHub Marketplace et couvrent une large gamme de t\xe2ches, telles que l\'installation de d\xe9pendances, l\'ex\xe9cution de tests et le d\xe9ploiement d\'applications.\\n\\n### Workflows\\n\\nLes workflows sont des fichiers de configuration YAML qui d\xe9finissent les actions \xe0 ex\xe9cuter en r\xe9ponse \xe0 des \xe9v\xe9nements sp\xe9cifiques. Un workflow peut contenir plusieurs jobs, chacun compos\xe9 de plusieurs \xe9tapes. Les workflows sont stock\xe9s dans le r\xe9pertoire `.github/workflows` du d\xe9p\xf4t.\\n\\n## Exemple de workflow GitHub Actions\\n\\nVoici un exemple de workflow GitHub Actions pour une application Node.js. Ce workflow s\'ex\xe9cute \xe0 chaque commit sur la branche principale, installe les d\xe9pendances, ex\xe9cute les tests et d\xe9ploie l\'application sur un serveur de production.\\n\\n```yaml\\nname: CI/CD Pipeline\\n\\non:\\n  push:\\n    branches:\\n      - main\\n\\njobs:\\n  build:\\n    runs-on: ubuntu-latest\\n\\n    steps:\\n      - name: Checkout code\\n        uses: actions/checkout@v2\\n\\n      - name: Set up Node.js\\n        uses: actions/setup-node@v2\\n        with:\\n          node-version: \'14\'\\n\\n      - name: Install dependencies\\n        run: npm install\\n\\n      - name: Run tests\\n        run: npm test\\n\\n      - name: Deploy to production\\n        run: |\\n          ssh user@server \'cd /path/to/app && git pull && npm install && pm2 restart app\'\\n```\\n\\n## Les runners GitHub Actions\\n\\nLes runners sont des machines virtuelles ou physiques qui ex\xe9cutent les jobs d\xe9finis dans les workflows. GitHub propose des runners h\xe9berg\xe9s, mais vous pouvez \xe9galement configurer vos propres runners auto-h\xe9berg\xe9s pour r\xe9pondre \xe0 des besoins sp\xe9cifiques. Les runners auto-h\xe9berg\xe9s offrent plus de contr\xf4le sur l\'environnement d\'ex\xe9cution et peuvent \xeatre utilis\xe9s pour des t\xe2ches n\xe9cessitant des ressources sp\xe9cifiques.\\n\\n## Conclusion\\n\\nGitHub Actions est un outil puissant pour automatiser les workflows de d\xe9veloppement et de d\xe9ploiement. En utilisant des fichiers de configuration YAML, les d\xe9veloppeurs peuvent cr\xe9er des workflows personnalis\xe9s pour r\xe9pondre aux besoins sp\xe9cifiques de leurs projets. Avec GitHub Actions, les \xe9quipes DevOps peuvent am\xe9liorer l\'efficacit\xe9, r\xe9duire les erreurs humaines et acc\xe9l\xe9rer le cycle de d\xe9veloppement.\\n\\nPour en savoir plus sur GitHub Actions, consultez la [documentation officielle](https://docs.github.com/en/actions)."},{"id":"/2024/01/01/devops-roadmap","metadata":{"permalink":"/blog/2024/01/01/devops-roadmap","source":"@site/blog/2024-01-01-devops-roadmap.md","title":"DevOps Roadmap","description":"Pr\xe9sentation de ma roadmap DevOps personnelle 2024","date":"2024-01-01T00:00:00.000Z","tags":[{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"},{"inline":true,"label":"Roadmap","permalink":"/blog/tags/roadmap"}],"readingTime":6.02,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"DevOps Roadmap","description":"Pr\xe9sentation de ma roadmap DevOps personnelle 2024","tags":["Devops","Roadmap"]},"unlisted":false,"prevItem":{"title":"Introduction \xe0 GitHub Actions","permalink":"/blog/2024/02/02/04-ci-cd/github-actions"}},"content":"Ing\xe9nieur en informatique au [CATIE](http://catie.fr/) sp\xe9cialis\xe9 en Robotique je suis amen\xe9 \xe0 travailler sur des projets de d\xe9veloppement logiciel et d\'int\xe9gration sur diff\xe9rentes plateformes. Intrigu\xe9 et passion\xe9 par l\'int\xe9gration et l\'automatisation des t\xe2ches, j\'ai d\xe9cid\xe9 d\'approfondir mes connaissances en DevOps.\\n\\n\x3c!--truncate--\x3e\\n\\nVoici un r\xe9sum\xe9 de ma roadmap DevOps personnelle pour 2024. Cette roadmap est bas\xe9e sur mes exp\xe9riences et mes objectifs personnels. Elle est sujette \xe0 des changements et des mises \xe0 jour r\xe9guli\xe8res. N\'h\xe9sitez pas \xe0 me contacter si vous avez des suggestions ou des commentaires.\\n\\n# DevOps Roadmap\\n\\nimport IconTitle from \'@site/src/components/IconTitle\';\\n\\n![DevOps](/img/devops.png)\\n\\n## <IconTitle logo=\\"mdi:code-braces\\" name=\\"01 Concepts du d\xe9veloppement logiciel\\"/>\\n\\nEn tant qu\'ing\xe9nieur DevOps, vous ne programmerez pas l\'application, mais comme vous travaillez en \xe9troite collaboration avec l\'\xe9quipe de d\xe9veloppement pour am\xe9liorer et automatiser les t\xe2ches pour eux, vous devez comprendre les concepts de :\\n\\n- Collaboration des d\xe9veloppeurs (Agile, Jira)\\n- Utilisation de Git\\n- Configuration des applications (Outils de build)\\n- Compr\xe9hension du cycle de vie du d\xe9veloppement logiciel\\n- Tests automatis\xe9s\\n\\n## <IconTitle logo=\\"skill-icons:linux-light\\" name=\\"02 OS & Linux\\"/>\\n\\nEn tant qu\'ing\xe9nieur DevOps, vous \xeates responsable de la pr\xe9paration et de la maintenance de l\'infrastructure (serveurs) sur laquelle l\'application est d\xe9ploy\xe9e. Vous devez donc conna\xeetre les bases de l\'administration d\'un serveur et de l\'installation de diff\xe9rents outils sur celui-ci. Voici les concepts de base des syst\xe8mes d\'exploitation que vous devez comprendre :\\n\\n- Commandes Shell\\n- Syst\xe8me de fichiers Linux & Permissions\\n- Gestion des cl\xe9s SSH\\n- Notions de base de la mise en r\xe9seau et de la s\xe9curit\xe9\\n- Configuration des pare-feu pour s\xe9curiser l\'acc\xe8s\\n- Comprendre comment fonctionnent les adresses IP, les ports et le DNS\\n- \xc9quilibreurs de charge\\n- Proxies\\n- HTTP/HTTPS\\n- Virtualisation\\n\\n## <IconTitle logo=\\"skill-icons:docker\\" name=\\"03 Conten\xe9risation - Docker\\"/>\\n\\nLes conteneurs sont devenus le nouveau standard de l\'emballage logiciel, vous ex\xe9cuterez probablement votre application en tant que conteneur. Cela signifie que vous devez g\xe9n\xe9ralement comprendre :\\n\\n- Concepts de virtualisation\\n- Concepts de conteneurisation\\n- Comment g\xe9rer les applications conteneuris\xe9es sur un serveur.\\n\\nDocker est de loin la technologie de conteneur la plus populaire ! Voici quelques points que vous devriez conna\xeetre :\\n\\n- Ex\xe9cuter des conteneurs\\n- Inspecter les conteneurs actifs\\n- R\xe9seau Docker\\n- Persister les donn\xe9es avec les volumes Docker\\n- Dockeriser les applications en utilisant Dockerfiles\\n- Ex\xe9cuter plusieurs conteneurs en utilisant Docker-Compose\\n- Travailler avec le d\xe9p\xf4t Docker\\n\\nLes conteneurs et les machines virtuelles ont des avantages similaires en termes d\'isolation et d\'allocation des ressources, mais fonctionnent diff\xe9remment. Les VMs virtualisent tout le syst\xe8me d\'exploitation. Les conteneurs virtualisent uniquement le niveau d\'application du syst\xe8me d\'exploitation. Par cons\xe9quent, les conteneurs sont plus l\xe9gers et plus rapides.\\n\\n## <IconTitle logo=\\"skill-icons:githubactions-light\\" name=\\"04 CI/CD Pipeline\\"/>\\n\\nCI/CD Pipelines\\n\\nCI/CD est en quelque sorte le c\u0153ur de DevOps. En DevOps, toutes les modifications de code, comme les nouvelles fonctionnalit\xe9s ou les corrections de bugs, doivent \xeatre int\xe9gr\xe9es dans l\'application existante et d\xe9ploy\xe9es pour l\'utilisateur final de mani\xe8re continue et automatis\xe9e. D\'o\xf9 le terme :\\nInt\xe9gration Continue et D\xe9ploiement Continu (CI/CD)\\n\\nComp\xe9tences que vous devez apprendre ici :\\n\\n- Configuration du serveur CI/CD\\n- Int\xe9gration du d\xe9p\xf4t de code pour d\xe9clencher le pipeline automatiquement\\n- Outils de construction et de gestion de packages pour ex\xe9cuter les tests et emballer l\'application\\n- Configuration des d\xe9p\xf4ts d\'artefacts (comme Nexus) et int\xe9gration avec le pipeline\\n\\n## <IconTitle logo=\\"skill-icons:aws-light\\" name=\\"05 Apprendre un fournisseur de Cloud\\"/>\\n\\nDe nos jours, de nombreuses entreprises utilisent une infrastructure virtuelle sur le cloud, au lieu de g\xe9rer leur propre infrastructure. Ce sont des plateformes Infrastructure as a Service (IaaS), qui offrent une gamme de services suppl\xe9mentaires, comme la sauvegarde, la s\xe9curit\xe9, l\'\xe9quilibrage de charge, etc.\\n\\nAWS est la plateforme IaaS la plus puissante et la plus largement utilis\xe9e, mais aussi une des plus difficiles. D\'autres populaires : Microsoft Azure, Google Cloud.\\n\\nCes services sont sp\xe9cifiques \xe0 la plateforme. Vous devez donc apprendre les services de cette plateforme sp\xe9cifique et apprendre \xe0 g\xe9rer toute l\'infrastructure de d\xe9ploiement sur celle-ci. Par exemple, pour AWS, vous devez conna\xeetre les bases de :\\n\\n- Service IAM - gestion des utilisateurs et des permissions\\n- Service VPC - votre r\xe9seau priv\xe9\\n- Service EC2 - serveurs virtuels\\n\\n## <IconTitle logo=\\"skill-icons:kubernetes\\" name=\\"06 Orchestration de conteneurs - Kubernetes & Docker Swarm\\"/>\\n\\nComme les conteneurs sont populaires et faciles \xe0 utiliser, de nombreuses entreprises ex\xe9cutent des centaines ou des milliers de conteneurs sur plusieurs serveurs. Cela signifie que ces conteneurs doivent \xeatre g\xe9r\xe9s d\'une mani\xe8re ou d\'une autre.\\n\\n\xc0 cette fin, il existe des outils d\'orchestration de conteneurs. Kubernetes (\xe9galement connu sous le nom de K8s) est l\'outil d\'orchestration de conteneurs le plus populaire.\\n\\nVous devez donc apprendre :\\n\\n- Apprendre les composants de base comme, Deployment, Service, ConfigMap, Secret, StatefulSet, Ingress\\n- CLI Kubernetes (Kubectl)\\n- Persistance des donn\xe9es avec les volumes K8s\\n- Namespaces\\n- Docker Swarm\\n\\n## <IconTitle logo=\\"skill-icons:prometheus\\" name=\\"07 Monitoring & Observabilit\xe9\\"/>\\n\\nUne fois que le logiciel est en production, il est important de le surveiller pour suivre les performances, d\xe9couvrir les probl\xe8mes dans votre infrastructure et l\'application. Donc, l\'une de vos responsabilit\xe9s en tant qu\'ing\xe9nieur DevOps est de :\\n\\n- Prometheus : Un outil de surveillance et d\'alerte populaire\\n- Grafana : Outil d\'analyse et de visualisation interactive\\n- ELK Stack : Une pile de gestion de logs populaire\\n\\n## <IconTitle logo=\\"skill-icons:terraform-light\\" name=\\"08 Infrastructure as Code\\"/>\\n\\nCr\xe9er et maintenir manuellement une infrastructure est chronophage et sujet \xe0 erreurs. Surtout lorsque vous devez r\xe9pliquer l\'infrastructure, par exemple pour un environnement de d\xe9veloppement, de test et de production.\\n\\nEn DevOps, nous voulons automatiser autant que possible et c\'est l\xe0 qu\'intervient l\'Infrastructure as Code.\\n\\n- Terraform est l\'outil de provisionnement d\'infrastructure le plus populaire\\n- Ansible est l\'outil de gestion de configuration le plus populaire\\n\\n## <IconTitle logo=\\"skill-icons:python-light\\" name=\\"09 Langages de script - Python\\"/>\\n\\nEn travaillant \xe9troitement avec les d\xe9veloppeurs et les administrateurs syst\xe8me pour automatiser les t\xe2ches de d\xe9veloppement et d\'op\xe9rations, vous aurez besoin d\'\xe9crire des scripts et de petites applications. Pour cela, vous aurez besoin de comp\xe9tences en scripting ou en programmation de base. Python est un langage largement utilis\xe9, facile \xe0 apprendre et utilis\xe9 pour de nombreux cas d\'utilisation diff\xe9rents, en particulier en DevOps.\\n\\n- Apprendre les bases de Python\\n- \xc9crire des scripts utilitaires, par exemple pour vider le cache, d\xe9marrer les builds et les d\xe9ploiements\\n- Comprendre les concepts de programmation de base\\n\\n<IconTitle logo=\\"skill-icons:git\\" name=\\"10 Contr\xf4le de version - Git\\"/>\\n\\nToute la logique d\'automatisation est \xe9crite sous forme de code. Tout comme le code d\'application, le code d\'automatisation doit \xe9galement \xeatre g\xe9r\xe9 et h\xe9berg\xe9 sur un outil de contr\xf4le de version, comme Git. Git est l\'outil de contr\xf4le de version le plus populaire et le plus largement utilis\xe9. Vos fichiers sont stock\xe9s de mani\xe8re centralis\xe9e dans un d\xe9p\xf4t Git distant sur le web. Les d\xe9p\xf4ts Git les plus populaires sont GitHub et GitLab. Git est un outil CLI, que vous installez localement. Il permet de suivre les modifications du code source et facilite la collaboration sur le code.\\n\\n- Apprendre \xe0 utiliser un d\xe9p\xf4t Git\\n- Ma\xeetriser les commandes de base de Git, comme git clone, git branch, git pull/push, git merge, etc.\\n- Apprendre \xe0 collaborer sur un projet, comme cr\xe9er des pull requests, faire des revues de code, g\xe9rer les branches"}]}}')}}]);