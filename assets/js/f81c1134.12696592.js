"use strict";(self.webpackChunksedelpeuch_net=self.webpackChunksedelpeuch_net||[]).push([[8130],{77735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/2025/06/06/06-orchestration/renouveller-certificats","metadata":{"permalink":"/blog/2025/06/06/06-orchestration/renouveller-certificats","source":"@site/blog/06-orchestration/2025-06-06-renouveller-certificats.md","title":"Renouvellement des certificats Kubernetes sur kubeadm","description":"Guide pratique pour renouveler les certificats expirants dans un cluster Kubernetes d\xe9ploy\xe9 avec kubeadm.","date":"2025-06-06T00:00:00.000Z","tags":[{"inline":true,"label":"Kubernetes","permalink":"/blog/tags/kubernetes"},{"inline":true,"label":"Orchestration","permalink":"/blog/tags/orchestration"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":4.71,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Renouvellement des certificats Kubernetes sur kubeadm","description":"Guide pratique pour renouveler les certificats expirants dans un cluster Kubernetes d\xe9ploy\xe9 avec kubeadm.","tags":["Kubernetes","Orchestration","Devops"]},"unlisted":false,"nextItem":{"title":"Pydantic: Validation de donn\xe9es robuste pour Python","permalink":"/blog/2025/03/30/09-scripting/pydantic-validation-donnees"}},"content":"Les certificats jouent un r\xf4le crucial dans la s\xe9curit\xe9 de Kubernetes. Ils assurent l\'authentification et le chiffrement des communications entre les diff\xe9rents composants du cluster. Cependant, ces certificats ont une dur\xe9e de vie limit\xe9e et doivent \xeatre renouvel\xe9s avant leur expiration pour maintenir le bon fonctionnement du cluster. \ud83d\udd10\\n\\n\x3c!--truncate--\x3e\\n\\n## La probl\xe9matique des certificats expirants \ud83d\udcc5\\n\\nPar d\xe9faut, les certificats g\xe9n\xe9r\xe9s par kubeadm ont une dur\xe9e de validit\xe9 d\'un an. Lorsqu\'ils expirent, les composants du cluster ne peuvent plus communiquer entre eux de mani\xe8re s\xe9curis\xe9e, ce qui peut entra\xeener une panne compl\xe8te du cluster.\\n\\nLes sympt\xf4mes typiques d\'un certificat expir\xe9 incluent :\\n\\n- Impossibilit\xe9 d\'utiliser `kubectl`\\n- Les nouveaux pods ne sont plus programm\xe9s\\n- Messages d\'erreur du type `x509: certificate has expired or is not yet valid`\\n\\n## V\xe9rification des dates d\'expiration \u23f1\ufe0f\\n\\nAvant de proc\xe9der au renouvellement, il est important de v\xe9rifier la date d\'expiration des certificats actuels. Pour cela, vous pouvez utiliser la commande suivante :\\n\\n```bash\\nkubeadm certs check-expiration\\n```\\n\\nCette commande affiche une liste de tous les certificats avec leurs dates d\'expiration respectives :\\n\\n```text\\nCERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED\\nadmin.conf                 Jun 05, 2026 12:51 UTC   364d            ca                      no\\napiserver                  Jun 05, 2026 12:51 UTC   364d            ca                      no\\napiserver-kubelet-client   Jun 05, 2026 12:51 UTC   364d            ca                      no\\ncontroller-manager.conf    Jun 05, 2026 12:51 UTC   364d            ca                      no\\nkubelet.conf              Jun 05, 2026 12:51 UTC   364d            ca                      no\\nscheduler.conf             Jun 05, 2026 12:51 UTC   364d            ca                      no\\n...\\n```\\n\\n## Processus de renouvellement des certificats \ud83d\udd04\\n\\n### 1. Renouvellement de tous les certificats\\n\\nLa m\xe9thode la plus simple consiste \xe0 renouveler tous les certificats \xe0 la fois :\\n\\n```bash\\nsudo kubeadm certs renew all\\n```\\n\\nCette commande renouvelle tous les certificats g\xe9r\xe9s par kubeadm et les stocke dans le r\xe9pertoire `/etc/kubernetes/pki`.\\n\\n### 2. Renouvellement des certificats sp\xe9cifiques\\n\\nSi vous pr\xe9f\xe9rez renouveler les certificats un par un, vous pouvez sp\xe9cifier le certificat \xe0 renouveler :\\n\\n```bash\\nsudo kubeadm certs renew apiserver\\nsudo kubeadm certs renew apiserver-kubelet-client\\nsudo kubeadm certs renew front-proxy-client\\n# etc.\\n```\\n\\n### 3. Mise \xe0 jour des fichiers kubeconfig\\n\\nApr\xe8s avoir renouvel\xe9 les certificats, il est n\xe9cessaire de mettre \xe0 jour les fichiers kubeconfig :\\n\\n```bash\\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\\n```\\n\\n## Red\xe9marrage des composants \ud83d\udd04\\n\\nPour que les nouveaux certificats soient pris en compte, il faut red\xe9marrer les composants du plan de contr\xf4le :\\n\\n```bash\\nsudo systemctl restart kubelet\\n```\\n\\nSur un cluster multi-n\u0153uds, vous devez \xe9galement red\xe9marrer le kubelet sur chaque n\u0153ud worker :\\n\\n```bash\\n# Sur chaque n\u0153ud worker\\nsudo systemctl restart kubelet\\n```\\n\\n### Forcer le red\xe9marrage en cas de probl\xe8me \u26a0\ufe0f\\n\\nDans certains cas, un simple red\xe9marrage du kubelet peut ne pas suffire pour que les nouveaux certificats soient pris en compte. Si vous rencontrez toujours des probl\xe8mes apr\xe8s le red\xe9marrage normal, deux m\xe9thodes plus radicales peuvent \xeatre utilis\xe9es :\\n\\n**M\xe9thode 1 : Manipulation des manifests statiques**\\n\\n```bash\\n# Sauvegarde et renommage temporaire des manifests\\ncd /etc/kubernetes/manifests\\nsudo mkdir -p /root/manifests_backup\\nsudo cp *.yaml /root/manifests_backup/\\nsudo mv *.yaml /tmp/\\n\\n# Attendre que le cluster s\'arr\xeate (les pods du plan de contr\xf4le dispara\xeetront)\\n# Puis restaurer les manifests pour red\xe9marrer les composants\\nsudo mv /tmp/*.yaml .\\n```\\n\\nCette m\xe9thode force kubelet \xe0 supprimer puis recr\xe9er tous les pods du plan de contr\xf4le, garantissant ainsi l\'utilisation des nouveaux certificats.\\n\\n**M\xe9thode 2 : Suppression manuelle des pods**\\n\\nSi vous avez encore acc\xe8s \xe0 l\'API Kubernetes, vous pouvez supprimer manuellement les pods du plan de contr\xf4le :\\n\\n```bash\\n# Attention : commande \xe0 utiliser avec pr\xe9caution\\nkubectl -n kube-system delete pod -l component=kube-apiserver\\nkubectl -n kube-system delete pod -l component=kube-controller-manager\\nkubectl -n kube-system delete pod -l component=kube-scheduler\\nkubectl -n kube-system delete pod -l k8s-app=kube-proxy\\n```\\n\\n> \u26a0\ufe0f **Attention** : Ces m\xe9thodes provoquent une interruption temporaire du service. Planifiez-les pendant une fen\xeatre de maintenance.\\n\\n## Automatisation du renouvellement \ud83e\udd16\\n\\nPour \xe9viter de devoir g\xe9rer manuellement le renouvellement des certificats, vous pouvez mettre en place une t\xe2che cron qui v\xe9rifie et renouvelle automatiquement les certificats :\\n\\n```bash\\n# Cr\xe9er un script de renouvellement des certificats\\ncat > /usr/local/bin/renew-k8s-certs.sh << \'EOF\'\\n#!/bin/bash\\n# V\xe9rifier si des certificats expirent dans moins de 30 jours\\nEXPIRING_CERTS=$(kubeadm certs check-expiration | grep -B 1 \\"< 30d\\" | grep -v \\"RESIDUAL\\" | awk \'{print $1}\')\\n\\nif [ ! -z \\"$EXPIRING_CERTS\\" ]; then\\n    echo \\"Renouvellement des certificats qui expirent bient\xf4t...\\"\\n    sudo kubeadm certs renew all\\n    sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\\n    sudo chown $(id -u):$(id -g) $HOME/.kube/config\\n    sudo systemctl restart kubelet\\n    echo \\"Certificats renouvel\xe9s avec succ\xe8s !\\"\\nelse\\n    echo \\"Aucun certificat n\'expire dans moins de 30 jours.\\"\\nfi\\nEOF\\n\\nchmod +x /usr/local/bin/renew-k8s-certs.sh\\n\\n# Ajouter une t\xe2che cron pour ex\xe9cuter le script une fois par mois\\n(crontab -l 2>/dev/null; echo \\"0 0 1 * * /usr/local/bin/renew-k8s-certs.sh >> /var/log/renew-k8s-certs.log 2>&1\\") | crontab -\\n```\\n\\n## Bonnes pratiques \ud83d\udee1\ufe0f\\n\\n1. **Planification pr\xe9ventive** : Renouvelez vos certificats au moins un mois avant leur expiration pour \xe9viter toute interruption de service.\\n\\n2. **Sauvegarde** : Avant de proc\xe9der au renouvellement, effectuez une sauvegarde du r\xe9pertoire `/etc/kubernetes/pki`.\\n\\n3. **Documentation** : Documentez clairement les dates de renouvellement et mettez en place des alertes pour \xeatre notifi\xe9 avant l\'expiration.\\n\\n4. **Test** : Testez le processus de renouvellement dans un environnement de d\xe9veloppement avant de l\'appliquer en production.\\n\\n## Conclusion \ud83c\udfaf\\n\\nLe renouvellement des certificats est une t\xe2che de maintenance critique pour garantir la s\xe9curit\xe9 et la disponibilit\xe9 de votre cluster Kubernetes. En suivant ce guide, vous pouvez facilement renouveler vos certificats et \xe9viter les probl\xe8mes li\xe9s \xe0 leur expiration.\\n\\nN\'oubliez pas que la s\xe9curit\xe9 est un processus continu, et la gestion proactive des certificats fait partie int\xe9grante de la maintenance d\'un cluster Kubernetes robuste et s\xe9curis\xe9."},{"id":"/2025/03/30/09-scripting/pydantic-validation-donnees","metadata":{"permalink":"/blog/2025/03/30/09-scripting/pydantic-validation-donnees","source":"@site/blog/09-scripting/2025-03-30-pydantic-validation-donnees.md","title":"Pydantic: Validation de donn\xe9es robuste pour Python","description":"Comment utiliser Pydantic pour valider, s\xe9rialiser et documenter vos mod\xe8les de donn\xe9es en Python.","date":"2025-03-30T00:00:00.000Z","tags":[{"inline":true,"label":"Python","permalink":"/blog/tags/python"},{"inline":true,"label":"Data Validation","permalink":"/blog/tags/data-validation"},{"inline":true,"label":"API","permalink":"/blog/tags/api"},{"inline":true,"label":"FastAPI","permalink":"/blog/tags/fast-api"},{"inline":true,"label":"Scripting","permalink":"/blog/tags/scripting"}],"readingTime":6.68,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Pydantic: Validation de donn\xe9es robuste pour Python","description":"Comment utiliser Pydantic pour valider, s\xe9rialiser et documenter vos mod\xe8les de donn\xe9es en Python.","tags":["Python","Data Validation","API","FastAPI","Scripting"]},"unlisted":false,"prevItem":{"title":"Renouvellement des certificats Kubernetes sur kubeadm","permalink":"/blog/2025/06/06/06-orchestration/renouveller-certificats"},"nextItem":{"title":"Introduction \xe0 Traefik","permalink":"/blog/2025/03/15/02-network/traefik"}},"content":"Dans un monde o\xf9 les APIs et les microservices se multiplient, la validation des donn\xe9es est devenue une pr\xe9occupation majeure. Pydantic s\'impose comme la solution de r\xe9f\xe9rence en Python pour d\xe9finir et valider des structures de donn\xe9es. D\xe9couvrons ensemble cette biblioth\xe8que puissante qui r\xe9volutionne la fa\xe7on dont nous manipulons les donn\xe9es. \ud83d\udd0d\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que Pydantic? \ud83e\udd14\\n\\nPydantic est une biblioth\xe8que Python qui permet de valider des donn\xe9es et de g\xe9rer les param\xe8tres de configuration en utilisant les annotations de type Python. Elle offre plusieurs avantages :\\n\\n- **Validation forte bas\xe9e sur les types Python**\\n- **Conversion automatique des donn\xe9es d\'entr\xe9e**\\n- **G\xe9n\xe9ration de documentation JSON Schema**\\n- **S\xe9rialisation et d\xe9s\xe9rialisation faciles**\\n- **Performances optimis\xe9es** gr\xe2ce \xe0 l\'utilisation de code compil\xe9 en Rust\\n\\nPydantic est notamment le syst\xe8me de mod\xe8les utilis\xe9 par FastAPI, ce qui en fait un incontournable pour les d\xe9veloppeurs d\'APIs modernes.\\n\\n## Installation de Pydantic \ud83d\ude80\\n\\nL\'installation de Pydantic est simple avec pip :\\n\\n```bash\\npip install pydantic\\n\\n# Pour la version 2.x avec des performances optimis\xe9es\\npip install \\"pydantic>=2.0.0\\"\\n```\\n\\nSi vous utilisez Poetry (comme nous l\'avons vu dans [notre article pr\xe9c\xe9dent](/blog/2025/03/01/09-scripting/poetry-python-dependency)) :\\n\\n```bash\\npoetry add pydantic\\n```\\n\\n## Les bases de Pydantic \ud83d\udcda\\n\\n### D\xe9finition de mod\xe8les\\n\\nLa premi\xe8re \xe9tape avec Pydantic consiste \xe0 d\xe9finir un mod\xe8le en cr\xe9ant une classe qui h\xe9rite de `BaseModel` :\\n\\n```python\\nfrom pydantic import BaseModel\\nfrom typing import Optional, List\\nfrom datetime import date\\n\\nclass User(BaseModel):\\n    id: int\\n    name: str\\n    email: str\\n    birth_date: date\\n    is_active: bool = True\\n    tags: List[str] = []\\n    website: Optional[str] = None\\n```\\n\\n### Validation automatique\\n\\nUne fois le mod\xe8le d\xe9fini, Pydantic valide automatiquement les donn\xe9es lors de la cr\xe9ation d\'une instance :\\n\\n```python\\n# Validation r\xe9ussie\\nuser = User(\\n    id=1,\\n    name=\\"John Doe\\",\\n    email=\\"john@example.com\\",\\n    birth_date=\\"1990-01-01\\",  # Conversion automatique en objet date\\n    tags=[\\"admin\\", \\"user\\"]\\n)\\n\\n# Validation \xe9chou\xe9e\\ntry:\\n    User(\\n        id=\\"not_an_integer\\",  # Erreur: la valeur n\'est pas un entier\\n        name=123,             # Sera converti en string automatiquement\\n        email=\\"invalid_email\\" # Pas d\'erreur par d\xe9faut: ce n\'est pas une validation de format\\n    )\\nexcept ValueError as e:\\n    print(f\\"Erreur de validation: {e}\\")\\n```\\n\\n### S\xe9rialisation et d\xe9s\xe9rialisation\\n\\nPydantic simplifie la conversion des mod\xe8les en dictionnaires, JSON ou d\'autres formats :\\n\\n```python\\n# Conversion en dictionnaire\\nuser_dict = user.model_dump()\\n\\n# Conversion en JSON\\nuser_json = user.model_dump_json()\\n\\n# D\xe9s\xe9rialisation depuis un dictionnaire\\nuser_data = {\\n    \\"id\\": 2,\\n    \\"name\\": \\"Jane Smith\\",\\n    \\"email\\": \\"jane@example.com\\",\\n    \\"birth_date\\": \\"1992-03-15\\"\\n}\\nnew_user = User.model_validate(user_data)\\n\\n# D\xe9s\xe9rialisation depuis JSON\\nuser_from_json = User.model_validate_json(\'{\\"id\\": 3, \\"name\\": \\"Bob\\", \\"email\\": \\"bob@example.com\\", \\"birth_date\\": \\"1985-07-20\\"}\')\\n```\\n\\n## Fonctionnalit\xe9s avanc\xe9es \ud83d\udd27\\n\\n### Validateurs personnalis\xe9s\\n\\nPydantic permet de cr\xe9er des validateurs personnalis\xe9s pour des v\xe9rifications plus complexes :\\n\\n```python\\nfrom pydantic import BaseModel, field_validator, EmailStr\\n\\nclass AdvancedUser(BaseModel):\\n    id: int\\n    name: str\\n    email: EmailStr  # Type sp\xe9cial pour valider les emails\\n    password: str\\n    password_confirm: str\\n\\n    @field_validator(\'name\')\\n    @classmethod\\n    def name_must_contain_space(cls, v):\\n        if \' \' not in v:\\n            raise ValueError(\'Le nom doit contenir un espace (pr\xe9nom et nom)\')\\n        return v.title()  # Convertit le nom en format titre\\n\\n    @field_validator(\'password_confirm\')\\n    @classmethod\\n    def passwords_match(cls, v, info):\\n        if \'password\' in info.data and v != info.data[\'password\']:\\n            raise ValueError(\'Les mots de passe ne correspondent pas\')\\n        return v\\n```\\n\\n### Types complexes\\n\\nPydantic prend en charge une vari\xe9t\xe9 de types complexes :\\n\\n```python\\nfrom pydantic import BaseModel, HttpUrl, conlist, constr\\nfrom typing import Dict, Union\\n\\nclass Product(BaseModel):\\n    name: str\\n    price: float\\n    description: Optional[str] = None\\n\\nclass Order(BaseModel):\\n    order_id: str\\n    # Une liste avec au moins 1 \xe9l\xe9ment\\n    products: conlist(Product, min_length=1)\\n    # Une cha\xeene avec contrainte de longueur\\n    customer_id: constr(min_length=5, max_length=20)\\n    # Union de types possibles\\n    payment_method: Union[str, Dict[str, str]]\\n    # URL valide\\n    store_url: HttpUrl\\n```\\n\\n### Configuration des mod\xe8les\\n\\nPydantic offre de nombreuses options de configuration pour contr\xf4ler le comportement des mod\xe8les :\\n\\n```python\\nclass Settings(BaseModel):\\n    model_config = {\\n        # Permettre les champs suppl\xe9mentaires\\n        \\"extra\\": \\"forbid\\",\\n        # Valider \xe9galement les attributs lors de l\'assignation\\n        \\"validate_assignment\\": True,\\n        # Aliases pour les noms de champs JSON\\n        \\"populate_by_name\\": True,\\n        # Noms JSON en format camelCase\\n        \\"alias_generator\\": lambda s: \'\'.join(\\n            word.capitalize() if i else word\\n            for i, word in enumerate(s.split(\'_\'))\\n        ),\\n    }\\n\\n    database_url: str\\n    api_key: str\\n    debug_mode: bool = False\\n    max_connections: int = 100\\n```\\n\\n## Pydantic et FastAPI : le duo parfait \ud83e\udd1d\\n\\nPydantic est particuli\xe8rement puissant lorsqu\'il est utilis\xe9 avec FastAPI :\\n\\n```python\\nfrom fastapi import FastAPI, Path\\nfrom pydantic import BaseModel, Field\\nfrom typing import List\\n\\napp = FastAPI()\\n\\nclass Item(BaseModel):\\n    name: str = Field(..., example=\\"Smartphone\\")\\n    description: Optional[str] = Field(None, example=\\"Un t\xe9l\xe9phone dernier cri\\")\\n    price: float = Field(..., gt=0, example=899.99)\\n    tax: Optional[float] = Field(None, example=20.0)\\n\\n    model_config = {\\n        \\"json_schema_extra\\": {\\n            \\"examples\\": [\\n                {\\n                    \\"name\\": \\"Smartphone\\",\\n                    \\"description\\": \\"Un t\xe9l\xe9phone dernier cri\\",\\n                    \\"price\\": 899.99,\\n                    \\"tax\\": 20.0,\\n                }\\n            ]\\n        }\\n    }\\n\\n@app.post(\\"/items/\\", response_model=Item)\\nasync def create_item(item: Item):\\n    return item\\n\\n@app.get(\\"/items/{item_id}\\", response_model=Item)\\nasync def read_item(\\n    item_id: int = Path(..., title=\\"L\'ID de l\'item \xe0 r\xe9cup\xe9rer\\", ge=1)\\n):\\n    # Logic to retrieve item\\n    return {\\"name\\": \\"Example Item\\", \\"price\\": 99.99, \\"description\\": \\"A sample item\\"}\\n```\\n\\nAvec cette configuration, FastAPI :\\n\\n- Valide automatiquement les requ\xeates entrantes\\n- Convertit les donn\xe9es en objets Python typ\xe9s\\n- G\xe9n\xe8re une documentation OpenAPI interactive\\n- Effectue la s\xe9rialisation des r\xe9ponses\\n\\n## Pydantic v1 vs v2 : les diff\xe9rences majeures \ud83d\udd04\\n\\nPydantic v2 (sorti en 2023) a introduit plusieurs changements importants :\\n\\n| Fonctionnalit\xe9 | v1 | v2 |\\n|----------------|-----|-----|\\n| Moteur de validation | Python pur | Core en Rust (10-50x plus rapide) |\\n| API | `.dict()`, `.json()` | `.model_dump()`, `.model_dump_json()` |\\n| Validateurs | `@validator`, `@root_validator` | `@field_validator`, `@model_validator` |\\n| Types g\xe9n\xe9riques | Support limit\xe9 | Support am\xe9lior\xe9 |\\n| JSON Schema | G\xe9n\xe9ration basique | Plus complet et personnalisable |\\n\\nExemple de migration :\\n\\n```python\\n# Pydantic v1\\nfrom pydantic import BaseModel, validator\\n\\nclass UserV1(BaseModel):\\n    name: str\\n    age: int\\n\\n    @validator(\'age\')\\n    def check_age(cls, v):\\n        if v < 18:\\n            raise ValueError(\'Doit \xeatre majeur\')\\n        return v\\n\\n    # Conversion en dict/json\\n    data = user.dict()\\n    json_data = user.json()\\n\\n# Pydantic v2\\nfrom pydantic import BaseModel, field_validator\\n\\nclass UserV2(BaseModel):\\n    name: str\\n    age: int\\n\\n    @field_validator(\'age\')\\n    @classmethod  # Maintenant obligatoire\\n    def check_age(cls, v):\\n        if v < 18:\\n            raise ValueError(\'Doit \xeatre majeur\')\\n        return v\\n\\n    # Conversion en dict/json\\n    data = user.model_dump()\\n    json_data = user.model_dump_json()\\n```\\n\\n## Bonnes pratiques avec Pydantic \ud83d\udc4d\\n\\n1. **Utilisez des types pr\xe9cis**: Les types comme `EmailStr`, `HttpUrl`, `conint`, etc. am\xe9liorent la validation\\n\\n2. **Cr\xe9ez une hi\xe9rarchie de mod\xe8les**: Utilisez l\'h\xe9ritage pour les structures complexes\\n\\n   ```python\\n   class BaseUser(BaseModel):\\n       id: int\\n       name: str\\n\\n   class UserIn(BaseUser):\\n       password: str\\n\\n   class UserOut(BaseUser):\\n       is_active: bool\\n   ```\\n\\n3. **Exploitez les validators pour les r\xe8gles m\xe9tier complexes**:\\n\\n   ```python\\n   @field_validator(\\"reservation_date\\")\\n   @classmethod\\n   def validate_date_is_future(cls, v, info):\\n       if v <= datetime.now():\\n           raise ValueError(\\"La r\xe9servation doit \xeatre dans le futur\\")\\n       return v\\n   ```\\n\\n4. **Utilisez FrozenModel pour l\'immutabilit\xe9**:\\n\\n   ```python\\n   from pydantic import BaseModel, ConfigDict\\n\\n   class Config(BaseModel):\\n       model_config = ConfigDict(frozen=True)\\n       api_key: str\\n       debug: bool = False\\n   ```\\n\\n5. **Ajoutez des exemples pour am\xe9liorer la documentation**:\\n\\n   ```python\\n   class Item(BaseModel):\\n       name: str\\n       price: float\\n\\n       model_config = {\\n           \\"json_schema_extra\\": {\\"examples\\": [{\\"name\\": \\"Foo\\", \\"price\\": 35.4}]}\\n       }\\n   ```\\n\\n## Cas d\'utilisation concrets \ud83d\udee0\ufe0f\\n\\n### Validation de configuration\\n\\n```python\\nfrom pydantic import BaseModel, Field, SecretStr\\nimport yaml\\nfrom pathlib import Path\\n\\nclass DatabaseConfig(BaseModel):\\n    host: str = \\"localhost\\"\\n    port: int = 5432\\n    user: str\\n    password: SecretStr\\n    name: str\\n    ssl: bool = False\\n\\nclass ApiConfig(BaseModel):\\n    endpoint: str\\n    timeout: int = 30\\n    retries: int = 3\\n\\nclass AppConfig(BaseModel):\\n    debug: bool = False\\n    log_level: str = \\"INFO\\"\\n    database: DatabaseConfig\\n    api: ApiConfig\\n\\n# Charger la configuration depuis un fichier YAML\\nconfig_path = Path(\\"config.yaml\\")\\nwith open(config_path) as f:\\n    config_dict = yaml.safe_load(f)\\n\\n# Valider la configuration\\ntry:\\n    config = AppConfig.model_validate(config_dict)\\n    print(f\\"Configuration valide: {config.model_dump(exclude={\'database\': {\'password\'}})}\\")\\nexcept ValueError as e:\\n    print(f\\"Configuration invalide: {e}\\")\\n```\\n\\n### Traitement de donn\xe9es d\'API\\n\\n```python\\nimport httpx\\nfrom pydantic import BaseModel, HttpUrl\\nfrom typing import List, Optional\\nfrom datetime import datetime\\n\\nclass Author(BaseModel):\\n    name: str\\n    url: Optional[HttpUrl] = None\\n\\nclass Article(BaseModel):\\n    id: int\\n    title: str\\n    content: str\\n    published: datetime\\n    author: Author\\n    tags: List[str] = []\\n\\nasync def fetch_articles():\\n    async with httpx.AsyncClient() as client:\\n        response = await client.get(\\"https://api.example.com/articles\\")\\n        data = response.json()\\n\\n        # Valider et convertir les donn\xe9es en objets Python\\n        articles = [Article.model_validate(item) for item in data]\\n\\n        # Maintenant on peut travailler avec des objets Python typ\xe9s\\n        for article in articles:\\n            print(f\\"Article: {article.title}, Publi\xe9 le: {article.published.strftime(\'%d/%m/%Y\')}\\")\\n            print(f\\"Auteur: {article.author.name}\\")\\n            print(\\"-\\" * 50)\\n\\n        return articles\\n```\\n\\n## Conclusion \ud83c\udfaf\\n\\nPydantic s\'est impos\xe9 comme un outil indispensable dans l\'\xe9cosyst\xe8me Python moderne, particuli\xe8rement pour le d\xe9veloppement d\'APIs et d\'applications manipulant des donn\xe9es structur\xe9es. Ses points forts :\\n\\n- **Validation robuste** des donn\xe9es bas\xe9e sur les types Python standard\\n- **API intuitive** permettant de d\xe9finir rapidement des mod\xe8les complexes\\n- **Performances impressionnantes** gr\xe2ce au moteur de validation en Rust\\n- **Int\xe9gration harmonieuse** avec FastAPI et d\'autres frameworks"},{"id":"/2025/03/15/02-network/traefik","metadata":{"permalink":"/blog/2025/03/15/02-network/traefik","source":"@site/blog/02-network/2025-03-15-traefik.md","title":"Introduction \xe0 Traefik","description":"Pr\xe9sentation de Traefik, ses fonctionnalit\xe9s et ses exemples d\'utilisation dans la vie r\xe9elle.","date":"2025-03-15T00:00:00.000Z","tags":[{"inline":true,"label":"Traefik","permalink":"/blog/tags/traefik"},{"inline":true,"label":"Network","permalink":"/blog/tags/network"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":4.89,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Introduction \xe0 Traefik","description":"Pr\xe9sentation de Traefik, ses fonctionnalit\xe9s et ses exemples d\'utilisation dans la vie r\xe9elle.","tags":["Traefik","Network","Devops"]},"unlisted":false,"prevItem":{"title":"Pydantic: Validation de donn\xe9es robuste pour Python","permalink":"/blog/2025/03/30/09-scripting/pydantic-validation-donnees"},"nextItem":{"title":"Poetry: G\xe9rer efficacement vos d\xe9pendances Python","permalink":"/blog/2025/03/01/09-scripting/poetry-python-dependency"}},"content":"Traefik est un proxy d\'application open-source con\xe7u pour simplifier le processus de publication des services. Il g\xe8re les requ\xeates au nom de votre syst\xe8me, identifie les composants responsables et les achemine de mani\xe8re s\xe9curis\xe9e. Traefik se distingue par sa capacit\xe9 \xe0 d\xe9couvrir automatiquement la bonne configuration pour vos services en inspectant votre infrastructure. Il est compatible avec les principales technologies de cluster comme Kubernetes, Docker Swarm et AWS, et peut g\xe9rer plusieurs technologies simultan\xe9ment. Traefik \xe9limine le besoin de maintenir des fichiers de configuration s\xe9par\xe9s, car tout se passe automatiquement en temps r\xe9el sans red\xe9marrages ni interruptions de connexion. Il vous permet de vous concentrer sur le d\xe9veloppement et le d\xe9ploiement de nouvelles fonctionnalit\xe9s plut\xf4t que sur la configuration et la maintenance du syst\xe8me. Traefik offre \xe9galement une int\xe9gration transparente des capacit\xe9s de passerelle API et de gestion des API. La documentation est organis\xe9e pour r\xe9pondre \xe0 diff\xe9rents profils d\'utilisateurs : D\xe9butants, Ing\xe9nieurs DevOps et D\xe9veloppeurs, fournissant des \xe9tapes guid\xe9es, de la fiabilit\xe9, des performances et des d\xe9ploiements simplifi\xe9s. Les concepts de base incluent les Entrypoints, les Routers, les Services et les Providers, qui travaillent ensemble pour g\xe9rer le trafic depuis l\'arriv\xe9e de la requ\xeate jusqu\'\xe0 la gestion de l\'application. La documentation fournit une navigation, des exemples pratiques et des sections de r\xe9f\xe9rence pour les d\xe9tails techniques.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que Traefik et pourquoi a-t-il \xe9t\xe9 cr\xe9\xe9 ?\\n\\nTraefik est un proxy d\'application open-source con\xe7u pour simplifier le processus de publication des services. Il g\xe8re les requ\xeates au nom de votre syst\xe8me, identifie les composants responsables et les achemine de mani\xe8re s\xe9curis\xe9e. Traefik se distingue par sa capacit\xe9 \xe0 d\xe9couvrir automatiquement la bonne configuration pour vos services en inspectant votre infrastructure. Il est compatible avec les principales technologies de cluster comme Kubernetes, Docker Swarm et AWS, et peut g\xe9rer plusieurs technologies simultan\xe9ment. Traefik \xe9limine le besoin de maintenir des fichiers de configuration s\xe9par\xe9s, car tout se passe automatiquement en temps r\xe9el sans red\xe9marrages ni interruptions de connexion. Il vous permet de vous concentrer sur le d\xe9veloppement et le d\xe9ploiement de nouvelles fonctionnalit\xe9s plut\xf4t que sur la configuration et la maintenance du syst\xe8me. Traefik offre \xe9galement une int\xe9gration transparente des capacit\xe9s de passerelle API et de gestion des API. La documentation est organis\xe9e pour r\xe9pondre \xe0 diff\xe9rents profils d\'utilisateurs : D\xe9butants, Ing\xe9nieurs DevOps et D\xe9veloppeurs, fournissant des \xe9tapes guid\xe9es, de la fiabilit\xe9, des performances et des d\xe9ploiements simplifi\xe9s. Les concepts de base incluent les Entrypoints, les Routers, les Services et les Providers, qui travaillent ensemble pour g\xe9rer le trafic depuis l\'arriv\xe9e de la requ\xeate jusqu\'\xe0 la gestion de l\'application. La documentation fournit une navigation, des exemples pratiques et des sections de r\xe9f\xe9rence pour les d\xe9tails techniques.\\n\\n### Exemples d\'utilisation de Traefik\\n\\nTraefik est souvent utilis\xe9 pour servir des pages web statiques et dynamiques. Il est capable de g\xe9rer des milliers de connexions simultan\xe9es avec une faible utilisation de la m\xe9moire.\\n\\nTraefik peut agir comme un proxy inverse pour distribuer les requ\xeates des clients \xe0 plusieurs serveurs backend. Cela permet de r\xe9partir la charge et d\'am\xe9liorer les performances.\\n\\nTraefik peut \xeatre utilis\xe9 pour r\xe9partir les requ\xeates entrantes entre plusieurs serveurs, assurant ainsi une r\xe9partition \xe9quilibr\xe9e de la charge.\\n\\nTraefik peut mettre en cache les r\xe9ponses des serveurs backend pour r\xe9duire la charge et am\xe9liorer les temps de r\xe9ponse.\\n\\n## Fonctionnalit\xe9s de Traefik\\n\\nL\'\xe9quilibrage de charge est une fonctionnalit\xe9 cl\xe9 de Traefik. Il permet de distribuer les requ\xeates entrantes entre plusieurs serveurs backend. Traefik prend en charge plusieurs algorithmes d\'\xe9quilibrage de charge, tels que le round-robin, le least connections, et l\'IP hash.\\n\\nTraefik peut mettre en cache les r\xe9ponses des serveurs backend pour r\xe9duire la charge et am\xe9liorer les temps de r\xe9ponse. Le caching est particuli\xe8rement utile pour les contenus statiques qui ne changent pas fr\xe9quemment.\\n\\nTraefik offre plusieurs fonctionnalit\xe9s de s\xe9curit\xe9, telles que la gestion des certificats SSL/TLS, la limitation du nombre de connexions, et la protection contre les attaques DDoS. En utilisant Traefik comme proxy inverse, vous pouvez \xe9galement masquer les d\xe9tails de votre infrastructure backend.\\n\\nTraefik peut compresser les r\xe9ponses avant de les envoyer aux clients. Cela permet de r\xe9duire la quantit\xe9 de donn\xe9es transf\xe9r\xe9es et d\'am\xe9liorer les temps de chargement des pages. Traefik prend en charge plusieurs formats de compression, tels que gzip et brotli.\\n\\n## Configuration de Traefik\\n\\nLa configuration de Traefik se fait \xe0 l\'aide de fichiers de configuration. Voici un exemple de configuration simple pour un serveur web :\\n\\n```yaml\\nentryPoints:\\n  web:\\n    address: \\":80\\"\\n\\nservices:\\n  my-service:\\n    loadBalancer:\\n      servers:\\n        - url: \\"http://127.0.0.1:8080\\"\\n\\nrouters:\\n  my-router:\\n    rule: \\"Host(`example.com`)\\"\\n    service: my-service\\n    entryPoints:\\n      - web\\n```\\n\\nDans cet exemple, Traefik \xe9coute sur le port 80 et achemine les requ\xeates vers le service `my-service` qui est configur\xe9 pour envoyer les requ\xeates \xe0 `http://127.0.0.1:8080`.\\n\\n## Exemple d\'utilisation avec Kubernetes\\n\\nVoici un exemple de configuration de Traefik avec Kubernetes pour exposer un service web :\\n\\n```yaml\\napiVersion: v1\\nkind: Service\\nmetadata:\\n  name: my-service\\n  labels:\\n    app: my-app\\nspec:\\n  ports:\\n    - port: 80\\n      targetPort: 80\\n  selector:\\n    app: my-app\\n---\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: my-app\\nspec:\\n  replicas: 3\\n  selector:\\n    matchLabels:\\n      app: my-app\\n  template:\\n    metadata:\\n      labels:\\n        app: my-app\\n    spec:\\n      containers:\\n        - name: my-app\\n          image: nginx:alpine\\n          ports:\\n            - containerPort: 80\\n---\\napiVersion: traefik.containo.us/v1alpha1\\nkind: IngressRoute\\nmetadata:\\n  name: my-ingressroute\\nspec:\\n  entryPoints:\\n    - web\\n  routes:\\n    - match: Host(`example.com`)\\n      kind: Rule\\n      services:\\n        - name: my-service\\n          port: 80\\n```\\n\\nDans cet exemple, un service Kubernetes est cr\xe9\xe9 pour exposer une application web ex\xe9cut\xe9e dans un d\xe9ploiement. Traefik est configur\xe9 pour acheminer les requ\xeates vers le service en utilisant un IngressRoute.\\n\\n## Conclusion\\n\\nTraefik est un outil puissant et polyvalent qui peut \xeatre utilis\xe9 pour une vari\xe9t\xe9 de t\xe2ches, allant de la simple diffusion de contenu web \xe0 l\'\xe9quilibrage de charge et au caching. Sa flexibilit\xe9 et ses performances en font un choix populaire pour de nombreuses entreprises et d\xe9veloppeurs.\\n\\nPour en savoir plus sur Traefik, vous pouvez consulter la [documentation officielle](https://doc.traefik.io/traefik/)."},{"id":"/2025/03/01/09-scripting/poetry-python-dependency","metadata":{"permalink":"/blog/2025/03/01/09-scripting/poetry-python-dependency","source":"@site/blog/09-scripting/2025-03-01-poetry-python-dependency.md","title":"Poetry: G\xe9rer efficacement vos d\xe9pendances Python","description":"Un guide complet sur Poetry, l\'outil moderne de gestion de d\xe9pendances et de packaging pour Python.","date":"2025-03-01T00:00:00.000Z","tags":[{"inline":true,"label":"Python","permalink":"/blog/tags/python"},{"inline":true,"label":"DevOps","permalink":"/blog/tags/dev-ops"},{"inline":true,"label":"Scripting","permalink":"/blog/tags/scripting"}],"readingTime":3.87,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Poetry: G\xe9rer efficacement vos d\xe9pendances Python","description":"Un guide complet sur Poetry, l\'outil moderne de gestion de d\xe9pendances et de packaging pour Python.","tags":["Python","DevOps","Scripting"]},"unlisted":false,"prevItem":{"title":"Introduction \xe0 Traefik","permalink":"/blog/2025/03/15/02-network/traefik"},"nextItem":{"title":"Secrets et ConfigMaps dans Kubernetes","permalink":"/blog/2025/02/15/06-orchestration/k8s-secrets-configmaps"}},"content":"Poetry est devenu un outil essentiel dans l\'\xe9cosyst\xe8me Python pour g\xe9rer les d\xe9pendances et le packaging de projets. Dans cet article, nous explorerons comment Poetry simplifie la gestion des d\xe9pendances Python, offrant une alternative \xe9l\xe9gante et robuste \xe0 pip et virtualenv. \ud83d\udc0d\\n\\n\x3c!--truncate--\x3e\\n\\n## Pourquoi utiliser Poetry ? \ud83e\udd14\\n\\nAvant de plonger dans les d\xe9tails techniques, voyons pourquoi vous devriez envisager d\'utiliser Poetry pour vos projets Python:\\n\\n1. **Gestion simplifi\xe9e des d\xe9pendances**: Poetry g\xe8re automatiquement les d\xe9pendances et leurs versions compatibles\\n2. **Environnements virtuels int\xe9gr\xe9s**: Cr\xe9ation et gestion des environnements virtuels sans configuration suppl\xe9mentaire\\n3. **R\xe9solution d\xe9terministe des d\xe9pendances**: Lock file garantissant la reproductibilit\xe9 des installations\\n4. **Publication facilit\xe9e**: D\xe9ploiement simplifi\xe9 de packages sur PyPI\\n5. **Interface utilisateur intuitive**: Commandes claires et feedback utile\\n\\n## Installation de Poetry \ud83d\ude80\\n\\nL\'installation de Poetry est simple et directe:\\n\\n```bash\\n# M\xe9thode recommand\xe9e (installation isol\xe9e)\\ncurl -sSL https://install.python-poetry.org | python3 -\\n\\n# V\xe9rifier l\'installation\\npoetry --version\\n```\\n\\nPour les utilisateurs de macOS ou Linux, ajoutez Poetry \xe0 votre PATH:\\n\\n```bash\\n# Ajouter \xe0 votre .zshrc ou .bashrc\\nexport PATH=\\"$HOME/.local/bin:$PATH\\"\\n```\\n\\n## Cr\xe9ation d\'un nouveau projet \ud83d\udcc1\\n\\nPour cr\xe9er un nouveau projet avec Poetry:\\n\\n```bash\\n# Cr\xe9er un nouveau projet\\npoetry new mon-super-projet\\n\\n# Structure g\xe9n\xe9r\xe9e\\nmon-super-projet/\\n\u251c\u2500\u2500 pyproject.toml\\n\u251c\u2500\u2500 README.md\\n\u251c\u2500\u2500 mon_super_projet/\\n\u2502   \u2514\u2500\u2500 __init__.py\\n\u2514\u2500\u2500 tests/\\n    \u2514\u2500\u2500 __init__.py\\n```\\n\\nLe fichier `pyproject.toml` est le c\u0153ur de votre projet, contenant toutes les m\xe9tadonn\xe9es et d\xe9pendances:\\n\\n```toml\\n[tool.poetry]\\nname = \\"mon-super-projet\\"\\nversion = \\"0.1.0\\"\\ndescription = \\"\\"\\nauthors = [\\"Votre Nom <votre.email@example.com>\\"]\\nreadme = \\"README.md\\"\\n\\n[tool.poetry.dependencies]\\npython = \\"^3.10\\"\\n\\n[tool.poetry.dev-dependencies]\\npytest = \\"^7.3.1\\"\\n\\n[build-system]\\nrequires = [\\"poetry-core>=1.0.0\\"]\\nbuild-backend = \\"poetry.core.masonry.api\\"\\n```\\n\\n## Gestion des d\xe9pendances \ud83d\udce6\\n\\n### Ajouter des d\xe9pendances\\n\\n```bash\\n# Ajouter une d\xe9pendance\\npoetry add requests\\n\\n# Ajouter une d\xe9pendance avec une contrainte de version sp\xe9cifique\\npoetry add \\"requests>=2.25.0,<3.0.0\\"\\n\\n# Ajouter une d\xe9pendance de d\xe9veloppement\\npoetry add pytest --group dev\\n```\\n\\n### Le fichier poetry.lock\\n\\nLorsque vous ajoutez des d\xe9pendances, Poetry cr\xe9e un fichier `poetry.lock` qui verrouille les versions exactes. Ce fichier assure que tous les environnements utiliseront exactement les m\xeames versions des packages.\\n\\n```bash\\n# Installer les d\xe9pendances depuis le lock file\\npoetry install\\n```\\n\\n## Utilisation quotidienne \ud83d\udcbb\\n\\n### Ex\xe9cuter des commandes dans l\'environnement virtuel\\n\\n```bash\\n# Ex\xe9cuter un script Python\\npoetry run python mon_script.py\\n\\n# Ex\xe9cuter une commande install\xe9e\\npoetry run pytest\\n\\n# Ouvrir un shell dans l\'environnement virtuel\\npoetry shell\\n```\\n\\n### Mise \xe0 jour des d\xe9pendances\\n\\n```bash\\n# Afficher les d\xe9pendances qui peuvent \xeatre mises \xe0 jour\\npoetry show --outdated\\n\\n# Mettre \xe0 jour toutes les d\xe9pendances\\npoetry update\\n\\n# Mettre \xe0 jour une d\xe9pendance sp\xe9cifique\\npoetry update requests\\n```\\n\\n## Configuration avanc\xe9e \ud83d\udd27\\n\\n### Gestion de plusieurs environnements Python\\n\\nPoetry permet de travailler facilement avec diff\xe9rentes versions de Python:\\n\\n```bash\\n# Sp\xe9cifier une version Python pour le projet\\npoetry env use python3.9\\n\\n# Lister les environnements virtuels associ\xe9s au projet\\npoetry env list\\n\\n# Supprimer un environnement virtuel\\npoetry env remove python3.8\\n```\\n\\n### Configuration des sources de packages\\n\\nVous pouvez configurer des sources de packages personnalis\xe9es:\\n\\n```bash\\n# Ajouter un repository priv\xe9\\npoetry source add mon-repo https://mon-repo-prive.com/simple/\\n\\n# Installer depuis un repository sp\xe9cifique\\npoetry add mon-package --source mon-repo\\n```\\n\\n## Workflows CI/CD avec Poetry \ud83d\udd04\\n\\nPoetry s\'int\xe8gre parfaitement dans les pipelines d\'int\xe9gration continue. Voici un exemple avec GitHub Actions:\\n\\n```yaml\\nname: Tests Python\\n\\non: [push, pull_request]\\n\\njobs:\\n  test:\\n    runs-on: ubuntu-latest\\n    steps:\\n      - uses: actions/checkout@v3\\n      - name: Set up Python\\n        uses: actions/setup-python@v4\\n        with:\\n          python-version: \'3.11\'\\n      - name: Install Poetry\\n        uses: snok/install-poetry@v1\\n        with:\\n          version: 1.6.1\\n      - name: Install dependencies\\n        run: poetry install\\n      - name: Run tests\\n        run: poetry run pytest\\n```\\n\\n## Publication de votre package \ud83d\udea2\\n\\nPoetry facilite \xe9norm\xe9ment la publication de packages sur PyPI:\\n\\n```bash\\n# Construire le package\\npoetry build\\n\\n# Publier sur PyPI\\npoetry publish\\n\\n# Construire et publier en une seule commande\\npoetry publish --build\\n```\\n\\nPour publier sur un index priv\xe9:\\n\\n```bash\\npoetry publish --repository mon-repo\\n```\\n\\n## Comparaison avec d\'autres outils \ud83d\udd0d\\n\\n| Fonctionnalit\xe9 | Poetry | pip + venv | pipenv |\\n|----------------|--------|------------|--------|\\n| Gestion des d\xe9pendances | \u2705 | \u26a0\ufe0f (manuel) | \u2705 |\\n| Lock file | \u2705 | \u274c | \u2705 |\\n| Environnements virtuels | \u2705 | \u2705 (s\xe9par\xe9) | \u2705 |\\n| Publication de package | \u2705 | \u274c (besoin de setuptools) | \u274c |\\n| R\xe9solution des d\xe9pendances | \u2705 (rapide) | \u274c | \u2705 (lent) |\\n| Innovation active | \u2705 | \u2705 | \u26a0\ufe0f |\\n\\n## Bonnes pratiques avec Poetry \ud83d\udc4d\\n\\n1. **Toujours commiter le fichier `poetry.lock`**: Il garantit la reproductibilit\xe9 des installations\\n2. **S\xe9parer clairement d\xe9pendances de production et de d\xe9veloppement**\\n3. **D\xe9finir des contraintes de version pr\xe9cises** pour les biblioth\xe8ques critiques\\n4. **Utiliser `poetry export`** pour g\xe9n\xe9rer un `requirements.txt` quand n\xe9cessaire:\\n\\n   ```bash\\n   poetry export -f requirements.txt --output requirements.txt\\n   ```\\n\\n5. **Mettre \xe0 jour r\xe9guli\xe8rement** vos d\xe9pendances pour des raisons de s\xe9curit\xe9\\n\\n## Conclusion \ud83c\udfaf\\n\\nPoetry a transform\xe9 la fa\xe7on dont les d\xe9veloppeurs Python g\xe8rent leurs projets en offrant une solution tout-en-un pour la gestion des d\xe9pendances, les environnements virtuels et le packaging. Son approche d\xe9clarative et sa simplicit\xe9 d\'utilisation en font un outil incontournable pour tout projet Python moderne.\\n\\nAu-del\xe0 d\'\xeatre un simple gestionnaire de d\xe9pendances, Poetry repr\xe9sente une \xe9volution significative dans l\'\xe9cosyst\xe8me Python, rendant le d\xe9veloppement plus reproductible, plus fiable et plus agr\xe9able."},{"id":"/2025/02/15/06-orchestration/k8s-secrets-configmaps","metadata":{"permalink":"/blog/2025/02/15/06-orchestration/k8s-secrets-configmaps","source":"@site/blog/06-orchestration/2025-02-15-k8s-secrets-configmaps.md","title":"Secrets et ConfigMaps dans Kubernetes","description":"D\xe9couvrez les concepts de Secrets et ConfigMaps dans Kubernetes, et comment les utiliser pour g\xe9rer les configurations et les informations sensibles.","date":"2025-02-15T00:00:00.000Z","tags":[{"inline":true,"label":"Kubernetes","permalink":"/blog/tags/kubernetes"},{"inline":true,"label":"Orchestration","permalink":"/blog/tags/orchestration"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":1.63,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Secrets et ConfigMaps dans Kubernetes","description":"D\xe9couvrez les concepts de Secrets et ConfigMaps dans Kubernetes, et comment les utiliser pour g\xe9rer les configurations et les informations sensibles.","tags":["Kubernetes","Orchestration","Devops"]},"unlisted":false,"prevItem":{"title":"Poetry: G\xe9rer efficacement vos d\xe9pendances Python","permalink":"/blog/2025/03/01/09-scripting/poetry-python-dependency"},"nextItem":{"title":"Stockage dans Kubernetes","permalink":"/blog/2025/02/10/06-orchestration/k8s-storage"}},"content":"Kubernetes offre des m\xe9canismes pour g\xe9rer les configurations et les informations sensibles de mani\xe8re s\xe9curis\xe9e et efficace. Dans cet article, les concepts de Secrets et ConfigMaps dans Kubernetes seront explor\xe9s, ainsi que leur utilisation pour g\xe9rer les configurations et les informations sensibles. \ud83d\udd12\\n\\n\x3c!--truncate--\x3e\\n\\n## ConfigMap\\n\\nUn ConfigMap est une ressource Kubernetes utilis\xe9e pour stocker des paires cl\xe9-valeur de configuration. Les ConfigMaps permettent de s\xe9parer les configurations des conteneurs, ce qui facilite la gestion et la mise \xe0 jour des configurations sans avoir \xe0 reconstruire les images des conteneurs.\\n\\n### Exemple de ConfigMap\\n\\n```yaml\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: my-config\\ndata:\\n  database_url: \\"postgres://user:password@hostname:5432/dbname\\"\\n  log_level: \\"debug\\"\\n```\\n\\n### Utilisation d\'un ConfigMap dans un Pod\\n\\n```yaml\\napiVersion: v1\\nkind: Pod\\nmetadata:\\n  name: my-pod\\nspec:\\n  containers:\\n    - name: my-container\\n      image: nginx:alpine\\n      env:\\n        - name: DATABASE_URL\\n          valueFrom:\\n            configMapKeyRef:\\n              name: my-config\\n              key: database_url\\n        - name: LOG_LEVEL\\n          valueFrom:\\n            configMapKeyRef:\\n              name: my-config\\n              key: log_level\\n```\\n\\n## Secret\\n\\nUn Secret est une ressource Kubernetes utilis\xe9e pour stocker des informations sensibles, telles que des mots de passe, des cl\xe9s API et des certificats. Les Secrets permettent de g\xe9rer les informations sensibles de mani\xe8re s\xe9curis\xe9e et de les injecter dans les conteneurs sans les exposer dans les fichiers de configuration.\\n\\n### Exemple de Secret\\n\\n```yaml\\napiVersion: v1\\nkind: Secret\\nmetadata:\\n  name: my-secret\\ntype: Opaque\\ndata:\\n  username: dXNlcm5hbWU=\\n  password: cGFzc3dvcmQ=\\n```\\n\\n### Utilisation d\'un Secret dans un Pod\\n\\n```yaml\\napiVersion: v1\\nkind: Pod\\nmetadata:\\n  name: my-pod\\nspec:\\n  containers:\\n    - name: my-container\\n      image: nginx:alpine\\n      env:\\n        - name: USERNAME\\n          valueFrom:\\n            secretKeyRef:\\n              name: my-secret\\n              key: username\\n        - name: PASSWORD\\n          valueFrom:\\n            secretKeyRef:\\n              name: my-secret\\n              key: password\\n```\\n\\n## Conclusion\\n\\nLes Secrets et ConfigMaps dans Kubernetes permettent de g\xe9rer les configurations et les informations sensibles de mani\xe8re s\xe9curis\xe9e et efficace. En utilisant ces ressources, il est possible de s\xe9parer les configurations des conteneurs, de faciliter la gestion des configurations et de prot\xe9ger les informations sensibles. \ud83d\udd10\\n\\nPour en savoir plus sur Kubernetes, consulter la [documentation officielle](https://kubernetes.io/fr/docs/concepts/)."},{"id":"/2025/02/10/06-orchestration/k8s-storage","metadata":{"permalink":"/blog/2025/02/10/06-orchestration/k8s-storage","source":"@site/blog/06-orchestration/2025-02-10-k8s-storage.md","title":"Stockage dans Kubernetes","description":"D\xe9couvrez les concepts de stockage dans Kubernetes, tels que PersistentVolume, PersistentVolumeClaim, StorageClass et Volume.","date":"2025-02-10T00:00:00.000Z","tags":[{"inline":true,"label":"Kubernetes","permalink":"/blog/tags/kubernetes"},{"inline":true,"label":"Orchestration","permalink":"/blog/tags/orchestration"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":4.42,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Stockage dans Kubernetes","description":"D\xe9couvrez les concepts de stockage dans Kubernetes, tels que PersistentVolume, PersistentVolumeClaim, StorageClass et Volume.","tags":["Kubernetes","Orchestration","Devops"]},"unlisted":false,"prevItem":{"title":"Secrets et ConfigMaps dans Kubernetes","permalink":"/blog/2025/02/15/06-orchestration/k8s-secrets-configmaps"},"nextItem":{"title":"Composants de base de Kubernetes","permalink":"/blog/2025/02/05/06-orchestration/k8s-basic-components"}},"content":"Kubernetes offre des m\xe9canismes pour monter et utiliser du stockage dans les pods, mais la gestion des donn\xe9es, y compris la provision, la sauvegarde et la r\xe9plication, est une t\xe2che qui incombe aux administrateurs du cluster. Dans cet article, les concepts de stockage dans Kubernetes, notamment PersistentVolume, PersistentVolumeClaim, StorageClass et Volume, seront explor\xe9s. \ud83d\udce6\\n\\n\x3c!--truncate--\x3e\\n\\n## PersistentVolume (PV)\\n\\nUn PersistentVolume (PV) est une ressource Kubernetes qui repr\xe9sente un volume de stockage dans le cluster. Il peut \xeatre provisionn\xe9 dynamiquement ou statiquement et est utilis\xe9 pour stocker des donn\xe9es de mani\xe8re persistante. Les PVs sont ind\xe9pendants des pods et peuvent \xeatre r\xe9clam\xe9s par des PersistentVolumeClaims (PVCs).\\n\\n### Exemple de PersistentVolume\\n\\n```yaml\\napiVersion: v1\\nkind: PersistentVolume\\nmetadata:\\n  name: my-pv\\nspec:\\n  capacity:\\n    storage: 1Gi\\n  accessModes:\\n    - ReadWriteOnce\\n  persistentVolumeReclaimPolicy: Retain\\n  storageClassName: my-storage-class\\n  hostPath:\\n    path: /mnt/data\\n```\\n\\n## PersistentVolumeClaim (PVC)\\n\\nUn PersistentVolumeClaim (PVC) est une ressource Kubernetes utilis\xe9e par les pods pour demander un certain type et une certaine quantit\xe9 de stockage persistant. Les PVCs sont li\xe9s aux PVs disponibles dans le cluster.\\n\\n### Exemple de PersistentVolumeClaim\\n\\n```yaml\\napiVersion: v1\\nkind: PersistentVolumeClaim\\nmetadata:\\n  name: my-pvc\\nspec:\\n  accessModes:\\n    - ReadWriteOnce\\n  resources:\\n    requests:\\n      storage: 1Gi\\n  storageClassName: my-storage-class\\n```\\n\\n## Cycle de vie des PersistentVolumes (PV) et PersistentVolumeClaims (PVC)\\n\\nLe cycle de vie des PersistentVolumes (PV) et PersistentVolumeClaims (PVC) dans Kubernetes suit plusieurs \xe9tapes, de la cr\xe9ation \xe0 la suppression.\\n\\n### Cycle de vie des PV\\n\\n1. **Provisioning**: Le PV est cr\xe9\xe9 soit statiquement par un administrateur, soit dynamiquement par le contr\xf4leur de stockage.\\n2. **Binding**: Le PV est li\xe9 \xe0 un PVC lorsqu\'un PVC correspondant est cr\xe9\xe9.\\n3. **Using**: Le PV est utilis\xe9 par un pod via le PVC.\\n4. **Reclaiming**: Lorsque le PVC est supprim\xe9, le PV entre dans une phase de r\xe9cup\xe9ration selon sa politique de r\xe9cup\xe9ration (Retain, Recycle, Delete).\\n5. **Releasing**: Le PV est lib\xe9r\xe9 mais reste associ\xe9 au PVC jusqu\'\xe0 ce que la politique de r\xe9cup\xe9ration soit appliqu\xe9e.\\n6. **Recycling/Deleting**: Le PV est soit recycl\xe9 pour \xeatre r\xe9utilis\xe9, soit supprim\xe9.\\n\\n### Cycle de vie des PVC\\n\\n1. **Pending**: Le PVC est cr\xe9\xe9 et attend qu\'un PV correspondant soit disponible.\\n2. **Bound**: Le PVC est li\xe9 \xe0 un PV disponible.\\n3. **Using**: Le PVC est utilis\xe9 par un pod pour acc\xe9der au stockage.\\n4. **Released**: Le PVC est supprim\xe9 et le PV entre dans la phase de r\xe9cup\xe9ration.\\n\\n### Diagramme Mermaid\\n\\n```mermaid\\ngraph TD\\n  subgraph PV\\n    A[Provisioning] --\x3e B[Binding]\\n    B --\x3e C[Using]\\n    C --\x3e D[Reclaiming]\\n    D --\x3e E[Releasing]\\n    E --\x3e F[Recycling/Deleting]\\n  end\\n\\n  subgraph PVC\\n    G[Pending] --\x3e H[Bound]\\n    H --\x3e I[Using]\\n    I --\x3e J[Released]\\n  end\\n\\n  B -.-> H\\n  H -.-> B\\n  J -.-> D\\n```\\n\\n## StorageClass\\n\\nUne StorageClass est une ressource Kubernetes utilis\xe9e pour d\xe9finir les types de stockage disponibles dans le cluster. Elle permet de provisionner dynamiquement des PersistentVolumes en fonction des besoins sp\xe9cifiques des applications.\\n\\n### Provisionnement dynamique\\n\\nLe provisionnement dynamique permet de cr\xe9er automatiquement des PersistentVolumes (PVs) lorsque des PersistentVolumeClaims (PVCs) sont demand\xe9s par les pods. Cela simplifie la gestion du stockage en \xe9liminant la n\xe9cessit\xe9 de cr\xe9er manuellement des PVs. Pour utiliser le provisionnement dynamique, les administrateurs du cluster doivent d\xe9finir des StorageClasses qui sp\xe9cifient les types de stockage disponibles et les param\xe8tres de provisionnement.\\n\\n### Exemple de StorageClass\\n\\n```yaml\\napiVersion: storage.k8s.io/v1\\nkind: StorageClass\\nmetadata:\\n  name: my-storage-class\\nprovisioner: kubernetes.io/no-provisioner\\nvolumeBindingMode: WaitForFirstConsumer\\n```\\n\\n### Exemple de PersistentVolumeClaim utilisant une StorageClass\\n\\n```yaml\\napiVersion: v1\\nkind: PersistentVolumeClaim\\nmetadata:\\n  name: my-pvc\\nspec:\\n  accessModes:\\n    - ReadWriteOnce\\n  resources:\\n    requests:\\n      storage: 1Gi\\n  storageClassName: my-storage-class\\n```\\n\\nEn utilisant une StorageClass avec le provisionnement dynamique, Kubernetes cr\xe9era automatiquement un PV correspondant aux sp\xe9cifications du PVC lorsque celui-ci sera cr\xe9\xe9. Cela est \xe9galement possible on-premise, \xe0 condition que le cluster Kubernetes soit configur\xe9 avec un provisionneur de stockage compatible. Les administrateurs du cluster doivent s\'assurer que les StorageClasses sont correctement d\xe9finies pour le stockage on-premise.\\n\\n## Volume\\n\\nUn Volume Kubernetes est un r\xe9pertoire, potentiellement mont\xe9 \xe0 partir du stockage du n\u0153ud, partag\xe9 entre les conteneurs d\'un pod. Les volumes sont utilis\xe9s pour stocker des donn\xe9es de mani\xe8re temporaire ou persistante.\\n\\n### Exemple de Volume\\n\\n```yaml\\napiVersion: v1\\nkind: Pod\\nmetadata:\\n  name: my-pod\\nspec:\\n  containers:\\n    - name: my-container\\n      image: nginx:alpine\\n      volumeMounts:\\n        - mountPath: /usr/share/nginx/html\\n          name: my-volume\\n  volumes:\\n    - name: my-volume\\n      persistentVolumeClaim:\\n        claimName: my-pvc\\n```\\n\\n## Stockage statique et dynamique\\n\\nLe stockage dans Kubernetes peut \xeatre provisionn\xe9 de mani\xe8re statique ou dynamique.\\n\\n### Stockage statique\\n\\nLe stockage statique implique la cr\xe9ation manuelle de PersistentVolumes (PVs) par les administrateurs du cluster. Les PVs sont d\xe9finis \xe0 l\'avance et sont disponibles pour \xeatre r\xe9clam\xe9s par les PersistentVolumeClaims (PVCs). Cette m\xe9thode est utile lorsque des exigences sp\xe9cifiques de stockage doivent \xeatre respect\xe9es.\\n\\n### Stockage dynamique\\n\\nLe stockage dynamique permet de provisionner automatiquement des PersistentVolumes (PVs) en fonction des besoins des applications. Les administrateurs du cluster d\xe9finissent des StorageClasses qui sp\xe9cifient les types de stockage disponibles. Lorsqu\'un PersistentVolumeClaim (PVC) est cr\xe9\xe9, Kubernetes utilise la StorageClass pour provisionner dynamiquement un PV correspondant aux sp\xe9cifications du PVC. Cette m\xe9thode simplifie la gestion du stockage et permet une allocation plus flexible des ressources.\\n\\n## Conclusion\\n\\nLes concepts de stockage dans Kubernetes, tels que PersistentVolume, PersistentVolumeClaim, StorageClass et Volume, permettent de g\xe9rer efficacement le stockage des donn\xe9es dans les applications conteneuris\xe9es. En comprenant ces concepts, il est possible de tirer parti de la puissance de Kubernetes pour g\xe9rer le stockage des applications. \ud83d\udcca\\n\\nPour en savoir plus sur Kubernetes, consulter la [documentation officielle](https://kubernetes.io/fr/docs/concepts/)."},{"id":"/2025/02/05/06-orchestration/k8s-basic-components","metadata":{"permalink":"/blog/2025/02/05/06-orchestration/k8s-basic-components","source":"@site/blog/06-orchestration/2025-02-05-k8s-basic-components.md","title":"Composants de base de Kubernetes","description":"D\xe9couvrez les composants de base de Kubernetes, tels que les Services, Pods, Deployments et StatefulSets.","date":"2025-02-05T00:00:00.000Z","tags":[{"inline":true,"label":"Kubernetes","permalink":"/blog/tags/kubernetes"},{"inline":true,"label":"Orchestration","permalink":"/blog/tags/orchestration"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":3.81,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Composants de base de Kubernetes","description":"D\xe9couvrez les composants de base de Kubernetes, tels que les Services, Pods, Deployments et StatefulSets.","tags":["Kubernetes","Orchestration","Devops"]},"unlisted":false,"prevItem":{"title":"Stockage dans Kubernetes","permalink":"/blog/2025/02/10/06-orchestration/k8s-storage"},"nextItem":{"title":"Introduction \xe0 Kubernetes","permalink":"/blog/2025/02/01/06-orchestration/k8s-introduction"}},"content":"Kubernetes est une plateforme d\'orchestration de conteneurs qui permet de g\xe9rer des clusters de machines ex\xe9cutant des conteneurs. Dans cet article, les composants de base de Kubernetes, notamment les Services, Pods, Deployments et StatefulSets, seront explor\xe9s. \ud83d\ude80\\n\\n\x3c!--truncate--\x3e\\n\\n## Pod\\n\\nUn Pod est l\'unit\xe9 de base de d\xe9ploiement dans Kubernetes. Il repr\xe9sente un ou plusieurs conteneurs qui partagent le m\xeame r\xe9seau et le m\xeame espace de stockage. Les Pods sont \xe9ph\xe9m\xe8res et peuvent \xeatre recr\xe9\xe9s en cas de d\xe9faillance.\\n\\n### Exemple de Pod\\n\\n```yaml\\napiVersion: v1\\nkind: Pod\\nmetadata:\\n  name: my-pod\\nspec:\\n  containers:\\n    - name: my-container\\n      image: nginx:alpine\\n      ports:\\n        - containerPort: 80\\n```\\n\\nLes Pods sont utilis\xe9s pour ex\xe9cuter des applications conteneuris\xe9es sur des n\u0153uds de travail. Ils peuvent contenir un ou plusieurs conteneurs, qui partagent le m\xeame r\xe9seau et le m\xeame espace de stockage. Les Pods sont \xe9ph\xe9m\xe8res, ce qui signifie qu\'ils peuvent \xeatre recr\xe9\xe9s en cas de d\xe9faillance. Les Pods sont \xe9galement utilis\xe9s pour regrouper des conteneurs qui doivent \xeatre ex\xe9cut\xe9s ensemble, par exemple, un conteneur d\'application et un conteneur de base de donn\xe9es.\\n\\n## Service\\n\\nUn Service est une abstraction qui permet d\'exposer une application ex\xe9cut\xe9e sur un ensemble de Pods en tant que service r\xe9seau. Les Services permettent de distribuer le trafic r\xe9seau entre les Pods et de garantir la haute disponibilit\xe9 des applications.\\n\\n### Exemple de Service\\n\\n```yaml\\napiVersion: v1\\nkind: Service\\nmetadata:\\n  name: my-service\\nspec:\\n  selector:\\n    app: my-app\\n  ports:\\n    - protocol: TCP\\n      port: 80\\n      targetPort: 80\\n  type: LoadBalancer\\n```\\n\\nLes Services sont utilis\xe9s pour exposer des applications ex\xe9cut\xe9es sur des Pods en tant que services r\xe9seau. Ils permettent de distribuer le trafic r\xe9seau entre les Pods et de garantir la haute disponibilit\xe9 des applications. Les Services peuvent \xeatre de diff\xe9rents types, tels que ClusterIP, NodePort et LoadBalancer, en fonction des besoins de l\'application.\\n\\n## Deployment\\n\\nUn Deployment est un objet Kubernetes qui g\xe8re le d\xe9ploiement et la mise \xe0 l\'\xe9chelle des applications conteneuris\xe9es. Il d\xe9finit l\'\xe9tat souhait\xe9 de l\'application et Kubernetes s\'occupe de cr\xe9er et de g\xe9rer les instances (Pods) pour atteindre cet \xe9tat.\\n\\n### Exemple de Deployment\\n\\n```yaml\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: my-deployment\\nspec:\\n  replicas: 3\\n  selector:\\n    matchLabels:\\n      app: my-app\\n  template:\\n    metadata:\\n      labels:\\n        app: my-app\\n    spec:\\n      containers:\\n        - name: my-container\\n          image: nginx:alpine\\n          ports:\\n            - containerPort: 80\\n```\\n\\nLes Deployments sont utilis\xe9s pour g\xe9rer le d\xe9ploiement et la mise \xe0 l\'\xe9chelle des applications conteneuris\xe9es. Ils d\xe9finissent l\'\xe9tat souhait\xe9 de l\'application, y compris le nombre de r\xe9plicas, l\'image du conteneur \xe0 utiliser, les ports expos\xe9s et les volumes. Kubernetes s\'occupe de cr\xe9er et de g\xe9rer les instances (Pods) pour atteindre cet \xe9tat. Les Deployments permettent \xe9galement de mettre \xe0 jour les applications de mani\xe8re transparente en effectuant des d\xe9ploiements progressifs.\\n\\n## StatefulSet\\n\\nUn StatefulSet est un objet Kubernetes qui g\xe8re le d\xe9ploiement et la mise \xe0 l\'\xe9chelle des applications avec \xe9tat. Contrairement aux Deployments, les StatefulSets garantissent l\'ordre et l\'unicit\xe9 des Pods, ce qui est essentiel pour les applications n\xe9cessitant un stockage persistant.\\n\\n### Exemple de StatefulSet\\n\\n```yaml\\napiVersion: apps/v1\\nkind: StatefulSet\\nmetadata:\\n  name: my-statefulset\\nspec:\\n  serviceName: \\"my-service\\"\\n  replicas: 3\\n  selector:\\n    matchLabels:\\n      app: my-app\\n  template:\\n    metadata:\\n      labels:\\n        app: my-app\\n    spec:\\n      containers:\\n        - name: my-container\\n          image: nginx:alpine\\n          ports:\\n            - containerPort: 80\\n          volumeMounts:\\n            - name: my-volume\\n              mountPath: /usr/share/nginx/html\\n  volumeClaimTemplates:\\n    - metadata:\\n        name: my-volume\\n      spec:\\n        accessModes: [ \\"ReadWriteOnce\\" ]\\n        resources:\\n          requests:\\n            storage: 1Gi\\n```\\n\\nLes StatefulSets sont utilis\xe9s pour g\xe9rer le d\xe9ploiement et la mise \xe0 l\'\xe9chelle des applications avec \xe9tat. Contrairement aux Deployments, les StatefulSets garantissent l\'ordre et l\'unicit\xe9 des Pods, ce qui est essentiel pour les applications n\xe9cessitant un stockage persistant. Les StatefulSets sont souvent utilis\xe9s pour des applications telles que les bases de donn\xe9es, qui n\xe9cessitent un stockage persistant et une gestion de l\'\xe9tat.\\n\\n## Interactions entre les composants\\n\\nLes composants de base de Kubernetes interagissent entre eux pour assurer le d\xe9ploiement, la mise \xe0 l\'\xe9chelle et la gestion des applications conteneuris\xe9es. Par exemple, un Deployment peut cr\xe9er plusieurs Pods, qui sont ensuite expos\xe9s en tant que service r\xe9seau par un Service. Les StatefulSets garantissent l\'ordre et l\'unicit\xe9 des Pods, ce qui est essentiel pour les applications n\xe9cessitant un stockage persistant. Les Services permettent de distribuer le trafic r\xe9seau entre les Pods et de garantir la haute disponibilit\xe9 des applications.\\n\\n## Conclusion\\n\\nLes composants de base de Kubernetes, tels que les Pods, Services, Deployments et StatefulSets, permettent de d\xe9ployer, g\xe9rer et mettre \xe0 l\'\xe9chelle des applications conteneuris\xe9es de mani\xe8re efficace. En comprenant ces composants et leurs interactions, il est possible de tirer parti de la puissance de Kubernetes pour g\xe9rer les applications.\\n\\nPour en savoir plus sur Kubernetes, consulter la [documentation officielle](https://kubernetes.io/fr/docs/concepts/)."},{"id":"/2025/02/01/06-orchestration/k8s-introduction","metadata":{"permalink":"/blog/2025/02/01/06-orchestration/k8s-introduction","source":"@site/blog/06-orchestration/2025-02-01-k8s-introduction.md","title":"Introduction \xe0 Kubernetes","description":"D\xe9couvrez les concepts de base de Kubernetes, une plateforme d\'orchestration de conteneurs.","date":"2025-02-01T00:00:00.000Z","tags":[{"inline":true,"label":"Kubernetes","permalink":"/blog/tags/kubernetes"},{"inline":true,"label":"Orchestration","permalink":"/blog/tags/orchestration"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":2.53,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Introduction \xe0 Kubernetes","description":"D\xe9couvrez les concepts de base de Kubernetes, une plateforme d\'orchestration de conteneurs.","tags":["Kubernetes","Orchestration","Devops"]},"unlisted":false,"prevItem":{"title":"Composants de base de Kubernetes","permalink":"/blog/2025/02/05/06-orchestration/k8s-basic-components"},"nextItem":{"title":"Nginx Proxy Manager","permalink":"/blog/2025/01/12/02-network/nginx-proxy-manager"}},"content":"Kubernetes est une plateforme open-source con\xe7ue pour automatiser le d\xe9ploiement, la mise \xe0 l\'\xe9chelle et la gestion des applications conteneuris\xe9es. Il permet de regrouper des conteneurs qui composent une application en unit\xe9s logiques pour une gestion et une d\xe9couverte plus faciles. \ud83d\ude80\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que Kubernetes ? \ud83e\udd14\\n\\nKubernetes, souvent abr\xe9g\xe9 en K8s, est une plateforme d\'orchestration de conteneurs qui permet de g\xe9rer des clusters de machines ex\xe9cutant des conteneurs. Il a \xe9t\xe9 initialement d\xe9velopp\xe9 par Google et est maintenant maintenu par la Cloud Native Computing Foundation (CNCF).\\n\\n### Architecture de Kubernetes \ud83c\udfd7\ufe0f\\n\\nL\'architecture de Kubernetes est compos\xe9e de plusieurs composants cl\xe9s :\\n\\n- **Master Node** : Le n\u0153ud ma\xeetre est responsable de la gestion du cluster. Il orchestre les t\xe2ches telles que le d\xe9ploiement des applications, la maintenance de l\'\xe9tat souhait\xe9 des applications, la mise \xe0 l\'\xe9chelle des applications et la mise \xe0 jour des applications.\\n- **Worker Nodes** : Les n\u0153uds de travail ex\xe9cutent les applications conteneuris\xe9es. Chaque n\u0153ud de travail contient les services n\xe9cessaires pour ex\xe9cuter les conteneurs et est g\xe9r\xe9 par le n\u0153ud ma\xeetre.\\n\\n![Architecture de Kubernetes](/img/k8s-architecture.png)\\n\\n### Composants principaux de Kubernetes \ud83d\udd27\\n\\n- **API Server** : L\'API Server est le point d\'entr\xe9e pour toutes les commandes Kubernetes. Il expose l\'API Kubernetes.\\n- **etcd** : etcd est un magasin de donn\xe9es cl\xe9-valeur distribu\xe9 qui stocke les donn\xe9es de configuration du cluster et l\'\xe9tat du cluster.\\n- **Scheduler** : Le Scheduler est responsable de la r\xe9partition des conteneurs sur les n\u0153uds de travail en fonction des ressources disponibles et des contraintes d\xe9finies.\\n- **Controller Manager** : Le Controller Manager ex\xe9cute les contr\xf4leurs qui surveillent l\'\xe9tat du cluster et effectuent les ajustements n\xe9cessaires pour atteindre l\'\xe9tat souhait\xe9.\\n- **Kubelet** : Kubelet est un agent qui s\'ex\xe9cute sur chaque n\u0153ud de travail et garantit que les conteneurs sont ex\xe9cut\xe9s dans un Pod.\\n- **Container Runtime** : Le Container Runtime est le logiciel responsable de l\'ex\xe9cution des conteneurs. Kubernetes prend en charge plusieurs runtimes de conteneurs, y compris Docker, containerd et CRI-O.\\n- **Kube-proxy** : Kube-proxy est un proxy r\xe9seau qui g\xe8re la mise en r\xe9seau des conteneurs et assure la communication entre les services.\\n\\n### Avantages de Kubernetes \ud83c\udf1f\\n\\n- **Portabilit\xe9** : Kubernetes est compatible avec plusieurs environnements de cloud, y compris AWS, Azure et Google Cloud, ainsi qu\'avec des environnements sur site.\\n- **Scalabilit\xe9** : Kubernetes permet de mettre \xe0 l\'\xe9chelle les applications de mani\xe8re horizontale (en ajoutant plus de r\xe9plicas) et verticale (en allouant plus de ressources \xe0 un conteneur).\\n- **R\xe9silience** : Kubernetes assure la haute disponibilit\xe9 des applications en red\xe9marrant automatiquement les conteneurs d\xe9faillants, en r\xe9pliquant les conteneurs et en \xe9quilibrant la charge du trafic r\xe9seau.\\n- **Gestion simplifi\xe9e** : Kubernetes automatise de nombreuses t\xe2ches de gestion des conteneurs, y compris le d\xe9ploiement, la mise \xe0 jour et la mise \xe0 l\'\xe9chelle des applications.\\n\\n## Conclusion \ud83c\udfaf\\n\\nKubernetes est une plateforme puissante et flexible pour l\'orchestration des conteneurs. En automatisant de nombreuses t\xe2ches de gestion des conteneurs, Kubernetes permet aux \xe9quipes de d\xe9veloppement et d\'exploitation de se concentrer sur la cr\xe9ation et la maintenance des applications, plut\xf4t que sur la gestion de l\'infrastructure sous-jacente.\\n\\nPour en savoir plus sur Kubernetes, consulter la [documentation officielle](https://kubernetes.io/fr/docs/concepts/)."},{"id":"/2025/01/12/02-network/nginx-proxy-manager","metadata":{"permalink":"/blog/2025/01/12/02-network/nginx-proxy-manager","source":"@site/blog/02-network/2025-01-12-nginx-proxy-manager.md","title":"Nginx Proxy Manager","description":"Pr\xe9sentation de Nginx Proxy Manager, ses fonctionnalit\xe9s et ses avantages, ainsi qu\'une d\xe9monstration d\'utilisation avec Docker.","date":"2025-01-12T00:00:00.000Z","tags":[{"inline":true,"label":"nginx-proxy-manager","permalink":"/blog/tags/nginx-proxy-manager"},{"inline":true,"label":"Docker","permalink":"/blog/tags/docker"},{"inline":true,"label":"Network","permalink":"/blog/tags/network"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":3.95,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Nginx Proxy Manager","description":"Pr\xe9sentation de Nginx Proxy Manager, ses fonctionnalit\xe9s et ses avantages, ainsi qu\'une d\xe9monstration d\'utilisation avec Docker.","tags":["nginx-proxy-manager","Docker","Network","Devops"]},"unlisted":false,"prevItem":{"title":"Introduction \xe0 Kubernetes","permalink":"/blog/2025/02/01/06-orchestration/k8s-introduction"},"nextItem":{"title":"DevOps Roadmap 2025","permalink":"/blog/2025/01/01/devops-roadmap-2025"}},"content":"Nginx Proxy Manager est une interface utilisateur graphique (GUI) pour g\xe9rer les proxys inverses Nginx. Il simplifie la gestion des proxys inverses, des certificats SSL et des redirections de trafic. Cet article pr\xe9sente Nginx Proxy Manager, explique ses fonctionnalit\xe9s et avantages, et fournit une d\xe9monstration d\'utilisation avec Docker.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que Nginx Proxy Manager ?\\n\\n![Nginx Proxy Manager](/img/nginx-proxy-manager.png)\\n\\n[Nginx Proxy Manager](https://nginxproxymanager.com/) est une interface utilisateur graphique (GUI) pour g\xe9rer les proxys inverses Nginx. Il permet de configurer facilement des proxys inverses, des certificats SSL et des redirections de trafic. Nginx Proxy Manager est con\xe7u pour \xeatre simple \xe0 utiliser et accessible aux utilisateurs non techniques.\\n\\n<details>\\n<summary>Qu\'est-ce qu\'un proxy ?</summary>\\n\\nUn proxy, \xe9galement connu sous le nom de proxy direct ou proxy de transfert, est un serveur qui agit comme un interm\xe9diaire entre un client (par exemple, un utilisateur ou un appareil) et un serveur de destination sur Internet. Voici un aper\xe7u d\xe9taill\xe9 de son fonctionnement :\\n\\n1. **Interception des requ\xeates** : Lorsqu\'un client souhaite acc\xe9der \xe0 une ressource sur Internet, il envoie une requ\xeate au proxy au lieu de se connecter directement au serveur de destination. Le proxy intercepte cette requ\xeate.\\n\\n2. **Filtrage et s\xe9curit\xe9** : Le proxy examine la requ\xeate pour s\'assurer qu\'elle respecte les politiques de s\xe9curit\xe9 et de filtrage d\xe9finies par l\'administrateur r\xe9seau. Il peut bloquer l\'acc\xe8s \xe0 certains sites web, filtrer les contenus inappropri\xe9s ou malveillants, et appliquer des r\xe8gles de s\xe9curit\xe9.\\n\\n3. **Anonymisation** : Le proxy peut masquer l\'adresse IP du client en utilisant sa propre adresse IP pour se connecter au serveur de destination. Cela permet de prot\xe9ger l\'identit\xe9 et la confidentialit\xe9 du client.\\n\\n4. **Mise en cache** : Le proxy peut mettre en cache les r\xe9ponses des serveurs de destination. Si un autre client demande la m\xeame ressource, le proxy peut fournir la r\xe9ponse mise en cache, ce qui r\xe9duit la charge sur le serveur de destination et am\xe9liore les temps de r\xe9ponse.\\n\\n5. **Transmission de la requ\xeate** : Si la requ\xeate est autoris\xe9e, le proxy la transmet au serveur de destination en utilisant sa propre adresse IP. Le serveur de destination r\xe9pond alors au proxy.\\n\\n6. **Retour de la r\xe9ponse** : Le proxy re\xe7oit la r\xe9ponse du serveur de destination, la filtre \xe0 nouveau si n\xe9cessaire, et la renvoie au client. Le client re\xe7oit ainsi la r\xe9ponse comme s\'il avait directement communiqu\xe9 avec le serveur de destination.\\n\\n</details>\\n\\n### Fonctionnalit\xe9s de Nginx Proxy Manager\\n\\n- **Gestion des proxys inverses** : Configurez facilement des proxys inverses pour vos applications web.\\n- **Certificats SSL** : G\xe9rez les certificats SSL pour s\xe9curiser vos sites web.\\n- **Redirections de trafic** : Configurez des redirections de trafic pour vos domaines et sous-domaines.\\n- **Interface utilisateur intuitive** : Utilisez une interface utilisateur graphique pour g\xe9rer vos configurations Nginx.\\n\\n### Avantages de Nginx Proxy Manager\\n\\n- **Simplicit\xe9** : Nginx Proxy Manager simplifie la gestion des proxys inverses et des certificats SSL.\\n- **Accessibilit\xe9** : L\'interface utilisateur graphique rend Nginx Proxy Manager accessible aux utilisateurs non techniques.\\n- **Flexibilit\xe9** : Nginx Proxy Manager prend en charge une vari\xe9t\xe9 de configurations et de sc\xe9narios d\'utilisation.\\n\\n## Utilisation de Nginx Proxy Manager avec Docker\\n\\nDans cette section, une d\xe9monstration est fournie pour montrer comment utiliser Nginx Proxy Manager avec Docker. Un conteneur Docker pour Nginx Proxy Manager sera cr\xe9\xe9 et un proxy inverse pour une application web sera configur\xe9.\\n\\n### Pr\xe9requis\\n\\n- Docker install\xe9 sur la machine\\n- Une application web \xe0 proxyfier\\n\\n### \xc9tapes\\n\\n1. **Cr\xe9er un fichier `docker-compose.yml`**\\n\\n   Cr\xe9ez un fichier `docker-compose.yml` avec le contenu suivant :\\n\\n   ```yaml\\n   version: \'3\'\\n   services:\\n     app:\\n       image: your-app-image\\n       container_name: your-app\\n       ports:\\n         - \\"8080:80\\"\\n     nginx-proxy-manager:\\n       image: jc21/nginx-proxy-manager:latest\\n       container_name: nginx-proxy-manager\\n       ports:\\n         - \\"80:80\\"\\n         - \\"81:81\\"\\n         - \\"443:443\\"\\n       volumes:\\n         - ./data:/data\\n         - ./letsencrypt:/etc/letsencrypt\\n   ```\\n\\n2. **D\xe9marrer les conteneurs Docker**\\n\\n   Ex\xe9cutez la commande suivante pour d\xe9marrer les conteneurs Docker :\\n\\n   ```bash\\n   docker-compose up -d\\n   ```\\n\\n3. **Acc\xe9der \xe0 l\'interface utilisateur de Nginx Proxy Manager**\\n\\n   Ouvrir le navigateur et acc\xe9der \xe0 `http://localhost:81`. Se connecter avec les informations d\'identification par d\xe9faut (`admin@example.com` / `changeme`) et changer le mot de passe.\\n\\n4. **Configurer un proxy inverse**\\n\\n   Dans l\'interface utilisateur de Nginx Proxy Manager, ajouter un nouveau proxy h\xf4te avec les param\xe8tres suivants :\\n\\n   - **Domain Names** : Entrer le nom de domaine ou l\'adresse IP de l\'application web.\\n   - **Forward Hostname / IP** : Entrer `app`.\\n   - **Forward Port** : Entrer `80`.\\n\\n   Enregistrer la configuration et acc\xe9der \xe0 l\'application web via le nom de domaine ou l\'adresse IP configur\xe9e.\\n\\n## Conclusion\\n\\nNginx Proxy Manager est un outil puissant et facile \xe0 utiliser pour g\xe9rer les proxys inverses Nginx, les certificats SSL et les redirections de trafic. En utilisant Docker, il est possible de d\xe9ployer et configurer rapidement Nginx Proxy Manager pour les applications web. Essayer Nginx Proxy Manager d\xe8s aujourd\'hui pour simplifier la gestion des proxys inverses et am\xe9liorer la s\xe9curit\xe9 des sites web."},{"id":"/2025/01/01/devops-roadmap-2025","metadata":{"permalink":"/blog/2025/01/01/devops-roadmap-2025","source":"@site/blog/2025-01-01-devops-roadmap-2025.md","title":"DevOps Roadmap 2025","description":"Pr\xe9sentation de ma roadmap DevOps personnelle 2025","date":"2025-01-01T00:00:00.000Z","tags":[{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"},{"inline":true,"label":"Roadmap","permalink":"/blog/tags/roadmap"}],"readingTime":0.85,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"DevOps Roadmap 2025","description":"Pr\xe9sentation de ma roadmap DevOps personnelle 2025","tags":["Devops","Roadmap"]},"unlisted":false,"prevItem":{"title":"Nginx Proxy Manager","permalink":"/blog/2025/01/12/02-network/nginx-proxy-manager"},"nextItem":{"title":"FastAPI","permalink":"/blog/2024/12/15/09-scripting/fastapi"}},"content":"Voici un r\xe9sum\xe9 de ma roadmap DevOps personnelle pour 2025. Cette roadmap est bas\xe9e sur mes exp\xe9riences et mes objectifs personnels. Elle est sujette \xe0 des changements et des mises \xe0 jour r\xe9guli\xe8res. N\'h\xe9sitez pas \xe0 me contacter si vous avez des suggestions ou des commentaires.\\n\\n\x3c!--truncate--\x3e\\n\\n# DevOps Roadmap\\n\\nimport IconTitle from \'@site/src/components/IconTitle\';\\n\\n![DevOps](/img/devops.png)\\n\\n## <IconTitle logo=\\"skill-icons:kubernetes\\" name=\\"06 Orchestration de conteneurs - Kubernetes & Docker Swarm\\"/>\\n\\n- Apprendre les composants de base comme, Deployment, Service, ConfigMap, Secret, StatefulSet\\n- CLI Kubernetes (Kubectl)\\n- Persistance des donn\xe9es avec les volumes K8s\\n- Externalisation des configurations avec ConfigMap et Secret\\n- Acc\xe8s aux applications avec les composants Ingress (Nginx)\\n\\n## <IconTitle logo=\\"skill-icons:prometheus\\" name=\\"07 Monitoring & Observabilit\xe9\\"/>\\n\\n- Grafana : Outil d\'analyse et de visualisation interactive\\n- Prometheus : Un outil de surveillance et d\'alerte populaire\\n- Loki : Une pile de gestion de logs populaire\\n\\n## <IconTitle logo=\\"skill-icons:terraform-light\\" name=\\"08 Infrastructure as Code\\"/>\\n\\n- Terraform est l\'outil de provisionnement d\'infrastructure le plus populaire\\n- Ansible est l\'outil de gestion de configuration le plus populaire"},{"id":"/2024/12/15/09-scripting/fastapi","metadata":{"permalink":"/blog/2024/12/15/09-scripting/fastapi","source":"@site/blog/09-scripting/2024-12-15-fastapi.md","title":"FastAPI","description":"FastAPI est un framework web moderne et rapide (hautes performances) pour la cr\xe9ation d\'API avec Python, bas\xe9 sur les annotations de types standard de Python.","date":"2024-12-15T00:00:00.000Z","tags":[{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"},{"inline":true,"label":"Python","permalink":"/blog/tags/python"}],"readingTime":3.51,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"FastAPI","description":"FastAPI est un framework web moderne et rapide (hautes performances) pour la cr\xe9ation d\'API avec Python, bas\xe9 sur les annotations de types standard de Python.","tags":["Devops","Python"]},"unlisted":false,"prevItem":{"title":"DevOps Roadmap 2025","permalink":"/blog/2025/01/01/devops-roadmap-2025"},"nextItem":{"title":"Dokku","permalink":"/blog/2024/11/30/06-orchestration/orchestration-dokku"}},"content":"FastAPI est un framework web moderne et rapide (hautes performances) pour la cr\xe9ation d\'API avec Python, bas\xe9 sur les annotations de types standard de Python.\\n\\n\x3c!--truncate--\x3e\\n\\n## Aper\xe7u\\n\\nFastAPI est un framework web moderne et rapide (hautes performances) pour la cr\xe9ation d\'API avec Python, bas\xe9 sur les annotations de types standard de Python. Il offre des performances \xe9lev\xe9es, comparables \xe0 celles de NodeJS et Go, gr\xe2ce \xe0 Starlette et Pydantic, ce qui en fait l\'un des frameworks Python les plus rapides disponibles. FastAPI permet d\'augmenter la vitesse de d\xe9veloppement des fonctionnalit\xe9s de 200% \xe0 300%, de r\xe9duire d\'environ 40% les erreurs humaines des d\xe9veloppeurs, et propose un excellent support des \xe9diteurs avec des compl\xe9tions.\\n\\n|                         |                                 |\\n| ----------------------- | ------------------------------- |\\n| Site Web                | [https://fastapi.tiangolo.com/](https://fastapi.tiangolo.com/) |\\n| GitHub Stars            | > 75k \u2b50                         |\\n| Nombre de contributeurs | 700                             |\\n| Licence                 | MIT                             |\\n\\n- Finalit\xe9 : Cr\xe9ation des API web avec Python\\n- Int\xe9r\xeat : FastAPI est facile \xe0 utiliser et \xe0 apprendre, r\xe9duit la duplication de code, et produit du code pr\xeat pour la production avec une documentation interactive bas\xe9e sur les standards OpenAPI et JSON Schema.\\n- Gouvernance : Assur\xe9e par une \xe9quipe de mainteneurs dont [tiangolo](https://github.com/tiangolo) est le cr\xe9ateur et mainteneurs principal. A cela s\'ajoute des contributeurs individuels, le projet est soutenu par la communaut\xe9.\\n\\n### FastAPI vs Flask\\n\\n**FastAPI** est reconnu pour sa rapidit\xe9 et ses performances \xe9lev\xe9es, gr\xe2ce \xe0 Starlette et Pydantic. Il utilise les annotations de types standard de Python, ce qui am\xe9liore la validation et la s\xe9rialisation des donn\xe9es. FastAPI g\xe9n\xe8re automatiquement une documentation interactive et est bas\xe9 sur les standards OpenAPI et JSON Schema. Il est id\xe9al pour les projets n\xe9cessitant des performances \xe9lev\xe9es et une validation stricte des donn\xe9es.\\n\\n**Flask**, en revanche, est un micro-framework l\xe9ger et flexible, facile \xe0 apprendre et \xe0 utiliser. Il offre une grande libert\xe9 aux d\xe9veloppeurs pour structurer leurs applications comme ils le souhaitent. Flask est extensible via de nombreuses extensions tierces, ce qui le rend adapt\xe9 aux projets de toutes tailles. Cependant, il ne fournit pas de validation de donn\xe9es int\xe9gr\xe9e ni de documentation automatique comme FastAPI.\\n\\nEn r\xe9sum\xe9, FastAPI est plus adapt\xe9 pour les projets n\xe9cessitant des performances \xe9lev\xe9es et une validation stricte des donn\xe9es, tandis que Flask est con\xe7u pour les projets n\xe9cessitant flexibilit\xe9 et simplicit\xe9.\\n\\n## Utilisation\\n\\nPour installer FastAPI, vous pouvez utiliser pip :\\n\\n```bash\\npip install \\"fastapi[standard]\\"\\n```\\n\\nL\'exemple ci dessous est une API simpliste de gestion des To-Do List permettant aux utilisateurs de cr\xe9\xe9r, lire, mettre \xe0 jour et supprimer des t\xe2ches. Les sp\xe9cifications sont les suivantes :\\n\\n1. Cr\xe9er une t\xe2che : Permettre aux utilisateurs de cr\xe9er une nouvelle t\xe2che avec un titre et une description.\\n2. Lire les t\xe2ches : R\xe9cup\xe9rer la liste de toutes les t\xe2ches ou une t\xe2che sp\xe9cifique par son identifiant.\\n3. Mettre \xe0 jour une t\xe2che : Modifier les d\xe9tails d\'une t\xe2che existante.\\n4. Supprimer une t\xe2che : Supprimer une t\xe2che par son identifiant.\\n\\nL\'exemple ci dessous m\xe9lange plusieurs fonctionnalit\xe9s de FastAPI.\\n\\n```python\\nfrom datetime import date\\nfrom typing import Optional\\nfrom fastapi import FastAPI, Query\\nfrom pydantic import BaseModel\\nimport uvicorn\\n\\napp = FastAPI()\\n\\n\\nclass Task(BaseModel):\\n    id: int\\n    title: str\\n    description: str\\n    date: date\\n\\n\\ntasks: list[Task] = []\\n\\n\\n@app.post(\\"/tasks/\\", response_model=Task)\\ndef create_task(task: Task):\\n    tasks.append(task)\\n    return task\\n\\n\\n@app.get(\\"/tasks/\\", response_model=list[Task])\\ndef read_tasks(skip: int = 0, limit: int = 10):\\n    return tasks[skip : skip + limit]\\n\\n\\n@app.get(\\"/tasks/{task_id}\\", response_model=Task)\\ndef read_task(task_id: int):\\n    for task in tasks:\\n        if task.id == task_id:\\n            return task\\n    return {\\"error\\": \\"Task not found\\"}\\n\\n\\n@app.put(\\"/tasks/{task_id}\\", response_model=Task)\\ndef update_task(task_id: int, updated_task: Task):\\n    for task in tasks:\\n        if task.id == task_id:\\n            task.title = updated_task.title\\n            task.description = updated_task.description\\n            task.date = updated_task.date\\n            return task\\n    return {\\"error\\": \\"Task not found\\"}\\n\\n\\n@app.delete(\\"/tasks/{task_id}\\")\\ndef delete_task(task_id: int):\\n    global tasks\\n    tasks = [task for task in tasks if task.id != task_id]\\n    return {\\"message\\": \\"Task deleted\\"}\\n\\n\\n@app.get(\\"/search_tasks\\", response_model=list[Task])\\ndef search_tasks(\\n    title: Optional[str] = Query(None), date: Optional[date] = Query(None)\\n):\\n    results = tasks\\n    if title:\\n        results = [task for task in results if title.lower() in task.title.lower()]\\n    if date:\\n        results = [task for task in results if task.date == date]\\n    return results\\n```\\n\\nPour lancer l\'application :\\n\\n```bash\\nfastapi run /path/to/file.py # production mode\\nfastapi dev /path/to/file.py # development mode\\n```\\n\\nEn plus de l\'API, FastAPI g\xe9n\xe8re automatiquement une documentation interactive accessible \xe0 l\'adresse `http://127.0.0.1:8000/docs`\\n\\n![documentation](/img/fast-api-documentation.png)"},{"id":"/2024/11/30/06-orchestration/orchestration-dokku","metadata":{"permalink":"/blog/2024/11/30/06-orchestration/orchestration-dokku","source":"@site/blog/06-orchestration/2024-11-30-orchestration-dokku.md","title":"Dokku","description":"Dokku est une plateforme open-source permettant le d\xe9ploiement, la gestion et la mise \xe0 l\'\xe9chelle des applications sur un serveur.","date":"2024-11-30T00:00:00.000Z","tags":[{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"},{"inline":true,"label":"Orchestration","permalink":"/blog/tags/orchestration"},{"inline":true,"label":"Alternatives","permalink":"/blog/tags/alternatives"}],"readingTime":4.18,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Dokku","description":"Dokku est une plateforme open-source permettant le d\xe9ploiement, la gestion et la mise \xe0 l\'\xe9chelle des applications sur un serveur.","tags":["Devops","Orchestration","Alternatives"]},"unlisted":false,"prevItem":{"title":"FastAPI","permalink":"/blog/2024/12/15/09-scripting/fastapi"},"nextItem":{"title":"Docker Compose","permalink":"/blog/2024/11/01/06-orchestration/docker-compose"}},"content":"Une alternative PAAS open source \xe0 Heroku [https://dokku.com/](https://dokku.com/)\\nDokku est une plateforme open-source permettant le d\xe9ploiement, la gestion et la mise \xe0 l\'\xe9chelle des applications sur un serveur. Inspir\xe9 par Heroku, il utilise une approche similaire pour le d\xe9ploiement d\'applications : le code se d\xe9ploie en effectuant un \\"push\\" vers un d\xe9p\xf4t Git sur le serveur. \xc0 la diff\xe9rence de Heroku, Dokku offre un contr\xf4le total sur l\'environnement de d\xe9ploiement. Ainsi, l\'infrastructure, le syst\xe8me d\'exploitation et les services (tels que les bases de donn\xe9es ou les files d\'attente de t\xe2ches) peuvent \xeatre personnalis\xe9s selon les besoins. Dokku s\'appuie sur Docker pour g\xe9rer les applications dans des conteneurs isol\xe9s, ce qui simplifie la gestion des applications et de leurs d\xe9pendances. Chaque \\"push\\" d\'une application \xe0 Dokku cr\xe9e un nouveau conteneur Docker.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Installation\\n\\n```shell\\n# download the installation script\\nwget -NP . <https://dokku.com/bootstrap.sh>\\n# run the installer\\nsudo DOKKU_TAG=v0.32.3 bash bootstrap.sh\\n# and your ssh key to the dokku user\\nPUBLIC_KEY=\\"your-public-key-contents-here\\"\\necho \\"$PUBLIC_KEY\\" | dokku ssh-keys:add admin\\n```\\n\\n## Premi\xe8re application\\n\\n```shell\\n# define global domains\\ndokku domains:set-global <your-domain>\\n# <your-domain> can be a rd party domain or a local domain like sonu-dev-gzsim.local\\n```\\n\\nSur la machine o\xf9 `dokku` est install\xe9\\n\\n```shell\\ndokku apps:create <app-name>\\nsudo dokku plugin:install <https://github.com/dokku/dokku-postgres.git>\\ndokku postgres:create railsdatabase\\ndokku postgres:link railsdatabase <app-name>\\n```\\n\\nSur la machine locale\\n\\n```shell\\ncd <app-name>\\ngit remote add dokku dokku@<your-domain>:<app-name>\\ngit push dokku main\\n```\\n\\n## Construire sa propre application\\n\\nDokku supporte plusieurs m\xe9thodes de build pour cr\xe9er des applications, chacun avec ses propres avantages sp\xe9cifiques :\\n\\n1. [**builder-dockerfile**](https://dokku.com/docs/deployment/builders/dockerfiles/): Cette m\xe9thode utilise un Dockerfile pour construire des applications via la commande `docker build`. Il donne un contr\xf4le maximal sur l\'environnement d\'ex\xe9cution de l\'application et sur la mani\xe8re dont l\'application est assembl\xe9e.\\n2. [**builder-herokuish**](https://dokku.com/docs/deployment/builders/herokuish-buildpacks/): Avec cette m\xe9thode, Dokku cr\xe9e des applications en utilisant la sp\xe9cification v2a Buildpack de Heroku via `gliderlabs/herokuish`. Il vous permet de profiter du m\xeame pipeline de build que Heroku, qui inclut le support pour de nombreux langages de programmation par d\xe9faut.\\n3. builder-lambda: Ce g\xe9n\xe9rateur construit des fonctions AWS Lambda dans un environnement simulant les temps d\'ex\xe9cution d\'AWS Lambda.\\n4. **builder-null**: Cette m\xe9thode ne fait rien pendant la phase de construction. C\'est utile pour les sc\xe9narios o\xf9 aucune construction n\'est n\xe9cessaire, comme le d\xe9ploiement d\'applications d\xe9j\xe0 compil\xe9es ou de conteneurs Docker.\\n5. **builder-pack**: Cette m\xe9thode utilise les Cloud Native Buildpacks pour construire des applications via l\'outil pack-cli. Les Cloud Native Buildpacks sont une norme ouverte qui \xe9tend les capacit\xe9s des Buildpacks classiques.\\n\\n## Automatiser le d\xe9ploiement via Github Actions\\n\\n```yaml\\nname: Deploy to Dokku (sonu-dev-gzsim)\\non:\\n    schedule:\\n    - cron: \'0 0 * * *\'\\n    workflow_dispatch:\\n    workflow_run:\\n    workflows: [ \\"Test build\\" ]\\n    types:\\n        - completed\\njobs:\\n    deploy:\\n    runs-on:\\n        group: default\\n    steps:\\n        - name: Cloning repo\\n        uses: actions/checkout@v4\\n        with:\\n            fetch-depth: 0\\n\\n        - name: Tailscale\\n        uses: tailscale/github-action@v2\\n        with:\\n            oauth-client-id: ${{ secrets.TS_OAUTH_CLIENT_ID }}\\n            oauth-secret: ${{ secrets.TS_OAUTH_SECRET }}\\n            tags: tag:server\\n\\n        - name: Push to dokku\\n        uses: dokku/github-action@master\\n        with:\\n            git_remote_url: \'ssh://dokku@100.65.237.90:22/rd25-robotics\'\\n            ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}\\n            branch: main\\n            git_push_flags: \'--force\'\\n\\n    if: ${{ github.event.workflow_run.conclusion == \'success\' }}\\n```\\n\\n## Astuces\\n\\n \u26a0\ufe0f Les astuces ci dessous correspondent **tr\xe8s certainement** \xe0 une incompr\xe9hension des m\xe9canismes de domain, proxy et reverse proxy\\n\\nPar d\xe9faut `dokku` d\xe9ploie l\u2019application sur une url construite comme suit : `http://<app-name>.<your-domain>` visiblement si le domaine est local (comme `sonu-dev-gzsim.local`) le reverse proxy ne fonctionne pas (la configuration `nginx` est \xe0 creuser) il est donc n\xe9cessaire de `disable` les domains avec la commande\\n\\n```shell\\ndokku domains:disable <app-name>\\n```\\n\\nCela aura pour effet de d\xe9sactiver le domaine pour l\u2019application en question. Elle tournera donc directement sur le port d\xe9fini al\xe9atoirement par `dokku`.\\n\xc0 chaque d\xe9ploiement, `dokku` construit un `dokker` pour g\xe9rer les applications de mani\xe8re isol\xe9e. Par d\xe9faut, les applications de type web doivent fournir leurs services sur le port `5000`. Par la suite, `dokku` s\u2019occupe de faire la redirection de port entre la machine et le container. Pour \xe9viter d\u2019avoir un port al\xe9atoire, il est possible de faire\\n\\n```shell\\ndokku ports:set <app-name> http:<machine-port>:<docker-port>\\n```\\n\\nAinsi, \xe0 chaque d\xe9ploiement, `dokku` redirigera le port de la machine vers le port du docker.\\nFinalement si vous souhaitez mettre en place une redirection comme `http://<your-domain>/<app-name>` vers l\u2019application il suffit de faire les modifications suivantes dans `nginx`\\nModifiez le fichier de configuration de Nginx pour votre site :\\n\\n```shell\\nsudo nano /etc/nginx/sites-available/your-config-file\\n```\\n\\nAjoutez la directive location dans votre configuration :\\n\\n```txt\\nserver { listen 80; server_name <your-domain>; location = <app-name> { return 301 http://$host:<machine-port>; } }\\n```\\n\\nCr\xe9ez un lien symbolique vers le fichier de configuration :\\n\\n```shell\\nsudo ln -s /etc/nginx/sites-available/your-config-file /etc/nginx/sites-enabled/\\n```\\n\\nV\xe9rifiez la configuration de Nginx :\\n\\n```shell\\nsudo nginx -t\\n```\\n\\nRed\xe9marrez Nginx pour appliquer les modifications :\\n\\n```shell\\nsudo systemctl restart nginx\\n```"},{"id":"/2024/11/01/06-orchestration/docker-compose","metadata":{"permalink":"/blog/2024/11/01/06-orchestration/docker-compose","source":"@site/blog/06-orchestration/2024-11-01-docker-compose.md","title":"Docker Compose","description":"Explication de Docker Compose","date":"2024-11-01T00:00:00.000Z","tags":[{"inline":true,"label":"Docker Compose","permalink":"/blog/tags/docker-compose"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"},{"inline":true,"label":"Orchestration","permalink":"/blog/tags/orchestration"}],"readingTime":10.23,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Docker Compose","description":"Explication de Docker Compose","tags":["Docker Compose","Devops","Orchestration"]},"unlisted":false,"prevItem":{"title":"Dokku","permalink":"/blog/2024/11/30/06-orchestration/orchestration-dokku"},"nextItem":{"title":"Containerization vs Virtualization","permalink":"/blog/2024/10/15/03-containerization/difference-conteneurisation-virtualisation"}},"content":"Docker Compose est un outil puissant qui permet de d\xe9finir et de g\xe9rer des applications multi-conteneurs Docker. Il utilise un fichier YAML pour configurer les services de l\'application. Ensuite, avec une seule commande, vous pouvez cr\xe9er et d\xe9marrer tous les services \xe0 partir de votre configuration.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que Docker Compose ?\\n\\nDocker Compose est un outil qui permet de d\xe9finir et de g\xe9rer des applications multi-conteneurs Docker. Il utilise un fichier YAML pour configurer les services de l\'application. Ensuite, avec une seule commande, vous pouvez cr\xe9er et d\xe9marrer tous les services \xe0 partir de votre configuration.\\n\\n## Exemple de fichier Docker Compose\\n\\nVoici un exemple de fichier `docker-compose.yml` pour une application web simple avec un service web et une base de donn\xe9es :\\n\\n```yaml\\nversion: \'3\'\\nservices:\\n  web:\\n    image: nginx:alpine\\n    ports:\\n      - \\"80:80\\"\\n  db:\\n    image: postgres:alpine\\n    environment:\\n      POSTGRES_DB: exampledb\\n      POSTGRES_USER: exampleuser\\n      POSTGRES_PASSWORD: examplepass\\n```\\n\\nDans cet exemple, nous avons deux services : `web` et `db`. Le service `web` utilise l\'image `nginx:alpine` et mappe le port 80 du conteneur au port 80 de l\'h\xf4te. Le service `db` utilise l\'image `postgres:alpine` et d\xe9finit quelques variables d\'environnement pour configurer la base de donn\xe9es.\\n\\n## Commandes Docker Compose\\n\\nVoici quelques commandes Docker Compose couramment utilis\xe9es :\\n\\n- `docker-compose up` : Cr\xe9e et d\xe9marre les conteneurs d\xe9finis dans le fichier `docker-compose.yml`.\\n- `docker-compose down` : Arr\xeate et supprime les conteneurs, les r\xe9seaux et les volumes cr\xe9\xe9s par `docker-compose up`.\\n- `docker-compose ps` : Affiche l\'\xe9tat des conteneurs d\xe9finis dans le fichier `docker-compose.yml`.\\n- `docker-compose logs` : Affiche les logs des conteneurs.\\n\\n## Sch\xe9ma explicatif\\n\\nVoici un sch\xe9ma expliquant comment Docker Compose fonctionne :\\n\\n![Sch\xe9ma Docker Compose](https://www.biaudelle.fr/wp-content/uploads/2021/07/docker-compose-archi.png)\\n\\n## D\xe9monstration pratique\\n\\nPour mieux comprendre l\'utilisation de Docker Compose, voici une d\xe9monstration pratique :\\n\\n```bash\\ndocker network create mynetwork\\ndocker-compose up -d\\ndocker-compose ps\\n```\\n\\nOuvrez votre navigateur et acc\xe9dez \xe0 `http://localhost`.\\n\\n```bash\\ndocker-compose down\\n```\\n\\n## Avantages cl\xe9s de Docker Compose\\n\\nL\'utilisation de Docker Compose offre plusieurs avantages qui simplifient le d\xe9veloppement, le d\xe9ploiement et la gestion des applications conteneuris\xe9es :\\n\\n- **Contr\xf4le simplifi\xe9** : Docker Compose vous permet de d\xe9finir et de g\xe9rer des applications multi-conteneurs dans un seul fichier YAML. Cela simplifie la t\xe2che complexe d\'orchestrer et de coordonner divers services, rendant plus facile la gestion et la r\xe9plication de votre environnement applicatif.\\n- **Collaboration efficace** : Les fichiers de configuration Docker Compose sont faciles \xe0 partager, facilitant la collaboration entre les d\xe9veloppeurs, les \xe9quipes d\'exploitation et les autres parties prenantes. Cette approche collaborative conduit \xe0 des flux de travail plus fluides, une r\xe9solution des probl\xe8mes plus rapide et une efficacit\xe9 globale accrue.\\n- **D\xe9veloppement rapide d\'applications** : Compose met en cache la configuration utilis\xe9e pour cr\xe9er un conteneur. Lorsque vous red\xe9marrez un service qui n\'a pas chang\xe9, Compose r\xe9utilise les conteneurs existants. La r\xe9utilisation des conteneurs signifie que vous pouvez apporter des modifications \xe0 votre environnement tr\xe8s rapidement.\\n- **Portabilit\xe9 entre les environnements** : Compose prend en charge les variables dans le fichier Compose. Vous pouvez utiliser ces variables pour personnaliser votre composition pour diff\xe9rents environnements ou diff\xe9rents utilisateurs.\\n- **Communaut\xe9 et support \xe9tendus** : Docker Compose b\xe9n\xe9ficie d\'une communaut\xe9 dynamique et active, ce qui signifie des ressources abondantes, des tutoriels et un support. Cet \xe9cosyst\xe8me communautaire contribue \xe0 l\'am\xe9lioration continue de Docker Compose et aide les utilisateurs \xe0 r\xe9soudre efficacement les probl\xe8mes.\\n\\nCompose peut \xeatre utilis\xe9 de nombreuses mani\xe8res diff\xe9rentes. Voici quelques cas d\'utilisation courants.\\n\\n### Environnements de d\xe9veloppement\\n\\nLorsque vous d\xe9veloppez des logiciels, la capacit\xe9 \xe0 ex\xe9cuter une application dans un environnement isol\xe9 et \xe0 interagir avec elle est cruciale. L\'outil en ligne de commande Compose peut \xeatre utilis\xe9 pour cr\xe9er l\'environnement et interagir avec lui.\\n\\nLe fichier Compose fournit un moyen de documenter et de configurer toutes les d\xe9pendances de service de l\'application (bases de donn\xe9es, files d\'attente, caches, API de services web, etc.). En utilisant l\'outil en ligne de commande Compose, vous pouvez cr\xe9er et d\xe9marrer un ou plusieurs conteneurs pour chaque d\xe9pendance avec une seule commande (`docker compose up`).\\n\\nEnsemble, ces fonctionnalit\xe9s offrent un moyen pratique de d\xe9marrer un projet. Compose peut r\xe9duire un \\"guide de d\xe9marrage pour les d\xe9veloppeurs\\" de plusieurs pages \xe0 un seul fichier Compose lisible par machine et quelques commandes.\\n\\n### Environnements de test automatis\xe9s\\n\\nUne partie importante de tout processus de d\xe9ploiement continu ou d\'int\xe9gration continue est la suite de tests automatis\xe9s. Les tests automatis\xe9s de bout en bout n\xe9cessitent un environnement dans lequel ex\xe9cuter les tests. Compose fournit un moyen pratique de cr\xe9er et de d\xe9truire des environnements de test isol\xe9s pour votre suite de tests. En d\xe9finissant l\'environnement complet dans un fichier Compose, vous pouvez cr\xe9er et d\xe9truire ces environnements en quelques commandes seulement.\\n\\n### D\xe9ploiements sur un seul h\xf4te\\n\\nCompose a traditionnellement \xe9t\xe9 ax\xe9 sur les flux de travail de d\xe9veloppement et de test, mais \xe0 chaque nouvelle version, nous progressons sur des fonctionnalit\xe9s plus orient\xe9es vers la production.\\n\\nPour plus de d\xe9tails sur l\'utilisation des fonctionnalit\xe9s orient\xe9es production, consultez [Compose en production](https://docs.docker.com/compose/production/).\\n\\n## Utilisation des secrets avec Docker Compose\\n\\nDocker Compose permet \xe9galement de g\xe9rer les secrets de mani\xe8re s\xe9curis\xe9e. Les secrets sont des informations sensibles telles que des mots de passe, des cl\xe9s API, etc., qui ne doivent pas \xeatre expos\xe9es dans le code source.\\n\\nVoici un exemple de configuration de secrets dans un fichier `docker-compose.yml` :\\n\\n```yaml\\nversion: \'3.7\'\\nservices:\\n  web:\\n    image: nginx:alpine\\n    secrets:\\n      - my_secret\\nsecrets:\\n  my_secret:\\n    file: ./my_secret.txt\\n```\\n\\nDans cet exemple, le service `web` utilise un secret nomm\xe9 `my_secret` qui est d\xe9fini dans le fichier `my_secret.txt`.\\n\\n## Support des GPU avec Docker Compose\\n\\nDocker Compose prend \xe9galement en charge l\'utilisation des GPU pour les applications n\xe9cessitant des capacit\xe9s de calcul intensif, telles que l\'apprentissage automatique et le traitement d\'images.\\n\\nVoici un exemple de configuration pour utiliser un GPU avec Docker Compose :\\n\\n```yaml\\nversion: \'3.8\'\\nservices:\\n  gpu_service:\\n    image: nvidia/cuda:10.2-base\\n    deploy:\\n      resources:\\n        reservations:\\n          devices:\\n            - capabilities: [gpu]\\n```\\n\\nDans cet exemple, le service `gpu_service` utilise l\'image `nvidia/cuda:10.2-base` et r\xe9serve un GPU pour le conteneur.\\n\\n\\n## Utilisation de la surveillance des fichiers avec Docker Compose\\n\\nDocker Compose permet \xe9galement de surveiller les modifications des fichiers et de red\xe9marrer automatiquement les services concern\xe9s. Cela est particuli\xe8rement utile pour les environnements de d\xe9veloppement.\\n\\nVoici un exemple de configuration de surveillance des fichiers dans un fichier `docker-compose.yml` :\\n\\n```yaml\\nversion: \'3.8\'\\nservices:\\n  web:\\n    image: nginx:alpine\\n    volumes:\\n      - ./src:/usr/share/nginx/html\\n    command: sh -c \\"nginx -g \'daemon off;\'\\"\\n    file_watch:\\n      watch: ./src\\n      action: restart\\n```\\n\\nDans cet exemple, le service `web` surveille les modifications dans le r\xe9pertoire `./src` et red\xe9marre automatiquement le service lorsque des modifications sont d\xe9tect\xe9es.\\n\\n## R\xe9seau dans Compose\\n\\n> **Important**\\n>\\n> La documentation de Docker se r\xe9f\xe8re et d\xe9crit les fonctionnalit\xe9s de Compose V2.\\n>\\n> \xc0 partir de juillet 2023, Compose V1 a cess\xe9 de recevoir des mises \xe0 jour et n\'est plus inclus dans les nouvelles versions de Docker Desktop. Compose V2 l\'a remplac\xe9 et est maintenant int\xe9gr\xe9 dans toutes les versions actuelles de Docker Desktop. Pour plus d\'informations, consultez [Migrer vers Compose V2](https://docs.docker.com/compose/migrate).\\n\\nPar d\xe9faut, Compose configure un seul [r\xe9seau](https://docs.docker.com/reference/cli/docker/network/create/) pour votre application. Chaque conteneur pour un service rejoint le r\xe9seau par d\xe9faut et est \xe0 la fois accessible par d\'autres conteneurs sur ce r\xe9seau et d\xe9couvrable par le nom du service.\\n\\n> **Remarque**\\n>\\n> Le r\xe9seau de votre application re\xe7oit un nom bas\xe9 sur le \\"nom du projet\\", qui est bas\xe9 sur le nom du r\xe9pertoire dans lequel il se trouve. Vous pouvez remplacer le nom du projet avec soit le [flag `--project-name`](https://docs.docker.com/reference/) soit la [variable d\'environnement `COMPOSE_PROJECT_NAME`](https://docs.docker.com/compose/environment-variables/envvars/#compose_project_name).\\n\\nPar exemple, supposons que votre application se trouve dans un r\xe9pertoire appel\xe9 `myapp`, et que votre `compose.yml` ressemble \xe0 ceci :\\n\\nLorsque vous ex\xe9cutez `docker compose up`, les actions suivantes se produisent :\\n\\n1.  Un r\xe9seau appel\xe9 `myapp_default` est cr\xe9\xe9.\\n2.  Un conteneur est cr\xe9\xe9 en utilisant la configuration de `web`. Il rejoint le r\xe9seau `myapp_default` sous le nom `web`.\\n3.  Un conteneur est cr\xe9\xe9 en utilisant la configuration de `db`. Il rejoint le r\xe9seau `myapp_default` sous le nom `db`.\\n\\nChaque conteneur peut maintenant rechercher le nom du service `web` ou `db` et obtenir l\'adresse IP appropri\xe9e du conteneur. Par exemple, le code de l\'application de `web` pourrait se connecter \xe0 l\'URL `postgres://db:5432` et commencer \xe0 utiliser la base de donn\xe9es Postgres.\\n\\nIl est important de noter la distinction entre `HOST_PORT` et `CONTAINER_PORT`. Dans l\'exemple ci-dessus, pour `db`, le `HOST_PORT` est `8001` et le port du conteneur est `5432` (par d\xe9faut pour postgres). La communication de service \xe0 service en r\xe9seau utilise le `CONTAINER_PORT`. Lorsque `HOST_PORT` est d\xe9fini, le service est \xe9galement accessible en dehors du swarm.\\n\\nDans le conteneur `web`, votre cha\xeene de connexion \xe0 `db` ressemblerait \xe0 `postgres://db:5432`, et depuis la machine h\xf4te, la cha\xeene de connexion ressemblerait \xe0 `postgres://{DOCKER_IP}:8001`, par exemple `postgres://localhost:8001` si votre conteneur s\'ex\xe9cute localement.\\n\\n### Mise \xe0 jour des conteneurs sur le r\xe9seau\\n\\nSi vous apportez une modification de configuration \xe0 un service et ex\xe9cutez `docker compose up` pour le mettre \xe0 jour, l\'ancien conteneur est supprim\xe9 et le nouveau rejoint le r\xe9seau sous une adresse IP diff\xe9rente mais avec le m\xeame nom. Les conteneurs en cours d\'ex\xe9cution peuvent rechercher ce nom et se connecter \xe0 la nouvelle adresse, mais l\'ancienne adresse cesse de fonctionner.\\n\\nSi des conteneurs ont des connexions ouvertes vers l\'ancien conteneur, elles sont ferm\xe9es. Il incombe au conteneur de d\xe9tecter cette condition, de rechercher \xe0 nouveau le nom et de se reconnecter.\\n\\n> **Astuce**\\n>\\n> R\xe9f\xe9rencez les conteneurs par nom, et non par IP, chaque fois que possible. Sinon, vous devrez constamment mettre \xe0 jour l\'adresse IP que vous utilisez.\\n\\n### R\xe9seau multi-h\xf4te\\n\\nLors du d\xe9ploiement d\'une application Compose sur un moteur Docker avec [le mode Swarm activ\xe9](https://docs.docker.com/engine/swarm/), vous pouvez utiliser le pilote int\xe9gr\xe9 `overlay` pour activer la communication multi-h\xf4te.\\n\\nLes r\xe9seaux overlay sont toujours cr\xe9\xe9s comme `attachable`. Vous pouvez \xe9ventuellement d\xe9finir la propri\xe9t\xe9 [`attachable`](https://docs.docker.com/reference/compose-file/networks/#attachable) sur `false`.\\n\\nConsultez la [section mode Swarm](https://docs.docker.com/engine/swarm/) pour savoir comment configurer un cluster Swarm, et le [guide de d\xe9marrage avec le r\xe9seau multi-h\xf4te](https://docs.docker.com/engine/network/tutorials/overlay/) pour en savoir plus sur les r\xe9seaux overlay multi-h\xf4te.\\n\\n### Sp\xe9cifier des r\xe9seaux personnalis\xe9s\\n\\nAu lieu d\'utiliser simplement le r\xe9seau d\'application par d\xe9faut, vous pouvez sp\xe9cifier vos propres r\xe9seaux avec la cl\xe9 de niveau sup\xe9rieur `networks`. Cela vous permet de cr\xe9er des topologies plus complexes et de sp\xe9cifier des [pilotes de r\xe9seau personnalis\xe9s](https://docs.docker.com/engine/extend/plugins_network/) et des options. Vous pouvez \xe9galement l\'utiliser pour connecter des services \xe0 des r\xe9seaux cr\xe9\xe9s en externe qui ne sont pas g\xe9r\xe9s par Compose.\\n\\nChaque service peut sp\xe9cifier \xe0 quels r\xe9seaux se connecter avec la cl\xe9 de niveau service `networks`, qui est une liste de noms r\xe9f\xe9rencant des entr\xe9es sous la cl\xe9 de niveau sup\xe9rieur `networks`.\\n\\nL\'exemple suivant montre un fichier Compose qui d\xe9finit deux r\xe9seaux personnalis\xe9s. Le service `proxy` est isol\xe9 du service `db`, car ils ne partagent pas de r\xe9seau en commun. Seul `app` peut parler aux deux.\\n\\nLes r\xe9seaux peuvent \xeatre configur\xe9s avec des adresses IP statiques en d\xe9finissant l\'[adresse ipv4 et/ou ipv6](https://docs.docker.com/reference/compose-file/services/#ipv4_address-ipv6_address) pour chaque r\xe9seau attach\xe9.\\n\\nLes r\xe9seaux peuvent \xe9galement recevoir un [nom personnalis\xe9](https://docs.docker.com/reference/compose-file/networks/#name) :\\n\\n### Configurer le r\xe9seau par d\xe9faut\\n\\nAu lieu de, ou en plus de, sp\xe9cifier vos propres r\xe9seaux, vous pouvez \xe9galement modifier les param\xe8tres du r\xe9seau par d\xe9faut de l\'application en d\xe9finissant une entr\xe9e sous `networks` nomm\xe9e `default` :\\n\\n### Utiliser un r\xe9seau pr\xe9existant\\n\\nSi vous souhaitez que vos conteneurs rejoignent un r\xe9seau pr\xe9existant, utilisez l\'option [`external`](https://docs.docker.com/reference/compose-file/networks/#external)\\n\\nAu lieu de tenter de cr\xe9er un r\xe9seau appel\xe9 `[projectname]_default`, Compose recherche un r\xe9seau appel\xe9 `my-pre-existing-network` et connecte les conteneurs de votre application \xe0 celui-ci.\\n\\n\\n## Conclusion\\n\\nDocker Compose est un outil puissant pour g\xe9rer des applications multi-conteneurs. Il simplifie la configuration, l\'isolation des environnements et la portabilit\xe9 des applications. En utilisant Docker Compose, vous pouvez facilement d\xe9finir et g\xe9rer des environnements de d\xe9veloppement, de test et de mise en sc\xe8ne, ainsi que des d\xe9ploiements de production simples.\\n\\nPour en savoir plus sur Docker Compose, vous pouvez consulter la [documentation officielle](https://docs.docker.com/compose/)."},{"id":"/2024/10/15/03-containerization/difference-conteneurisation-virtualisation","metadata":{"permalink":"/blog/2024/10/15/03-containerization/difference-conteneurisation-virtualisation","source":"@site/blog/03-containerization/2024-10-15-difference-conteneurisation-virtualisation.md","title":"Containerization vs Virtualization","description":"Comparaison entre Docker et les machines virtuelles (VM) en termes de taille d\'image, de vitesse et de compatibilit\xe9.","date":"2024-10-15T00:00:00.000Z","tags":[{"inline":true,"label":"Containerization","permalink":"/blog/tags/containerization"},{"inline":true,"label":"Virtualization","permalink":"/blog/tags/virtualization"},{"inline":true,"label":"Docker","permalink":"/blog/tags/docker"},{"inline":true,"label":"VM","permalink":"/blog/tags/vm"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":1.38,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Containerization vs Virtualization","description":"Comparaison entre Docker et les machines virtuelles (VM) en termes de taille d\'image, de vitesse et de compatibilit\xe9.","tags":["Containerization","Virtualization","Docker","VM","Devops"]},"unlisted":false,"prevItem":{"title":"Docker Compose","permalink":"/blog/2024/11/01/06-orchestration/docker-compose"},"nextItem":{"title":"GitHub GHCR","permalink":"/blog/2024/09/31/03-containerization/ghrc"}},"content":"Docker et les machines virtuelles (VM) sont des outils de virtualisation, mais ils fonctionnent diff\xe9remment. Docker virtualise la couche des applications du syst\xe8me d\'exploitation, utilisant le noyau de l\'h\xf4te, tandis qu\'une VM virtualise l\'ensemble du syst\xe8me d\'exploitation, incluant son propre noyau et sa couche d\'applications. Cette diff\xe9rence entra\xeene plusieurs distinctions majeures.\\n\\n\x3c!--truncate--\x3e\\n\\nDocker et les machines virtuelles (VM) sont des outils de virtualisation, mais ils fonctionnent diff\xe9remment. Docker virtualise la couche des applications du syst\xe8me d\'exploitation, utilisant le noyau de l\'h\xf4te, tandis qu\'une VM virtualise l\'ensemble du syst\xe8me d\'exploitation, incluant son propre noyau et sa couche d\'applications. Cette diff\xe9rence entra\xeene plusieurs distinctions majeures.\\n\\nLes images Docker sont beaucoup plus petites et rapides \xe0 t\xe9l\xe9charger que les images de VM, car elles n\'ont qu\'une seule couche \xe0 impl\xe9menter. Les images Docker sont g\xe9n\xe9ralement de quelques m\xe9gaoctets, tandis que les images de VM peuvent atteindre plusieurs gigaoctets.\\n\\nLes conteneurs Docker d\xe9marrent beaucoup plus rapidement que les VM, car ils n\'ont besoin de d\xe9marrer que la couche des applications, contrairement aux VM qui doivent d\xe9marrer l\'ensemble du syst\xe8me d\'exploitation.\\n\\nDocker pr\xe9sente des probl\xe8mes de compatibilit\xe9. Une image de VM de n\'importe quel syst\xe8me d\'exploitation peut \xeatre ex\xe9cut\xe9e sur n\'importe quel h\xf4te, mais ce n\'est pas le cas pour Docker. Par exemple, une image Docker bas\xe9e sur Linux ne peut pas utiliser le noyau Windows directement. Cependant, Docker Desktop permet de contourner ce probl\xe8me en utilisant une couche hyperviseur avec une distribution Linux l\xe9g\xe8re pour fournir le noyau n\xe9cessaire.\\n\\nEn r\xe9sum\xe9, Docker est plus l\xe9ger et rapide, mais moins compatible que les VM. Docker Desktop permet de d\xe9velopper localement sur Windows ou Mac en ex\xe9cutant des conteneurs bas\xe9s sur Linux."},{"id":"/2024/09/31/03-containerization/ghrc","metadata":{"permalink":"/blog/2024/09/31/03-containerization/ghrc","source":"@site/blog/03-containerization/2024-09-31-ghrc.md","title":"GitHub GHCR","description":"GitHub Container Registry (GHCR) est un service d\'h\xe9bergement de packages logiciels propos\xe9 par GitHub, permettant aux utilisateurs de stocker des packages priv\xe9s ou publics et de les utiliser comme d\xe9pendances dans leurs projets. Compatible avec plusieurs langages de programmation, GitHub Packages propose des registres pour des gestionnaires de packages tels que npm, RubyGems, Maven, Gradle, Docker, et NuGet. L\'authentification sur GitHub Packages se fait exclusivement via un \\"personal access token (classic)\\". Les utilisateurs doivent disposer de ce token pour effectuer des op\xe9rations telles que la publication, l\'installation et la suppression de packages, qu\'ils soient publics, priv\xe9s ou internes. Pour les packages priv\xe9s, GitHub Packages applique des limites de stockage et de transfert de donn\xe9es en fonction du plan du compte. La gestion des packages peut \xeatre r\xe9alis\xe9e \xe0 travers l\'interface utilisateur GitHub ou via l\'API REST. Des webhooks peuvent \xe9galement \xeatre configur\xe9s pour suivre des \xe9v\xe9nements li\xe9s aux packages, comme la publication ou la mise \xe0 jour.","date":"2024-10-01T00:00:00.000Z","tags":[{"inline":true,"label":"Containerization","permalink":"/blog/tags/containerization"},{"inline":true,"label":"Registry","permalink":"/blog/tags/registry"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":4.22,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"GitHub GHCR","tags":["Containerization","Registry","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Containerization vs Virtualization","permalink":"/blog/2024/10/15/03-containerization/difference-conteneurisation-virtualisation"},"nextItem":{"title":"Pratiques recommand\xe9es pour Docker","permalink":"/blog/2024/08/30/03-containerization/docker-best-practices"}},"content":"GitHub Container Registry (GHCR) est un service d\'h\xe9bergement de packages logiciels propos\xe9 par GitHub, permettant aux utilisateurs de stocker des packages priv\xe9s ou publics et de les utiliser comme d\xe9pendances dans leurs projets. Compatible avec plusieurs langages de programmation, GitHub Packages propose des registres pour des gestionnaires de packages tels que npm, RubyGems, Maven, Gradle, Docker, et NuGet. L\'authentification sur GitHub Packages se fait exclusivement via un \\"personal access token (classic)\\". Les utilisateurs doivent disposer de ce token pour effectuer des op\xe9rations telles que la publication, l\'installation et la suppression de packages, qu\'ils soient publics, priv\xe9s ou internes. Pour les packages priv\xe9s, GitHub Packages applique des limites de stockage et de transfert de donn\xe9es en fonction du plan du compte. La gestion des packages peut \xeatre r\xe9alis\xe9e \xe0 travers l\'interface utilisateur GitHub ou via l\'API REST. Des webhooks peuvent \xe9galement \xeatre configur\xe9s pour suivre des \xe9v\xe9nements li\xe9s aux packages, comme la publication ou la mise \xe0 jour.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que GitHub GHCR?\\n\\nGitHub Container Registry (GHCR) est un service d\'h\xe9bergement de conteneurs Docker propos\xe9 par GitHub. Il permet aux utilisateurs de stocker, g\xe9rer et distribuer des images Docker en toute s\xe9curit\xe9. GHCR est int\xe9gr\xe9 \xe0 GitHub, ce qui facilite l\'utilisation des conteneurs dans les workflows de d\xe9veloppement et de d\xe9ploiement.\\n\\n## Pourquoi utiliser GitHub GHCR?\\n\\nL\'utilisation de GitHub GHCR pr\xe9sente plusieurs avantages :\\n\\n1. **S\xe9curit\xe9** : GHCR offre des fonctionnalit\xe9s de s\xe9curit\xe9 avanc\xe9es, telles que l\'authentification et l\'autorisation bas\xe9es sur les tokens d\'acc\xe8s personnels (PAT). Les images peuvent \xeatre priv\xe9es ou publiques, et les utilisateurs peuvent contr\xf4ler l\'acc\xe8s aux images en fonction de leurs besoins.\\n\\n2. **Int\xe9gration avec GitHub** : GHCR est \xe9troitement int\xe9gr\xe9 \xe0 GitHub, ce qui permet aux utilisateurs de g\xe9rer leurs images Docker directement depuis leurs d\xe9p\xf4ts GitHub. Les workflows GitHub Actions peuvent \xeatre utilis\xe9s pour automatiser la cr\xe9ation, le test et le d\xe9ploiement des images Docker.\\n\\n3. **Gestion des versions** : GHCR prend en charge la gestion des versions des images Docker, ce qui permet aux utilisateurs de suivre les modifications apport\xe9es aux images et de revenir \xe0 des versions ant\xe9rieures si n\xe9cessaire.\\n\\n4. **Suivi des \xe9v\xe9nements** : GHCR permet de configurer des webhooks pour suivre les \xe9v\xe9nements li\xe9s aux images Docker, tels que la publication, la mise \xe0 jour et la suppression. Cela permet aux utilisateurs de rester inform\xe9s des modifications apport\xe9es aux images et de r\xe9agir en cons\xe9quence.\\n\\n## Exemple de workflow pour utiliser GitHub GHCR\\n\\nLe workflow suppose que vous avez un `Dockerfile` \xe0 la racine du d\xe9p\xf4t. Ce `Dockerfile` doit r\xe9ussir la commande de `build` avec succ\xe8s\\n\\n### Cr\xe9ez un fichier YAML pour le Workflow\\n\\nCr\xe9ez un fichier YAML (par exemple, `docker-publish.yml`) dans le r\xe9pertoire `.github/workflows/` de votre d\xe9p\xf4t avec le contenu suivant :\\n\\n```yaml\\nname: Create and publish a Docker image\\n\\non:\\n    push:\\n    branches: [\'release\']\\n\\nenv:\\n    REGISTRY: ghcr.io\\n    IMAGE_NAME: ${{ github.repository }}\\n\\njobs:\\n    build-and-push-image:\\n    runs-on: ubuntu-latest\\n\\n    permissions:\\n        contents: read\\n        packages: write\\n\\n    steps:\\n        - name: Checkout repository\\n        uses: actions/checkout@v4\\n\\n        - name: Log in to the Container registry\\n        uses: docker/login-action@65b78e6e13532edd9afa3aa52ac7964289d1a9c1\\n        with:\\n            registry: ${{ env.REGISTRY }}\\n            username: ${{ github.actor }}\\n            password: ${{ secrets.GITHUB_TOKEN }}\\n\\n        - name: Extract metadata (tags, labels) for Docker\\n        id: meta\\n        uses: docker/metadata-action@9ec57ed1fcdbf14dcef7dfbe97b2010124a938b7\\n        with:\\n            images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\\n\\n        - name: Build and push Docker image\\n        uses: docker/build-push-action@f2a1d5e99d037542a71f64918e516c093c6f3fc4\\n        with:\\n            context: .\\n            push: true\\n            tags: ${{ steps.meta.outputs.tags }}\\n            labels: ${{ steps.meta.outputs.labels }}\\n```\\n\\n### Configurez les Options du Workflow\\n\\nDans le fichier YAML, vous pouvez personnaliser les options suivantes selon vos besoins :\\n\\n- `branches`: Modifiez la branche d\xe9clenchant le workflow.\\n- `REGISTRY` et `IMAGE_NAME`: Modifiez-les si vous souhaitez utiliser un autre registre ou nom d\'image.\\n- `permissions`: Ajustez les autorisations en fonction de vos besoins.\\n\\n**Enregistrez et Poussez vos Modifications**\\nEnregistrez les modifications dans le fichier YAML et poussez-les vers la branche \\"release\\" de votre d\xe9p\xf4t GitHub.\\n\\n```shell\\ngit add .github/workflows/docker-publish.yml\\ngit commit -m \\"Ajout du workflow de publication Docker\\"\\ngit push origin release\\n```\\n\\n### Utilisation d\u2019un package GHCR\\n\\nUne fois d\xe9ploy\xe9, le package s\u2019utilise comme n\u2019importe quel docker\\n\\n```shell\\ndocker pull ghcr.io/{USER}/{REPO-NAME}:master\\n```\\n\\n\ud83d\udca1 L\u2019utilisation des Github GHCR entraine des consommations d\u2019espace. Le CATIE a le droit \xe0 2Gb de stockage sur GHCR et 10Gb de transit par mois. Au del\xe0 de ces limites, nous sommes factur\xe9s.\\nL\u2019utilisation (sous n\u2019importe quelle forme) de GHCR sur des d\xe9p\xf4ts **publics** est totalement gratuite Sur des d\xe9p\xf4ts priv\xe9s : le pull via des actions est gratuit. Pour les actions `self-hosted` le pull est gratuit si l\u2019action est authentifi\xe9e par le `GITHUB_TOKEN` et non un PAT.\\n\\nVoici un exemple d\u2019utilisation sans co\xfbt associ\xe9\\n\\n```yaml\\nname: Run in container from GHCR\\n\\non: [ push ]\\n\\njobs:\\n    myJob:\\n    runs-on: ubuntu-latest\\n    container:\\n        image: ghcr.io/sedelpeuch/github-ghcr-test:master\\n    steps:\\n\\n        - name: Checkout code\\n        uses: actions/checkout@v2\\n\\n        - name: Run a command\\n        run: echo \\"Running inside the container\\"\\n```\\n\\nL\u2019image [ghcr.io/sedelpeuch/github-ghcr-test:master](<http://ghcr.io/sedelpeuch/github-ghcr-test:master>) est priv\xe9e, l\u2019acc\xe8s est possible sans donner de PAT gr\xe2ce \xe0 l\u2019authentification par jeton automatique qui poss\xe8de la lecture des packages priv\xe9s [https://docs.github.com/fr/actions/security-guides/automatic-token-authentication#permissions-for-the-github_token](https://docs.github.com/fr/actions/security-guides/automatic-token-authentication#permissions-for-the-github_token)"},{"id":"/2024/08/30/03-containerization/docker-best-practices","metadata":{"permalink":"/blog/2024/08/30/03-containerization/docker-best-practices","source":"@site/blog/03-containerization/2024-08-30-docker-best-practices.md","title":"Pratiques recommand\xe9es pour Docker","description":"L\'adoption de Docker augmente constamment et beaucoup le connaissent, mais tout le monde n\'utilise pas Docker selon les meilleures pratiques.","date":"2024-08-30T00:00:00.000Z","tags":[{"inline":true,"label":"Containerization","permalink":"/blog/tags/containerization"},{"inline":true,"label":"Docker","permalink":"/blog/tags/docker"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":4.47,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Pratiques recommand\xe9es pour Docker","description":"L\'adoption de Docker augmente constamment et beaucoup le connaissent, mais tout le monde n\'utilise pas Docker selon les meilleures pratiques.","tags":["Containerization","Docker","Devops"]},"unlisted":false,"prevItem":{"title":"GitHub GHCR","permalink":"/blog/2024/09/31/03-containerization/ghrc"},"nextItem":{"title":"D\xe9bogage des conteneurs Docker","permalink":"/blog/2024/08/15/03-containerization/debugging-docker-containers"}},"content":"\x3c!--truncate--\x3e\\n\\n## Utilisez une image Docker officielle et v\xe9rifi\xe9e comme image de base, chaque fois disponible\\n\\nDisons que vous d\xe9veloppez une application Node.js et que vous souhaitez la cr\xe9er et l\'ex\xe9cuter en tant qu\'image Docker.\\n\\nAu lieu de prendre une image du syst\xe8me d\'exploitation de base et d\'installer Node.js, NPM et tous les autres outils dont vous avez besoin pour votre application, utilisez l\'image de node officiel pour votre application.\\n\\n## Utilisez des versions d\'image docker sp\xe9cifiques\\n\\nD\'accord, nous avons donc s\xe9lectionn\xe9 l\'image de base, mais maintenant lorsque nous construisons notre image d\'applications \xe0 partir de ce Dockerfile, il utilisera toujours la derni\xe8re balise de l\'image de n\u0153ud.\\n\\nAinsi, au lieu d\'une \xe9tiquette d\'image al\xe9atoire, vous souhaitez fixer la version, et tout comme vous d\xe9ployez votre propre application avec une version sp\xe9cifique, vous souhaitez utiliser l\'image officielle avec une version sp\xe9cifique.\\n\\n## Utiliser des images officielles de petite taille\\n\\nLors du choix d\'une image Node.js, vous verrez qu\'il y a en fait plusieurs images officielles. Non seulement avec diff\xe9rents num\xe9ros de version mais aussi avec diff\xe9rentes distributions de syst\xe8mes d\'exploitation:\\n\\n1) Taille de l\'image : si l\'image est bas\xe9e sur une distribution de syst\xe8me d\'exploitation \xe0 part enti\xe8re comme Ubuntu ou Centos, vous aurez un tas d\'outils d\xe9j\xe0 emball\xe9s dans l\'image. Ainsi, la taille de l\'image sera plus grande, mais vous n\'avez pas besoin de la plupart de ces outils dans vos images d\'application.\\n\\n2) Probl\xe8me de s\xe9curit\xe9 : avec de nombreux outils install\xe9s \xe0 l\'int\xe9rieur, vous devez consid\xe9rer l\'aspect de s\xe9curit\xe9. Parce que ces images de base contiennent g\xe9n\xe9ralement [des centaines de vuln\xe9rabilit\xe9s connues](https://snyk.io/blog/openSourcesEcurity-2020Survey/) et cr\xe9ent essentiellement une plus grande surface d\'attaque \xe0 votre image d\'application.\\n\\nAinsi, la meilleure pratique ici serait de s\xe9lectionner une image avec une version sp\xe9cifique bas\xe9e sur une distribution plus maigre comme Alpine.\\n\\n## Optimiser la mise en cache pour les couches d\'image lors de la construction d\'une image\\n\\n1) Que sont les layer d\'image? Une image Docker est construite sur la base d\'un dockerfile.\\n\\nEt dans un dockerfile, chaque commande ou instruction cr\xe9e un layer d\'image.\\n\\nAinsi, lorsque nous utilisons une image de base d\'alpine, il a d\xe9j\xe0 des layers, car il a d\xe9j\xe0 \xe9t\xe9 construit en utilisant son propre dockerfile. Dans notre dockerfile, nous avons quelques autres commandes qui ajouteront chacune un nouveau layer \xe0 cette image.\\n\\nAinsi, lorsque vous reconstruisez votre image, si votre Dockerfile n\'a pas chang\xe9, Docker n\'utilisera que les layers en cache pour construire l\'image.\\n\\nAvantages des layers d\'image en cache:\\n\\n- Contruction d\'image plus rapide\\n- Push et pull plus rapides de nouvelles versions d\'image: Si je pull une nouvelle version d\'image de la m\xeame application et, disons, 2 nouveaux layers ont \xe9t\xe9 ajout\xe9es dans la nouvelle version: seule la nouvelle version des layers ajout\xe9es seront t\xe9l\xe9charg\xe9es Les autres sont d\xe9j\xe0 mis en cache localement par Docker.\\n\\nOptimiser la mise en cache : une fois qu\'un layer change, tous les layers suivants doivent \xe9galement \xeatre recr\xe9\xe9es. En d\'autres termes: lorsque vous modifiez le contenu d\'une ligne dans le dockerfile, les caches de toutes les lignes ou layers suivantes seront invalid\xe9s.\\n\\nAinsi, la r\xe8gle ici et la meilleure pratique est: placez vos commandes dans le Dockerfile du moins au plus fr\xe9quemment modif\xe9.\\n\\n## \xe0 l\'aide d\'un fichier .dockerignore\\n\\nC\'est assez simple. Nous cr\xe9ons simplement ce fichier .dockerignore et r\xe9pertorions tous les fichiers et dossiers que nous voulons \xeatre ignor\xe9s, et lors de la cr\xe9ation de l\'image, Docker examinera le contenu et ignorera tout ce qui est sp\xe9cifi\xe9 \xe0 l\'int\xe9rieur.\\n\\n## Utilisez des versions multi-\xe9tages\\n\\nMaintenant, disons qu\'il existe un outil dans votre projet dont vous avez besoin pour construire l\'image mais vous n\'en avez pas besoin dans l\'image finale pour ex\xe9cuter leapplication.\\n\\nSupposons que vous conserviez ces artefacts dans votre image finale, m\xeame s\'ils sont absolument inutiles pour ex\xe9cuter l\'application. Dans ce cas, cela entra\xeenera \xe0 nouveau une augmentation de la taille de l\'image et une augmentation de la surface d\'attaque.\\n\\nPour cela, vous pouvez utiliser ce qu\'on appelle les constructions \xe0 plusieurs \xe9tages\\n\\nLa fonction de construction en plusieurs \xe9tapes vous permet d\'utiliser plusieurs images temporaires pendant le processus de construction, mais ne conserve que la derni\xe8re image comme artefact final.\\n\\n## Utilisez l\'utilisateur le moins privil\xe9gi\xe9\\n\\nMaintenant, lorsque nous cr\xe9ons cette image et que nous l\'ex\xe9cutons finalement en tant que conteneur, quel utilisateur du syst\xe8me d\'exploitation sera utilis\xe9 pour d\xe9marrer l\'application \xe0 l\'int\xe9rieur? Par d\xe9faut, lorsqu\'un DockerFile ne sp\xe9cifie pas un utilisateur, il utilise un utilisateur root. Mais en r\xe9alit\xe9, il n\'y a surtout aucune raison d\'ex\xe9cuter des conteneurs avec des privil\xe8ges root.\\n\\nCela introduit essentiellement un probl\xe8me de s\xe9curit\xe9 car lorsque le conteneur commence sur l\'h\xf4te, il aura potentiellement un acc\xe8s root sur l\'h\xf4te Docker.\\n\\nPour \xe9viter cela, la meilleure pratique consiste \xe0 cr\xe9er simplement un utilisateur d\xe9di\xe9 et un groupe d\xe9di\xe9 dans l\'image Docker pour ex\xe9cuter l\'application et \xe9galement ex\xe9cuter l\'application \xe0 l\'int\xe9rieur du conteneur avec cet utilisateur.\\n\\n## Scannez vos images pour les vuln\xe9rabilit\xe9s de s\xe9curit\xe9\\n\\nEnfin, comment s\'assurer et valider que l\'image que vous construisez a peu ou pas de vuln\xe9rabilit\xe9s de s\xe9curit\xe9 ?\\n\\nLa meilleure pratique est, une fois que vous avez construit l\'image, la scannez pour des vuln\xe9rabilit\xe9s de s\xe9curit\xe9 \xe0 l\'aide de la commande docker scan.\\n\\nEn arri\xe8re-plan, Docker utilise en fait un service appel\xe9 SNYK pour faire la num\xe9risation de la vuln\xe9rabilit\xe9 des images. Le scan utilise une base de donn\xe9es de vuln\xe9rabilit\xe9s, qui est constamment mise \xe0 jour."},{"id":"/2024/08/15/03-containerization/debugging-docker-containers","metadata":{"permalink":"/blog/2024/08/15/03-containerization/debugging-docker-containers","source":"@site/blog/03-containerization/2024-08-15-debugging-docker-containers.md","title":"D\xe9bogage des conteneurs Docker","description":"Guide pour d\xe9boguer les conteneurs Docker en utilisant des commandes de base et des options avanc\xe9es.","date":"2024-08-15T00:00:00.000Z","tags":[{"inline":true,"label":"Docker","permalink":"/blog/tags/docker"},{"inline":true,"label":"Debugging","permalink":"/blog/tags/debugging"},{"inline":true,"label":"Containers","permalink":"/blog/tags/containers"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":2.28,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"D\xe9bogage des conteneurs Docker","description":"Guide pour d\xe9boguer les conteneurs Docker en utilisant des commandes de base et des options avanc\xe9es.","tags":["Docker","Debugging","Containers","Devops"]},"unlisted":false,"prevItem":{"title":"Pratiques recommand\xe9es pour Docker","permalink":"/blog/2024/08/30/03-containerization/docker-best-practices"},"nextItem":{"title":"Les containers Docker","permalink":"/blog/2024/07/30/03-containerization/docker-containers"}},"content":"Le d\xe9bogage des conteneurs Docker est une comp\xe9tence essentielle pour tout d\xe9veloppeur ou administrateur syst\xe8me travaillant avec des environnements conteneuris\xe9s. Docker offre une vari\xe9t\xe9 de commandes et d\'options pour aider \xe0 identifier et r\xe9soudre les probl\xe8mes qui peuvent survenir dans les conteneurs. Dans cet article, nous allons explorer certaines des commandes de base et des techniques avanc\xe9es pour d\xe9boguer les conteneurs Docker.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Commandes de base pour le d\xe9bogage\\n\\n### docker ps\\n\\nLa commande `docker ps` est utilis\xe9e pour lister les conteneurs en cours d\'ex\xe9cution. Vous pouvez utiliser l\'option `-a` pour afficher tous les conteneurs, qu\'ils soient en cours d\'ex\xe9cution ou arr\xeat\xe9s.\\n\\n```bash\\ndocker ps\\ndocker ps -a\\n```\\n\\n### docker logs\\n\\nLa commande `docker logs` permet de visualiser les journaux d\'un conteneur. Cela peut \xeatre tr\xe8s utile pour identifier les erreurs ou les comportements inattendus.\\n\\n```bash\\ndocker logs <container_id>\\n```\\n\\nVous pouvez \xe9galement utiliser le nom du conteneur \xe0 la place de l\'ID.\\n\\n### docker exec\\n\\nLa commande `docker exec` permet d\'ex\xe9cuter des commandes \xe0 l\'int\xe9rieur d\'un conteneur en cours d\'ex\xe9cution. Cela peut \xeatre utile pour naviguer dans le syst\xe8me de fichiers du conteneur, v\xe9rifier les configurations ou ex\xe9cuter des scripts de diagnostic.\\n\\n```bash\\ndocker exec -it <container_id> /bin/bash\\n```\\n\\n### docker inspect\\n\\nLa commande `docker inspect` fournit des informations d\xe9taill\xe9es sur un conteneur ou une image Docker. Cela inclut des d\xe9tails sur la configuration, les r\xe9seaux, les volumes et plus encore.\\n\\n```bash\\ndocker inspect <container_id>\\n```\\n\\n## Techniques avanc\xe9es de d\xe9bogage\\n\\n### Utilisation de docker run avec des options\\n\\nLa commande `docker run` peut \xeatre utilis\xe9e avec diverses options pour faciliter le d\xe9bogage. Par exemple, l\'option `-d` permet de d\xe9marrer un conteneur en mode d\xe9tach\xe9, tandis que l\'option `-p` permet de mapper les ports entre l\'h\xf4te et le conteneur.\\n\\n```bash\\ndocker run -d -p 8080:80 <image_name>\\n```\\n\\n### Red\xe9marrage des conteneurs\\n\\nLes commandes `docker start` et `docker stop` permettent de red\xe9marrer les conteneurs. Cela peut \xeatre utile si vous avez apport\xe9 des modifications \xe0 la configuration du conteneur et que vous souhaitez les appliquer.\\n\\n```bash\\ndocker stop <container_id>\\ndocker start <container_id>\\n```\\n\\n### Nommage des conteneurs\\n\\nLorsque vous cr\xe9ez un conteneur, vous pouvez lui attribuer un nom pour faciliter son identification. Cela peut \xeatre fait en utilisant l\'option `--name` avec la commande `docker run`.\\n\\n```bash\\ndocker run --name my_container <image_name>\\n```\\n\\n## Conclusion\\n\\nLe d\xe9bogage des conteneurs Docker peut sembler complexe au d\xe9but, mais en utilisant les commandes et techniques appropri\xe9es, vous pouvez rapidement identifier et r\xe9soudre les probl\xe8mes. Les commandes de base comme `docker ps`, `docker logs`, `docker exec` et `docker inspect` sont essentielles pour tout d\xe9veloppeur ou administrateur syst\xe8me travaillant avec Docker. En combinant ces commandes avec des techniques avanc\xe9es comme l\'utilisation de `docker run` avec des options et le red\xe9marrage des conteneurs, vous pouvez am\xe9liorer consid\xe9rablement votre efficacit\xe9 dans le d\xe9bogage des conteneurs Docker."},{"id":"/2024/07/30/03-containerization/docker-containers","metadata":{"permalink":"/blog/2024/07/30/03-containerization/docker-containers","source":"@site/blog/03-containerization/2024-07-30-docker-containers.md","title":"Les containers Docker","description":"Pr\xe9sentation des conteneurs Docker, leur fonctionnement et des exemples d\'utilisation.","date":"2024-07-30T00:00:00.000Z","tags":[{"inline":true,"label":"Docker","permalink":"/blog/tags/docker"},{"inline":true,"label":"Containerization","permalink":"/blog/tags/containerization"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":2.42,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Les containers Docker","description":"Pr\xe9sentation des conteneurs Docker, leur fonctionnement et des exemples d\'utilisation.","tags":["Docker","Containerization","Devops"]},"unlisted":false,"prevItem":{"title":"D\xe9bogage des conteneurs Docker","permalink":"/blog/2024/08/15/03-containerization/debugging-docker-containers"},"nextItem":{"title":"Le concept containerisation (Docker)","permalink":"/blog/2024/07/15/03-containerization/docker"}},"content":"Les conteneurs Docker sont des unit\xe9s logicielles l\xe9g\xe8res et portables qui encapsulent une application et ses d\xe9pendances dans une image. Ces images sont compos\xe9es de plusieurs couches, souvent bas\xe9es sur une distribution Linux l\xe9g\xe8re comme Alpine, pour minimiser la taille. Les conteneurs permettent de maintenir des applications isol\xe9es et coh\xe9rentes, ind\xe9pendamment de l\'environnement d\'ex\xe9cution.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce qu\'un conteneur Docker ?\\n\\nUn conteneur Docker est une unit\xe9 logicielle l\xe9g\xe8re et portable qui encapsule une application et ses d\xe9pendances dans une image. Ces images sont compos\xe9es de plusieurs couches, souvent bas\xe9es sur une distribution Linux l\xe9g\xe8re comme Alpine, pour minimiser la taille. Les conteneurs permettent de maintenir des applications isol\xe9es et coh\xe9rentes, ind\xe9pendamment de l\'environnement d\'ex\xe9cution.\\n\\n### Structure d\'un conteneur Docker\\n\\nUn conteneur Docker est compos\xe9 de plusieurs couches d\'images empil\xe9es les unes sur les autres. \xc0 la base de la plupart des conteneurs, on trouve une image Linux, souvent Alpine en raison de sa petite taille. Les couches sup\xe9rieures contiennent les d\xe9pendances et l\'application elle-m\xeame. Cette structure en couches permet de r\xe9utiliser les couches communes entre plusieurs conteneurs, r\xe9duisant ainsi la taille et le temps de t\xe9l\xe9chargement.\\n\\n### Diff\xe9rence entre une image Docker et un conteneur Docker\\n\\nUne image Docker est un package statique qui contient tout ce dont une application a besoin pour fonctionner : le code, les biblioth\xe8ques, les d\xe9pendances et les configurations. C\'est un mod\xe8le pr\xeat \xe0 \xeatre ex\xe9cut\xe9. En revanche, un conteneur Docker est une instance en cours d\'ex\xe9cution de cette image. Lorsque vous d\xe9marrez un conteneur, Docker utilise l\'image pour cr\xe9er un environnement isol\xe9 o\xf9 l\'application peut s\'ex\xe9cuter. En d\'autres termes, une image est un mod\xe8le, tandis qu\'un conteneur est une instance active de ce mod\xe8le.\\n\\n## Commandes Docker de base\\n\\nVoici quelques commandes Docker de base pour g\xe9rer les conteneurs :\\n\\n- `docker run` : Cette commande permet de cr\xe9er et de d\xe9marrer un conteneur \xe0 partir d\'une image Docker. Par exemple, `docker run redis` d\xe9marre un conteneur Redis.\\n- `docker ps` : Cette commande affiche la liste des conteneurs en cours d\'ex\xe9cution. Par exemple, `docker ps` montre tous les conteneurs actifs.\\n- `docker stop` : Cette commande arr\xeate un conteneur en cours d\'ex\xe9cution. Par exemple, `docker stop <container_id>` arr\xeate le conteneur sp\xe9cifi\xe9.\\n- `docker start` : Cette commande red\xe9marre un conteneur arr\xeat\xe9. Par exemple, `docker start <container_id>` red\xe9marre le conteneur sp\xe9cifi\xe9.\\n\\n## Exemple pratique : Utilisation de PostgreSQL avec Docker\\n\\nPour illustrer l\'utilisation des conteneurs Docker, prenons l\'exemple de PostgreSQL. En utilisant Docker Hub, un d\xe9p\xf4t public d\'images Docker, on peut rechercher et t\xe9l\xe9charger une version sp\xe9cifique de PostgreSQL. Par exemple, pour obtenir la version 9.6, il suffit d\'ex\xe9cuter la commande `docker pull` suivie de `docker run` pour d\xe9marrer le conteneur. Docker t\xe9l\xe9charge les couches n\xe9cessaires et d\xe9marre l\'application automatiquement.\\n\\n```bash\\n# Rechercher l\'image officielle de PostgreSQL sur Docker Hub\\ndocker search postgres\\n\\n# T\xe9l\xe9charger l\'image de PostgreSQL version 9.6\\ndocker pull postgres:9.6\\n\\n# D\xe9marrer un conteneur PostgreSQL avec la version 9.6\\ndocker run --name my-postgres -e POSTGRES_PASSWORD=mysecretpassword -d postgres:9.6\\n```"},{"id":"/2024/07/15/03-containerization/docker","metadata":{"permalink":"/blog/2024/07/15/03-containerization/docker","source":"@site/blog/03-containerization/2024-07-15-docker.md","title":"Le concept containerisation (Docker)","description":"Docker est un outil open source qui permet aux d\xe9veloppeurs de cr\xe9er, d\xe9ployer, ex\xe9cuter, mettre \xe0 jour et g\xe9rer les conteneurs.","date":"2024-07-15T00:00:00.000Z","tags":[{"inline":true,"label":"Containerization","permalink":"/blog/tags/containerization"},{"inline":true,"label":"Docker","permalink":"/blog/tags/docker"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":5.09,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Le concept containerisation (Docker)","description":"Docker est un outil open source qui permet aux d\xe9veloppeurs de cr\xe9er, d\xe9ployer, ex\xe9cuter, mettre \xe0 jour et g\xe9rer les conteneurs.","tags":["Containerization","Docker","Devops"]},"unlisted":false,"prevItem":{"title":"Les containers Docker","permalink":"/blog/2024/07/30/03-containerization/docker-containers"},"nextItem":{"title":"Architecture compl\xe8te","permalink":"/blog/2024/06/11/04-ci-cd/exemple"}},"content":"Docker est de plus en plus populaire car il r\xe9sout des probl\xe8mes courants dans le d\xe9veloppement logiciel, en particulier ceux li\xe9s \xe0 la configuration de l\'environnement et \xe0 la compatibilit\xe9. Les applications modernes utilisent souvent une combinaison de diff\xe9rentes technologies, chacune avec des d\xe9pendances de version sp\xe9cifiques. Ces applications doivent fonctionner de mani\xe8re coh\xe9rente dans divers environnements (d\xe9veloppement, test, production), qui peuvent diff\xe9rer en termes de syst\xe8me d\'exploitation, de version et de mat\xe9riel. Sans Docker, chaque environnement doit \xeatre configur\xe9 avec les versions correctes des services, ce qui entra\xeene des probl\xe8mes de compatibilit\xe9 et des configurations complexes.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce qu\'un conteneur et quels probl\xe8mes r\xe9sout-il?\\n\\nUn conteneur est un **moyen de packager des applications** avec tout ce dont ils ont besoin \xe0 l\'int\xe9rieur de ce package, y compris toutes ses d\xe9pendances et toutes les configurations n\xe9cessaires.\\n\\nLe package est portable comme tout autre artefact, et ce package peut \xeatre facilement partag\xe9 et d\xe9plac\xe9 entre une \xe9quipe de d\xe9veloppement ou une \xe9quipe de d\xe9veloppement et d\'op\xe9rations.\\n\\nLa portabilit\xe9 des conteneurs, ainsi que tout ce qui est packag\xe9 dans un **environnement isol\xe9**, lui donne des avantages qui rendent le processus de d\xe9veloppement et de d\xe9ploiement plus efficace.\\n\\n### Probl\xe8mes r\xe9solus par Docker\\n\\nDocker est de plus en plus populaire car il r\xe9sout des probl\xe8mes courants dans le d\xe9veloppement logiciel, en particulier ceux li\xe9s \xe0 la configuration de l\'environnement et \xe0 la compatibilit\xe9. Les applications modernes utilisent souvent une combinaison de diff\xe9rentes technologies, chacune avec des d\xe9pendances de version sp\xe9cifiques. Ces applications doivent fonctionner de mani\xe8re coh\xe9rente dans divers environnements (d\xe9veloppement, test, production), qui peuvent diff\xe9rer en termes de syst\xe8me d\'exploitation, de version et de mat\xe9riel. Sans Docker, chaque environnement doit \xeatre configur\xe9 avec les versions correctes des services, ce qui entra\xeene des probl\xe8mes de compatibilit\xe9 et des configurations complexes.\\n\\nLes principaux probl\xe8mes que Docker r\xe9sout incluent :\\n1. La compatibilit\xe9 des services avec le syst\xe8me d\'exploitation sous-jacent et ses biblioth\xe8ques.\\n2. La gestion des diff\xe9rentes versions des services et de leurs d\xe9pendances.\\n3. La simplification du processus de configuration pour les nouveaux d\xe9veloppeurs.\\n\\nLa solution de Docker consiste \xe0 regrouper chaque service avec ses d\xe9pendances syst\xe8me requises dans des conteneurs isol\xe9s. Cela permet de changer des composants sans affecter les autres services et de modifier le syst\xe8me d\'exploitation sous-jacent sans impacter les services. Docker garantit que les applications fonctionnent de mani\xe8re coh\xe9rente dans diff\xe9rents environnements, \xe9vitant ainsi le probl\xe8me du \\"\xe7a fonctionne sur ma machine\\".\\n\\nDe plus, Docker fournit des images pr\xeates \xe0 l\'emploi pour divers environnements dans son d\xe9p\xf4t officiel, ce qui facilite la configuration et l\'ex\xe9cution des services localement pour les d\xe9veloppeurs. Par exemple, les d\xe9veloppeurs peuvent r\xe9cup\xe9rer une version sp\xe9cifique d\'une image de base de donn\xe9es Postgres et l\'ex\xe9cuter avec une seule commande. Cette flexibilit\xe9 s\'\xe9tend \xe0 l\'ex\xe9cution de plusieurs versions du m\xeame service pour diff\xe9rentes applications.\\n\\nEn r\xe9sum\xe9, Docker simplifie la configuration des environnements, assure la compatibilit\xe9 et offre une flexibilit\xe9 dans la gestion des services et de leurs d\xe9pendances.\\n\\n## D\xe9veloppement d\'applications avant / apr\xe8s conteneur\\n\\nVoyons maintenant comment les conteneurs am\xe9liorent le processus de d\xe9veloppement par des exemples sp\xe9cifiques.\\n\\nComment avons-nous d\xe9velopp\xe9 des applications avant les conteneurs?\\n\\nHabituellement, lorsque vous avez une \xe9quipe de d\xe9veloppeurs travaillant sur une application, vous devez installer directement la plupart des services sur votre syst\xe8me d\'exploitation.\\n\\nChaque d\xe9veloppeur de l\'\xe9quipe devrait alors aller installer les binaires de ces services, les configurer et les ex\xe9cuter sur son environnement de d\xe9veloppement local. Le processus d\'installation sera diff\xe9rent en fonction du syst\xe8me d\'exploitation qu\'ils utilisent.\\n\\nVous avez donc quelques commandes \xe0 ex\xe9cuter, et les **chances qu\'une erreur se produise sont \xe9lev\xe9es**, en raison du nombre d\'\xe9tapes n\xe9cessaires pour installer chaque service.\\n\\nMaintenant, voyons comment les conteneurs r\xe9solvent certains de ces probl\xe8mes.\\n\\nVous n\'avez pas \xe0 installer des services directement sur votre syst\xe8me d\'exploitation, car le conteneur poss\xe8de **sa propre couche de syst\xe8me d\'exploitation isol\xe9e** avec une image de base Linux.\\n\\nVous avez tout packag\xe9 dans un environnement isol\xe9, en tant que d\xe9veloppeur, vous n\'avez pas chercher les binaires \xe0 t\xe9l\xe9charger sur votre machine. Au lieu de cela, vous allez consulter le registre de conteneurs pour trouver le conteneur sp\xe9cifique \xe0 votre application et le t\xe9l\xe9charger sur votre machine locale.\\n\\n## D\xe9ploiement d\'application avant / apr\xe8s conteneur\\n\\n### Avant les conteneurs\\n\\nUn processus de d\xe9ploiement traditionnel ressemblera \xe0 ceci:\\n\\nL\'\xe9quipe de d\xe9veloppeur cr\xe9era des artefacts, qui sont essentiellement des fichiers, ainsi que des instructions sur l\'installation et les configurer sur le serveur. Tous ces artefacts et instructions seront fournis par l\'\xe9quipe de d\xe9veloppement:\\n\\n![alt text](/img/image.png)\\n\\nL\'\xe9quipe de d\xe9veloppement donnerait donc ces artefacts \xe0 l\'\xe9quipe des op\xe9rations, et l\'\xe9quipe d\'op\xe9ration mettrait en place les environnements pour d\xe9ployer ces applications:\\n\\n![Texte alt](/img/image-1.png)\\n\\n- **D\xe9pendances externes sur le syst\xe8me d\'exploitation du serveur**: Le probl\xe8me avec cette approche est que vous devez d\'abord configurer tout et tout installer directement sur le syst\xe8me d\'exploitation du serveur. Cela pourrait entra\xeener des conflits avec les versions de d\xe9pendance.\\n- **Mauvaise communication**: un autre probl\xe8me qui pourrait r\xe9sulter de ce processus est un malentendu entre l\'\xe9quipe de d\xe9veloppement et les op\xe9rations. Parce que tout est dans un guide textuel, il pourrait y avoir des cas, o\xf9 les d\xe9veloppeurs manquent de mentionner certains points critiques sur la configuration et en cas d\'\xe9chec, l\'\xe9quipe d\'op\xe9rations doit retourner aux d\xe9veloppeurs et demander plus de d\xe9tails.\\n\\n### Avec les Conteneurs\\n\\nAvec les conteneurs, ce processus est simplifi\xe9, car maintenant les d\xe9veloppeurs et les op\xe9rations fonctionnent dans une \xe9quipe pour former toutes les d\xe9pendances de configuration dans l\'application.\\n\\n![Texte alt](/img/image-2.png)\\n\\nCela signifie que si vous utilisez un conteneur Docker, vous n\'avez pas besoin de configurer quoi que ce soit directement sur le serveur, car tout est d\xe9j\xe0 encapsul\xe9 dans le conteneur. Au lieu de cela, il vous suffit d\'ex\xe9cuter une commande docker qui r\xe9cup\xe8re le conteneur que vous avez stock\xe9 dans le registre, puis l\'ex\xe9cute.\\n\\nC\'est donc beaucoup plus simple et aucune configuration environnementale n\'est n\xe9cessaire sur le serveur. La seule chose bien s\xfbr est que vous devez installer et configurer le runtime docker sur le serveur avant de pouvoir y ex\xe9cuter des conteneurs. Mais ce n\'est qu\'un effort unique."},{"id":"/2024/06/11/04-ci-cd/exemple","metadata":{"permalink":"/blog/2024/06/11/04-ci-cd/exemple","source":"@site/blog/04-ci-cd/2024-06-11-exemple.md","title":"Architecture compl\xe8te","description":"Exemple complet d\'architecture CI/CD r\xe9utilisable","date":"2024-06-11T00:00:00.000Z","tags":[{"inline":true,"label":"CI/CD","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":2.77,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Architecture compl\xe8te","description":"Exemple complet d\'architecture CI/CD r\xe9utilisable","tags":["CI/CD","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Le concept containerisation (Docker)","permalink":"/blog/2024/07/15/03-containerization/docker"},"nextItem":{"title":"Action Runner Controller GitHub","permalink":"/blog/2024/05/10/04-ci-cd/github-arc"}},"content":"L\'objectif est de cr\xe9er une architecture CI/CD compl\xe8te pour un projet de d\xe9veloppement adressant une technologie (par exemple ROS). Cette architecture doit \xeatre :\\n\\n- facilement r\xe9utilisable dans d\'autres projets\\n- \xe9viter la duplication de code\\n- maintenable et \xe9volutive ais\xe9ment\\n- applicable \xe0 d\'autres projets\\n\\n\x3c!--truncate--\x3e\\n\\n## Cr\xe9ation d\'une architecture CI/CD\\n\\nL\'id\xe9e de l\'architecture est de cr\xe9er un d\xe9p\xf4t contenant tous les workflows et les actions propres \xe0 une technologie / projet (par exemple ROS). Ce d\xe9p\xf4t sera ensuite utilis\xe9 comme cible pour les workflows des projets utilisant cette technologie.\\n\\n```mermaid\\ngraph LR\\n    subgraph Repositories ROS1\\n        repo1[ros_package_1/.github/workflows/ci.yml]\\n        repo2[ros_package_2/.github/workflows/ci.yml]\\n        repo3[ros_package_n/.github/workflows/ci.yml]\\n    end\\n    subgraph ros_workflows\\n        ros.yml[.github/workflows/ros1.yml]\\n        ros2.yml[.github/workflows/ros2.yml]\\n        ros_build.yml[ros_build/action.yml]\\n        ros.yml --\x3e ros_build.yml\\n        ros2.yml --\x3e ros_build.yml\\n    end\\n    subgraph generic_workflows\\n        pre-commit.yml[.github/workflows/pre-commit.yml]\\n\\n    end\\n\\n    ros.yml --\x3e pre-commit.yml\\n\\n    repo1 --\x3e ros.yml\\n    repo2 --\x3e ros.yml\\n    repo3 --\x3e ros.yml\\n```\\n\\nDans cet exemple, nous avons un d\xe9p\xf4t `ros_workflows` contenant les workflows et les actions propres \xe0 la technologie ROS. Ce d\xe9p\xf4t est ensuite utilis\xe9 par les d\xe9p\xf4ts `ros_package_1`, `ros_package_2`, `ros_package_n` pour ex\xe9cuter les workflows. Les diff\xe9rents workflows pr\xe9sents dans `ros_workflows` sont les **uniques** points d\'entr\xe9e pour les workflows des d\xe9p\xf4ts `ros_package_1`, `ros_package_2`, `ros_package_n`. Ainsi s\'il est n\xe9cessaire de modifier un workflow, il suffit de le faire dans le d\xe9p\xf4t `ros_workflows` et tous les d\xe9p\xf4ts utilisant ce workflow seront mis \xe0 jour.\\n\\nDe plus le d\xe9p\xf4t `ros_workflows` peut d\xe9finir des `actions-composites` pour \xe9viter la duplication de code entre leurs propres workflows. Ces actions sont utilis\xe9es par les workflows du d\xe9p\xf4t `ros_workflows` et par cons\xe9quent des d\xe9p\xf4ts `ros_package_1`, `ros_package_2`, `ros_package_n`. Elles peuvent aussi \xeatre appel\xe9es directement au besoin.\\n\\nFinalemet, le d\xe9p\xf4t `ros_workflows` peut aussi utiliser des workflows g\xe9n\xe9riques (par exemple `pre-commit.yml`) pour automatiser des t\xe2ches communes \xe0 toutes les technologies.\\n\\n### Exemple de workflow `ros1.yml`\\n\\n```yaml\\nname: Build & Test ROS Packages\\n\\non:\\n  workflow_call:\\n    inputs:\\n      package-name:\\n        description: \'The name of the ROS package to build and test.\'\\n        required: true\\n        type: string\\n    secrets:\\n      PAT:\\n        required: false\\n        description: \'A GitHub Personal Access Token (PAT) used to import the private repository into the container.\'\\n\\n\\njobs:\\n  pre-commit:\\n    uses: catie-aq/generic_workflows/.github/workflows/pre-commit.yaml@main\\n  build_and_test_ros_package:\\n    runs-on: self-hosted # Use self-hosted runner\\n    strategy: # Define a matrix of ROS distributions and Docker images\\n      matrix:\\n        include:\\n          - docker_image: osrf/ros:noetic-desktop-full\\n            ros_distribution: noetic\\n    container: # Use the Docker image defined in the matrix\\n      image: ${{ matrix.docker_image }}\\n    steps:\\n      - name: Setup ROS environment\\n        uses: ros-tooling/setup-ros@v0.7\\n        with:\\n          required-ros-distributions: ${{ matrix.ros_distribution }}\\n\\n      - name: Build and test ROS\\n        uses: ros-tooling/action-ros-ci@v0.2\\n        with:\\n          package-name: ${{ inputs.package-name }}\\n          target-ros1-distro: ${{ matrix.ros_distribution }}\\n          import-token: ${{ secrets.PAT }}\\n```\\n\\n### Exemple de workflow `ci.yml`\\n\\n```yaml\\nname: \\"ROS CI/CD\\"\\n\\non:\\n  push:\\n\\njobs:\\n  ros:\\n    uses: {user}/ros_workflows/.github/workflows/ros.yml@main\\n```\\n\\n### Exemple d\'action composite `ros_build/action.yml`\\n\\n```yaml\\nname: \'Build and Test ROS\'\\ndescription: \'Build and test a ROS package\'\\n\\ninputs:\\n  package-name:\\n    description: \'The name of the ROS package to build and test.\'\\n    required: true\\n    type: string\\n  ros-distribution:\\n    description: \'The ROS distribution to use for building and testing.\'\\n    required: true\\n    type: string\\n  import-token:\\n    description: \'A GitHub Personal Access Token (PAT) used to import the private repository into the container.\'\\n    required: false\\n    type: string\\n\\nruns:\\n    using: \\"composite\\"\\n    steps:\\n        - run: echo \\"Building and testing ROS package ${{ inputs.package-name }} for ROS ${{ inputs.ros-distribution }}.\\"\\n        shell: bash\\n```"},{"id":"/2024/05/10/04-ci-cd/github-arc","metadata":{"permalink":"/blog/2024/05/10/04-ci-cd/github-arc","source":"@site/blog/04-ci-cd/2024-05-10-github-arc.md","title":"Action Runner Controller GitHub","description":"Explication de l\'installation et de l\'utilisation de l\'Action Runner Controller GitHub","date":"2024-05-10T00:00:00.000Z","tags":[{"inline":true,"label":"CI/CD","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":3.52,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Action Runner Controller GitHub","description":"Explication de l\'installation et de l\'utilisation de l\'Action Runner Controller GitHub","tags":["CI/CD","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Architecture compl\xe8te","permalink":"/blog/2024/06/11/04-ci-cd/exemple"},"nextItem":{"title":"Runner GitHub Self-Hosted","permalink":"/blog/2024/04/15/04-ci-cd/self-host-runner"}},"content":"Actions Runner Controller (ARC) est un op\xe9rateur de Kubernetes qui orchestre et g\xe8re les runners auto-h\xe9berg\xe9s pour les actions GitHub.\\n\\n\x3c!--truncate--\x3e\\n\\n## GitHub ARC\\n\\nLes runners auto-h\xe9berg\xe9s offrent un contr\xf4le total sur l\'environnement d\'ex\xe9cution, permettant de personnaliser les configurations et d\'optimiser les performances selon les besoins sp\xe9cifiques. Ils sont \xe9galement plus rentables \xe0 long terme, car ils n\'entra\xeenent pas de co\xfbts suppl\xe9mentaires li\xe9s \xe0 l\'utilisation des ressources de GitHub. Cependant, ils n\xe9cessitent une maintenance r\xe9guli\xe8re et une gestion de la s\xe9curit\xe9 pour garantir leur bon fonctionnement et leur protection contre les menaces potentielles. En revanche, GitHub Actions Runner Controller (ARC) est une solution \xe9volutive g\xe9r\xe9e par GitHub, qui permet de g\xe9rer automatiquement les runners dans un environnement Kubernetes. ARC offre une gestion simplifi\xe9e et une mise \xe0 l\'\xe9chelle automatique des runners en fonction des besoins, ce qui est id\xe9al pour les grandes organisations avec des charges de travail variables. Cependant, l\'utilisation de GitHub ARC peut entra\xeener des co\xfbts plus \xe9lev\xe9s pour les d\xe9ploiements \xe0 grande \xe9chelle, et les utilisateurs ont moins de contr\xf4le sur l\'environnement d\'ex\xe9cution par rapport aux runners auto-h\xe9berg\xe9s.\\n\\nAvec ARC, il est possible de cr\xe9er des ensembles de runners qui \xe9voluent automatiquement en fonction du nombre de workflows ex\xe9cut\xe9s dans votre d\xe9p\xf4t, organisation ou entreprise.\\n\\nLe diagramme suivant illustre l\'architecture du mode Scaleset Runner Autoscaling d\'Arc.\\n\\n[Documentation compl\xe8te](https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/quickstart-for-actions-runner-controller)\\n\\n![alt text](/img/arc.png)\\n\\n:::danger\\nSur GitHub les ARC sont identifi\xe9s par leur nom d\'installation. Il est important de choisir un nom unique pour chaque installation. De plus pour simplifier l\'\xe9criture des workflows il est consill\xe9 de g\xe9rer les runners par des groupes de runners. La cl\xe9 `runs-on` des jobs des workflows doit \xeatre \xe9gale \xe0 un groupe de runners.\\n:::\\n\\n## Pr\xe9requis\\n\\nPour utiliser l\'ARC, il est n\xe9cessaire de disposer des \xe9l\xe9ments suivants :\\n\\n- Un cluster Kubernetes\\n- Helm 3.0 ou version ult\xe9rieure\\n\\n## Installation rapide\\n\\n:::warning\\nLa suite du guide permet de rapidement installer ARC. Les diff\xe9rents concepts et la configuration avanc\xe9e ne sont pas abord\xe9s. Pour une installation plus compl\xe8te, regarder la [documentation officielle](https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/quickstart-for-actions-runner-controller).\\n:::\\n\\n- Le pod de contr\xf4le est en charge de la gestion des pods de runner. Il s\'occupe de la cr\xe9ation, de la mise \xe0 l\'\xe9chelle et de la suppression des pods de runner.\\n- Le pod de runner est d\xe9di\xe9 \xe0 l\'ex\xe9cution des workflows GitHub Actions. Il se compose de deux conteneurs : un conteneur DinD et un conteneur runner. Le conteneur DinD fournit un environnement d\'ex\xe9cution Docker pour le conteneur runner. Le conteneur runner est utilis\xe9 pour ex\xe9cuter les workflows GitHub Actions.\\n\\n## Usage\\n\\nPour lancer le pod de contr\xf4le :\\n\\n```shell\\nNAMESPACE=\\"arc-systems\\"\\nhelm install arc \\\\\\n    --namespace \\"${NAMESPACE}\\" \\\\\\n    --create-namespace \\\\\\n    oci://ghcr.io/actions/actions-runner-controller-charts/gha-runner-scale-set-controller\\n```\\n\\nPour lancer le pod de runner :\\n\\n```shell\\nINSTALLATION_NAME=\\"elegantencoder\\"\\nNAMESPACE=\\"arc-runners\\"\\nhelm install \\"${INSTALLATION_NAME}\\" \\\\\\n    --namespace \\"${NAMESPACE}\\" \\\\\\n    --create-namespace \\\\\\n    -f value.yaml \\\\\\n    oci://ghcr.io/actions/actions-runner-controller-charts/gha-runner-scale-set;\\n```\\n\\n## Authentification\\n\\nPour que le pod de contr\xf4le puisse cr\xe9er des pods de runner, il faut lui donner les droits n\xe9cessaires. Pour cela, il faut cr\xe9er un secret contenant un token d\'authentification. Les diff\xe9rents \xe9l\xe9ments proviennent de l\'enregistrement d\'une application GitHub au niveau de l\'organisation concern\xe9e.\\n\\n```shell\\nkubectl create secret generic pre-defined-secret \\\\\\n   --namespace=arc-runners \\\\\\n   --from-literal=github_app_id=xxx \\\\\\n   --from-literal=github_app_installation_id=xxx \\\\\\n   --from-literal=github_app_private_key=\'xxx\'\\n```\\n\\n## Monitoring\\n\\nDashboard Helm\\n\\n```shell\\nhelm dashboard --bind 0.0.0.0\\n```\\n\\nPortainer\\n\\n## Docker cache\\n\\nNous avons rencontr\xe9 un probl\xe8me de lenteur lors de la construction des images Docker. Pour y rem\xe9dier, nous avons mis en place la mutualisation des couches des images Docker entre les diff\xe9rents pods et l\'h\xf4te. Cela implique la cr\xe9ation d\'un volume partag\xe9 entre les diff\xe9rents pods et l\'h\xf4te. Ces volumes sont mont\xe9s dans le conteneur DinD du pod qui les utilise pour fournir les images Docker au conteneur du runner. Chaque pod de runner contient un conteneur DinD qui est utilis\xe9 pour construire les images Docker.\\n\\n```yaml\\n- name: overlay2\\n    hostPath:\\n    path: /var/lib/docker/overlay2\\n- name: image-overlay2\\n    hostPath:\\n    path: /var/lib/docker/image/overlay2\\n```"},{"id":"/2024/04/15/04-ci-cd/self-host-runner","metadata":{"permalink":"/blog/2024/04/15/04-ci-cd/self-host-runner","source":"@site/blog/04-ci-cd/2024-04-15-self-host-runner.md","title":"Runner GitHub Self-Hosted","description":"Explication de la cr\xe9ation et de l\'installation d\'un nouveau runner au niveau de l\'organisation","date":"2024-04-15T00:00:00.000Z","tags":[{"inline":true,"label":"CI/CD","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":3.74,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Runner GitHub Self-Hosted","description":"Explication de la cr\xe9ation et de l\'installation d\'un nouveau runner au niveau de l\'organisation","tags":["CI/CD","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Action Runner Controller GitHub","permalink":"/blog/2024/05/10/04-ci-cd/github-arc"},"nextItem":{"title":"Actions Composites","permalink":"/blog/2024/03/28/04-ci-cd/action"}},"content":"Un `runner` est une machine virtuelle ou physique qui ex\xe9cute des `jobs` dans un `workflow`. Les `runners` peuvent \xeatre h\xe9berg\xe9s par GitHub ou auto-h\xe9berg\xe9s. Les `runners` h\xe9berg\xe9s par GitHub sont ex\xe9cut\xe9s dans un environnement de cloud partag\xe9 et sont g\xe9r\xe9s par GitHub et peuvent entrainer des surcouts. Les `runners` auto-h\xe9berg\xe9s sont ex\xe9cut\xe9s sur une machine que vous poss\xe9dez et g\xe9rez.\\n\\n\x3c!--truncate--\x3e\\n\\n## Comparaison entre les runners auto-h\xe9berg\xe9s et les runners cloud-h\xe9berg\xe9s de GitHub\\n\\nLes runners auto-h\xe9berg\xe9s offrent un contr\xf4le total sur l\'environnement d\'ex\xe9cution, ce qui permet de personnaliser les configurations et d\'optimiser les performances selon les besoins sp\xe9cifiques. Ils sont \xe9galement plus rentables \xe0 long terme, car ils n\'entra\xeenent pas de co\xfbts suppl\xe9mentaires li\xe9s \xe0 l\'utilisation des ressources de GitHub. Cependant, ils n\xe9cessitent une maintenance r\xe9guli\xe8re et une gestion de la s\xe9curit\xe9 pour garantir leur bon fonctionnement et leur protection contre les menaces potentielles.\\n\\nLes runners cloud-h\xe9berg\xe9s de GitHub sont g\xe9r\xe9s par GitHub, ce qui signifie que les utilisateurs n\'ont pas \xe0 se soucier de la maintenance, de la s\xe9curit\xe9 ou de la mise \xe0 jour des runners. Ils sont \xe9galement facilement \xe9volutifs, car GitHub peut ajouter des ressources suppl\xe9mentaires en fonction des besoins. Cependant, les runners cloud-h\xe9berg\xe9s peuvent entra\xeener des co\xfbts suppl\xe9mentaires pour les utilisateurs, en particulier pour les projets de grande envergure ou les charges de travail intensives.\\n\\nEn r\xe9sum\xe9, les runners auto-h\xe9berg\xe9s sont id\xe9aux pour les \xe9quipes ou les projets avec des besoins sp\xe9cifiques en mati\xe8re de configuration et de performances, tandis que les runners cloud-h\xe9berg\xe9s de GitHub sont mieux adapt\xe9s aux utilisateurs qui pr\xe9f\xe8rent une solution g\xe9r\xe9e et \xe9volutive sans avoir \xe0 se soucier de la maintenance et de la s\xe9curit\xe9. Le choix entre les deux d\xe9pend des besoins sp\xe9cifiques de l\'\xe9quipe et des ressources disponibles.\\n\\n## Cr\xe9\xe9r un runner auto-h\xe9berg\xe9s\\n\\nPour t\xe9l\xe9charger un nouveau `runner`, ex\xe9cutez les lignes suivantes\\n\\n```shell\\n# Create a folder\\nmkdir actions-runner && cd actions-runner\\n# Download the latest runner package\\ncurl -o actions-runner-linux-x64-2.312.0.tar.gz -L <https://github.com/actions/runner/releases/download/v2.312.0/actions-runner-linux-x64-2.312.0.tar.gz> # ! update this documentation with the latest release\\n# Optional: Validate the hash\\necho \\"85c1bbd104d539f666a89edef70a18db2596df374a1b51670f2af1578ecbe031  actions-runner-linux-x64-2.312.0.tar.gz\\" | shasum -a 256 -c\\n# Extract the installer\\ntar xzf ./actions-runner-linux-x64-2.312.0.tar.gz\\n```\\n\\nIl est ensuite n\xe9cessaire de configurer votre `runner`\\n\\n```shell\\n# Create the runner and start the configuration experience\\n./config.sh --url <https://github.com/><org>/<repo> --token <token># Last step, run it!\\n./run.sh\\n```\\n\\n:::info\\nLe token est \xe0 obtenir au pr\xe8s d\u2019un `owner` de l\u2019organisation accessible sur le lien suivant [https://github.com/organizations/](https://github.com/organizations/org/settings/actions/runners/new?arch=x64&os=linux)\\n:::\\n\\n\u27a1\ufe0f Lors de la configuration, il est possible d\'ajouter des **labels** pour identifier la machine (par exemple `GPU`).\\n\\n## Cr\xe9er une action `self-hosted`\\n\\nIl n\u2019est pas possible de cr\xe9er une action visant une machine `self-hosted` particuli\xe8re (\xe0 confirmer). Chaque `repository` d\u2019une organisation peut acc\xe9der \xe0 :\\n\\n- Toutes les machines dans le groupe `D\xe9faut` qui sont automatiquement partag\xe9es \xe0 tous les d\xe9p\xf4ts.\\n- Toutes les machines dans un groupe `Name` qui sont manuellement partag\xe9es au d\xe9p\xf4t concern\xe9 (l\u2019affectation manuelle des d\xe9p\xf4ts \xe0 des groupes de machines nous encourage \xe0 ne pas utiliser ceci sauf cas particulier)\\n\\nParmi les machines disponibles le `repository` peut demander d\u2019utiliser une machine en fonction de son `label` par exemple l\u2019action ci-dessous, permettant de v\xe9rifier que le d\xe9p\xf4t est compilable sous ROS, r\xe9quisitionne une machine ayant le label `Robotics`. Ceci est modifiable \xe0 la ligne `runs-on: Robotics`.\\n\\n```yaml\\nname: CI\\n\\non: [pull_request]\\n\\njobs:\\n  industrial_ci:\\n    strategy:\\n      matrix:\\n        env:\\n          - {ROS_DISTRO: melodic, ROS_REPO: main}\\n    runs-on: Robotics\\n    steps:\\n      - uses: actions/checkout@v3\\n      - uses: \'ros-industrial/industrial_ci@master\'\\n        env: ${{matrix.env}}\\n```\\n\\nLors de la premi\xe8re utilisation, si vous rencontrez un erreur `docker` sp\xe9cifiant un manque de permission, il est n\xe9cessaire de taper la commande suivante sur la machine distance `sudo setfacl --modify user:<user>:rw /var/run/docker.sock`\\nLorsqu\u2019une action est cr\xe9\xe9 en `self-hosted` il est fortement conseill\xe9 de mettre les actions dans un `container`. Lorsque c\u2019est impossible (comme `tailscale`) il est n\xe9cessaire d\u2019ajouer un clean de l\u2019environnement \xe0 la fin de l\u2019action en ajoutant cette `step`\\n\\n```yaml\\n- name: Clean runner\\n  if: always()\\n  run: rm -rf ${{ github.workspace }}/*\\n```\\n\\n## Mettre en place le runner sous forme de service\\n\\nDans le dossier de votre `runnner` sur la machine, transformer le `./run.sh` en service, tapez simplement les lignes ci-dessous pour que le `runner` s\u2019active au d\xe9marrage de la machine.\\n\\n```shell\\nsudo ./svc.sh install\\nsudo ./svc.sh start\\n```"},{"id":"/2024/03/28/04-ci-cd/action","metadata":{"permalink":"/blog/2024/03/28/04-ci-cd/action","source":"@site/blog/04-ci-cd/2024-03-28-action.md","title":"Actions Composites","description":"Cr\xe9\xe9er une action r\xe9utilisable","date":"2024-03-28T00:00:00.000Z","tags":[{"inline":true,"label":"CI/CD","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":4.31,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Actions Composites","description":"Cr\xe9\xe9er une action r\xe9utilisable","tags":["CI/CD","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Runner GitHub Self-Hosted","permalink":"/blog/2024/04/15/04-ci-cd/self-host-runner"},"nextItem":{"title":"Workflows","permalink":"/blog/2024/03/17/04-ci-cd/workflow"}},"content":"## Exemple de cr\xe9ation et d\'utilisation d\'une action GitHub\\n\\nVoici un exemple de cr\xe9ation et d\'utilisation d\'une action GitHub pour automatiser le d\xe9ploiement d\'une application Node.js.\\n\\n1. Cr\xe9ez un fichier `action.yml` dans le r\xe9pertoire `.github/actions/deploy` de votre d\xe9p\xf4t avec le contenu suivant :\\n\\n```yaml\\nname: \'Deploy Node.js App\'\\ndescription: \'Deploy a Node.js application to a remote server\'\\ninputs:\\n  server:\\n    description: \'The remote server to deploy to\'\\n    required: true\\n  username:\\n    description: \'The username to use for the deployment\'\\n    required: true\\n  password:\\n    description: \'The password to use for the deployment\'\\n    required: true\\nruns:\\n  using: \'composite\'\\n  steps:\\n    - name: Checkout code\\n      uses: actions/checkout@v4\\n    - name: Install dependencies\\n      run: npm install\\n    - name: Build application\\n      run: npm run build\\n    - name: Deploy application\\n      run: |\\n        sshpass -p ${{ inputs.password }} ssh ${{ inputs.username }}@${{ inputs.server }} \'mkdir -p /var/www/myapp\'\\n        sshpass -p ${{ inputs.password }} scp -r ./build/* ${{ inputs.username }}@${{ inputs.server }}:/var/www/myapp\\n```\\n\\n2. Cr\xe9ez un fichier `deploy.yml` dans le r\xe9pertoire `.github/workflows` de votre d\xe9p\xf4t avec le contenu suivant :\\n\\n```yaml\\nname: Deploy Node.js App\\n\\non:\\n  push:\\n    branches:\\n      - main\\n\\njobs:\\n  deploy:\\n    runs-on: ubuntu-latest\\n    steps:\\n      - name: Deploy application\\n        uses: ./.github/actions/deploy\\n        with:\\n          server: ${{ secrets.DEPLOY_SERVER }}\\n          username: ${{ secrets.DEPLOY_USERNAME }}\\n          password: ${{ secrets.DEPLOY_PASSWORD }}\\n```\\n\\nDans cet exemple, l\'action `Deploy Node.js App` est utilis\xe9e pour d\xe9ployer une application Node.js sur un serveur distant. L\'action est d\xe9clench\xe9e \xe0 chaque fois qu\'un push est effectu\xe9 sur la branche `main`. Les informations de d\xe9ploiement (serveur, nom d\'utilisateur et mot de passe) sont stock\xe9es dans les secrets du d\xe9p\xf4t pour des raisons de s\xe9curit\xe9.\\n\\nLes actions GitHub permettent d\'automatiser, personnaliser et ex\xe9cuter un flux de travail directement depuis votre d\xe9p\xf4t. Avec les actions GitHub, il est possible de cr\xe9er des t\xe2ches personnalis\xe9es pour automatiser un flux de travail, partager et d\xe9couvrir des actions pour effectuer des t\xe2ches sp\xe9cifiques.\\n\\n\x3c!--truncate--\x3e\\n\\n## Comment cr\xe9er ses propres actions\\n\\nDocumentation compl\xe8te : [https://docs.github.com/fr/actions/creating-actions](https://docs.github.com/fr/actions/creating-actions)\\n\\nLa cr\xe9ation d\'actions personnalis\xe9es offre la possibilit\xe9 de concevoir du code sp\xe9cifique qui interagit avec le d\xe9p\xf4t selon les besoins. Ces actions peuvent s\'int\xe9grer aux API de GitHub ou \xe0 toute API tierce accessible publiquement. Par exemple, une action pourrait \xeatre configur\xe9e pour publier des modules npm, envoyer des alertes par SMS en cas de cr\xe9ation de probl\xe8mes urgents, ou encore d\xe9ployer du code pr\xeat pour la production.\\nCe guide expose les \xe9l\xe9ments fondamentaux requis pour la cr\xe9ation et l\'utilisation d\'une action composite empaquet\xe9e.\\n\\n:::warning\\nLors de la cr\xe9ation de flux de travail et d\'actions, il est imp\xe9ratif d\'\xe9valuer constamment la possibilit\xe9 d\'ex\xe9cution d\'une entr\xe9e non fiable provenant de sources potentiellement malveillantes. Certains contextes doivent \xeatre trait\xe9s comme des entr\xe9es non fiables, car un attaquant pourrait ins\xe9rer son propre contenu malveillant. Pour de plus amples informations, veuillez consulter la section \xab [Durcissement de la s\xe9curit\xe9 pour GitHub Actions](https://docs.github.com/fr/actions/security-guides/security-hardening-for-github-actions#understanding-the-risk-of-script-injections) \xbb.\\n:::\\n\\n## Cr\xe9ation d\u2019une action\\n\\nUn d\xe9p\xf4t doit \xeatre cr\xe9\xe9 sur [GitHub.com](http://GitHub.com).\\n\\n- Cr\xe9ez un nouveau d\xe9p\xf4t sur [GitHub](http://GitHub.com), en choisissant n\'importe quel nom de d\xe9p\xf4t ou en utilisant l\'exemple suivant : `hello-world-composite-action`. Les fichiers peuvent \xeatre ajout\xe9s une fois que le projet est pouss\xe9 sur GitHub. Pour plus d\'informations, veuillez vous r\xe9f\xe9rer \xe0 la section [Cr\xe9ation d\'un d\xe9p\xf4t](https://docs.github.com/fr/repositories/creating-and-managing-repositories/creating-a-new-repository).\\n- Dans le d\xe9p\xf4t `hello-world-composite-action`, cr\xe9ez un fichier nomm\xe9 `goodbye.sh` et ajoutez le code `echo \\"Goodbye`\\n- Rendez `goodbye.sh` ex\xe9cutable depuis votre terminal.\\n- Dans le d\xe9p\xf4t `hello-world-composite-action`, cr\xe9ez un fichier nomm\xe9 `action.yml` et ajoutez le code suivant en exemple. Pour plus d\'informations sur cette syntaxe, consultez la section [Syntaxe des m\xe9tadonn\xe9es pour les actions GitHub](https://docs.github.com/fr/actions/creating-actions/metadata-syntax-for-github-actions#runs-for-composite-actions) .\\n\\n```yaml\\n    name: \'Hello World\'\\n    description: \'Greet someone\'\\n    inputs:\\n      who-to-greet:  # id of input\\n        description: \'Who to greet\'\\n        required: true\\n        default: \'World\'\\n    outputs:\\n      random-number:\\n        description: \\"Random number\\"\\n        value: ${{ steps.random-number-generator.outputs.random-number }}\\n    runs:\\n      using: \\"composite\\"\\n      steps:\\n        - run: echo Hello ${{ inputs.who-to-greet }}.\\n          shell: bash\\n        - id: random-number-generator\\n          run: echo \\"random-number=$(echo $RANDOM)\\" >> $GITHUB_OUTPUT\\n          shell: bash\\n        - run: echo \\"${{ github.action_path }}\\" >> $GITHUB_PATH\\n          shell: bash\\n        - run: goodbye.sh\\n          shell: bash\\n```\\n\\n- Ce fichier d\xe9finit l\'entr\xe9e `who-to-greet`, mappe le nombre g\xe9n\xe9r\xe9 al\xe9atoirement \xe0 la variable de sortie `random-number`, ajoute le chemin d\'acc\xe8s de l\'action au chemin d\'acc\xe8s du syst\xe8me de l\'ex\xe9cuteur (pour localiser le script `goodbye.sh` lors de l\'ex\xe9cution) et ex\xe9cute le script .\\n- Effectuez le commit de votre fichier `action.yml` depuis votre terminal.\\n\\n```shell\\n    git add action.yml\\n    git commit -m \\"Add action\\"\\n    git push\\n```\\n\\n- Ajoutez une \xe9tiquette depuis votre terminal. Cet exemple utilise une \xe9tiquette nomm\xe9e `v1`.\\n\\n```shell\\n    git tag -a -m \\"Description of this release\\" v1\\n    git push --follow-tags\\n```\\n\\n## Tester l\u2019action dans un workflow\\n\\nCopiez le code de workflow dans un fichier `.github/workflows/main.yml` d\'un autre d\xe9p\xf4t\\n\\n```yaml\\n    on: [push]\\n\\n    jobs:\\n      hello_world_job:\\n        runs-on: ubuntu-latest\\n        name: A job to say hello\\n        steps:\\n          - uses: actions/checkout@v4\\n          - id: foo\\n            uses: actions/hello-world-composite-action@v1\\n            with:\\n              who-to-greet: \'Mona the Octocat\'\\n          - run: echo random-number ${{ steps.foo.outputs.random-number }}\\n            shell: bash\\n```\\n\\n## Action dans un workflow priv\xe9\\n\\nDans les param\xe8tres des actions, il est n\xe9cessaire de la partager \xe0 l\u2019organisation\\n\\n![AllowAction](/img/allow_action.png)"},{"id":"/2024/03/17/04-ci-cd/workflow","metadata":{"permalink":"/blog/2024/03/17/04-ci-cd/workflow","source":"@site/blog/04-ci-cd/2024-03-17-workflow.md","title":"Workflows","description":"Cr\xe9\xe9er un workflow avec GitHub Actions","date":"2024-03-17T00:00:00.000Z","tags":[{"inline":true,"label":"CI/CD","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":5.53,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Workflows","description":"Cr\xe9\xe9er un workflow avec GitHub Actions","tags":["CI/CD","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Actions Composites","permalink":"/blog/2024/03/28/04-ci-cd/action"},"nextItem":{"title":"Introduction \xe0 GitHub Actions","permalink":"/blog/2024/02/22/04-ci-cd/github-actions"}},"content":"## Exemple d\'int\xe9gration des actions GitHub dans les workflows\\n\\nVoici un exemple d\'int\xe9gration des actions GitHub dans un workflow pour automatiser le d\xe9ploiement d\'une application Node.js.\\n\\nUn workflow est l\'\xe9l\xe9ment central de GitHub Actions. Il s\'agit d\'un processus automatis\xe9 compos\xe9 de `jobs` et de `steps` qui s\'ex\xe9cutent sur des `runners`. Les workflows sont d\xe9clench\xe9s par des \xe9v\xe9nements, tels que des pushs, des pull requests, des forks, etc.\\n\\n\x3c!--truncate--\x3e\\n\\nPour cr\xe9er un fichier de workflow, il faut cr\xe9er un fichier `.yml` dans le dossier `.github/workflows` du d\xe9p\xf4t. Un workflow est compos\xe9 de `jobs` et de `steps`. Un `job` est une suite d\'\xe9tapes qui s\'ex\xe9cutent sur le m\xeame runner, tandis qu\'un `step` est une t\xe2che individuelle qui peut s\'ex\xe9cuter dans un `job`. Chaque `job` est ex\xe9cut\xe9 dans un environnement d\xe9di\xe9 d\xe9fini par [`runs-on`](#type-de-machine).\\n\\n```yml\\nname: CI\\n\\non: [push]\\n\\njobs:\\n  build:\\n    runs-on: ubuntu-latest\\n    steps:\\n      - uses: actions/checkout@v2\\n      - name: Run a one-line script\\n        run: echo Hello, world!\\n      - name: Run a multi-line script\\n        run: |\\n          echo Add other actions to build,\\n          echo test, and deploy your project.\\n```\\n\\nDocumentation Compl\xe8te  : [https://docs.github.com/en/actions/learn-github-actions/introduction-to-github-actions](https://docs.github.com/en/actions/learn-github-actions/introduction-to-github-actions)\\n\\n## D\xe9clenchement des actions\\n\\nLes d\xe9clencheurs de workflow sont des \xe9v\xe9nements qui entra\xeenent l\u2019ex\xe9cution d\u2019un workflow. La syntaxe d\xe9pend du niveau de pr\xe9cision\\n\\n- Pour tout ce qui concerne un \xe9v\xe9nement :\\n\\n```yaml\\n    on: [push] # pull_request, fork etc\\n```\\n\\n- Pour plus de finesse sur l\u2019\xe9v\xe9nement :\\n\\n```yaml\\n    on: # trigger\\n      label: # type d\'event (push, fork, pull_request)\\n        types:\\n          - created # trigger \xe0 chaque fois qu\'un label est cr\xe9\xe9\\n      push:\\n        branches:\\n          - main # tous les push sur la branche main\\n```\\n\\n- D\xe9clenchement manuel de l\u2019op\xe9ration (avec prise d\u2019argument)\\n\\n```yaml\\n    on:\\n      workflow_dispatch:\\n        inputs:\\n          test_mode:\\n            description: \'True or False\'\\n            required: true\\n```\\n\\nLa liste compl\xe8te des d\xe9clencheurs est disponible dans la [Documentation Github](https://docs.github.com/fr/actions/using-workflows/events-that-trigger-workflows)\\n\\nUne ex\xe9cution de workflow est compos\xe9e d\u2019un ou de plusieurs `jobs`, qui s\u2019ex\xe9cutent en parall\xe8le par d\xe9faut. Chaque job est constitu\xe9 d\u2019un `name` et d\u2019au moins un `step` pour \xeatre ex\xe9cutable et peut \xeatre configur\xe9.\\nLa documentation pr\xe9cise des job est disponible dans la [Documentation Github](https://docs.github.com/fr/actions/using-workflows/workflow-syntax-for-github-actions#jobs)\\n\\n## Marketplace\\n\\nChaque `job` permet d\u2019ex\xe9cuter un script. Le script le plus basique est un simple `run` avec des commandes `bash` derri\xe8re. Cependant, il est possible de r\xe9utiliser des actions d\xe9finies dans le marketplace. Par exemple le `steps` ci-dessous permet d\u2019ex\xe9cuter l\u2019action [https://github.com/ros-tooling/action-ros-ci](https://github.com/ros-tooling/action-ros-ci). Le mot cl\xe9 `with` permet de passer des param\xe8tres \xe0 l\u2019action.\\n\\n:::danger\\nLe marketplace permet de r\xe9utiliser des actions d\xe9j\xe0 d\xe9finies par la communaut\xe9. Il est important de v\xe9rifier la source de l\u2019action avant de l\u2019utiliser.\\n:::\\n\\n```yaml\\nsteps:\\n    - name: build and test ROS 2\\n    uses: ros-tooling/action-ros-ci@v0.2\\n    with:\\n        package-name: github-action-test\\n        target-ros2-distro: ${{ matrix.ros_distribution }}\\n        import-token: ${{ secrets.GITHUB_TOKEN }} # token autogenerated par github\\n```\\n\\n## R\xe9utiliser les Workflows et Actions\\n\\nIl est possible de r\xe9utiliser des `workflows` et des `actions` dans un workflow. Pour cela, il est possible de cr\xe9er des `workflows` et des `actions` dans des fichiers s\xe9par\xe9s et de les appeler dans le workflow principal.\\n\\n```yaml\\njobs:\\n    workflow: # r\xe9utilisation du workflow\\n      uses: path/to/your-workflow.yml@v1\\n    action: # r\xe9utilisation d\'une action\\n      runs-on: ubuntu-latest\\n      container: ubuntu:latest\\n      steps:\\n        - uses: path/to/your-action@v1\\n```\\n\\n[Documentation des wokflows r\xe9utilisables](https://docs.github.com/en/actions/learn-github-actions/reusing-workflows)\\n\\n[Documentation des actions r\xe9utilisables](https://docs.github.com/en/actions/creating-actions/creating-a-composite-action)\\n\\n:::info\\n\\nLorsqu\'un workflow est r\xe9utilis\xe9 il d\xe9fini son propre environnement (runner, container, etc). De plus il n\'est pas utilisable dans une `step`.\\n\\n\xc0 l\'inverse, une action est utilisable dans une `step` et fonctionne dans l\'environnement du `job` qui l\'appelle.\\n:::\\n\\n## Type de machine\\n\\nUtilisez `jobs.<job_id>.runs-on` pour d\xe9finir le type de machine sur laquelle le travail doit \xeatre ex\xe9cut\xe9. La configuration prend en argument un `tag` d\xe9fini pour les runners\\n\\n```yaml\\njobs:\\n    name-job:\\n    runs-on: ubuntu-latest # runner distant sur les serveur de Github\\n    runs-on: self-hosted # runner local\\n    steps:\\n        - run: echo \\"Hello World !\\"\\n```\\n\\nLes `runners` distants fourni par Github consomment du temps pour l\u2019organisation dans les limites de 2 000 minutes gratuites par mois. Il est pr\xe9f\xe9rable d\u2019utiliser des `runners self hosted` (voir [https://docs.github.com/fr/actions/hosting-your-own-runners/managing-self-hosted-runners/about-self-hosted-runners](https://docs.github.com/fr/actions/hosting-your-own-runners/managing-self-hosted-runners/about-self-hosted-runners))\\n\\nLe choix du `runner` se fait via les tags. Toutes les machines auto-h\xe9berg\xe9es partagent le tag `self-hosted` , le tag de leur syst\xe8me d\u2019exploitation (`Linux`, `Windows`), leur architecture (`x64`) et des tags personnalis\xe9s par machine.\\n\\n## Container\\n\\nL\u2019utilisation d\u2019un `container` permet de cr\xe9er un nouveau conteneur permettant d\u2019ex\xe9cuter les \xe9tapes d\u2019un travail dans un conteneur sp\xe9cifif\xe9. Si vous ne d\xe9finissez pas de `container`, toutes les \xe9tapes s\u2019ex\xe9cutent directement sur l\u2019h\xf4te sp\xe9cifi\xe9 par `runs-on` dans le cas d\u2019une machine auto-h\xe9berg\xe9es, il n\u2019y a donc acc\xe8s qu\u2019aux packages install\xe9s sur la machine. Un `container` est rattach\xe9 \xe0 un `job`.\\n\\n```yaml\\njobs:\\n    name-job:\\n    runs-on: self-hosted\\n    container:\\n    image: ubuntu:jammy # run job with ubuntu:jammy docker\\n        steps:\\n            - run: echo \\"Hello World !\\"\\n```\\n\\n## Strategy\\n\\nL\u2019utilisation de `strategy` permet cr\xe9er automatiquement plusieurs ex\xe9cutions de travaux bas\xe9es sur des combinaisons de variables. Une strat\xe9gie de matrice est utile pour tester du code dans diff\xe9rentes versions d\'un langage ou sur diff\xe9rents syst\xe8mes d\'exploitation.\\nPar exemple\\n\\n```yaml\\njobs:\\n    example_matrix:\\n    strategy:\\n        matrix:\\n        version: [10, 12, 14]\\n        os: [ubuntu-latest, windows-latest]\\n        steps:\\n            - run : echo \\"${{ matrix.version }} ${{ matrix.os }}\\"\\n```\\n\\nUn travail s\u2019ex\xe9cute pour chaque combinaison possible des variables. Dans cet exemple, le workflow ex\xe9cute six travaux, un pour chaque combinaison des variables `os` et `version`.\\n\\n## Art\xe9fact\\n\\nLes artefacts permettent de conserver des donn\xe9es une fois un travail termin\xe9 et de les partager avec une autre action. Un artefact est un fichier ou une collection de fichiers g\xe9n\xe9r\xe9s pendant l\u2019ex\xe9cution d\u2019un workflow. Cet exemple permet de stocker un fichier comme artefact.\\n\\n```yaml\\n- name: Archive code coverage results\\n    uses: actions/upload-artifact@v3\\n    with:\\n        name: code-coverage-report\\n        path: output/test/code-coverage.html\\n```\\n\\nPour r\xe9cup\xe9rer un artefact\\n\\n```yaml\\n- name: Download math result for job 2\\n    uses: actions/download-artifact@v3\\n    with:\\n        name: homework\\n```\\n\\n## Vrac\\n\\n- `needs` le job actuel ne commencera que quand le job mentionn\xe9 sera termin\xe9\\n- `if` condition de lancement du job\\n- `permission` permet d\u2019augmenter les droits du `GITHUB_TOKEN` (voir [https://docs.github.com/fr/actions/security-guides/automatic-token-authentication#permissions-for-the-github_token](https://docs.github.com/fr/actions/security-guides/automatic-token-authentication#permissions-for-the-github_token))\\n- `environnement` permet de d\xe9finir des variables d\u2019environnement"},{"id":"/2024/02/22/04-ci-cd/github-actions","metadata":{"permalink":"/blog/2024/02/22/04-ci-cd/github-actions","source":"@site/blog/04-ci-cd/2024-02-22-github-actions.md","title":"Introduction \xe0 GitHub Actions","description":"D\xe9couvrez comment GitHub Actions peut automatiser vos workflows de d\xe9veloppement et de d\xe9ploiement.","date":"2024-02-22T00:00:00.000Z","tags":[{"inline":true,"label":"CI/CD","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"GitHub","permalink":"/blog/tags/git-hub"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":3.4,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Introduction \xe0 GitHub Actions","description":"D\xe9couvrez comment GitHub Actions peut automatiser vos workflows de d\xe9veloppement et de d\xe9ploiement.","tags":["CI/CD","GitHub","Devops"]},"unlisted":false,"prevItem":{"title":"Workflows","permalink":"/blog/2024/03/17/04-ci-cd/workflow"},"nextItem":{"title":"Diff\xe9rence entre un proxy et un reverse proxy","permalink":"/blog/2024/02/01/02-network/proxy-vs-reverse-proxy"}},"content":"Dans le monde du d\xe9veloppement logiciel, l\'automatisation est devenue une n\xe9cessit\xe9 pour am\xe9liorer l\'efficacit\xe9 et r\xe9duire les erreurs humaines. GitHub Actions est une plateforme puissante qui permet d\'automatiser les workflows de d\xe9veloppement et de d\xe9ploiement. Dans cet article, nous allons explorer les concepts de base de GitHub Actions, ses avantages, et fournir des exemples concrets pour vous aider \xe0 d\xe9marrer.\\n\\n\x3c!--truncate--\x3e\\n\\n### Qu\'est-ce que GitHub Actions ?\\n\\nGitHub Actions est une plateforme d\'automatisation des workflows de d\xe9veloppement et de d\xe9ploiement. Elle permet aux d\xe9veloppeurs d\'automatiser des t\xe2ches r\xe9p\xe9titives, telles que les tests, les builds et les d\xe9ploiements, en utilisant des fichiers de configuration YAML.\\n\\n### Pourquoi utiliser GitHub Actions ?\\n\\nGitHub Actions offre plusieurs avantages pour les d\xe9veloppeurs et les \xe9quipes DevOps :\\n\\n1. **Automatisation des workflows** : GitHub Actions permet d\'automatiser les t\xe2ches r\xe9p\xe9titives, ce qui r\xe9duit les erreurs humaines et am\xe9liore l\'efficacit\xe9.\\n2. **Int\xe9gration continue (CI)** : Les workflows peuvent \xeatre configur\xe9s pour s\'ex\xe9cuter automatiquement \xe0 chaque commit, garantissant que le code est toujours test\xe9 et pr\xeat \xe0 \xeatre d\xe9ploy\xe9.\\n3. **D\xe9ploiement continu (CD)** : GitHub Actions facilite le d\xe9ploiement automatique des applications sur diff\xe9rents environnements, tels que les serveurs de production, les environnements de test et les conteneurs Docker.\\n4. **Flexibilit\xe9** : Les workflows peuvent \xeatre personnalis\xe9s pour r\xe9pondre aux besoins sp\xe9cifiques de chaque projet, en utilisant des actions pr\xe9d\xe9finies ou en cr\xe9ant des actions personnalis\xe9es.\\n5. **Communaut\xe9 et \xe9cosyst\xe8me** : GitHub Actions b\xe9n\xe9ficie d\'une large communaut\xe9 de d\xe9veloppeurs et d\'un \xe9cosyst\xe8me riche en actions pr\xe9d\xe9finies, ce qui facilite l\'int\xe9gration avec d\'autres outils et services.\\n\\n### Marketplace et r\xe9utilisation\\n\\nLe GitHub Marketplace est une ressource pr\xe9cieuse pour trouver des actions pr\xe9d\xe9finies cr\xe9\xe9es par la communaut\xe9. Vous pouvez r\xe9utiliser ces actions dans vos workflows pour automatiser des t\xe2ches courantes sans avoir \xe0 les coder vous-m\xeame. Cela permet de gagner du temps et de b\xe9n\xe9ficier des meilleures pratiques de la communaut\xe9.\\n\\n## Concepts de base de GitHub Actions\\n\\n### \xc9v\xe9nements\\n\\nLes \xe9v\xe9nements sont des d\xe9clencheurs qui activent l\'ex\xe9cution des workflows. Les \xe9v\xe9nements courants incluent les commits, les pull requests, les issues et les releases. Par exemple, un workflow peut \xeatre configur\xe9 pour s\'ex\xe9cuter \xe0 chaque commit sur la branche principale.\\n\\n### Actions\\n\\nLes actions sont des t\xe2ches individuelles qui composent un workflow. Elles peuvent \xeatre pr\xe9d\xe9finies ou personnalis\xe9es. Les actions pr\xe9d\xe9finies sont disponibles dans le GitHub Marketplace et couvrent une large gamme de t\xe2ches, telles que l\'installation de d\xe9pendances, l\'ex\xe9cution de tests et le d\xe9ploiement d\'applications.\\n\\n### Workflows\\n\\nLes workflows sont des fichiers de configuration YAML qui d\xe9finissent les actions \xe0 ex\xe9cuter en r\xe9ponse \xe0 des \xe9v\xe9nements sp\xe9cifiques. Un workflow peut contenir plusieurs jobs, chacun compos\xe9 de plusieurs \xe9tapes. Les workflows sont stock\xe9s dans le r\xe9pertoire `.github/workflows` du d\xe9p\xf4t.\\n\\n## Exemple de workflow GitHub Actions\\n\\nVoici un exemple de workflow GitHub Actions pour une application Node.js. Ce workflow s\'ex\xe9cute \xe0 chaque commit sur la branche principale, installe les d\xe9pendances, ex\xe9cute les tests et d\xe9ploie l\'application sur un serveur de production.\\n\\n```yaml\\nname: CI/CD Pipeline\\n\\non:\\n  push:\\n    branches:\\n      - main\\n\\njobs:\\n  build:\\n    runs-on: ubuntu-latest\\n\\n    steps:\\n      - name: Checkout code\\n        uses: actions/checkout@v2\\n\\n      - name: Set up Node.js\\n        uses: actions/setup-node@v2\\n        with:\\n          node-version: \'14\'\\n\\n      - name: Install dependencies\\n        run: npm install\\n\\n      - name: Run tests\\n        run: npm test\\n\\n      - name: Deploy to production\\n        run: |\\n          ssh user@server \'cd /path/to/app && git pull && npm install && pm2 restart app\'\\n```\\n\\n## Les runners GitHub Actions\\n\\nLes runners sont des machines virtuelles ou physiques qui ex\xe9cutent les jobs d\xe9finis dans les workflows. GitHub propose des runners h\xe9berg\xe9s, mais vous pouvez \xe9galement configurer vos propres runners auto-h\xe9berg\xe9s pour r\xe9pondre \xe0 des besoins sp\xe9cifiques. Les runners auto-h\xe9berg\xe9s offrent plus de contr\xf4le sur l\'environnement d\'ex\xe9cution et peuvent \xeatre utilis\xe9s pour des t\xe2ches n\xe9cessitant des ressources sp\xe9cifiques.\\n\\n## Conclusion\\n\\nGitHub Actions est un outil puissant pour automatiser les workflows de d\xe9veloppement et de d\xe9ploiement. En utilisant des fichiers de configuration YAML, les d\xe9veloppeurs peuvent cr\xe9er des workflows personnalis\xe9s pour r\xe9pondre aux besoins sp\xe9cifiques de leurs projets. Avec GitHub Actions, les \xe9quipes DevOps peuvent am\xe9liorer l\'efficacit\xe9, r\xe9duire les erreurs humaines et acc\xe9l\xe9rer le cycle de d\xe9veloppement.\\n\\nPour en savoir plus sur GitHub Actions, consultez la [documentation officielle](https://docs.github.com/en/actions)."},{"id":"/2024/02/01/02-network/proxy-vs-reverse-proxy","metadata":{"permalink":"/blog/2024/02/01/02-network/proxy-vs-reverse-proxy","source":"@site/blog/02-network/2024-02-01-proxy-vs-reverse-proxy.md","title":"Diff\xe9rence entre un proxy et un reverse proxy","description":"Explication de la diff\xe9rence entre un proxy et un reverse proxy, inspir\xe9e du transcript de la vid\xe9o \'Proxy vs Reverse Proxy vs Load Balancer | Simply Explained\'.","date":"2024-02-01T00:00:00.000Z","tags":[{"inline":true,"label":"Proxy","permalink":"/blog/tags/proxy"},{"inline":true,"label":"Reverse Proxy","permalink":"/blog/tags/reverse-proxy"},{"inline":true,"label":"Network","permalink":"/blog/tags/network"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":5.04,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Diff\xe9rence entre un proxy et un reverse proxy","description":"Explication de la diff\xe9rence entre un proxy et un reverse proxy, inspir\xe9e du transcript de la vid\xe9o \'Proxy vs Reverse Proxy vs Load Balancer | Simply Explained\'.","tags":["Proxy","Reverse Proxy","Network","Devops"]},"unlisted":false,"prevItem":{"title":"Introduction \xe0 GitHub Actions","permalink":"/blog/2024/02/22/04-ci-cd/github-actions"},"nextItem":{"title":"Pr\xe9sentation de Nginx","permalink":"/blog/2024/01/15/02-network/nginx"}},"content":"Dans cet article, nous allons explorer la diff\xe9rence entre un proxy et un reverse proxy.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce qu\'un proxy ?\\n\\nUn proxy, \xe9galement connu sous le nom de proxy direct ou proxy de transfert, est un serveur qui agit comme un interm\xe9diaire entre un client (par exemple, un utilisateur ou un appareil) et un serveur de destination sur Internet. Voici un aper\xe7u d\xe9taill\xe9 de son fonctionnement :\\n\\n1. **Interception des requ\xeates** : Lorsqu\'un client souhaite acc\xe9der \xe0 une ressource sur Internet, il envoie une requ\xeate au proxy au lieu de se connecter directement au serveur de destination. Le proxy intercepte cette requ\xeate.\\n\\n2. **Filtrage et s\xe9curit\xe9** : Le proxy examine la requ\xeate pour s\'assurer qu\'elle respecte les politiques de s\xe9curit\xe9 et de filtrage d\xe9finies par l\'administrateur r\xe9seau. Il peut bloquer l\'acc\xe8s \xe0 certains sites web, filtrer les contenus inappropri\xe9s ou malveillants, et appliquer des r\xe8gles de s\xe9curit\xe9.\\n\\n3. **Anonymisation** : Le proxy peut masquer l\'adresse IP du client en utilisant sa propre adresse IP pour se connecter au serveur de destination. Cela permet de prot\xe9ger l\'identit\xe9 et la confidentialit\xe9 du client.\\n\\n4. **Mise en cache** : Le proxy peut mettre en cache les r\xe9ponses des serveurs de destination. Si un autre client demande la m\xeame ressource, le proxy peut fournir la r\xe9ponse mise en cache, ce qui r\xe9duit la charge sur le serveur de destination et am\xe9liore les temps de r\xe9ponse.\\n\\n5. **Transmission de la requ\xeate** : Si la requ\xeate est autoris\xe9e, le proxy la transmet au serveur de destination en utilisant sa propre adresse IP. Le serveur de destination r\xe9pond alors au proxy.\\n\\n6. **Retour de la r\xe9ponse** : Le proxy re\xe7oit la r\xe9ponse du serveur de destination, la filtre \xe0 nouveau si n\xe9cessaire, et la renvoie au client. Le client re\xe7oit ainsi la r\xe9ponse comme s\'il avait directement communiqu\xe9 avec le serveur de destination.\\n\\n### Exemple d\'utilisation d\'un proxy\\n\\nImaginez que vous planifiez un d\xeener dans un restaurant populaire, mais que vous ne voulez pas interagir directement avec le personnel. Vous avez donc un assistant personnel qui fait la r\xe9servation pour vous. Le personnel du restaurant ne communique qu\'avec votre assistant, pas directement avec vous. Dans ce sc\xe9nario, votre assistant personnel est un proxy.\\n\\nDans un contexte d\'entreprise, un administrateur peut configurer tout le trafic Internet des ordinateurs des employ\xe9s pour qu\'il passe par un proxy. Cela permet de prot\xe9ger le r\xe9seau interne de l\'entreprise en bloquant les sites web malveillants et en filtrant le trafic.\\n\\nUn proxy peut \xe9galement mettre en cache les r\xe9ponses des serveurs backend pour r\xe9duire la charge et am\xe9liorer les temps de r\xe9ponse. Par exemple, si un employ\xe9 regarde une vid\xe9o YouTube, le proxy peut mettre en cache cette vid\xe9o pour que les autres employ\xe9s puissent la regarder sans consommer de bande passante suppl\xe9mentaire.\\n\\n## Qu\'est-ce qu\'un reverse proxy ?\\n\\n\\nUn reverse proxy, \xe9galement connu sous le nom de proxy inverse, est un serveur qui se trouve devant les serveurs internes d\'une entreprise et g\xe8re les requ\xeates entrantes des clients. Voici un aper\xe7u d\xe9taill\xe9 de son fonctionnement :\\n\\n1. **R\xe9ception des requ\xeates** : Lorsqu\'un client envoie une requ\xeate pour acc\xe9der \xe0 une ressource sur un serveur interne, la requ\xeate est d\'abord re\xe7ue par le reverse proxy au lieu d\'\xeatre directement envoy\xe9e au serveur interne.\\n\\n2. **Distribution des requ\xeates** : Le reverse proxy examine la requ\xeate et la distribue au serveur interne appropri\xe9 en fonction de la capacit\xe9, de la charge et des r\xe8gles de routage d\xe9finies. Cela permet de r\xe9partir la charge de mani\xe8re \xe9quilibr\xe9e entre les serveurs internes.\\n\\n3. **S\xe9curit\xe9 et filtrage** : Le reverse proxy peut appliquer des politiques de s\xe9curit\xe9 pour filtrer les requ\xeates malveillantes, bloquer les attaques DDoS, et assurer le chiffrement SSL/TLS pour s\xe9curiser les communications entre les clients et les serveurs internes.\\n\\n4. **Mise en cache** : Le reverse proxy peut mettre en cache les r\xe9ponses des serveurs internes. Si un autre client demande la m\xeame ressource, le reverse proxy peut fournir la r\xe9ponse mise en cache, ce qui r\xe9duit la charge sur les serveurs internes et am\xe9liore les temps de r\xe9ponse.\\n\\n5. **Retour de la r\xe9ponse** : Le serveur interne r\xe9pond au reverse proxy, qui filtre \xe0 nouveau la r\xe9ponse si n\xe9cessaire, et la renvoie au client. Le client re\xe7oit ainsi la r\xe9ponse comme s\'il avait directement communiqu\xe9 avec le serveur interne.\\n\\n6. **Surveillance et journalisation** : Le reverse proxy peut surveiller et journaliser les requ\xeates et les r\xe9ponses pour des raisons de s\xe9curit\xe9, de d\xe9pannage et d\'analyse des performances.\\n\\n### Exemple d\'utilisation d\'un reverse proxy\\n\\nReprenons l\'analogie du restaurant. Lorsque vous arrivez au restaurant, au lieu de chercher une table vous-m\xeame, vous vous enregistrez \xe0 la r\xe9ception. Le r\xe9ceptionniste vous montre la table appropri\xe9e. Ici, le r\xe9ceptionniste est un reverse proxy.\\n\\nUn reverse proxy peut \xe9galement agir comme un bouclier pour prot\xe9ger les serveurs internes en filtrant les requ\xeates et en assurant le chiffrement SSL. Il peut \xe9galement mettre en cache les r\xe9ponses pour acc\xe9l\xe9rer les temps de r\xe9ponse aux clients.\\n\\nUn reverse proxy peut \xe9galement fournir des fonctionnalit\xe9s d\'\xe9quilibrage de charge. Par exemple, si un serveur est surcharg\xe9, le reverse proxy peut rediriger les requ\xeates vers un autre serveur moins occup\xe9. Cela permet d\'assurer une r\xe9partition \xe9quilibr\xe9e de la charge et d\'am\xe9liorer les performances globales du syst\xe8me.\\n\\n## Diff\xe9rences cl\xe9s entre un proxy et un reverse proxy\\n\\n- **Fonctionnalit\xe9** : Un proxy agit comme un interm\xe9diaire pour les requ\xeates sortantes, tandis qu\'un reverse proxy g\xe8re les requ\xeates entrantes.\\n- **S\xe9curit\xe9** : Les deux types de proxy offrent des fonctionnalit\xe9s de s\xe9curit\xe9, mais un reverse proxy prot\xe8ge les serveurs internes en filtrant les requ\xeates entrantes.\\n- **Caching** : Les deux types de proxy peuvent mettre en cache les r\xe9ponses, mais un reverse proxy le fait pour acc\xe9l\xe9rer les temps de r\xe9ponse aux clients.\\n\\nEn r\xe9sum\xe9, un proxy et un reverse proxy ont des r\xf4les diff\xe9rents mais compl\xe9mentaires dans la gestion du trafic r\xe9seau. Un proxy prot\xe8ge les utilisateurs en filtrant le trafic sortant, tandis qu\'un reverse proxy prot\xe8ge les serveurs en g\xe9rant les requ\xeates entrantes.\\n\\n## Sch\xe9ma r\xe9capitulatif\\n\\n![Sch\xe9ma r\xe9capitulatif](https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fwqces5nwe4hb4bydyd13.png)"},{"id":"/2024/01/15/02-network/nginx","metadata":{"permalink":"/blog/2024/01/15/02-network/nginx","source":"@site/blog/02-network/2024-01-15-nginx.md","title":"Pr\xe9sentation de Nginx","description":"Pr\xe9sentation de Nginx, son but et ses exemples d\'utilisation dans la vie r\xe9elle.","date":"2024-01-15T00:00:00.000Z","tags":[{"inline":true,"label":"Nginx","permalink":"/blog/tags/nginx"},{"inline":true,"label":"Network","permalink":"/blog/tags/network"},{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"}],"readingTime":2.55,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Pr\xe9sentation de Nginx","description":"Pr\xe9sentation de Nginx, son but et ses exemples d\'utilisation dans la vie r\xe9elle.","tags":["Nginx","Network","Devops"]},"unlisted":false,"prevItem":{"title":"Diff\xe9rence entre un proxy et un reverse proxy","permalink":"/blog/2024/02/01/02-network/proxy-vs-reverse-proxy"},"nextItem":{"title":"DevOps Roadmap 2024","permalink":"/blog/2024/01/01/devops-roadmap-2024"}},"content":"Nginx est un serveur web open-source con\xe7u pour g\xe9rer un grand nombre de connexions simultan\xe9es. Il couvre les fonctionnalit\xe9s de Nginx telles que l\'\xe9quilibrage de charge, le caching, la s\xe9curit\xe9 et la compression, ainsi que des exemples d\'utilisation dans la vie r\xe9elle.\\n\\n\x3c!--truncate--\x3e\\n\\n## Qu\'est-ce que Nginx et pourquoi a-t-il \xe9t\xe9 cr\xe9\xe9 ?\\n\\nNginx est un serveur web open-source qui a \xe9t\xe9 cr\xe9\xe9 pour g\xe9rer un grand nombre de connexions simultan\xe9es. Il a \xe9t\xe9 con\xe7u pour \xeatre rapide, l\xe9ger et efficace. Nginx est souvent utilis\xe9 comme serveur web, mais il peut \xe9galement \xeatre utilis\xe9 comme proxy inverse, \xe9quilibrage de charge, et serveur de cache.\\n\\n### Exemples d\'utilisation de Nginx\\n\\nNginx est souvent utilis\xe9 pour servir des pages web statiques et dynamiques. Il est capable de g\xe9rer des milliers de connexions simultan\xe9es avec une faible utilisation de la m\xe9moire.\\n\\nNginx peut agir comme un proxy inverse pour distribuer les requ\xeates des clients \xe0 plusieurs serveurs backend. Cela permet de r\xe9partir la charge et d\'am\xe9liorer les performances.\\n\\nNginx peut \xeatre utilis\xe9 pour r\xe9partir les requ\xeates entrantes entre plusieurs serveurs, assurant ainsi une r\xe9partition \xe9quilibr\xe9e de la charge.\\n\\nNginx peut mettre en cache les r\xe9ponses des serveurs backend pour r\xe9duire la charge et am\xe9liorer les temps de r\xe9ponse.\\n\\n## Fonctionnalit\xe9s de Nginx\\n\\nL\'\xe9quilibrage de charge est une fonctionnalit\xe9 cl\xe9 de Nginx. Il permet de distribuer les requ\xeates entrantes entre plusieurs serveurs backend. Nginx prend en charge plusieurs algorithmes d\'\xe9quilibrage de charge, tels que le round-robin, le least connections, et l\'IP hash.\\n\\nNginx peut mettre en cache les r\xe9ponses des serveurs backend pour r\xe9duire la charge et am\xe9liorer les temps de r\xe9ponse. Le caching est particuli\xe8rement utile pour les contenus statiques qui ne changent pas fr\xe9quemment.\\n\\nNginx offre plusieurs fonctionnalit\xe9s de s\xe9curit\xe9, telles que la gestion des certificats SSL/TLS, la limitation du nombre de connexions, et la protection contre les attaques DDoS. En utilisant Nginx comme proxy inverse, vous pouvez \xe9galement masquer les d\xe9tails de votre infrastructure backend.\\n\\nNginx peut compresser les r\xe9ponses avant de les envoyer aux clients. Cela permet de r\xe9duire la quantit\xe9 de donn\xe9es transf\xe9r\xe9es et d\'am\xe9liorer les temps de chargement des pages. Nginx prend en charge plusieurs formats de compression, tels que gzip et brotli.\\n\\n## Configuration de Nginx\\n\\nLa configuration de Nginx se fait \xe0 l\'aide de fichiers de configuration. Voici un exemple de configuration simple pour un serveur web :\\n\\n```nginx\\nserver {\\n    listen 80;\\n    server_name example.com;\\n\\n    location / {\\n        root /var/www/html;\\n        index index.html index.htm;\\n    }\\n\\n    location /images/ {\\n        root /data;\\n    }\\n}\\n```\\n\\nDans cet exemple, Nginx \xe9coute sur le port 80 et sert les fichiers du r\xe9pertoire `/var/www/html` pour les requ\xeates \xe0 la racine. Les requ\xeates pour `/images/` sont servies \xe0 partir du r\xe9pertoire `/data`.\\n\\n## Conclusion\\n\\nNginx est un outil puissant et polyvalent qui peut \xeatre utilis\xe9 pour une vari\xe9t\xe9 de t\xe2ches, allant de la simple diffusion de contenu web \xe0 l\'\xe9quilibrage de charge et au caching. Sa flexibilit\xe9 et ses performances en font un choix populaire pour de nombreuses entreprises et d\xe9veloppeurs.\\n\\nPour en savoir plus sur Nginx, vous pouvez consulter la [documentation officielle](https://nginx.org/en/docs/)."},{"id":"/2024/01/01/devops-roadmap-2024","metadata":{"permalink":"/blog/2024/01/01/devops-roadmap-2024","source":"@site/blog/2024-01-01-devops-roadmap-2024.md","title":"DevOps Roadmap 2024","description":"Pr\xe9sentation de ma roadmap DevOps personnelle 2024","date":"2024-01-01T00:00:00.000Z","tags":[{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"},{"inline":true,"label":"Roadmap","permalink":"/blog/tags/roadmap"}],"readingTime":0.96,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"DevOps Roadmap 2024","description":"Pr\xe9sentation de ma roadmap DevOps personnelle 2024","tags":["Devops","Roadmap"]},"unlisted":false,"prevItem":{"title":"Pr\xe9sentation de Nginx","permalink":"/blog/2024/01/15/02-network/nginx"},"nextItem":{"title":"DevOps Roadmap Acquis","permalink":"/blog/2024/01/01/devops-roadmap-acquis"}},"content":"Voici un r\xe9sum\xe9 de ma roadmap DevOps personnelle pour 2024. Cette roadmap est bas\xe9e sur mes exp\xe9riences et mes objectifs personnels. Elle est sujette \xe0 des changements et des mises \xe0 jour r\xe9guli\xe8res. N\'h\xe9sitez pas \xe0 me contacter si vous avez des suggestions ou des commentaires.\\n\\n\x3c!--truncate--\x3e\\n\\n# DevOps Roadmap 2024\\n\\nimport IconTitle from \'@site/src/components/IconTitle\';\\n\\n![DevOps](/img/devops.png)\\n\\n## <IconTitle logo=\\"skill-icons:linux-light\\" name=\\"02 OS & Linux\\"/>\\n\\n- Notions de base de la mise en r\xe9seau et de la s\xe9curit\xe9\\n- Configuration des pare-feu pour s\xe9curiser l\'acc\xe8s\\n- \xc9quilibreurs de charge\\n- Proxies\\n- HTTP/HTTPS\\n- Virtualisation\\n\\n## <IconTitle logo=\\"skill-icons:docker\\" name=\\"03 Conten\xe9risation - Docker\\"/>\\n\\n- Ex\xe9cuter des conteneurs\\n- Inspecter les conteneurs actifs\\n- R\xe9seau Docker\\n- Persister les donn\xe9es avec les volumes Docker\\n- Dockeriser les applications en utilisant Dockerfiles\\n- Ex\xe9cuter plusieurs conteneurs en utilisant Docker-Compose\\n- Travailler avec le d\xe9p\xf4t Docker\\n\\n## <IconTitle logo=\\"skill-icons:githubactions-light\\" name=\\"04 CI/CD Pipeline\\"/>\\n\\n- Configuration du serveur CI/CD\\n- Int\xe9gration du d\xe9p\xf4t de code pour d\xe9clencher le pipeline automatiquement\\n- Outils de construction et de gestion de packages pour ex\xe9cuter les tests et emballer l\'application\\n- Configuration des d\xe9p\xf4ts d\'artefacts (comme Nexus) et int\xe9gration avec le pipeline"},{"id":"/2024/01/01/devops-roadmap-acquis","metadata":{"permalink":"/blog/2024/01/01/devops-roadmap-acquis","source":"@site/blog/2024-01-01-devops-roadmap-acquis.md","title":"DevOps Roadmap Acquis","description":"Pr\xe9sentation de ma roadmap DevOps personnelle - Acquis","date":"2024-01-01T00:00:00.000Z","tags":[{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"},{"inline":true,"label":"Roadmap","permalink":"/blog/tags/roadmap"}],"readingTime":1.17,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"DevOps Roadmap Acquis","description":"Pr\xe9sentation de ma roadmap DevOps personnelle - Acquis","tags":["Devops","Roadmap"]},"unlisted":false,"prevItem":{"title":"DevOps Roadmap 2024","permalink":"/blog/2024/01/01/devops-roadmap-2024"},"nextItem":{"title":"DevOps Roadmap","permalink":"/blog/2024/01/01/devops-roadmap"}},"content":"Voici un r\xe9sum\xe9 vis \xe0 vis de la roadmap DevOps personnelle g\xe9n\xe9rale des comp\xe9tences d\xe9j\xe0 acquises via ma formation et mes exp\xe9riences professionnelles. Cette roadmap est bas\xe9e sur mes exp\xe9riences et mes objectifs personnels. Elle est sujette \xe0 des changements et des mises \xe0 jour r\xe9guli\xe8res. N\'h\xe9sitez pas \xe0 me contacter si vous avez des suggestions ou des commentaires.\\n\\n\x3c!--truncate--\x3e\\n\\n# Les acquis\\n\\nimport IconTitle from \'@site/src/components/IconTitle\';\\n\\n![DevOps](/img/devops.png)\\n\\n## <IconTitle logo=\\"mdi:code-braces\\" name=\\"01 Concepts du d\xe9veloppement logiciel\\"/>\\n\\n- Collaboration des d\xe9veloppeurs (Agile, Jira)\\n- Utilisation de Git\\n- Configuration des applications (Outils de build)\\n- Compr\xe9hension du cycle de vie du d\xe9veloppement logiciel\\n- Tests automatis\xe9s\\n\\n## <IconTitle logo=\\"skill-icons:linux-light\\" name=\\"02 OS & Linux\\"/>\\n\\n- Commandes Shell\\n- Syst\xe8me de fichiers Linux & Permissions\\n- Gestion des cl\xe9s SSH\\n- Comprendre comment fonctionnent les adresses IP, les ports et le DNS\\n\\n## <IconTitle logo=\\"skill-icons:python-light\\" name=\\"09 Langages de script - Python\\"/>\\n\\n- Apprendre les bases de Python\\n- \xc9crire des scripts utilitaires, par exemple pour vider le cache, d\xe9marrer les builds et les d\xe9ploiements\\n- Comprendre les concepts de programmation de base\\n\\n<IconTitle logo=\\"skill-icons:git\\" name=\\"10 Contr\xf4le de version - Git\\"/>\\n\\n- Apprendre \xe0 utiliser un d\xe9p\xf4t Git\\n- Ma\xeetriser les commandes de base de Git, comme git clone, git branch, git pull/push, git merge, etc.\\n- Apprendre \xe0 collaborer sur un projet, comme cr\xe9er des pull requests, faire des revues de code, g\xe9rer les branches"},{"id":"/2024/01/01/devops-roadmap","metadata":{"permalink":"/blog/2024/01/01/devops-roadmap","source":"@site/blog/2024-01-01-devops-roadmap.md","title":"DevOps Roadmap","description":"Pr\xe9sentation de ma roadmap DevOps personnelle","date":"2024-01-01T00:00:00.000Z","tags":[{"inline":true,"label":"Devops","permalink":"/blog/tags/devops"},{"inline":true,"label":"Roadmap","permalink":"/blog/tags/roadmap"}],"readingTime":5.4,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"DevOps Roadmap","description":"Pr\xe9sentation de ma roadmap DevOps personnelle","tags":["Devops","Roadmap"]},"unlisted":false,"prevItem":{"title":"DevOps Roadmap Acquis","permalink":"/blog/2024/01/01/devops-roadmap-acquis"}},"content":"Ing\xe9nieur en informatique au [CATIE](http://catie.fr/) sp\xe9cialis\xe9 en Robotique je suis amen\xe9 \xe0 travailler sur des projets de d\xe9veloppement logiciel et d\'int\xe9gration sur diff\xe9rentes plateformes. Intrigu\xe9 et passion\xe9 par l\'int\xe9gration et l\'automatisation des t\xe2ches, j\'ai d\xe9cid\xe9 d\'approfondir mes connaissances en DevOps.\\n\\n\x3c!--truncate--\x3e\\n\\nVoici un r\xe9sum\xe9 de ma roadmap DevOps personnelle pour 2024. Cette roadmap est bas\xe9e sur mes exp\xe9riences et mes objectifs personnels. Elle est sujette \xe0 des changements et des mises \xe0 jour r\xe9guli\xe8res. N\'h\xe9sitez pas \xe0 me contacter si vous avez des suggestions ou des commentaires.\\n\\n# DevOps Roadmap\\n\\nimport IconTitle from \'@site/src/components/IconTitle\';\\n\\n![DevOps](/img/devops.png)\\n\\n## <IconTitle logo=\\"mdi:code-braces\\" name=\\"01 Concepts du d\xe9veloppement logiciel\\"/>\\n\\nIl est essentiel de comprendre les concepts suivants pour collaborer efficacement avec l\'\xe9quipe de d\xe9veloppement et automatiser les t\xe2ches :\\n\\n\\n- Collaboration des d\xe9veloppeurs (Agile, Jira)\\n- Utilisation de Git\\n- Configuration des applications (Outils de build)\\n- Compr\xe9hension du cycle de vie du d\xe9veloppement logiciel\\n- Tests automatis\xe9s\\n\\n## <IconTitle logo=\\"skill-icons:linux-light\\" name=\\"02 OS & Linux\\"/>\\n\\nIl est essentiel de pr\xe9parer et de maintenir l\'infrastructure (serveurs) sur laquelle l\'application est d\xe9ploy\xe9e. Il est donc n\xe9cessaire de conna\xeetre les bases de l\'administration d\'un serveur et de l\'installation de diff\xe9rents outils. Voici les concepts de base des syst\xe8mes d\'exploitation \xe0 comprendre :\\n\\n- Commandes Shell\\n- Syst\xe8me de fichiers Linux & Permissions\\n- Gestion des cl\xe9s SSH\\n- Notions de base de la mise en r\xe9seau et de la s\xe9curit\xe9\\n- Configuration des pare-feu pour s\xe9curiser l\'acc\xe8s\\n- Comprendre comment fonctionnent les adresses IP, les ports et le DNS\\n- \xc9quilibreurs de charge\\n- Proxies\\n- HTTP/HTTPS\\n- Virtualisation\\n\\n## <IconTitle logo=\\"skill-icons:docker\\" name=\\"03 Conten\xe9risation - Docker\\"/>\\n\\nLes conteneurs sont devenus le standard de l\'emballage logiciel, et il est essentiel de comprendre les concepts de virtualisation et de conteneurisation, ainsi que la gestion des applications conteneuris\xe9es sur un serveur. Docker, la technologie de conteneur la plus populaire, n\xe9cessite la ma\xeetrise de plusieurs points cl\xe9s.\\n\\n- Ex\xe9cuter des conteneurs\\n- Inspecter les conteneurs actifs\\n- R\xe9seau Docker\\n- Persister les donn\xe9es avec les volumes Docker\\n- Dockeriser les applications en utilisant Dockerfiles\\n- Ex\xe9cuter plusieurs conteneurs en utilisant Docker-Compose\\n- Travailler avec le d\xe9p\xf4t Docker\\n\\n## <IconTitle logo=\\"skill-icons:githubactions-light\\" name=\\"04 CI/CD Pipeline\\"/>\\n\\nCI/CD est au c\u0153ur de DevOps. Toutes les modifications de code, telles que les nouvelles fonctionnalit\xe9s ou les corrections de bugs, doivent \xeatre int\xe9gr\xe9es dans l\'application existante et d\xe9ploy\xe9es pour l\'utilisateur final de mani\xe8re continue et automatis\xe9e. D\'o\xf9 le terme : Int\xe9gration Continue et D\xe9ploiement Continu (CI/CD).\\n\\n- Configuration du serveur CI/CD\\n- Int\xe9gration du d\xe9p\xf4t de code pour d\xe9clencher le pipeline automatiquement\\n- Outils de construction et de gestion de packages pour ex\xe9cuter les tests et emballer l\'application\\n- Configuration des d\xe9p\xf4ts d\'artefacts (comme Nexus) et int\xe9gration avec le pipeline\\n\\n## <IconTitle logo=\\"skill-icons:aws-light\\" name=\\"05 Apprendre un fournisseur de Cloud\\"/>\\n\\nDe nombreuses entreprises utilisent aujourd\'hui une infrastructure virtuelle sur le cloud, plut\xf4t que de g\xe9rer leur propre infrastructure. Les plateformes Infrastructure as a Service (IaaS) offrent une gamme de services suppl\xe9mentaires, tels que la sauvegarde, la s\xe9curit\xe9 et l\'\xe9quilibrage de charge. AWS est la plateforme IaaS la plus puissante et la plus largement utilis\xe9e, bien qu\'elle soit \xe9galement l\'une des plus complexes. D\'autres plateformes populaires incluent Microsoft Azure et Google Cloud. Ces services sont sp\xe9cifiques \xe0 chaque plateforme, il est donc n\xe9cessaire d\'apprendre les services de la plateforme choisie et de savoir g\xe9rer toute l\'infrastructure de d\xe9ploiement sur celle-ci. Par exemple, pour AWS, il est important de conna\xeetre les bases des services IAM, VPC et EC2.\\n\\n- Service IAM - gestion des utilisateurs et des permissions\\n- Service VPC - votre r\xe9seau priv\xe9\\n- Service EC2 - serveurs virtuels\\n\\n## <IconTitle logo=\\"skill-icons:kubernetes\\" name=\\"06 Orchestration de conteneurs - Kubernetes & Docker Swarm\\"/>\\n\\nAvec la popularit\xe9 et la facilit\xe9 d\'utilisation des conteneurs, de nombreuses entreprises ex\xe9cutent des centaines ou des milliers de conteneurs sur plusieurs serveurs, n\xe9cessitant une gestion efficace. Pour cela, des outils d\'orchestration de conteneurs comme Kubernetes (K8s) sont utilis\xe9s. Kubernetes est l\'outil d\'orchestration de conteneurs le plus populaire, et il est essentiel de le ma\xeetriser.\\n\\n- Apprendre les composants de base comme, Deployment, Service, ConfigMap, Secret, StatefulSet, Ingress\\n- CLI Kubernetes (Kubectl)\\n- Persistance des donn\xe9es avec les volumes K8s\\n- Namespaces\\n- Docker Swarm\\n\\n## <IconTitle logo=\\"skill-icons:prometheus\\" name=\\"07 Monitoring & Observabilit\xe9\\"/>\\n\\nUne fois le logiciel en production, il est important de le surveiller pour suivre les performances et d\xe9couvrir les probl\xe8mes dans l\'infrastructure et l\'application. Ainsi, l\'une des responsabilit\xe9s d\'un ing\xe9nieur DevOps est de :\\n\\n- Prometheus : Un outil de surveillance et d\'alerte populaire\\n- Grafana : Outil d\'analyse et de visualisation interactive\\n- ELK Stack : Une pile de gestion de logs populaire\\n\\n## <IconTitle logo=\\"skill-icons:terraform-light\\" name=\\"08 Infrastructure as Code\\"/>\\n\\nCr\xe9er et maintenir manuellement une infrastructure est une t\xe2che chronophage et sujette \xe0 erreurs, notamment lorsqu\'il s\'agit de r\xe9pliquer l\'infrastructure pour diff\xe9rents environnements tels que le d\xe9veloppement, les tests et la production. En DevOps, l\'objectif est d\'automatiser autant que possible, et c\'est l\xe0 qu\'intervient l\'Infrastructure as Code.\\n\\n- Terraform est l\'outil de provisionnement d\'infrastructure le plus populaire\\n- Ansible est l\'outil de gestion de configuration le plus populaire\\n\\n## <IconTitle logo=\\"skill-icons:python-light\\" name=\\"09 Langages de script - Python\\"/>\\n\\nTravailler \xe9troitement avec les d\xe9veloppeurs et les administrateurs syst\xe8me pour automatiser les t\xe2ches de d\xe9veloppement et d\'op\xe9rations n\xe9cessite l\'\xe9criture de scripts et de petites applications. Pour cela, des comp\xe9tences en scripting ou en programmation de base sont n\xe9cessaires. Python est un langage largement utilis\xe9, facile \xe0 apprendre et adapt\xe9 \xe0 de nombreux cas d\'utilisation diff\xe9rents, en particulier en DevOps.\\n\\n- Apprendre les bases de Python\\n- \xc9crire des scripts utilitaires, par exemple pour vider le cache, d\xe9marrer les builds et les d\xe9ploiements\\n- Comprendre les concepts de programmation de base\\n\\n<IconTitle logo=\\"skill-icons:git\\" name=\\"10 Contr\xf4le de version - Git\\"/>\\n\\nToute la logique d\'automatisation est \xe9crite sous forme de code. Comme pour le code d\'application, le code d\'automatisation doit \xe9galement \xeatre g\xe9r\xe9 et h\xe9berg\xe9 sur un outil de contr\xf4le de version, tel que Git. Git est l\'outil de contr\xf4le de version le plus populaire et le plus largement utilis\xe9. Les fichiers sont stock\xe9s de mani\xe8re centralis\xe9e dans un d\xe9p\xf4t Git distant sur le web. Les d\xe9p\xf4ts Git les plus populaires sont GitHub et GitLab. Git est un outil CLI, install\xe9 localement. Il permet de suivre les modifications du code source et facilite la collaboration sur le code.\\n\\n- Apprendre \xe0 utiliser un d\xe9p\xf4t Git\\n- Ma\xeetriser les commandes de base de Git, comme git clone, git branch, git pull/push, git merge, etc.\\n- Apprendre \xe0 collaborer sur un projet, comme cr\xe9er des pull requests, faire des revues de code, g\xe9rer les branches"}]}}')}}]);