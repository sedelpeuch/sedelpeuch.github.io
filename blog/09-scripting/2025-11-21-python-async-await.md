---
title: "Python : async/await"
description: "Ma√Ætrisez la programmation asynchrone en Python pour cr√©er des applications performantes et r√©actives."
tags: [Python, Async, Asyncio, Performance, FastAPI, DevOps]
---

La programmation asynchrone est devenue essentielle pour cr√©er des applications Python performantes, notamment pour les APIs, les web scrapers, ou les applications traitant de nombreuses op√©rations I/O. Dans cet article, nous explorerons en profondeur `async`/`await` et `asyncio`, avec des cas d'usage pratiques notamment avec FastAPI. üöÄ

<!--truncate-->

## Comprendre la programmation asynchrone ü§î

### Le probl√®me : l'attente inutile

Dans un programme synchrone classique, chaque op√©ration attend la fin de la pr√©c√©dente, m√™me si elle ne fait rien d'utile pendant ce temps. C'est comme faire la queue au supermarch√© : si la caissi√®re attend que le client pr√©c√©dent range ses courses dans son sac, tout le monde attend inutilement.

**Exemple concret :** Imaginez une application qui doit r√©cup√©rer des donn√©es depuis 3 APIs diff√©rentes. En mode synchrone, le programme attend la r√©ponse de l'API 1 (2 secondes), puis attend l'API 2 (2 secondes), puis l'API 3 (2 secondes) = **6 secondes au total**.

### La solution : l'asynchrone

La programmation asynchrone permet de ne pas rester bloqu√© pendant les op√©rations d'attente (I/O). Pendant qu'une requ√™te HTTP est en cours, le programme peut lancer d'autres requ√™tes ou effectuer d'autres t√¢ches.

**Avec l'asynchrone :** Les 3 requ√™tes sont lanc√©es simultan√©ment, et le programme attend seulement le temps de la plus longue = **2 secondes au total**.

```python
import asyncio

async def faire_requete(url):
    await asyncio.sleep(2)  # Simule une requ√™te HTTP
    return f"Donn√©es de {url}"

async def main():
    # Les 3 requ√™tes s'ex√©cutent en parall√®le
    resultats = await asyncio.gather(
        faire_requete("api.example.com/1"),
        faire_requete("api.example.com/2"),
        faire_requete("api.example.com/3")
    )
    return resultats

asyncio.run(main())
```

### Quand utiliser l'asynchrone ?

L'asynchrone est efficace uniquement pour les op√©rations **I/O-bound** (limit√©es par les entr√©es/sorties), pas pour les calculs **CPU-bound**.

‚úÖ **Bon pour (I/O-bound) :**
- Requ√™tes HTTP/API : attente r√©seau
- Op√©rations de base de donn√©es : attente disque/r√©seau
- Lecture/√©criture de fichiers : attente disque
- WebSockets : attente de messages

‚ùå **Pas adapt√© pour (CPU-bound) :**
- Calculs math√©matiques complexes
- Traitement d'images/vid√©os
- Compression de donn√©es
- Pour ces cas, utiliser `multiprocessing` ou `threading`

## Les bases d'async/await üìö

### Les coroutines : des fonctions "pausables"

Une **coroutine** est une fonction sp√©ciale qui peut √™tre suspendue et reprise. Elle se d√©clare avec `async def` au lieu de `def`.

**Concept cl√© :** Une coroutine ne s'ex√©cute pas imm√©diatement quand on l'appelle. Elle retourne un objet "coroutine" qui doit √™tre `await`√© pour s'ex√©cuter r√©ellement.

```python
async def fonction_async():
    return "Hello"

# ‚ùå Ceci ne fait RIEN, retourne juste un objet coroutine
resultat = fonction_async()

# ‚úÖ Pour ex√©cuter, il faut await dans un contexte async
async def main():
    resultat = await fonction_async()  # Maintenant √ßa s'ex√©cute
    print(resultat)

asyncio.run(main())  # Point d'entr√©e pour d√©marrer l'async
```

### Le mot-cl√© `await` : point de suspension

`await` signifie "attends que cette op√©ration se termine, mais pendant ce temps, laisse d'autres t√¢ches s'ex√©cuter".

**Analogie :** C'est comme dire "je mets cette t√¢che en pause, fais autre chose en attendant, et reviens me voir quand c'est pr√™t".

```python
async def operation_longue():
    print("D√©but")
    await asyncio.sleep(2)  # "Pause ici pendant 2s, fais autre chose"
    print("Fin")
    return "Termin√©"
```

### Ex√©cuter plusieurs coroutines en parall√®le

**Le probl√®me :** Comment lancer plusieurs t√¢ches asynchrones en m√™me temps ?

**Solution 1 : `asyncio.gather()`** - Lance tout en parall√®le et attend tous les r√©sultats

```python
async def tache(nom, duree):
    await asyncio.sleep(duree)
    return f"{nom} termin√©e"

async def main():
    # Les 3 t√¢ches d√©marrent en m√™me temps
    resultats = await asyncio.gather(
        tache("T√¢che 1", 2),
        tache("T√¢che 2", 1),
        tache("T√¢che 3", 3)
    )
    # Attend que TOUTES soient finies
    print(resultats)  # ['T√¢che 1 termin√©e', 'T√¢che 2 termin√©e', 'T√¢che 3 termin√©e']
```

**Solution 2 : `asyncio.create_task()`** - Plus de contr√¥le individuel

```python
async def main():
    # D√©marre la t√¢che imm√©diatement en arri√®re-plan
    task = asyncio.create_task(tache("A", 1))

    # Fait autre chose...
    print("La t√¢che tourne en arri√®re-plan")

    # Attend le r√©sultat quand n√©cessaire
    resultat = await task
```

## asyncio : fonctionnalit√©s essentielles üõ†Ô∏è

### L'Event Loop : le chef d'orchestre

L'**event loop** (boucle d'√©v√©nements) est le moteur qui g√®re l'ex√©cution de toutes les coroutines. C'est lui qui d√©cide quelle t√¢che ex√©cuter et quand.

**Analogie :** C'est comme un chef d'orchestre qui coordonne tous les musiciens (coroutines). Quand un musicien doit faire une pause (await), le chef donne la parole √† un autre.

```python
async def hello():
    await asyncio.sleep(1)
    print("World")

# asyncio.run() cr√©e l'event loop, ex√©cute la coroutine, puis nettoie
asyncio.run(hello())
```

**Point important :** `asyncio.run()` est le point d'entr√©e principal. C'est lui qui d√©marre l'event loop et permet √† tout le syst√®me asynchrone de fonctionner.

### Gestion des erreurs : ne pas tout casser

**Le probl√®me :** Si une t√¢che √©choue avec `gather()`, par d√©faut toutes les autres sont annul√©es.

**La solution :** `return_exceptions=True` capture les erreurs comme des r√©sultats normaux.

```python
# Sans return_exceptions : si operation_risquee(2) √©choue, tout s'arr√™te
resultats = await asyncio.gather(
    operation_risquee(1),  # R√©ussit
    operation_risquee(2),  # √âchoue
    operation_risquee(3),  # Ne s'ex√©cute jamais
)

# Avec return_exceptions : toutes s'ex√©cutent, les erreurs sont dans les r√©sultats
resultats = await asyncio.gather(
    operation_risquee(1),
    operation_risquee(2),
    operation_risquee(3),
    return_exceptions=True  # Les exceptions sont retourn√©es comme r√©sultats
)
# resultats = ["Succ√®s 1", Exception(...), "Succ√®s 3"]
```

### Timeouts : limiter le temps d'attente

**Utilit√© :** √âviter d'attendre ind√©finiment une op√©ration qui ne r√©pond plus.

```python
try:
    # Attend maximum 3 secondes
    resultat = await asyncio.wait_for(operation_longue(), timeout=3.0)
except asyncio.TimeoutError:
    print("L'op√©ration a pris trop de temps !")
```

## Requ√™tes HTTP asynchrones üåê

### Le cas d'usage parfait pour l'asynchrone

Les requ√™tes HTTP sont le meilleur exemple d'op√©ration I/O-bound : le programme passe la majorit√© du temps √† attendre la r√©ponse du serveur, sans rien faire.

**Avantage de l'async :** Pendant qu'une requ√™te attend la r√©ponse, on peut en lancer d'autres. R√©sultat : 10 requ√™tes prennent le temps d'une seule !

### Avec httpx : le client HTTP asynchrone

`httpx` est l'√©quivalent moderne et asynchrone de `requests`.

```python
import httpx
import asyncio

async def fetch_users(usernames: list[str]) -> list[dict]:
    # AsyncClient g√®re les connexions de mani√®re asynchrone
    async with httpx.AsyncClient() as client:
        # Cr√©e une liste de coroutines (pas encore ex√©cut√©es)
        tasks = [
            client.get(f"https://api.github.com/users/{username}")
            for username in usernames
        ]
        # Lance toutes les requ√™tes en parall√®le
        responses = await asyncio.gather(*tasks)
        return [response.json() for response in responses]

# 10 utilisateurs r√©cup√©r√©s en parall√®le = temps d'une seule requ√™te
users = await fetch_users(["python", "microsoft", "google", "facebook", "apple"])
```

**Gain de performance :** Sans async, 10 requ√™tes de 200ms = 2 secondes. Avec async = 200ms !

## Int√©gration avec FastAPI üöÄ

### Pourquoi FastAPI et async sont faits l'un pour l'autre

FastAPI est con√ßu d√®s le d√©part pour l'asynchrone. Une API web est l'exemple parfait d'application I/O-bound : la plupart du temps est pass√© √† attendre des bases de donn√©es, des APIs externes, ou des fichiers.

**Avantage :** Avec async, un serveur FastAPI peut g√©rer des milliers de requ√™tes simultan√©es sans cr√©er de threads, simplement en utilisant l'event loop.

### Routes asynchrones

D√©clarer une route avec `async def` permet √† FastAPI de g√©rer plusieurs requ√™tes en parall√®le sans blocage.

```python
from fastapi import FastAPI
import httpx

app = FastAPI()

@app.get("/users/{username}")
async def get_user(username: str):
    # Pendant que cette requ√™te attend la r√©ponse de GitHub,
    # FastAPI peut traiter d'autres requ√™tes entrantes
    async with httpx.AsyncClient() as client:
        response = await client.get(f"https://api.github.com/users/{username}")
        return response.json()
```

**Sans async :** Chaque requ√™te bloque le serveur pendant l'appel √† GitHub (100-200ms). Avec async : des centaines de requ√™tes peuvent attendre en parall√®le.

### Base de donn√©es asynchrone avec SQLAlchemy

Les requ√™tes SQL sont des op√©rations I/O qui b√©n√©ficient √©norm√©ment de l'async.

```python
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy import select

# asyncpg est le driver PostgreSQL asynchrone
engine = create_async_engine("postgresql+asyncpg://user:pass@localhost/db")

@app.get("/users")
async def get_users(db: AsyncSession = Depends(get_db)):
    # Requ√™te SQL non-bloquante
    result = await db.execute(select(User))
    return result.scalars().all()
```

**Gain :** Pendant qu'une requ√™te SQL s'ex√©cute sur la DB, FastAPI peut traiter d'autres endpoints.

### Cache Redis asynchrone

Redis est souvent utilis√© comme cache pour acc√©l√©rer les r√©ponses. L'async permet de ne pas bloquer pendant les acc√®s Redis.

```python
import aioredis

@app.get("/users/{user_id}")
async def get_user_cached(user_id: int):
    # V√©rifie le cache (op√©ration r√©seau)
    cached = await redis.get(f"user:{user_id}")
    if cached:
        return json.loads(cached)

    # R√©cup√®re depuis la DB si pas en cache
    user = await fetch_user_from_db(user_id)

    # Met en cache pour 1h
    await redis.setex(f"user:{user_id}", 3600, json.dumps(user))
    return user
```

**Architecture typique :** API FastAPI ‚Üí Cache Redis ‚Üí Base de donn√©es PostgreSQL, le tout en asynchrone bout en bout.

## Patterns avanc√©s üéØ

### Limiter la concurrence avec Semaphore

**Le probl√®me :** Lancer 1000 requ√™tes HTTP en m√™me temps peut surcharger le serveur ou √©puiser les ressources (connexions, m√©moire).

**La solution :** Un **Semaphore** limite le nombre d'op√©rations simultan√©es. C'est comme un parking avec un nombre limit√© de places : si toutes les places sont prises, les nouvelles voitures doivent attendre qu'une place se lib√®re.

```python
from asyncio import Semaphore

async def operation(numero: int, semaphore: Semaphore):
    # Attend qu'une "place" soit disponible
    async with semaphore:
        # Maximum 3 op√©rations ici en m√™me temps
        await asyncio.sleep(2)
        return numero

async def main():
    semaphore = Semaphore(3)  # Maximum 3 op√©rations simultan√©es
    # Lance 10 op√©rations, mais seulement 3 √† la fois
    tasks = [operation(i, semaphore) for i in range(10)]
    resultats = await asyncio.gather(*tasks)
```

**R√©sultat :** 10 op√©rations s'ex√©cutent par vagues de 3, au lieu de toutes en m√™me temps.

### Retry avec backoff exponentiel

**Le probl√®me :** Une API temporairement indisponible ou un timeout r√©seau ne doit pas faire √©chouer toute l'op√©ration.

**La solution :** R√©essayer automatiquement avec des d√©lais croissants (1s, 2s, 4s, 8s...).

```python
async def retry_with_backoff(coro, max_retries=3, initial_delay=1.0, backoff_factor=2.0):
    delay = initial_delay
    for attempt in range(max_retries):
        try:
            return await coro()
        except Exception as e:
            if attempt == max_retries - 1:
                raise  # Dernier essai, on abandonne
            await asyncio.sleep(delay)  # Attente avant r√©essai
            delay *= backoff_factor  # Double le d√©lai : 1s, 2s, 4s...

# Utilisation
resultat = await retry_with_backoff(lambda: fetch_data("api.com"))
```

**Avantage :** R√©silience face aux erreurs temporaires sans surcharger le serveur avec des r√©essais trop fr√©quents.

### Context Manager asynchrone

**Utilit√© :** G√©rer automatiquement l'ouverture et la fermeture de ressources asynchrones (connexions DB, clients HTTP, fichiers...).

```python
class AsyncResource:
    async def __aenter__(self):
        # Initialisation (ex: ouvrir connexion DB)
        await self.connect()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        # Nettoyage automatique (ex: fermer connexion)
        await self.disconnect()

# Le nettoyage est garanti, m√™me en cas d'erreur
async with AsyncResource() as resource:
    await resource.operation()
```

## Bonnes pratiques üêõ

### Erreurs courantes √† √©viter

#### 1. Oublier le `await`

**Erreur fr√©quente :** Appeler une coroutine sans `await` ne fait rien, elle ne s'ex√©cute pas !

```python
# ‚ùå Mauvais : la fonction ne s'ex√©cute jamais
result = async_function()  # Retourne un objet coroutine non ex√©cut√©
print(result)  # <coroutine object async_function at 0x...>

# ‚úÖ Bon : la fonction s'ex√©cute vraiment
result = await async_function()
print(result)  # R√©sultat attendu
```

#### 2. Bloquer l'event loop

**Le probl√®me le plus grave :** Utiliser des fonctions bloquantes (`time.sleep`, `requests.get`, op√©rations CPU lourdes) dans une coroutine paralyse tout le syst√®me asynchrone.

```python
# ‚ùå CATASTROPHIQUE : bloque TOUT pendant 10 secondes
async def bad():
    time.sleep(10)  # Aucune autre coroutine ne peut s'ex√©cuter !
    return "Done"

# ‚úÖ Bon : suspend seulement cette coroutine
async def good():
    await asyncio.sleep(10)  # Les autres coroutines continuent
    return "Done"
```

**R√®gle d'or :** Dans une fonction `async`, toutes les op√©rations I/O doivent √™tre async (avec `await`).

#### 3. N√©gliger la gestion des ressources

**Probl√®me :** Les connexions DB, HTTP clients, fichiers doivent √™tre ferm√©s proprement.

```python
# ‚ùå Risque de fuite de connexions
async def bad():
    client = httpx.AsyncClient()
    response = await client.get(url)
    # Oubli de fermer le client !

# ‚úÖ Bon : fermeture automatique
async def good():
    async with httpx.AsyncClient() as client:
        response = await client.get(url)
        # Client ferm√© automatiquement, m√™me en cas d'erreur
```

### Mode debug : d√©tecter les probl√®mes

Le mode debug d'asyncio d√©tecte automatiquement les erreurs courantes (coroutines non await√©s, event loop bloqu√© trop longtemps...).

```python
# Active les warnings d√©taill√©s
asyncio.run(main(), debug=True)

# Affiche un warning si une coroutine met plus de 100ms sans yield
```

**Utile pendant le d√©veloppement** pour rep√©rer les op√©rations bloquantes accidentelles.

## Conclusion üéØ

La programmation asynchrone en Python avec `async`/`await` et `asyncio` est essentielle pour cr√©er des applications performantes et r√©actives. Elle brille particuli√®rement avec FastAPI pour les APIs modernes.

Points cl√©s √† retenir :

- **async/await** : syntaxe simple pour la concurrence
- **asyncio** : biblioth√®que standard puissante
- **I/O-bound** : parfait pour les op√©rations r√©seau/disque
- **FastAPI** : framework id√©al pour l'async
- **Patterns** : queue, semaphore, retry, etc.

Ces connaissances permettent de cr√©er des applications Python hautement performantes.

## Ressources utiles üìö

- [Documentation asyncio](https://docs.python.org/3/library/asyncio.html)
- [Real Python - Async IO](https://realpython.com/async-io-python/)
- [FastAPI Async](https://fastapi.tiangolo.com/async/)
- [aiohttp Documentation](https://docs.aiohttp.org/)
